[
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "aiofiles",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "aiofiles",
        "description": "aiofiles",
        "detail": "aiofiles",
        "documentation": {}
    },
    {
        "label": "FastAPI",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "File",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "Form",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "HTTPException",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "Request",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "Response",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "UploadFile",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "Body",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "Query",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "RequestValidationError",
        "importPath": "fastapi.exceptions",
        "description": "fastapi.exceptions",
        "isExtraImport": true,
        "detail": "fastapi.exceptions",
        "documentation": {}
    },
    {
        "label": "JSONResponse",
        "importPath": "fastapi.responses",
        "description": "fastapi.responses",
        "isExtraImport": true,
        "detail": "fastapi.responses",
        "documentation": {}
    },
    {
        "label": "StreamingResponse",
        "importPath": "fastapi.responses",
        "description": "fastapi.responses",
        "isExtraImport": true,
        "detail": "fastapi.responses",
        "documentation": {}
    },
    {
        "label": "CORSMiddleware",
        "importPath": "fastapi.middleware.cors",
        "description": "fastapi.middleware.cors",
        "isExtraImport": true,
        "detail": "fastapi.middleware.cors",
        "documentation": {}
    },
    {
        "label": "HTTPException",
        "importPath": "starlette.exceptions",
        "description": "starlette.exceptions",
        "isExtraImport": true,
        "detail": "starlette.exceptions",
        "documentation": {}
    },
    {
        "label": "contextlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "contextlib",
        "description": "contextlib",
        "detail": "contextlib",
        "documentation": {}
    },
    {
        "label": "asynccontextmanager",
        "importPath": "contextlib",
        "description": "contextlib",
        "isExtraImport": true,
        "detail": "contextlib",
        "documentation": {}
    },
    {
        "label": "contextmanager",
        "importPath": "contextlib",
        "description": "contextlib",
        "isExtraImport": true,
        "detail": "contextlib",
        "documentation": {}
    },
    {
        "label": "contextmanager",
        "importPath": "contextlib",
        "description": "contextlib",
        "isExtraImport": true,
        "detail": "contextlib",
        "documentation": {}
    },
    {
        "label": "BaseModel",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "Field",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "BaseModel",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "log",
        "importPath": "mcd.logger",
        "description": "mcd.logger",
        "isExtraImport": true,
        "detail": "mcd.logger",
        "documentation": {}
    },
    {
        "label": "log",
        "importPath": "mcd.logger",
        "description": "mcd.logger",
        "isExtraImport": true,
        "detail": "mcd.logger",
        "documentation": {}
    },
    {
        "label": "log",
        "importPath": "mcd.logger",
        "description": "mcd.logger",
        "isExtraImport": true,
        "detail": "mcd.logger",
        "documentation": {}
    },
    {
        "label": "mcd.video",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "mcd.video",
        "description": "mcd.video",
        "detail": "mcd.video",
        "documentation": {}
    },
    {
        "label": "get_cameras",
        "importPath": "mcd.camera",
        "description": "mcd.camera",
        "isExtraImport": true,
        "detail": "mcd.camera",
        "documentation": {}
    },
    {
        "label": "mcd.conf",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "mcd.conf",
        "description": "mcd.conf",
        "detail": "mcd.conf",
        "documentation": {}
    },
    {
        "label": "re",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "re",
        "description": "re",
        "detail": "re",
        "documentation": {}
    },
    {
        "label": "shutil",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "shutil",
        "description": "shutil",
        "detail": "shutil",
        "documentation": {}
    },
    {
        "label": "subprocess",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "subprocess",
        "description": "subprocess",
        "detail": "subprocess",
        "documentation": {}
    },
    {
        "label": "BeautifulSoup",
        "importPath": "bs4",
        "description": "bs4",
        "isExtraImport": true,
        "detail": "bs4",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "OrderedDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "namedtuple",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "OrderedDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "deque",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "abc",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "argparse",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "argparse",
        "description": "argparse",
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "time",
        "importPath": "time",
        "description": "time",
        "isExtraImport": true,
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "time",
        "importPath": "time",
        "description": "time",
        "isExtraImport": true,
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Type",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Type",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Type",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Generator",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "urlparse",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "urlparse",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "urlsplit",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "cv2",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "cv2",
        "description": "cv2",
        "detail": "cv2",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "torch",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch",
        "description": "torch",
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "distributed",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "optim",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "AutoModel",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "AutoProcessor",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "YOLO",
        "importPath": "ultralytics",
        "description": "ultralytics",
        "isExtraImport": true,
        "detail": "ultralytics",
        "documentation": {}
    },
    {
        "label": "YOLO",
        "importPath": "ultralytics",
        "description": "ultralytics",
        "isExtraImport": true,
        "detail": "ultralytics",
        "documentation": {}
    },
    {
        "label": "YOLO",
        "importPath": "ultralytics",
        "description": "ultralytics",
        "isExtraImport": true,
        "detail": "ultralytics",
        "documentation": {}
    },
    {
        "label": "YOLO",
        "importPath": "ultralytics",
        "description": "ultralytics",
        "isExtraImport": true,
        "detail": "ultralytics",
        "documentation": {}
    },
    {
        "label": "YOLO",
        "importPath": "ultralytics",
        "description": "ultralytics",
        "isExtraImport": true,
        "detail": "ultralytics",
        "documentation": {}
    },
    {
        "label": "YOLO",
        "importPath": "ultralytics",
        "description": "ultralytics",
        "isExtraImport": true,
        "detail": "ultralytics",
        "documentation": {}
    },
    {
        "label": "Explorer",
        "importPath": "ultralytics",
        "description": "ultralytics",
        "isExtraImport": true,
        "detail": "ultralytics",
        "documentation": {}
    },
    {
        "label": "YOLO",
        "importPath": "ultralytics",
        "description": "ultralytics",
        "isExtraImport": true,
        "detail": "ultralytics",
        "documentation": {}
    },
    {
        "label": "YOLO",
        "importPath": "ultralytics",
        "description": "ultralytics",
        "isExtraImport": true,
        "detail": "ultralytics",
        "documentation": {}
    },
    {
        "label": "download",
        "importPath": "ultralytics",
        "description": "ultralytics",
        "isExtraImport": true,
        "detail": "ultralytics",
        "documentation": {}
    },
    {
        "label": "RTDETR",
        "importPath": "ultralytics",
        "description": "ultralytics",
        "isExtraImport": true,
        "detail": "ultralytics",
        "documentation": {}
    },
    {
        "label": "YOLO",
        "importPath": "ultralytics",
        "description": "ultralytics",
        "isExtraImport": true,
        "detail": "ultralytics",
        "documentation": {}
    },
    {
        "label": "YOLO",
        "importPath": "ultralytics",
        "description": "ultralytics",
        "isExtraImport": true,
        "detail": "ultralytics",
        "documentation": {}
    },
    {
        "label": "solutions",
        "importPath": "ultralytics",
        "description": "ultralytics",
        "isExtraImport": true,
        "detail": "ultralytics",
        "documentation": {}
    },
    {
        "label": "Explorer",
        "importPath": "ultralytics",
        "description": "ultralytics",
        "isExtraImport": true,
        "detail": "ultralytics",
        "documentation": {}
    },
    {
        "label": "SAM",
        "importPath": "ultralytics",
        "description": "ultralytics",
        "isExtraImport": true,
        "detail": "ultralytics",
        "documentation": {}
    },
    {
        "label": "YOLO",
        "importPath": "ultralytics",
        "description": "ultralytics",
        "isExtraImport": true,
        "detail": "ultralytics",
        "documentation": {}
    },
    {
        "label": "YOLO",
        "importPath": "ultralytics",
        "description": "ultralytics",
        "isExtraImport": true,
        "detail": "ultralytics",
        "documentation": {}
    },
    {
        "label": "YOLOWorld",
        "importPath": "ultralytics",
        "description": "ultralytics",
        "isExtraImport": true,
        "detail": "ultralytics",
        "documentation": {}
    },
    {
        "label": "get_best_youtube_url",
        "importPath": "ultralytics.data.loaders",
        "description": "ultralytics.data.loaders",
        "isExtraImport": true,
        "detail": "ultralytics.data.loaders",
        "documentation": {}
    },
    {
        "label": "LOADERS",
        "importPath": "ultralytics.data.loaders",
        "description": "ultralytics.data.loaders",
        "isExtraImport": true,
        "detail": "ultralytics.data.loaders",
        "documentation": {}
    },
    {
        "label": "LoadImagesAndVideos",
        "importPath": "ultralytics.data.loaders",
        "description": "ultralytics.data.loaders",
        "isExtraImport": true,
        "detail": "ultralytics.data.loaders",
        "documentation": {}
    },
    {
        "label": "LoadPilAndNumpy",
        "importPath": "ultralytics.data.loaders",
        "description": "ultralytics.data.loaders",
        "isExtraImport": true,
        "detail": "ultralytics.data.loaders",
        "documentation": {}
    },
    {
        "label": "LoadScreenshots",
        "importPath": "ultralytics.data.loaders",
        "description": "ultralytics.data.loaders",
        "isExtraImport": true,
        "detail": "ultralytics.data.loaders",
        "documentation": {}
    },
    {
        "label": "LoadStreams",
        "importPath": "ultralytics.data.loaders",
        "description": "ultralytics.data.loaders",
        "isExtraImport": true,
        "detail": "ultralytics.data.loaders",
        "documentation": {}
    },
    {
        "label": "LoadTensor",
        "importPath": "ultralytics.data.loaders",
        "description": "ultralytics.data.loaders",
        "isExtraImport": true,
        "detail": "ultralytics.data.loaders",
        "documentation": {}
    },
    {
        "label": "SourceTypes",
        "importPath": "ultralytics.data.loaders",
        "description": "ultralytics.data.loaders",
        "isExtraImport": true,
        "detail": "ultralytics.data.loaders",
        "documentation": {}
    },
    {
        "label": "autocast_list",
        "importPath": "ultralytics.data.loaders",
        "description": "ultralytics.data.loaders",
        "isExtraImport": true,
        "detail": "ultralytics.data.loaders",
        "documentation": {}
    },
    {
        "label": "Annotator",
        "importPath": "ultralytics.utils.plotting",
        "description": "ultralytics.utils.plotting",
        "isExtraImport": true,
        "detail": "ultralytics.utils.plotting",
        "documentation": {}
    },
    {
        "label": "Annotator",
        "importPath": "ultralytics.utils.plotting",
        "description": "ultralytics.utils.plotting",
        "isExtraImport": true,
        "detail": "ultralytics.utils.plotting",
        "documentation": {}
    },
    {
        "label": "colors",
        "importPath": "ultralytics.utils.plotting",
        "description": "ultralytics.utils.plotting",
        "isExtraImport": true,
        "detail": "ultralytics.utils.plotting",
        "documentation": {}
    },
    {
        "label": "Colors",
        "importPath": "ultralytics.utils.plotting",
        "description": "ultralytics.utils.plotting",
        "isExtraImport": true,
        "detail": "ultralytics.utils.plotting",
        "documentation": {}
    },
    {
        "label": "Annotator",
        "importPath": "ultralytics.utils.plotting",
        "description": "ultralytics.utils.plotting",
        "isExtraImport": true,
        "detail": "ultralytics.utils.plotting",
        "documentation": {}
    },
    {
        "label": "plot_images",
        "importPath": "ultralytics.utils.plotting",
        "description": "ultralytics.utils.plotting",
        "isExtraImport": true,
        "detail": "ultralytics.utils.plotting",
        "documentation": {}
    },
    {
        "label": "Annotator",
        "importPath": "ultralytics.utils.plotting",
        "description": "ultralytics.utils.plotting",
        "isExtraImport": true,
        "detail": "ultralytics.utils.plotting",
        "documentation": {}
    },
    {
        "label": "colors",
        "importPath": "ultralytics.utils.plotting",
        "description": "ultralytics.utils.plotting",
        "isExtraImport": true,
        "detail": "ultralytics.utils.plotting",
        "documentation": {}
    },
    {
        "label": "save_one_box",
        "importPath": "ultralytics.utils.plotting",
        "description": "ultralytics.utils.plotting",
        "isExtraImport": true,
        "detail": "ultralytics.utils.plotting",
        "documentation": {}
    },
    {
        "label": "plot_tune_results",
        "importPath": "ultralytics.utils.plotting",
        "description": "ultralytics.utils.plotting",
        "isExtraImport": true,
        "detail": "ultralytics.utils.plotting",
        "documentation": {}
    },
    {
        "label": "plot_images",
        "importPath": "ultralytics.utils.plotting",
        "description": "ultralytics.utils.plotting",
        "isExtraImport": true,
        "detail": "ultralytics.utils.plotting",
        "documentation": {}
    },
    {
        "label": "plot_results",
        "importPath": "ultralytics.utils.plotting",
        "description": "ultralytics.utils.plotting",
        "isExtraImport": true,
        "detail": "ultralytics.utils.plotting",
        "documentation": {}
    },
    {
        "label": "plot_images",
        "importPath": "ultralytics.utils.plotting",
        "description": "ultralytics.utils.plotting",
        "isExtraImport": true,
        "detail": "ultralytics.utils.plotting",
        "documentation": {}
    },
    {
        "label": "plot_images",
        "importPath": "ultralytics.utils.plotting",
        "description": "ultralytics.utils.plotting",
        "isExtraImport": true,
        "detail": "ultralytics.utils.plotting",
        "documentation": {}
    },
    {
        "label": "plot_labels",
        "importPath": "ultralytics.utils.plotting",
        "description": "ultralytics.utils.plotting",
        "isExtraImport": true,
        "detail": "ultralytics.utils.plotting",
        "documentation": {}
    },
    {
        "label": "plot_results",
        "importPath": "ultralytics.utils.plotting",
        "description": "ultralytics.utils.plotting",
        "isExtraImport": true,
        "detail": "ultralytics.utils.plotting",
        "documentation": {}
    },
    {
        "label": "output_to_target",
        "importPath": "ultralytics.utils.plotting",
        "description": "ultralytics.utils.plotting",
        "isExtraImport": true,
        "detail": "ultralytics.utils.plotting",
        "documentation": {}
    },
    {
        "label": "plot_images",
        "importPath": "ultralytics.utils.plotting",
        "description": "ultralytics.utils.plotting",
        "isExtraImport": true,
        "detail": "ultralytics.utils.plotting",
        "documentation": {}
    },
    {
        "label": "output_to_rotated_target",
        "importPath": "ultralytics.utils.plotting",
        "description": "ultralytics.utils.plotting",
        "isExtraImport": true,
        "detail": "ultralytics.utils.plotting",
        "documentation": {}
    },
    {
        "label": "plot_images",
        "importPath": "ultralytics.utils.plotting",
        "description": "ultralytics.utils.plotting",
        "isExtraImport": true,
        "detail": "ultralytics.utils.plotting",
        "documentation": {}
    },
    {
        "label": "plot_images",
        "importPath": "ultralytics.utils.plotting",
        "description": "ultralytics.utils.plotting",
        "isExtraImport": true,
        "detail": "ultralytics.utils.plotting",
        "documentation": {}
    },
    {
        "label": "plot_results",
        "importPath": "ultralytics.utils.plotting",
        "description": "ultralytics.utils.plotting",
        "isExtraImport": true,
        "detail": "ultralytics.utils.plotting",
        "documentation": {}
    },
    {
        "label": "output_to_target",
        "importPath": "ultralytics.utils.plotting",
        "description": "ultralytics.utils.plotting",
        "isExtraImport": true,
        "detail": "ultralytics.utils.plotting",
        "documentation": {}
    },
    {
        "label": "plot_images",
        "importPath": "ultralytics.utils.plotting",
        "description": "ultralytics.utils.plotting",
        "isExtraImport": true,
        "detail": "ultralytics.utils.plotting",
        "documentation": {}
    },
    {
        "label": "plot_images",
        "importPath": "ultralytics.utils.plotting",
        "description": "ultralytics.utils.plotting",
        "isExtraImport": true,
        "detail": "ultralytics.utils.plotting",
        "documentation": {}
    },
    {
        "label": "plot_results",
        "importPath": "ultralytics.utils.plotting",
        "description": "ultralytics.utils.plotting",
        "isExtraImport": true,
        "detail": "ultralytics.utils.plotting",
        "documentation": {}
    },
    {
        "label": "output_to_target",
        "importPath": "ultralytics.utils.plotting",
        "description": "ultralytics.utils.plotting",
        "isExtraImport": true,
        "detail": "ultralytics.utils.plotting",
        "documentation": {}
    },
    {
        "label": "plot_images",
        "importPath": "ultralytics.utils.plotting",
        "description": "ultralytics.utils.plotting",
        "isExtraImport": true,
        "detail": "ultralytics.utils.plotting",
        "documentation": {}
    },
    {
        "label": "feature_visualization",
        "importPath": "ultralytics.utils.plotting",
        "description": "ultralytics.utils.plotting",
        "isExtraImport": true,
        "detail": "ultralytics.utils.plotting",
        "documentation": {}
    },
    {
        "label": "Annotator",
        "importPath": "ultralytics.utils.plotting",
        "description": "ultralytics.utils.plotting",
        "isExtraImport": true,
        "detail": "ultralytics.utils.plotting",
        "documentation": {}
    },
    {
        "label": "Annotator",
        "importPath": "ultralytics.utils.plotting",
        "description": "ultralytics.utils.plotting",
        "isExtraImport": true,
        "detail": "ultralytics.utils.plotting",
        "documentation": {}
    },
    {
        "label": "colors",
        "importPath": "ultralytics.utils.plotting",
        "description": "ultralytics.utils.plotting",
        "isExtraImport": true,
        "detail": "ultralytics.utils.plotting",
        "documentation": {}
    },
    {
        "label": "Annotator",
        "importPath": "ultralytics.utils.plotting",
        "description": "ultralytics.utils.plotting",
        "isExtraImport": true,
        "detail": "ultralytics.utils.plotting",
        "documentation": {}
    },
    {
        "label": "Annotator",
        "importPath": "ultralytics.utils.plotting",
        "description": "ultralytics.utils.plotting",
        "isExtraImport": true,
        "detail": "ultralytics.utils.plotting",
        "documentation": {}
    },
    {
        "label": "colors",
        "importPath": "ultralytics.utils.plotting",
        "description": "ultralytics.utils.plotting",
        "isExtraImport": true,
        "detail": "ultralytics.utils.plotting",
        "documentation": {}
    },
    {
        "label": "Annotator",
        "importPath": "ultralytics.utils.plotting",
        "description": "ultralytics.utils.plotting",
        "isExtraImport": true,
        "detail": "ultralytics.utils.plotting",
        "documentation": {}
    },
    {
        "label": "Annotator",
        "importPath": "ultralytics.utils.plotting",
        "description": "ultralytics.utils.plotting",
        "isExtraImport": true,
        "detail": "ultralytics.utils.plotting",
        "documentation": {}
    },
    {
        "label": "colors",
        "importPath": "ultralytics.utils.plotting",
        "description": "ultralytics.utils.plotting",
        "isExtraImport": true,
        "detail": "ultralytics.utils.plotting",
        "documentation": {}
    },
    {
        "label": "Annotator",
        "importPath": "ultralytics.utils.plotting",
        "description": "ultralytics.utils.plotting",
        "isExtraImport": true,
        "detail": "ultralytics.utils.plotting",
        "documentation": {}
    },
    {
        "label": "colors",
        "importPath": "ultralytics.utils.plotting",
        "description": "ultralytics.utils.plotting",
        "isExtraImport": true,
        "detail": "ultralytics.utils.plotting",
        "documentation": {}
    },
    {
        "label": "select_device",
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "TORCH_1_9",
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "TORCH_1_13",
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "TORCH_1_9",
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "TORCHVISION_0_10",
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "TORCHVISION_0_11",
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "TORCHVISION_0_13",
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "TORCHVISION_0_18",
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "TORCH_1_13",
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "get_latest_opset",
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "select_device",
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "smart_inference_mode",
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "select_device",
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "smart_inference_mode",
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "smart_inference_mode",
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "EarlyStopping",
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "ModelEMA",
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "convert_optimizer_state_dict_to_fp16",
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "init_seeds",
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "one_cycle",
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "select_device",
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "strip_optimizer",
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "torch_distributed_zero_first",
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "de_parallel",
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "select_device",
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "smart_inference_mode",
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "model_info",
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "smart_inference_mode",
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "model_info",
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "select_device",
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "is_parallel",
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "strip_optimizer",
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "torch_distributed_zero_first",
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "de_parallel",
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "torch_distributed_zero_first",
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "de_parallel",
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "de_parallel",
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "fuse_conv_and_bn",
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "fuse_conv_and_bn",
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "fuse_deconv_and_bn",
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "initialize_weights",
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "intersect_dicts",
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "make_divisible",
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "model_info",
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "scale_img",
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "time_sync",
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "model_info_for_loggers",
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "profile",
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "select_device",
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "onnxruntime",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "onnxruntime",
        "description": "onnxruntime",
        "detail": "onnxruntime",
        "documentation": {}
    },
    {
        "label": "ASSETS",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "yaml_load",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "ASSETS",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "yaml_load",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "ASSETS",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "yaml_load",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "ASSETS",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "yaml_load",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "ASSETS",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "WEIGHTS_DIR",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "checks",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "ASSETS",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "WEIGHTS_DIR",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "ASSETS",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "DEFAULT_CFG",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "WEIGHTS_DIR",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "ASSETS",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "IS_RASPBERRYPI",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "LINUX",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "MACOS",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "WINDOWS",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "checks",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "DATASETS_DIR",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "SETTINGS",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "ASSETS",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "DEFAULT_CFG",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "DEFAULT_CFG_PATH",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "ONLINE",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "ROOT",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "WEIGHTS_DIR",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "WINDOWS",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "checks",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "ROOT",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "SETTINGS",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "USER_CONFIG_DIR",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "IterableSimpleNamespace",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "checks",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "SETTINGS",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "colorstr",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "DEFAULT_CFG",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "LOCAL_RANK",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "NUM_THREADS",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "TQDM",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "RANK",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "colorstr",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "TQDM",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "LOCAL_RANK",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "NUM_THREADS",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "TQDM",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "colorstr",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "IS_COLAB",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "IS_KAGGLE",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "ops",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "DATASETS_DIR",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "NUM_THREADS",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "ROOT",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "SETTINGS_YAML",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "TQDM",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "clean_url",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "colorstr",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "emojis",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "is_dir_writeable",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "yaml_load",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "yaml_save",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "ARM64",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "DEFAULT_CFG",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "IS_JETSON",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "LINUX",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "MACOS",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "PYTHON_VERSION",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "ROOT",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "WINDOWS",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "__version__",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "callbacks",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "colorstr",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "get_default_args",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "yaml_save",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "ARGV",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "ASSETS",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "DEFAULT_CFG_DICT",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "RANK",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "callbacks",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "checks",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "emojis",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "yaml_load",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "DEFAULT_CFG",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "MACOS",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "WINDOWS",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "callbacks",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "colorstr",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "ops",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "SimpleClass",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "ops",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "DEFAULT_CFG",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "RANK",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "TQDM",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "__version__",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "callbacks",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "clean_url",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "colorstr",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "emojis",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "yaml_save",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "DEFAULT_CFG",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "callbacks",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "colorstr",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "remove_colorstr",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "yaml_print",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "yaml_save",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "TQDM",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "callbacks",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "colorstr",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "emojis",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "IS_COLAB",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "SETTINGS",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "emojis",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "IS_COLAB",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "SETTINGS",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "__version__",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "checks",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "emojis",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "ARGV",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "ENVIRONMENT",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "IS_COLAB",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "IS_GIT_DIR",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "IS_PIP_PACKAGE",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "ONLINE",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "RANK",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "SETTINGS",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "TESTS_RUNNING",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "TQDM",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "TryExcept",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "__version__",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "colorstr",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "get_git_origin_url",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "TQDM",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "checks",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "ops",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "ops",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "ops",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "RANK",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "colorstr",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "colorstr",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "ops",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "DEFAULT_CFG",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "ops",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "DEFAULT_CFG",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "ops",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "DEFAULT_CFG",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "RANK",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "colorstr",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "ops",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "RANK",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "ops",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "DEFAULT_CFG",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "ops",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "DEFAULT_CFG",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "RANK",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "ops",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "DEFAULT_CFG",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "ops",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "DEFAULT_CFG",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "ops",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "DEFAULT_CFG",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "ops",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "DEFAULT_CFG",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "RANK",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "NUM_THREADS",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "ops",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "DEFAULT_CFG",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "RANK",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "checks",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "DEFAULT_CFG",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "ROOT",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "yaml_load",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "ARM64",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "IS_JETSON",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "IS_RASPBERRYPI",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "LINUX",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "ROOT",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "yaml_load",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "DEFAULT_CFG_DICT",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "DEFAULT_CFG_KEYS",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "colorstr",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "emojis",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "yaml_load",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "IterableSimpleNamespace",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "yaml_load",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "SETTINGS",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "TESTS_RUNNING",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "RANK",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "SETTINGS",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "TESTS_RUNNING",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "ops",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "SETTINGS",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "TESTS_RUNNING",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "checks",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "RANK",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "SETTINGS",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "RUNS_DIR",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "SETTINGS",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "TESTS_RUNNING",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "colorstr",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "SETTINGS",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "TESTS_RUNNING",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "SETTINGS",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "SETTINGS",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "TESTS_RUNNING",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "colorstr",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "SETTINGS",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "TESTS_RUNNING",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "DEFAULT_CFG",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "colorstr",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "ARM64",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "ASSETS",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "IS_JETSON",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "IS_RASPBERRYPI",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "LINUX",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "MACOS",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "TQDM",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "WEIGHTS_DIR",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "ASSETS",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "AUTOINSTALL",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "IS_COLAB",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "IS_JUPYTER",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "IS_KAGGLE",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "IS_PIP_PACKAGE",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "LINUX",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "ONLINE",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "PYTHON_VERSION",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "ROOT",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "TORCHVISION_VERSION",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "USER_CONFIG_DIR",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "Retry",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "SimpleNamespace",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "ThreadingLocked",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "TryExcept",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "clean_url",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "colorstr",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "downloads",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "emojis",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "is_github_action_running",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "url2file",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "TQDM",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "checks",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "clean_url",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "emojis",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "is_online",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "url2file",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "emojis",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "SimpleClass",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "TryExcept",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "plt_settings",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "TryExcept",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "ops",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "plt_settings",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "threaded",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "DEFAULT_CFG_DICT",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "DEFAULT_CFG_KEYS",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "NUM_THREADS",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "PYTHON_VERSION",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "TORCHVISION_VERSION",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "__version__",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "colorstr",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "DEFAULT_CFG",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "DEFAULT_CFG_DICT",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "NUM_THREADS",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "checks",
        "importPath": "ultralytics.utils",
        "description": "ultralytics.utils",
        "isExtraImport": true,
        "detail": "ultralytics.utils",
        "documentation": {}
    },
    {
        "label": "check_requirements",
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_yaml",
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_yaml",
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_yaml",
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_yaml",
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_requirements",
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_requirements",
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_requirements",
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_version",
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_file",
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_requirements",
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_requirements",
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_file",
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_font",
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "is_ascii",
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_imgsz",
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_is_path_safe",
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_requirements",
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_version",
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_imgsz",
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_imshow",
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_amp",
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_file",
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_imgsz",
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_model_file_from_stem",
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "print_args",
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_imgsz",
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_requirements",
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_requirements",
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_requirements",
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_requirements",
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_suffix",
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_version",
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_yaml",
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_requirements",
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_suffix",
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_yaml",
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_imshow",
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_imshow",
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_imshow",
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_requirements",
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_imshow",
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_requirements",
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_imshow",
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_requirements",
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_imshow",
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_requirements",
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_imshow",
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_requirements",
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_yaml",
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "IS_PYTHON_3_12",
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_requirements",
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_yolo",
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_font",
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_version",
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "is_ascii",
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_version",
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "cv2.dnn",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "cv2.dnn",
        "description": "cv2.dnn",
        "detail": "cv2.dnn",
        "documentation": {}
    },
    {
        "label": "interpreter",
        "importPath": "tflite_runtime",
        "description": "tflite_runtime",
        "isExtraImport": true,
        "detail": "tflite_runtime",
        "documentation": {}
    },
    {
        "label": "Polygon",
        "importPath": "shapely.geometry",
        "description": "shapely.geometry",
        "isExtraImport": true,
        "detail": "shapely.geometry",
        "documentation": {}
    },
    {
        "label": "Polygon",
        "importPath": "shapely.geometry",
        "description": "shapely.geometry",
        "isExtraImport": true,
        "detail": "shapely.geometry",
        "documentation": {}
    },
    {
        "label": "LineString",
        "importPath": "shapely.geometry",
        "description": "shapely.geometry",
        "isExtraImport": true,
        "detail": "shapely.geometry",
        "documentation": {}
    },
    {
        "label": "Point",
        "importPath": "shapely.geometry",
        "description": "shapely.geometry",
        "isExtraImport": true,
        "detail": "shapely.geometry",
        "documentation": {}
    },
    {
        "label": "Polygon",
        "importPath": "shapely.geometry",
        "description": "shapely.geometry",
        "isExtraImport": true,
        "detail": "shapely.geometry",
        "documentation": {}
    },
    {
        "label": "LineString",
        "importPath": "shapely.geometry",
        "description": "shapely.geometry",
        "isExtraImport": true,
        "detail": "shapely.geometry",
        "documentation": {}
    },
    {
        "label": "Point",
        "importPath": "shapely.geometry",
        "description": "shapely.geometry",
        "isExtraImport": true,
        "detail": "shapely.geometry",
        "documentation": {}
    },
    {
        "label": "Polygon",
        "importPath": "shapely.geometry",
        "description": "shapely.geometry",
        "isExtraImport": true,
        "detail": "shapely.geometry",
        "documentation": {}
    },
    {
        "label": "Point",
        "importPath": "shapely.geometry",
        "description": "shapely.geometry",
        "isExtraImport": true,
        "detail": "shapely.geometry",
        "documentation": {}
    },
    {
        "label": "Polygon",
        "importPath": "shapely.geometry",
        "description": "shapely.geometry",
        "isExtraImport": true,
        "detail": "shapely.geometry",
        "documentation": {}
    },
    {
        "label": "Point",
        "importPath": "shapely.geometry.point",
        "description": "shapely.geometry.point",
        "isExtraImport": true,
        "detail": "shapely.geometry.point",
        "documentation": {}
    },
    {
        "label": "increment_path",
        "importPath": "ultralytics.utils.files",
        "description": "ultralytics.utils.files",
        "isExtraImport": true,
        "detail": "ultralytics.utils.files",
        "documentation": {}
    },
    {
        "label": "increment_path",
        "importPath": "ultralytics.utils.files",
        "description": "ultralytics.utils.files",
        "isExtraImport": true,
        "detail": "ultralytics.utils.files",
        "documentation": {}
    },
    {
        "label": "increment_path",
        "importPath": "ultralytics.utils.files",
        "description": "ultralytics.utils.files",
        "isExtraImport": true,
        "detail": "ultralytics.utils.files",
        "documentation": {}
    },
    {
        "label": "file_size",
        "importPath": "ultralytics.utils.files",
        "description": "ultralytics.utils.files",
        "isExtraImport": true,
        "detail": "ultralytics.utils.files",
        "documentation": {}
    },
    {
        "label": "spaces_in_path",
        "importPath": "ultralytics.utils.files",
        "description": "ultralytics.utils.files",
        "isExtraImport": true,
        "detail": "ultralytics.utils.files",
        "documentation": {}
    },
    {
        "label": "increment_path",
        "importPath": "ultralytics.utils.files",
        "description": "ultralytics.utils.files",
        "isExtraImport": true,
        "detail": "ultralytics.utils.files",
        "documentation": {}
    },
    {
        "label": "get_latest_run",
        "importPath": "ultralytics.utils.files",
        "description": "ultralytics.utils.files",
        "isExtraImport": true,
        "detail": "ultralytics.utils.files",
        "documentation": {}
    },
    {
        "label": "file_size",
        "importPath": "ultralytics.utils.files",
        "description": "ultralytics.utils.files",
        "isExtraImport": true,
        "detail": "ultralytics.utils.files",
        "documentation": {}
    },
    {
        "label": "increment_path",
        "importPath": "ultralytics.utils.files",
        "description": "ultralytics.utils.files",
        "isExtraImport": true,
        "detail": "ultralytics.utils.files",
        "documentation": {}
    },
    {
        "label": "AutoDetectionModel",
        "importPath": "sahi",
        "description": "sahi",
        "isExtraImport": true,
        "detail": "sahi",
        "documentation": {}
    },
    {
        "label": "get_sliced_prediction",
        "importPath": "sahi.predict",
        "description": "sahi.predict",
        "isExtraImport": true,
        "detail": "sahi.predict",
        "documentation": {}
    },
    {
        "label": "download_yolov8s_model",
        "importPath": "sahi.utils.yolov8",
        "description": "sahi.utils.yolov8",
        "isExtraImport": true,
        "detail": "sahi.utils.yolov8",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "stringify",
        "importPath": "flatted",
        "description": "flatted",
        "isExtraImport": true,
        "detail": "flatted",
        "documentation": {}
    },
    {
        "label": "parse",
        "importPath": "flatted",
        "description": "flatted",
        "isExtraImport": true,
        "detail": "flatted",
        "documentation": {}
    },
    {
        "label": "platform",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "platform",
        "description": "platform",
        "detail": "platform",
        "documentation": {}
    },
    {
        "label": "Results",
        "importPath": "ultralytics.engine.results",
        "description": "ultralytics.engine.results",
        "isExtraImport": true,
        "detail": "ultralytics.engine.results",
        "documentation": {}
    },
    {
        "label": "Results",
        "importPath": "ultralytics.engine.results",
        "description": "ultralytics.engine.results",
        "isExtraImport": true,
        "detail": "ultralytics.engine.results",
        "documentation": {}
    },
    {
        "label": "Results",
        "importPath": "ultralytics.engine.results",
        "description": "ultralytics.engine.results",
        "isExtraImport": true,
        "detail": "ultralytics.engine.results",
        "documentation": {}
    },
    {
        "label": "Results",
        "importPath": "ultralytics.engine.results",
        "description": "ultralytics.engine.results",
        "isExtraImport": true,
        "detail": "ultralytics.engine.results",
        "documentation": {}
    },
    {
        "label": "Results",
        "importPath": "ultralytics.engine.results",
        "description": "ultralytics.engine.results",
        "isExtraImport": true,
        "detail": "ultralytics.engine.results",
        "documentation": {}
    },
    {
        "label": "Results",
        "importPath": "ultralytics.engine.results",
        "description": "ultralytics.engine.results",
        "isExtraImport": true,
        "detail": "ultralytics.engine.results",
        "documentation": {}
    },
    {
        "label": "Results",
        "importPath": "ultralytics.engine.results",
        "description": "ultralytics.engine.results",
        "isExtraImport": true,
        "detail": "ultralytics.engine.results",
        "documentation": {}
    },
    {
        "label": "Results",
        "importPath": "ultralytics.engine.results",
        "description": "ultralytics.engine.results",
        "isExtraImport": true,
        "detail": "ultralytics.engine.results",
        "documentation": {}
    },
    {
        "label": "Results",
        "importPath": "ultralytics.engine.results",
        "description": "ultralytics.engine.results",
        "isExtraImport": true,
        "detail": "ultralytics.engine.results",
        "documentation": {}
    },
    {
        "label": "Results",
        "importPath": "ultralytics.engine.results",
        "description": "ultralytics.engine.results",
        "isExtraImport": true,
        "detail": "ultralytics.engine.results",
        "documentation": {}
    },
    {
        "label": "copy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "copy",
        "description": "copy",
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "copy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "copy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "copy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "copy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "copy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "copy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "logging",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "logging",
        "description": "logging",
        "detail": "logging",
        "documentation": {}
    },
    {
        "label": "colorlog",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "colorlog",
        "description": "colorlog",
        "detail": "colorlog",
        "documentation": {}
    },
    {
        "label": "PersonResults",
        "importPath": "mcd.custom_result",
        "description": "mcd.custom_result",
        "isExtraImport": true,
        "detail": "mcd.custom_result",
        "documentation": {}
    },
    {
        "label": "os;os.makedirs(model_result_save_dir,exist_ok=True)",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os;os.makedirs(model_result_save_dir.exist_ok=True)",
        "description": "os;os.makedirs(model_result_save_dir.exist_ok=True)",
        "detail": "os;os.makedirs(model_result_save_dir.exist_ok=True)",
        "documentation": {}
    },
    {
        "label": "test_nn_modules_block",
        "importPath": "tests.test_python",
        "description": "tests.test_python",
        "isExtraImport": true,
        "detail": "tests.test_python",
        "documentation": {}
    },
    {
        "label": "TMP",
        "importPath": "tests",
        "description": "tests",
        "isExtraImport": true,
        "detail": "tests",
        "documentation": {}
    },
    {
        "label": "CUDA_DEVICE_COUNT",
        "importPath": "tests",
        "description": "tests",
        "isExtraImport": true,
        "detail": "tests",
        "documentation": {}
    },
    {
        "label": "CUDA_IS_AVAILABLE",
        "importPath": "tests",
        "description": "tests",
        "isExtraImport": true,
        "detail": "tests",
        "documentation": {}
    },
    {
        "label": "CUDA_DEVICE_COUNT",
        "importPath": "tests",
        "description": "tests",
        "isExtraImport": true,
        "detail": "tests",
        "documentation": {}
    },
    {
        "label": "CUDA_IS_AVAILABLE",
        "importPath": "tests",
        "description": "tests",
        "isExtraImport": true,
        "detail": "tests",
        "documentation": {}
    },
    {
        "label": "MODEL",
        "importPath": "tests",
        "description": "tests",
        "isExtraImport": true,
        "detail": "tests",
        "documentation": {}
    },
    {
        "label": "SOURCE",
        "importPath": "tests",
        "description": "tests",
        "isExtraImport": true,
        "detail": "tests",
        "documentation": {}
    },
    {
        "label": "MODEL",
        "importPath": "tests",
        "description": "tests",
        "isExtraImport": true,
        "detail": "tests",
        "documentation": {}
    },
    {
        "label": "MODEL",
        "importPath": "tests",
        "description": "tests",
        "isExtraImport": true,
        "detail": "tests",
        "documentation": {}
    },
    {
        "label": "SOURCE",
        "importPath": "tests",
        "description": "tests",
        "isExtraImport": true,
        "detail": "tests",
        "documentation": {}
    },
    {
        "label": "MODEL",
        "importPath": "tests",
        "description": "tests",
        "isExtraImport": true,
        "detail": "tests",
        "documentation": {}
    },
    {
        "label": "SOURCE",
        "importPath": "tests",
        "description": "tests",
        "isExtraImport": true,
        "detail": "tests",
        "documentation": {}
    },
    {
        "label": "TMP",
        "importPath": "tests",
        "description": "tests",
        "isExtraImport": true,
        "detail": "tests",
        "documentation": {}
    },
    {
        "label": "CFG",
        "importPath": "tests",
        "description": "tests",
        "isExtraImport": true,
        "detail": "tests",
        "documentation": {}
    },
    {
        "label": "IS_TMP_WRITEABLE",
        "importPath": "tests",
        "description": "tests",
        "isExtraImport": true,
        "detail": "tests",
        "documentation": {}
    },
    {
        "label": "MODEL",
        "importPath": "tests",
        "description": "tests",
        "isExtraImport": true,
        "detail": "tests",
        "documentation": {}
    },
    {
        "label": "SOURCE",
        "importPath": "tests",
        "description": "tests",
        "isExtraImport": true,
        "detail": "tests",
        "documentation": {}
    },
    {
        "label": "TMP",
        "importPath": "tests",
        "description": "tests",
        "isExtraImport": true,
        "detail": "tests",
        "documentation": {}
    },
    {
        "label": "pytest",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pytest",
        "description": "pytest",
        "detail": "pytest",
        "documentation": {}
    },
    {
        "label": "TestClient",
        "importPath": "fastapi.testclient",
        "description": "fastapi.testclient",
        "isExtraImport": true,
        "detail": "fastapi.testclient",
        "documentation": {}
    },
    {
        "label": "app",
        "importPath": "api.app",
        "description": "api.app",
        "isExtraImport": true,
        "detail": "api.app",
        "documentation": {}
    },
    {
        "label": "conf",
        "importPath": "mcd",
        "description": "mcd",
        "isExtraImport": true,
        "detail": "mcd",
        "documentation": {}
    },
    {
        "label": "PIL",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "PIL",
        "description": "PIL",
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "ImageOps",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "ImageDraw",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "ImageFont",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "__version__",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "TASK2DATA",
        "importPath": "ultralytics.cfg",
        "description": "ultralytics.cfg",
        "isExtraImport": true,
        "detail": "ultralytics.cfg",
        "documentation": {}
    },
    {
        "label": "TASK2MODEL",
        "importPath": "ultralytics.cfg",
        "description": "ultralytics.cfg",
        "isExtraImport": true,
        "detail": "ultralytics.cfg",
        "documentation": {}
    },
    {
        "label": "TASKS",
        "importPath": "ultralytics.cfg",
        "description": "ultralytics.cfg",
        "isExtraImport": true,
        "detail": "ultralytics.cfg",
        "documentation": {}
    },
    {
        "label": "TASK2DATA",
        "importPath": "ultralytics.cfg",
        "description": "ultralytics.cfg",
        "isExtraImport": true,
        "detail": "ultralytics.cfg",
        "documentation": {}
    },
    {
        "label": "TASK2MODEL",
        "importPath": "ultralytics.cfg",
        "description": "ultralytics.cfg",
        "isExtraImport": true,
        "detail": "ultralytics.cfg",
        "documentation": {}
    },
    {
        "label": "TASKS",
        "importPath": "ultralytics.cfg",
        "description": "ultralytics.cfg",
        "isExtraImport": true,
        "detail": "ultralytics.cfg",
        "documentation": {}
    },
    {
        "label": "get_cfg",
        "importPath": "ultralytics.cfg",
        "description": "ultralytics.cfg",
        "isExtraImport": true,
        "detail": "ultralytics.cfg",
        "documentation": {}
    },
    {
        "label": "TASK2DATA",
        "importPath": "ultralytics.cfg",
        "description": "ultralytics.cfg",
        "isExtraImport": true,
        "detail": "ultralytics.cfg",
        "documentation": {}
    },
    {
        "label": "TASK2MODEL",
        "importPath": "ultralytics.cfg",
        "description": "ultralytics.cfg",
        "isExtraImport": true,
        "detail": "ultralytics.cfg",
        "documentation": {}
    },
    {
        "label": "TASKS",
        "importPath": "ultralytics.cfg",
        "description": "ultralytics.cfg",
        "isExtraImport": true,
        "detail": "ultralytics.cfg",
        "documentation": {}
    },
    {
        "label": "MODELS",
        "importPath": "ultralytics.cfg",
        "description": "ultralytics.cfg",
        "isExtraImport": true,
        "detail": "ultralytics.cfg",
        "documentation": {}
    },
    {
        "label": "TASK2DATA",
        "importPath": "ultralytics.cfg",
        "description": "ultralytics.cfg",
        "isExtraImport": true,
        "detail": "ultralytics.cfg",
        "documentation": {}
    },
    {
        "label": "TASKS",
        "importPath": "ultralytics.cfg",
        "description": "ultralytics.cfg",
        "isExtraImport": true,
        "detail": "ultralytics.cfg",
        "documentation": {}
    },
    {
        "label": "TASK2DATA",
        "importPath": "ultralytics.cfg",
        "description": "ultralytics.cfg",
        "isExtraImport": true,
        "detail": "ultralytics.cfg",
        "documentation": {}
    },
    {
        "label": "get_cfg",
        "importPath": "ultralytics.cfg",
        "description": "ultralytics.cfg",
        "isExtraImport": true,
        "detail": "ultralytics.cfg",
        "documentation": {}
    },
    {
        "label": "TASK2DATA",
        "importPath": "ultralytics.cfg",
        "description": "ultralytics.cfg",
        "isExtraImport": true,
        "detail": "ultralytics.cfg",
        "documentation": {}
    },
    {
        "label": "get_cfg",
        "importPath": "ultralytics.cfg",
        "description": "ultralytics.cfg",
        "isExtraImport": true,
        "detail": "ultralytics.cfg",
        "documentation": {}
    },
    {
        "label": "get_save_dir",
        "importPath": "ultralytics.cfg",
        "description": "ultralytics.cfg",
        "isExtraImport": true,
        "detail": "ultralytics.cfg",
        "documentation": {}
    },
    {
        "label": "get_cfg",
        "importPath": "ultralytics.cfg",
        "description": "ultralytics.cfg",
        "isExtraImport": true,
        "detail": "ultralytics.cfg",
        "documentation": {}
    },
    {
        "label": "get_save_dir",
        "importPath": "ultralytics.cfg",
        "description": "ultralytics.cfg",
        "isExtraImport": true,
        "detail": "ultralytics.cfg",
        "documentation": {}
    },
    {
        "label": "get_cfg",
        "importPath": "ultralytics.cfg",
        "description": "ultralytics.cfg",
        "isExtraImport": true,
        "detail": "ultralytics.cfg",
        "documentation": {}
    },
    {
        "label": "get_save_dir",
        "importPath": "ultralytics.cfg",
        "description": "ultralytics.cfg",
        "isExtraImport": true,
        "detail": "ultralytics.cfg",
        "documentation": {}
    },
    {
        "label": "get_cfg",
        "importPath": "ultralytics.cfg",
        "description": "ultralytics.cfg",
        "isExtraImport": true,
        "detail": "ultralytics.cfg",
        "documentation": {}
    },
    {
        "label": "get_save_dir",
        "importPath": "ultralytics.cfg",
        "description": "ultralytics.cfg",
        "isExtraImport": true,
        "detail": "ultralytics.cfg",
        "documentation": {}
    },
    {
        "label": "get_cfg",
        "importPath": "ultralytics.cfg",
        "description": "ultralytics.cfg",
        "isExtraImport": true,
        "detail": "ultralytics.cfg",
        "documentation": {}
    },
    {
        "label": "get_save_dir",
        "importPath": "ultralytics.cfg",
        "description": "ultralytics.cfg",
        "isExtraImport": true,
        "detail": "ultralytics.cfg",
        "documentation": {}
    },
    {
        "label": "TASK2DATA",
        "importPath": "ultralytics.cfg",
        "description": "ultralytics.cfg",
        "isExtraImport": true,
        "detail": "ultralytics.cfg",
        "documentation": {}
    },
    {
        "label": "TASK2METRIC",
        "importPath": "ultralytics.cfg",
        "description": "ultralytics.cfg",
        "isExtraImport": true,
        "detail": "ultralytics.cfg",
        "documentation": {}
    },
    {
        "label": "TASK2DATA",
        "importPath": "ultralytics.cfg",
        "description": "ultralytics.cfg",
        "isExtraImport": true,
        "detail": "ultralytics.cfg",
        "documentation": {}
    },
    {
        "label": "TASK2METRIC",
        "importPath": "ultralytics.cfg",
        "description": "ultralytics.cfg",
        "isExtraImport": true,
        "detail": "ultralytics.cfg",
        "documentation": {}
    },
    {
        "label": "get_save_dir",
        "importPath": "ultralytics.cfg",
        "description": "ultralytics.cfg",
        "isExtraImport": true,
        "detail": "ultralytics.cfg",
        "documentation": {}
    },
    {
        "label": "itertools",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "itertools",
        "description": "itertools",
        "detail": "itertools",
        "documentation": {}
    },
    {
        "label": "product",
        "importPath": "itertools",
        "description": "itertools",
        "isExtraImport": true,
        "detail": "itertools",
        "documentation": {}
    },
    {
        "label": "product",
        "importPath": "itertools",
        "description": "itertools",
        "isExtraImport": true,
        "detail": "itertools",
        "documentation": {}
    },
    {
        "label": "repeat",
        "importPath": "itertools",
        "description": "itertools",
        "isExtraImport": true,
        "detail": "itertools",
        "documentation": {}
    },
    {
        "label": "product",
        "importPath": "itertools",
        "description": "itertools",
        "isExtraImport": true,
        "detail": "itertools",
        "documentation": {}
    },
    {
        "label": "cycle",
        "importPath": "itertools",
        "description": "itertools",
        "isExtraImport": true,
        "detail": "itertools",
        "documentation": {}
    },
    {
        "label": "repeat",
        "importPath": "itertools",
        "description": "itertools",
        "isExtraImport": true,
        "detail": "itertools",
        "documentation": {}
    },
    {
        "label": "repeat",
        "importPath": "itertools",
        "description": "itertools",
        "isExtraImport": true,
        "detail": "itertools",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "mock",
        "importPath": "unittest",
        "description": "unittest",
        "isExtraImport": true,
        "detail": "unittest",
        "documentation": {}
    },
    {
        "label": "Exporter",
        "importPath": "ultralytics.engine.exporter",
        "description": "ultralytics.engine.exporter",
        "isExtraImport": true,
        "detail": "ultralytics.engine.exporter",
        "documentation": {}
    },
    {
        "label": "export_formats",
        "importPath": "ultralytics.engine.exporter",
        "description": "ultralytics.engine.exporter",
        "isExtraImport": true,
        "detail": "ultralytics.engine.exporter",
        "documentation": {}
    },
    {
        "label": "classify",
        "importPath": "ultralytics.models.yolo",
        "description": "ultralytics.models.yolo",
        "isExtraImport": true,
        "detail": "ultralytics.models.yolo",
        "documentation": {}
    },
    {
        "label": "detect",
        "importPath": "ultralytics.models.yolo",
        "description": "ultralytics.models.yolo",
        "isExtraImport": true,
        "detail": "ultralytics.models.yolo",
        "documentation": {}
    },
    {
        "label": "segment",
        "importPath": "ultralytics.models.yolo",
        "description": "ultralytics.models.yolo",
        "isExtraImport": true,
        "detail": "ultralytics.models.yolo",
        "documentation": {}
    },
    {
        "label": "uuid",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "uuid",
        "description": "uuid",
        "detail": "uuid",
        "documentation": {}
    },
    {
        "label": "urllib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "urllib",
        "description": "urllib",
        "detail": "urllib",
        "documentation": {}
    },
    {
        "label": "parse",
        "importPath": "urllib",
        "description": "urllib",
        "isExtraImport": true,
        "detail": "urllib",
        "documentation": {}
    },
    {
        "label": "request",
        "importPath": "urllib",
        "description": "urllib",
        "isExtraImport": true,
        "detail": "urllib",
        "documentation": {}
    },
    {
        "label": "yaml",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "yaml",
        "description": "yaml",
        "detail": "yaml",
        "documentation": {}
    },
    {
        "label": "load_inference_source",
        "importPath": "ultralytics.data.build",
        "description": "ultralytics.data.build",
        "isExtraImport": true,
        "detail": "ultralytics.data.build",
        "documentation": {}
    },
    {
        "label": "download",
        "importPath": "ultralytics.utils.downloads",
        "description": "ultralytics.utils.downloads",
        "isExtraImport": true,
        "detail": "ultralytics.utils.downloads",
        "documentation": {}
    },
    {
        "label": "safe_download",
        "importPath": "ultralytics.utils.downloads",
        "description": "ultralytics.utils.downloads",
        "isExtraImport": true,
        "detail": "ultralytics.utils.downloads",
        "documentation": {}
    },
    {
        "label": "download",
        "importPath": "ultralytics.utils.downloads",
        "description": "ultralytics.utils.downloads",
        "isExtraImport": true,
        "detail": "ultralytics.utils.downloads",
        "documentation": {}
    },
    {
        "label": "safe_download",
        "importPath": "ultralytics.utils.downloads",
        "description": "ultralytics.utils.downloads",
        "isExtraImport": true,
        "detail": "ultralytics.utils.downloads",
        "documentation": {}
    },
    {
        "label": "unzip_file",
        "importPath": "ultralytics.utils.downloads",
        "description": "ultralytics.utils.downloads",
        "isExtraImport": true,
        "detail": "ultralytics.utils.downloads",
        "documentation": {}
    },
    {
        "label": "attempt_download_asset",
        "importPath": "ultralytics.utils.downloads",
        "description": "ultralytics.utils.downloads",
        "isExtraImport": true,
        "detail": "ultralytics.utils.downloads",
        "documentation": {}
    },
    {
        "label": "get_github_assets",
        "importPath": "ultralytics.utils.downloads",
        "description": "ultralytics.utils.downloads",
        "isExtraImport": true,
        "detail": "ultralytics.utils.downloads",
        "documentation": {}
    },
    {
        "label": "safe_download",
        "importPath": "ultralytics.utils.downloads",
        "description": "ultralytics.utils.downloads",
        "isExtraImport": true,
        "detail": "ultralytics.utils.downloads",
        "documentation": {}
    },
    {
        "label": "GITHUB_ASSETS_NAMES",
        "importPath": "ultralytics.utils.downloads",
        "description": "ultralytics.utils.downloads",
        "isExtraImport": true,
        "detail": "ultralytics.utils.downloads",
        "documentation": {}
    },
    {
        "label": "attempt_download_asset",
        "importPath": "ultralytics.utils.downloads",
        "description": "ultralytics.utils.downloads",
        "isExtraImport": true,
        "detail": "ultralytics.utils.downloads",
        "documentation": {}
    },
    {
        "label": "attempt_download_asset",
        "importPath": "ultralytics.utils.downloads",
        "description": "ultralytics.utils.downloads",
        "isExtraImport": true,
        "detail": "ultralytics.utils.downloads",
        "documentation": {}
    },
    {
        "label": "is_url",
        "importPath": "ultralytics.utils.downloads",
        "description": "ultralytics.utils.downloads",
        "isExtraImport": true,
        "detail": "ultralytics.utils.downloads",
        "documentation": {}
    },
    {
        "label": "GITHUB_ASSETS_STEMS",
        "importPath": "ultralytics.utils.downloads",
        "description": "ultralytics.utils.downloads",
        "isExtraImport": true,
        "detail": "ultralytics.utils.downloads",
        "documentation": {}
    },
    {
        "label": "safe_download",
        "importPath": "ultralytics.utils.downloads",
        "description": "ultralytics.utils.downloads",
        "isExtraImport": true,
        "detail": "ultralytics.utils.downloads",
        "documentation": {}
    },
    {
        "label": "threading",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "threading",
        "description": "threading",
        "detail": "threading",
        "documentation": {}
    },
    {
        "label": "Thread",
        "importPath": "threading",
        "description": "threading",
        "isExtraImport": true,
        "detail": "threading",
        "documentation": {}
    },
    {
        "label": "Thread",
        "importPath": "threading",
        "description": "threading",
        "isExtraImport": true,
        "detail": "threading",
        "documentation": {}
    },
    {
        "label": "streamlit",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "streamlit",
        "description": "streamlit",
        "detail": "streamlit",
        "documentation": {}
    },
    {
        "label": "image_select",
        "importPath": "streamlit_select",
        "description": "streamlit_select",
        "isExtraImport": true,
        "detail": "streamlit_select",
        "documentation": {}
    },
    {
        "label": "io",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "io",
        "description": "io",
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "BytesIO",
        "importPath": "io",
        "description": "io",
        "isExtraImport": true,
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "pyplot",
        "importPath": "matplotlib",
        "description": "matplotlib",
        "isExtraImport": true,
        "detail": "matplotlib",
        "documentation": {}
    },
    {
        "label": "Format",
        "importPath": "ultralytics.data.augment",
        "description": "ultralytics.data.augment",
        "isExtraImport": true,
        "detail": "ultralytics.data.augment",
        "documentation": {}
    },
    {
        "label": "LetterBox",
        "importPath": "ultralytics.data.augment",
        "description": "ultralytics.data.augment",
        "isExtraImport": true,
        "detail": "ultralytics.data.augment",
        "documentation": {}
    },
    {
        "label": "LetterBox",
        "importPath": "ultralytics.data.augment",
        "description": "ultralytics.data.augment",
        "isExtraImport": true,
        "detail": "ultralytics.data.augment",
        "documentation": {}
    },
    {
        "label": "classify_transforms",
        "importPath": "ultralytics.data.augment",
        "description": "ultralytics.data.augment",
        "isExtraImport": true,
        "detail": "ultralytics.data.augment",
        "documentation": {}
    },
    {
        "label": "LetterBox",
        "importPath": "ultralytics.data.augment",
        "description": "ultralytics.data.augment",
        "isExtraImport": true,
        "detail": "ultralytics.data.augment",
        "documentation": {}
    },
    {
        "label": "LetterBox",
        "importPath": "ultralytics.data.augment",
        "description": "ultralytics.data.augment",
        "isExtraImport": true,
        "detail": "ultralytics.data.augment",
        "documentation": {}
    },
    {
        "label": "Compose",
        "importPath": "ultralytics.data.augment",
        "description": "ultralytics.data.augment",
        "isExtraImport": true,
        "detail": "ultralytics.data.augment",
        "documentation": {}
    },
    {
        "label": "Format",
        "importPath": "ultralytics.data.augment",
        "description": "ultralytics.data.augment",
        "isExtraImport": true,
        "detail": "ultralytics.data.augment",
        "documentation": {}
    },
    {
        "label": "v8_transforms",
        "importPath": "ultralytics.data.augment",
        "description": "ultralytics.data.augment",
        "isExtraImport": true,
        "detail": "ultralytics.data.augment",
        "documentation": {}
    },
    {
        "label": "LetterBox",
        "importPath": "ultralytics.data.augment",
        "description": "ultralytics.data.augment",
        "isExtraImport": true,
        "detail": "ultralytics.data.augment",
        "documentation": {}
    },
    {
        "label": "YOLODataset",
        "importPath": "ultralytics.data.dataset",
        "description": "ultralytics.data.dataset",
        "isExtraImport": true,
        "detail": "ultralytics.data.dataset",
        "documentation": {}
    },
    {
        "label": "GroundingDataset",
        "importPath": "ultralytics.data.dataset",
        "description": "ultralytics.data.dataset",
        "isExtraImport": true,
        "detail": "ultralytics.data.dataset",
        "documentation": {}
    },
    {
        "label": "YOLODataset",
        "importPath": "ultralytics.data.dataset",
        "description": "ultralytics.data.dataset",
        "isExtraImport": true,
        "detail": "ultralytics.data.dataset",
        "documentation": {}
    },
    {
        "label": "YOLOMultiModalDataset",
        "importPath": "ultralytics.data.dataset",
        "description": "ultralytics.data.dataset",
        "isExtraImport": true,
        "detail": "ultralytics.data.dataset",
        "documentation": {}
    },
    {
        "label": "YOLODataset",
        "importPath": "ultralytics.data.dataset",
        "description": "ultralytics.data.dataset",
        "isExtraImport": true,
        "detail": "ultralytics.data.dataset",
        "documentation": {}
    },
    {
        "label": "check_det_dataset",
        "importPath": "ultralytics.data.utils",
        "description": "ultralytics.data.utils",
        "isExtraImport": true,
        "detail": "ultralytics.data.utils",
        "documentation": {}
    },
    {
        "label": "polygons2masks",
        "importPath": "ultralytics.data.utils",
        "description": "ultralytics.data.utils",
        "isExtraImport": true,
        "detail": "ultralytics.data.utils",
        "documentation": {}
    },
    {
        "label": "polygons2masks_overlap",
        "importPath": "ultralytics.data.utils",
        "description": "ultralytics.data.utils",
        "isExtraImport": true,
        "detail": "ultralytics.data.utils",
        "documentation": {}
    },
    {
        "label": "FORMATS_HELP_MSG",
        "importPath": "ultralytics.data.utils",
        "description": "ultralytics.data.utils",
        "isExtraImport": true,
        "detail": "ultralytics.data.utils",
        "documentation": {}
    },
    {
        "label": "HELP_URL",
        "importPath": "ultralytics.data.utils",
        "description": "ultralytics.data.utils",
        "isExtraImport": true,
        "detail": "ultralytics.data.utils",
        "documentation": {}
    },
    {
        "label": "IMG_FORMATS",
        "importPath": "ultralytics.data.utils",
        "description": "ultralytics.data.utils",
        "isExtraImport": true,
        "detail": "ultralytics.data.utils",
        "documentation": {}
    },
    {
        "label": "IMG_FORMATS",
        "importPath": "ultralytics.data.utils",
        "description": "ultralytics.data.utils",
        "isExtraImport": true,
        "detail": "ultralytics.data.utils",
        "documentation": {}
    },
    {
        "label": "PIN_MEMORY",
        "importPath": "ultralytics.data.utils",
        "description": "ultralytics.data.utils",
        "isExtraImport": true,
        "detail": "ultralytics.data.utils",
        "documentation": {}
    },
    {
        "label": "VID_FORMATS",
        "importPath": "ultralytics.data.utils",
        "description": "ultralytics.data.utils",
        "isExtraImport": true,
        "detail": "ultralytics.data.utils",
        "documentation": {}
    },
    {
        "label": "FORMATS_HELP_MSG",
        "importPath": "ultralytics.data.utils",
        "description": "ultralytics.data.utils",
        "isExtraImport": true,
        "detail": "ultralytics.data.utils",
        "documentation": {}
    },
    {
        "label": "IMG_FORMATS",
        "importPath": "ultralytics.data.utils",
        "description": "ultralytics.data.utils",
        "isExtraImport": true,
        "detail": "ultralytics.data.utils",
        "documentation": {}
    },
    {
        "label": "VID_FORMATS",
        "importPath": "ultralytics.data.utils",
        "description": "ultralytics.data.utils",
        "isExtraImport": true,
        "detail": "ultralytics.data.utils",
        "documentation": {}
    },
    {
        "label": "exif_size",
        "importPath": "ultralytics.data.utils",
        "description": "ultralytics.data.utils",
        "isExtraImport": true,
        "detail": "ultralytics.data.utils",
        "documentation": {}
    },
    {
        "label": "img2label_paths",
        "importPath": "ultralytics.data.utils",
        "description": "ultralytics.data.utils",
        "isExtraImport": true,
        "detail": "ultralytics.data.utils",
        "documentation": {}
    },
    {
        "label": "check_cls_dataset",
        "importPath": "ultralytics.data.utils",
        "description": "ultralytics.data.utils",
        "isExtraImport": true,
        "detail": "ultralytics.data.utils",
        "documentation": {}
    },
    {
        "label": "check_det_dataset",
        "importPath": "ultralytics.data.utils",
        "description": "ultralytics.data.utils",
        "isExtraImport": true,
        "detail": "ultralytics.data.utils",
        "documentation": {}
    },
    {
        "label": "check_cls_dataset",
        "importPath": "ultralytics.data.utils",
        "description": "ultralytics.data.utils",
        "isExtraImport": true,
        "detail": "ultralytics.data.utils",
        "documentation": {}
    },
    {
        "label": "check_det_dataset",
        "importPath": "ultralytics.data.utils",
        "description": "ultralytics.data.utils",
        "isExtraImport": true,
        "detail": "ultralytics.data.utils",
        "documentation": {}
    },
    {
        "label": "check_cls_dataset",
        "importPath": "ultralytics.data.utils",
        "description": "ultralytics.data.utils",
        "isExtraImport": true,
        "detail": "ultralytics.data.utils",
        "documentation": {}
    },
    {
        "label": "check_det_dataset",
        "importPath": "ultralytics.data.utils",
        "description": "ultralytics.data.utils",
        "isExtraImport": true,
        "detail": "ultralytics.data.utils",
        "documentation": {}
    },
    {
        "label": "check_det_dataset",
        "importPath": "ultralytics.data.utils",
        "description": "ultralytics.data.utils",
        "isExtraImport": true,
        "detail": "ultralytics.data.utils",
        "documentation": {}
    },
    {
        "label": "YOLO",
        "importPath": "ultralytics.models.yolo.model",
        "description": "ultralytics.models.yolo.model",
        "isExtraImport": true,
        "detail": "ultralytics.models.yolo.model",
        "documentation": {}
    },
    {
        "label": "getpass",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "getpass",
        "description": "getpass",
        "detail": "getpass",
        "documentation": {}
    },
    {
        "label": "xyxy2xywh",
        "importPath": "ultralytics.utils.ops",
        "description": "ultralytics.utils.ops",
        "isExtraImport": true,
        "detail": "ultralytics.utils.ops",
        "documentation": {}
    },
    {
        "label": "segment2box",
        "importPath": "ultralytics.utils.ops",
        "description": "ultralytics.utils.ops",
        "isExtraImport": true,
        "detail": "ultralytics.utils.ops",
        "documentation": {}
    },
    {
        "label": "xyxyxyxy2xywhr",
        "importPath": "ultralytics.utils.ops",
        "description": "ultralytics.utils.ops",
        "isExtraImport": true,
        "detail": "ultralytics.utils.ops",
        "documentation": {}
    },
    {
        "label": "resample_segments",
        "importPath": "ultralytics.utils.ops",
        "description": "ultralytics.utils.ops",
        "isExtraImport": true,
        "detail": "ultralytics.utils.ops",
        "documentation": {}
    },
    {
        "label": "segments2boxes",
        "importPath": "ultralytics.utils.ops",
        "description": "ultralytics.utils.ops",
        "isExtraImport": true,
        "detail": "ultralytics.utils.ops",
        "documentation": {}
    },
    {
        "label": "Profile",
        "importPath": "ultralytics.utils.ops",
        "description": "ultralytics.utils.ops",
        "isExtraImport": true,
        "detail": "ultralytics.utils.ops",
        "documentation": {}
    },
    {
        "label": "Profile",
        "importPath": "ultralytics.utils.ops",
        "description": "ultralytics.utils.ops",
        "isExtraImport": true,
        "detail": "ultralytics.utils.ops",
        "documentation": {}
    },
    {
        "label": "xywh2xyxy",
        "importPath": "ultralytics.utils.ops",
        "description": "ultralytics.utils.ops",
        "isExtraImport": true,
        "detail": "ultralytics.utils.ops",
        "documentation": {}
    },
    {
        "label": "xyxy2xywh",
        "importPath": "ultralytics.utils.ops",
        "description": "ultralytics.utils.ops",
        "isExtraImport": true,
        "detail": "ultralytics.utils.ops",
        "documentation": {}
    },
    {
        "label": "crop_mask",
        "importPath": "ultralytics.utils.ops",
        "description": "ultralytics.utils.ops",
        "isExtraImport": true,
        "detail": "ultralytics.utils.ops",
        "documentation": {}
    },
    {
        "label": "xywh2xyxy",
        "importPath": "ultralytics.utils.ops",
        "description": "ultralytics.utils.ops",
        "isExtraImport": true,
        "detail": "ultralytics.utils.ops",
        "documentation": {}
    },
    {
        "label": "xyxy2xywh",
        "importPath": "ultralytics.utils.ops",
        "description": "ultralytics.utils.ops",
        "isExtraImport": true,
        "detail": "ultralytics.utils.ops",
        "documentation": {}
    },
    {
        "label": "math",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "math",
        "description": "math",
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "ceil",
        "importPath": "math",
        "description": "math",
        "isExtraImport": true,
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "random",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "random",
        "description": "random",
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "Instances",
        "importPath": "ultralytics.utils.instance",
        "description": "ultralytics.utils.instance",
        "isExtraImport": true,
        "detail": "ultralytics.utils.instance",
        "documentation": {}
    },
    {
        "label": "to_2tuple",
        "importPath": "ultralytics.utils.instance",
        "description": "ultralytics.utils.instance",
        "isExtraImport": true,
        "detail": "ultralytics.utils.instance",
        "documentation": {}
    },
    {
        "label": "bbox_ioa",
        "importPath": "ultralytics.utils.metrics",
        "description": "ultralytics.utils.metrics",
        "isExtraImport": true,
        "detail": "ultralytics.utils.metrics",
        "documentation": {}
    },
    {
        "label": "box_iou",
        "importPath": "ultralytics.utils.metrics",
        "description": "ultralytics.utils.metrics",
        "isExtraImport": true,
        "detail": "ultralytics.utils.metrics",
        "documentation": {}
    },
    {
        "label": "SegmentMetrics",
        "importPath": "ultralytics.utils.metrics",
        "description": "ultralytics.utils.metrics",
        "isExtraImport": true,
        "detail": "ultralytics.utils.metrics",
        "documentation": {}
    },
    {
        "label": "bbox_iou",
        "importPath": "ultralytics.utils.metrics",
        "description": "ultralytics.utils.metrics",
        "isExtraImport": true,
        "detail": "ultralytics.utils.metrics",
        "documentation": {}
    },
    {
        "label": "bbox_iou",
        "importPath": "ultralytics.utils.metrics",
        "description": "ultralytics.utils.metrics",
        "isExtraImport": true,
        "detail": "ultralytics.utils.metrics",
        "documentation": {}
    },
    {
        "label": "ClassifyMetrics",
        "importPath": "ultralytics.utils.metrics",
        "description": "ultralytics.utils.metrics",
        "isExtraImport": true,
        "detail": "ultralytics.utils.metrics",
        "documentation": {}
    },
    {
        "label": "ConfusionMatrix",
        "importPath": "ultralytics.utils.metrics",
        "description": "ultralytics.utils.metrics",
        "isExtraImport": true,
        "detail": "ultralytics.utils.metrics",
        "documentation": {}
    },
    {
        "label": "ConfusionMatrix",
        "importPath": "ultralytics.utils.metrics",
        "description": "ultralytics.utils.metrics",
        "isExtraImport": true,
        "detail": "ultralytics.utils.metrics",
        "documentation": {}
    },
    {
        "label": "DetMetrics",
        "importPath": "ultralytics.utils.metrics",
        "description": "ultralytics.utils.metrics",
        "isExtraImport": true,
        "detail": "ultralytics.utils.metrics",
        "documentation": {}
    },
    {
        "label": "box_iou",
        "importPath": "ultralytics.utils.metrics",
        "description": "ultralytics.utils.metrics",
        "isExtraImport": true,
        "detail": "ultralytics.utils.metrics",
        "documentation": {}
    },
    {
        "label": "OBBMetrics",
        "importPath": "ultralytics.utils.metrics",
        "description": "ultralytics.utils.metrics",
        "isExtraImport": true,
        "detail": "ultralytics.utils.metrics",
        "documentation": {}
    },
    {
        "label": "batch_probiou",
        "importPath": "ultralytics.utils.metrics",
        "description": "ultralytics.utils.metrics",
        "isExtraImport": true,
        "detail": "ultralytics.utils.metrics",
        "documentation": {}
    },
    {
        "label": "OKS_SIGMA",
        "importPath": "ultralytics.utils.metrics",
        "description": "ultralytics.utils.metrics",
        "isExtraImport": true,
        "detail": "ultralytics.utils.metrics",
        "documentation": {}
    },
    {
        "label": "PoseMetrics",
        "importPath": "ultralytics.utils.metrics",
        "description": "ultralytics.utils.metrics",
        "isExtraImport": true,
        "detail": "ultralytics.utils.metrics",
        "documentation": {}
    },
    {
        "label": "box_iou",
        "importPath": "ultralytics.utils.metrics",
        "description": "ultralytics.utils.metrics",
        "isExtraImport": true,
        "detail": "ultralytics.utils.metrics",
        "documentation": {}
    },
    {
        "label": "kpt_iou",
        "importPath": "ultralytics.utils.metrics",
        "description": "ultralytics.utils.metrics",
        "isExtraImport": true,
        "detail": "ultralytics.utils.metrics",
        "documentation": {}
    },
    {
        "label": "SegmentMetrics",
        "importPath": "ultralytics.utils.metrics",
        "description": "ultralytics.utils.metrics",
        "isExtraImport": true,
        "detail": "ultralytics.utils.metrics",
        "documentation": {}
    },
    {
        "label": "box_iou",
        "importPath": "ultralytics.utils.metrics",
        "description": "ultralytics.utils.metrics",
        "isExtraImport": true,
        "detail": "ultralytics.utils.metrics",
        "documentation": {}
    },
    {
        "label": "mask_iou",
        "importPath": "ultralytics.utils.metrics",
        "description": "ultralytics.utils.metrics",
        "isExtraImport": true,
        "detail": "ultralytics.utils.metrics",
        "documentation": {}
    },
    {
        "label": "batch_probiou",
        "importPath": "ultralytics.utils.metrics",
        "description": "ultralytics.utils.metrics",
        "isExtraImport": true,
        "detail": "ultralytics.utils.metrics",
        "documentation": {}
    },
    {
        "label": "bbox_ioa",
        "importPath": "ultralytics.utils.metrics",
        "description": "ultralytics.utils.metrics",
        "isExtraImport": true,
        "detail": "ultralytics.utils.metrics",
        "documentation": {}
    },
    {
        "label": "OKS_SIGMA",
        "importPath": "ultralytics.utils.metrics",
        "description": "ultralytics.utils.metrics",
        "isExtraImport": true,
        "detail": "ultralytics.utils.metrics",
        "documentation": {}
    },
    {
        "label": "batch_probiou",
        "importPath": "ultralytics.utils.metrics",
        "description": "ultralytics.utils.metrics",
        "isExtraImport": true,
        "detail": "ultralytics.utils.metrics",
        "documentation": {}
    },
    {
        "label": "glob",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "glob",
        "description": "glob",
        "detail": "glob",
        "documentation": {}
    },
    {
        "label": "glob",
        "importPath": "glob",
        "description": "glob",
        "isExtraImport": true,
        "detail": "glob",
        "documentation": {}
    },
    {
        "label": "ThreadPool",
        "importPath": "multiprocessing.pool",
        "description": "multiprocessing.pool",
        "isExtraImport": true,
        "detail": "multiprocessing.pool",
        "documentation": {}
    },
    {
        "label": "ThreadPool",
        "importPath": "multiprocessing.pool",
        "description": "multiprocessing.pool",
        "isExtraImport": true,
        "detail": "multiprocessing.pool",
        "documentation": {}
    },
    {
        "label": "ThreadPool",
        "importPath": "multiprocessing.pool",
        "description": "multiprocessing.pool",
        "isExtraImport": true,
        "detail": "multiprocessing.pool",
        "documentation": {}
    },
    {
        "label": "ThreadPool",
        "importPath": "multiprocessing.pool",
        "description": "multiprocessing.pool",
        "isExtraImport": true,
        "detail": "multiprocessing.pool",
        "documentation": {}
    },
    {
        "label": "ThreadPool",
        "importPath": "multiprocessing.pool",
        "description": "multiprocessing.pool",
        "isExtraImport": true,
        "detail": "multiprocessing.pool",
        "documentation": {}
    },
    {
        "label": "psutil",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "psutil",
        "description": "psutil",
        "detail": "psutil",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "dataloader",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "distributed",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "ConcatDataset",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "requests",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "requests",
        "description": "requests",
        "detail": "requests",
        "documentation": {}
    },
    {
        "label": "hashlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "hashlib",
        "description": "hashlib",
        "detail": "hashlib",
        "documentation": {}
    },
    {
        "label": "zipfile",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "zipfile",
        "description": "zipfile",
        "detail": "zipfile",
        "documentation": {}
    },
    {
        "label": "is_tarfile",
        "importPath": "tarfile",
        "description": "tarfile",
        "isExtraImport": true,
        "detail": "tarfile",
        "documentation": {}
    },
    {
        "label": "check_class_names",
        "importPath": "ultralytics.nn.autobackend",
        "description": "ultralytics.nn.autobackend",
        "isExtraImport": true,
        "detail": "ultralytics.nn.autobackend",
        "documentation": {}
    },
    {
        "label": "check_class_names",
        "importPath": "ultralytics.nn.autobackend",
        "description": "ultralytics.nn.autobackend",
        "isExtraImport": true,
        "detail": "ultralytics.nn.autobackend",
        "documentation": {}
    },
    {
        "label": "default_class_names",
        "importPath": "ultralytics.nn.autobackend",
        "description": "ultralytics.nn.autobackend",
        "isExtraImport": true,
        "detail": "ultralytics.nn.autobackend",
        "documentation": {}
    },
    {
        "label": "AutoBackend",
        "importPath": "ultralytics.nn.autobackend",
        "description": "ultralytics.nn.autobackend",
        "isExtraImport": true,
        "detail": "ultralytics.nn.autobackend",
        "documentation": {}
    },
    {
        "label": "AutoBackend",
        "importPath": "ultralytics.nn.autobackend",
        "description": "ultralytics.nn.autobackend",
        "isExtraImport": true,
        "detail": "ultralytics.nn.autobackend",
        "documentation": {}
    },
    {
        "label": "gc",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "gc",
        "description": "gc",
        "detail": "gc",
        "documentation": {}
    },
    {
        "label": "warnings",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "warnings",
        "description": "warnings",
        "detail": "warnings",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "build_dataloader",
        "importPath": "ultralytics.data",
        "description": "ultralytics.data",
        "isExtraImport": true,
        "detail": "ultralytics.data",
        "documentation": {}
    },
    {
        "label": "load_inference_source",
        "importPath": "ultralytics.data",
        "description": "ultralytics.data",
        "isExtraImport": true,
        "detail": "ultralytics.data",
        "documentation": {}
    },
    {
        "label": "YOLODataset",
        "importPath": "ultralytics.data",
        "description": "ultralytics.data",
        "isExtraImport": true,
        "detail": "ultralytics.data",
        "documentation": {}
    },
    {
        "label": "ClassificationDataset",
        "importPath": "ultralytics.data",
        "description": "ultralytics.data",
        "isExtraImport": true,
        "detail": "ultralytics.data",
        "documentation": {}
    },
    {
        "label": "build_dataloader",
        "importPath": "ultralytics.data",
        "description": "ultralytics.data",
        "isExtraImport": true,
        "detail": "ultralytics.data",
        "documentation": {}
    },
    {
        "label": "ClassificationDataset",
        "importPath": "ultralytics.data",
        "description": "ultralytics.data",
        "isExtraImport": true,
        "detail": "ultralytics.data",
        "documentation": {}
    },
    {
        "label": "build_dataloader",
        "importPath": "ultralytics.data",
        "description": "ultralytics.data",
        "isExtraImport": true,
        "detail": "ultralytics.data",
        "documentation": {}
    },
    {
        "label": "build_dataloader",
        "importPath": "ultralytics.data",
        "description": "ultralytics.data",
        "isExtraImport": true,
        "detail": "ultralytics.data",
        "documentation": {}
    },
    {
        "label": "build_yolo_dataset",
        "importPath": "ultralytics.data",
        "description": "ultralytics.data",
        "isExtraImport": true,
        "detail": "ultralytics.data",
        "documentation": {}
    },
    {
        "label": "build_dataloader",
        "importPath": "ultralytics.data",
        "description": "ultralytics.data",
        "isExtraImport": true,
        "detail": "ultralytics.data",
        "documentation": {}
    },
    {
        "label": "build_yolo_dataset",
        "importPath": "ultralytics.data",
        "description": "ultralytics.data",
        "isExtraImport": true,
        "detail": "ultralytics.data",
        "documentation": {}
    },
    {
        "label": "converter",
        "importPath": "ultralytics.data",
        "description": "ultralytics.data",
        "isExtraImport": true,
        "detail": "ultralytics.data",
        "documentation": {}
    },
    {
        "label": "build_yolo_dataset",
        "importPath": "ultralytics.data",
        "description": "ultralytics.data",
        "isExtraImport": true,
        "detail": "ultralytics.data",
        "documentation": {}
    },
    {
        "label": "YOLOConcatDataset",
        "importPath": "ultralytics.data",
        "description": "ultralytics.data",
        "isExtraImport": true,
        "detail": "ultralytics.data",
        "documentation": {}
    },
    {
        "label": "build_grounding",
        "importPath": "ultralytics.data",
        "description": "ultralytics.data",
        "isExtraImport": true,
        "detail": "ultralytics.data",
        "documentation": {}
    },
    {
        "label": "build_yolo_dataset",
        "importPath": "ultralytics.data",
        "description": "ultralytics.data",
        "isExtraImport": true,
        "detail": "ultralytics.data",
        "documentation": {}
    },
    {
        "label": "C2f",
        "importPath": "ultralytics.nn.modules",
        "description": "ultralytics.nn.modules",
        "isExtraImport": true,
        "detail": "ultralytics.nn.modules",
        "documentation": {}
    },
    {
        "label": "Detect",
        "importPath": "ultralytics.nn.modules",
        "description": "ultralytics.nn.modules",
        "isExtraImport": true,
        "detail": "ultralytics.nn.modules",
        "documentation": {}
    },
    {
        "label": "RTDETRDecoder",
        "importPath": "ultralytics.nn.modules",
        "description": "ultralytics.nn.modules",
        "isExtraImport": true,
        "detail": "ultralytics.nn.modules",
        "documentation": {}
    },
    {
        "label": "LayerNorm2d",
        "importPath": "ultralytics.nn.modules",
        "description": "ultralytics.nn.modules",
        "isExtraImport": true,
        "detail": "ultralytics.nn.modules",
        "documentation": {}
    },
    {
        "label": "LayerNorm2d",
        "importPath": "ultralytics.nn.modules",
        "description": "ultralytics.nn.modules",
        "isExtraImport": true,
        "detail": "ultralytics.nn.modules",
        "documentation": {}
    },
    {
        "label": "MLPBlock",
        "importPath": "ultralytics.nn.modules",
        "description": "ultralytics.nn.modules",
        "isExtraImport": true,
        "detail": "ultralytics.nn.modules",
        "documentation": {}
    },
    {
        "label": "MLPBlock",
        "importPath": "ultralytics.nn.modules",
        "description": "ultralytics.nn.modules",
        "isExtraImport": true,
        "detail": "ultralytics.nn.modules",
        "documentation": {}
    },
    {
        "label": "AIFI",
        "importPath": "ultralytics.nn.modules",
        "description": "ultralytics.nn.modules",
        "isExtraImport": true,
        "detail": "ultralytics.nn.modules",
        "documentation": {}
    },
    {
        "label": "C1",
        "importPath": "ultralytics.nn.modules",
        "description": "ultralytics.nn.modules",
        "isExtraImport": true,
        "detail": "ultralytics.nn.modules",
        "documentation": {}
    },
    {
        "label": "C2",
        "importPath": "ultralytics.nn.modules",
        "description": "ultralytics.nn.modules",
        "isExtraImport": true,
        "detail": "ultralytics.nn.modules",
        "documentation": {}
    },
    {
        "label": "C3",
        "importPath": "ultralytics.nn.modules",
        "description": "ultralytics.nn.modules",
        "isExtraImport": true,
        "detail": "ultralytics.nn.modules",
        "documentation": {}
    },
    {
        "label": "C3TR",
        "importPath": "ultralytics.nn.modules",
        "description": "ultralytics.nn.modules",
        "isExtraImport": true,
        "detail": "ultralytics.nn.modules",
        "documentation": {}
    },
    {
        "label": "ELAN1",
        "importPath": "ultralytics.nn.modules",
        "description": "ultralytics.nn.modules",
        "isExtraImport": true,
        "detail": "ultralytics.nn.modules",
        "documentation": {}
    },
    {
        "label": "OBB",
        "importPath": "ultralytics.nn.modules",
        "description": "ultralytics.nn.modules",
        "isExtraImport": true,
        "detail": "ultralytics.nn.modules",
        "documentation": {}
    },
    {
        "label": "PSA",
        "importPath": "ultralytics.nn.modules",
        "description": "ultralytics.nn.modules",
        "isExtraImport": true,
        "detail": "ultralytics.nn.modules",
        "documentation": {}
    },
    {
        "label": "SPP",
        "importPath": "ultralytics.nn.modules",
        "description": "ultralytics.nn.modules",
        "isExtraImport": true,
        "detail": "ultralytics.nn.modules",
        "documentation": {}
    },
    {
        "label": "SPPELAN",
        "importPath": "ultralytics.nn.modules",
        "description": "ultralytics.nn.modules",
        "isExtraImport": true,
        "detail": "ultralytics.nn.modules",
        "documentation": {}
    },
    {
        "label": "SPPF",
        "importPath": "ultralytics.nn.modules",
        "description": "ultralytics.nn.modules",
        "isExtraImport": true,
        "detail": "ultralytics.nn.modules",
        "documentation": {}
    },
    {
        "label": "AConv",
        "importPath": "ultralytics.nn.modules",
        "description": "ultralytics.nn.modules",
        "isExtraImport": true,
        "detail": "ultralytics.nn.modules",
        "documentation": {}
    },
    {
        "label": "ADown",
        "importPath": "ultralytics.nn.modules",
        "description": "ultralytics.nn.modules",
        "isExtraImport": true,
        "detail": "ultralytics.nn.modules",
        "documentation": {}
    },
    {
        "label": "Bottleneck",
        "importPath": "ultralytics.nn.modules",
        "description": "ultralytics.nn.modules",
        "isExtraImport": true,
        "detail": "ultralytics.nn.modules",
        "documentation": {}
    },
    {
        "label": "BottleneckCSP",
        "importPath": "ultralytics.nn.modules",
        "description": "ultralytics.nn.modules",
        "isExtraImport": true,
        "detail": "ultralytics.nn.modules",
        "documentation": {}
    },
    {
        "label": "C2f",
        "importPath": "ultralytics.nn.modules",
        "description": "ultralytics.nn.modules",
        "isExtraImport": true,
        "detail": "ultralytics.nn.modules",
        "documentation": {}
    },
    {
        "label": "C2fAttn",
        "importPath": "ultralytics.nn.modules",
        "description": "ultralytics.nn.modules",
        "isExtraImport": true,
        "detail": "ultralytics.nn.modules",
        "documentation": {}
    },
    {
        "label": "C2fCIB",
        "importPath": "ultralytics.nn.modules",
        "description": "ultralytics.nn.modules",
        "isExtraImport": true,
        "detail": "ultralytics.nn.modules",
        "documentation": {}
    },
    {
        "label": "C3Ghost",
        "importPath": "ultralytics.nn.modules",
        "description": "ultralytics.nn.modules",
        "isExtraImport": true,
        "detail": "ultralytics.nn.modules",
        "documentation": {}
    },
    {
        "label": "C3x",
        "importPath": "ultralytics.nn.modules",
        "description": "ultralytics.nn.modules",
        "isExtraImport": true,
        "detail": "ultralytics.nn.modules",
        "documentation": {}
    },
    {
        "label": "CBFuse",
        "importPath": "ultralytics.nn.modules",
        "description": "ultralytics.nn.modules",
        "isExtraImport": true,
        "detail": "ultralytics.nn.modules",
        "documentation": {}
    },
    {
        "label": "CBLinear",
        "importPath": "ultralytics.nn.modules",
        "description": "ultralytics.nn.modules",
        "isExtraImport": true,
        "detail": "ultralytics.nn.modules",
        "documentation": {}
    },
    {
        "label": "Classify",
        "importPath": "ultralytics.nn.modules",
        "description": "ultralytics.nn.modules",
        "isExtraImport": true,
        "detail": "ultralytics.nn.modules",
        "documentation": {}
    },
    {
        "label": "Concat",
        "importPath": "ultralytics.nn.modules",
        "description": "ultralytics.nn.modules",
        "isExtraImport": true,
        "detail": "ultralytics.nn.modules",
        "documentation": {}
    },
    {
        "label": "Conv",
        "importPath": "ultralytics.nn.modules",
        "description": "ultralytics.nn.modules",
        "isExtraImport": true,
        "detail": "ultralytics.nn.modules",
        "documentation": {}
    },
    {
        "label": "Conv2",
        "importPath": "ultralytics.nn.modules",
        "description": "ultralytics.nn.modules",
        "isExtraImport": true,
        "detail": "ultralytics.nn.modules",
        "documentation": {}
    },
    {
        "label": "ConvTranspose",
        "importPath": "ultralytics.nn.modules",
        "description": "ultralytics.nn.modules",
        "isExtraImport": true,
        "detail": "ultralytics.nn.modules",
        "documentation": {}
    },
    {
        "label": "Detect",
        "importPath": "ultralytics.nn.modules",
        "description": "ultralytics.nn.modules",
        "isExtraImport": true,
        "detail": "ultralytics.nn.modules",
        "documentation": {}
    },
    {
        "label": "DWConv",
        "importPath": "ultralytics.nn.modules",
        "description": "ultralytics.nn.modules",
        "isExtraImport": true,
        "detail": "ultralytics.nn.modules",
        "documentation": {}
    },
    {
        "label": "DWConvTranspose2d",
        "importPath": "ultralytics.nn.modules",
        "description": "ultralytics.nn.modules",
        "isExtraImport": true,
        "detail": "ultralytics.nn.modules",
        "documentation": {}
    },
    {
        "label": "Focus",
        "importPath": "ultralytics.nn.modules",
        "description": "ultralytics.nn.modules",
        "isExtraImport": true,
        "detail": "ultralytics.nn.modules",
        "documentation": {}
    },
    {
        "label": "GhostBottleneck",
        "importPath": "ultralytics.nn.modules",
        "description": "ultralytics.nn.modules",
        "isExtraImport": true,
        "detail": "ultralytics.nn.modules",
        "documentation": {}
    },
    {
        "label": "GhostConv",
        "importPath": "ultralytics.nn.modules",
        "description": "ultralytics.nn.modules",
        "isExtraImport": true,
        "detail": "ultralytics.nn.modules",
        "documentation": {}
    },
    {
        "label": "HGBlock",
        "importPath": "ultralytics.nn.modules",
        "description": "ultralytics.nn.modules",
        "isExtraImport": true,
        "detail": "ultralytics.nn.modules",
        "documentation": {}
    },
    {
        "label": "HGStem",
        "importPath": "ultralytics.nn.modules",
        "description": "ultralytics.nn.modules",
        "isExtraImport": true,
        "detail": "ultralytics.nn.modules",
        "documentation": {}
    },
    {
        "label": "ImagePoolingAttn",
        "importPath": "ultralytics.nn.modules",
        "description": "ultralytics.nn.modules",
        "isExtraImport": true,
        "detail": "ultralytics.nn.modules",
        "documentation": {}
    },
    {
        "label": "Pose",
        "importPath": "ultralytics.nn.modules",
        "description": "ultralytics.nn.modules",
        "isExtraImport": true,
        "detail": "ultralytics.nn.modules",
        "documentation": {}
    },
    {
        "label": "RepC3",
        "importPath": "ultralytics.nn.modules",
        "description": "ultralytics.nn.modules",
        "isExtraImport": true,
        "detail": "ultralytics.nn.modules",
        "documentation": {}
    },
    {
        "label": "RepConv",
        "importPath": "ultralytics.nn.modules",
        "description": "ultralytics.nn.modules",
        "isExtraImport": true,
        "detail": "ultralytics.nn.modules",
        "documentation": {}
    },
    {
        "label": "RepNCSPELAN4",
        "importPath": "ultralytics.nn.modules",
        "description": "ultralytics.nn.modules",
        "isExtraImport": true,
        "detail": "ultralytics.nn.modules",
        "documentation": {}
    },
    {
        "label": "RepVGGDW",
        "importPath": "ultralytics.nn.modules",
        "description": "ultralytics.nn.modules",
        "isExtraImport": true,
        "detail": "ultralytics.nn.modules",
        "documentation": {}
    },
    {
        "label": "ResNetLayer",
        "importPath": "ultralytics.nn.modules",
        "description": "ultralytics.nn.modules",
        "isExtraImport": true,
        "detail": "ultralytics.nn.modules",
        "documentation": {}
    },
    {
        "label": "RTDETRDecoder",
        "importPath": "ultralytics.nn.modules",
        "description": "ultralytics.nn.modules",
        "isExtraImport": true,
        "detail": "ultralytics.nn.modules",
        "documentation": {}
    },
    {
        "label": "SCDown",
        "importPath": "ultralytics.nn.modules",
        "description": "ultralytics.nn.modules",
        "isExtraImport": true,
        "detail": "ultralytics.nn.modules",
        "documentation": {}
    },
    {
        "label": "Segment",
        "importPath": "ultralytics.nn.modules",
        "description": "ultralytics.nn.modules",
        "isExtraImport": true,
        "detail": "ultralytics.nn.modules",
        "documentation": {}
    },
    {
        "label": "WorldDetect",
        "importPath": "ultralytics.nn.modules",
        "description": "ultralytics.nn.modules",
        "isExtraImport": true,
        "detail": "ultralytics.nn.modules",
        "documentation": {}
    },
    {
        "label": "v10Detect",
        "importPath": "ultralytics.nn.modules",
        "description": "ultralytics.nn.modules",
        "isExtraImport": true,
        "detail": "ultralytics.nn.modules",
        "documentation": {}
    },
    {
        "label": "DetectionModel",
        "importPath": "ultralytics.nn.tasks",
        "description": "ultralytics.nn.tasks",
        "isExtraImport": true,
        "detail": "ultralytics.nn.tasks",
        "documentation": {}
    },
    {
        "label": "SegmentationModel",
        "importPath": "ultralytics.nn.tasks",
        "description": "ultralytics.nn.tasks",
        "isExtraImport": true,
        "detail": "ultralytics.nn.tasks",
        "documentation": {}
    },
    {
        "label": "WorldModel",
        "importPath": "ultralytics.nn.tasks",
        "description": "ultralytics.nn.tasks",
        "isExtraImport": true,
        "detail": "ultralytics.nn.tasks",
        "documentation": {}
    },
    {
        "label": "attempt_load_one_weight",
        "importPath": "ultralytics.nn.tasks",
        "description": "ultralytics.nn.tasks",
        "isExtraImport": true,
        "detail": "ultralytics.nn.tasks",
        "documentation": {}
    },
    {
        "label": "guess_model_task",
        "importPath": "ultralytics.nn.tasks",
        "description": "ultralytics.nn.tasks",
        "isExtraImport": true,
        "detail": "ultralytics.nn.tasks",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "ultralytics.nn.tasks",
        "description": "ultralytics.nn.tasks",
        "isExtraImport": true,
        "detail": "ultralytics.nn.tasks",
        "documentation": {}
    },
    {
        "label": "yaml_model_load",
        "importPath": "ultralytics.nn.tasks",
        "description": "ultralytics.nn.tasks",
        "isExtraImport": true,
        "detail": "ultralytics.nn.tasks",
        "documentation": {}
    },
    {
        "label": "attempt_load_one_weight",
        "importPath": "ultralytics.nn.tasks",
        "description": "ultralytics.nn.tasks",
        "isExtraImport": true,
        "detail": "ultralytics.nn.tasks",
        "documentation": {}
    },
    {
        "label": "attempt_load_weights",
        "importPath": "ultralytics.nn.tasks",
        "description": "ultralytics.nn.tasks",
        "isExtraImport": true,
        "detail": "ultralytics.nn.tasks",
        "documentation": {}
    },
    {
        "label": "RTDETRDetectionModel",
        "importPath": "ultralytics.nn.tasks",
        "description": "ultralytics.nn.tasks",
        "isExtraImport": true,
        "detail": "ultralytics.nn.tasks",
        "documentation": {}
    },
    {
        "label": "RTDETRDetectionModel",
        "importPath": "ultralytics.nn.tasks",
        "description": "ultralytics.nn.tasks",
        "isExtraImport": true,
        "detail": "ultralytics.nn.tasks",
        "documentation": {}
    },
    {
        "label": "ClassificationModel",
        "importPath": "ultralytics.nn.tasks",
        "description": "ultralytics.nn.tasks",
        "isExtraImport": true,
        "detail": "ultralytics.nn.tasks",
        "documentation": {}
    },
    {
        "label": "DetectionModel",
        "importPath": "ultralytics.nn.tasks",
        "description": "ultralytics.nn.tasks",
        "isExtraImport": true,
        "detail": "ultralytics.nn.tasks",
        "documentation": {}
    },
    {
        "label": "OBBModel",
        "importPath": "ultralytics.nn.tasks",
        "description": "ultralytics.nn.tasks",
        "isExtraImport": true,
        "detail": "ultralytics.nn.tasks",
        "documentation": {}
    },
    {
        "label": "PoseModel",
        "importPath": "ultralytics.nn.tasks",
        "description": "ultralytics.nn.tasks",
        "isExtraImport": true,
        "detail": "ultralytics.nn.tasks",
        "documentation": {}
    },
    {
        "label": "SegmentationModel",
        "importPath": "ultralytics.nn.tasks",
        "description": "ultralytics.nn.tasks",
        "isExtraImport": true,
        "detail": "ultralytics.nn.tasks",
        "documentation": {}
    },
    {
        "label": "WorldModel",
        "importPath": "ultralytics.nn.tasks",
        "description": "ultralytics.nn.tasks",
        "isExtraImport": true,
        "detail": "ultralytics.nn.tasks",
        "documentation": {}
    },
    {
        "label": "ClassificationModel",
        "importPath": "ultralytics.nn.tasks",
        "description": "ultralytics.nn.tasks",
        "isExtraImport": true,
        "detail": "ultralytics.nn.tasks",
        "documentation": {}
    },
    {
        "label": "DetectionModel",
        "importPath": "ultralytics.nn.tasks",
        "description": "ultralytics.nn.tasks",
        "isExtraImport": true,
        "detail": "ultralytics.nn.tasks",
        "documentation": {}
    },
    {
        "label": "OBBModel",
        "importPath": "ultralytics.nn.tasks",
        "description": "ultralytics.nn.tasks",
        "isExtraImport": true,
        "detail": "ultralytics.nn.tasks",
        "documentation": {}
    },
    {
        "label": "PoseModel",
        "importPath": "ultralytics.nn.tasks",
        "description": "ultralytics.nn.tasks",
        "isExtraImport": true,
        "detail": "ultralytics.nn.tasks",
        "documentation": {}
    },
    {
        "label": "SegmentationModel",
        "importPath": "ultralytics.nn.tasks",
        "description": "ultralytics.nn.tasks",
        "isExtraImport": true,
        "detail": "ultralytics.nn.tasks",
        "documentation": {}
    },
    {
        "label": "WorldModel",
        "importPath": "ultralytics.nn.tasks",
        "description": "ultralytics.nn.tasks",
        "isExtraImport": true,
        "detail": "ultralytics.nn.tasks",
        "documentation": {}
    },
    {
        "label": "inspect",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "inspect",
        "description": "inspect",
        "detail": "inspect",
        "documentation": {}
    },
    {
        "label": "HUB_WEB_ROOT",
        "importPath": "ultralytics.hub",
        "description": "ultralytics.hub",
        "isExtraImport": true,
        "detail": "ultralytics.hub",
        "documentation": {}
    },
    {
        "label": "HUBTrainingSession",
        "importPath": "ultralytics.hub",
        "description": "ultralytics.hub",
        "isExtraImport": true,
        "detail": "ultralytics.hub",
        "documentation": {}
    },
    {
        "label": "HUB_WEB_ROOT",
        "importPath": "ultralytics.hub",
        "description": "ultralytics.hub",
        "isExtraImport": true,
        "detail": "ultralytics.hub",
        "documentation": {}
    },
    {
        "label": "PREFIX",
        "importPath": "ultralytics.hub",
        "description": "ultralytics.hub",
        "isExtraImport": true,
        "detail": "ultralytics.hub",
        "documentation": {}
    },
    {
        "label": "HUBTrainingSession",
        "importPath": "ultralytics.hub",
        "description": "ultralytics.hub",
        "isExtraImport": true,
        "detail": "ultralytics.hub",
        "documentation": {}
    },
    {
        "label": "events",
        "importPath": "ultralytics.hub",
        "description": "ultralytics.hub",
        "isExtraImport": true,
        "detail": "ultralytics.hub",
        "documentation": {}
    },
    {
        "label": "lru_cache",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "partial",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "partial",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "check_train_batch_size",
        "importPath": "ultralytics.utils.autobatch",
        "description": "ultralytics.utils.autobatch",
        "isExtraImport": true,
        "detail": "ultralytics.utils.autobatch",
        "documentation": {}
    },
    {
        "label": "ddp_cleanup",
        "importPath": "ultralytics.utils.dist",
        "description": "ultralytics.utils.dist",
        "isExtraImport": true,
        "detail": "ultralytics.utils.dist",
        "documentation": {}
    },
    {
        "label": "generate_ddp_command",
        "importPath": "ultralytics.utils.dist",
        "description": "ultralytics.utils.dist",
        "isExtraImport": true,
        "detail": "ultralytics.utils.dist",
        "documentation": {}
    },
    {
        "label": "HUB_API_ROOT",
        "importPath": "ultralytics.hub.utils",
        "description": "ultralytics.hub.utils",
        "isExtraImport": true,
        "detail": "ultralytics.hub.utils",
        "documentation": {}
    },
    {
        "label": "HUB_WEB_ROOT",
        "importPath": "ultralytics.hub.utils",
        "description": "ultralytics.hub.utils",
        "isExtraImport": true,
        "detail": "ultralytics.hub.utils",
        "documentation": {}
    },
    {
        "label": "PREFIX",
        "importPath": "ultralytics.hub.utils",
        "description": "ultralytics.hub.utils",
        "isExtraImport": true,
        "detail": "ultralytics.hub.utils",
        "documentation": {}
    },
    {
        "label": "request_with_credentials",
        "importPath": "ultralytics.hub.utils",
        "description": "ultralytics.hub.utils",
        "isExtraImport": true,
        "detail": "ultralytics.hub.utils",
        "documentation": {}
    },
    {
        "label": "HELP_MSG",
        "importPath": "ultralytics.hub.utils",
        "description": "ultralytics.hub.utils",
        "isExtraImport": true,
        "detail": "ultralytics.hub.utils",
        "documentation": {}
    },
    {
        "label": "HUB_WEB_ROOT",
        "importPath": "ultralytics.hub.utils",
        "description": "ultralytics.hub.utils",
        "isExtraImport": true,
        "detail": "ultralytics.hub.utils",
        "documentation": {}
    },
    {
        "label": "PREFIX",
        "importPath": "ultralytics.hub.utils",
        "description": "ultralytics.hub.utils",
        "isExtraImport": true,
        "detail": "ultralytics.hub.utils",
        "documentation": {}
    },
    {
        "label": "TQDM",
        "importPath": "ultralytics.hub.utils",
        "description": "ultralytics.hub.utils",
        "isExtraImport": true,
        "detail": "ultralytics.hub.utils",
        "documentation": {}
    },
    {
        "label": "HTTPStatus",
        "importPath": "http",
        "description": "http",
        "isExtraImport": true,
        "detail": "http",
        "documentation": {}
    },
    {
        "label": "HUBModelError",
        "importPath": "ultralytics.utils.errors",
        "description": "ultralytics.utils.errors",
        "isExtraImport": true,
        "detail": "ultralytics.utils.errors",
        "documentation": {}
    },
    {
        "label": "Model",
        "importPath": "ultralytics.engine.model",
        "description": "ultralytics.engine.model",
        "isExtraImport": true,
        "detail": "ultralytics.engine.model",
        "documentation": {}
    },
    {
        "label": "Model",
        "importPath": "ultralytics.engine.model",
        "description": "ultralytics.engine.model",
        "isExtraImport": true,
        "detail": "ultralytics.engine.model",
        "documentation": {}
    },
    {
        "label": "Model",
        "importPath": "ultralytics.engine.model",
        "description": "ultralytics.engine.model",
        "isExtraImport": true,
        "detail": "ultralytics.engine.model",
        "documentation": {}
    },
    {
        "label": "Model",
        "importPath": "ultralytics.engine.model",
        "description": "ultralytics.engine.model",
        "isExtraImport": true,
        "detail": "ultralytics.engine.model",
        "documentation": {}
    },
    {
        "label": "Model",
        "importPath": "ultralytics.engine.model",
        "description": "ultralytics.engine.model",
        "isExtraImport": true,
        "detail": "ultralytics.engine.model",
        "documentation": {}
    },
    {
        "label": "SegmentationPredictor",
        "importPath": "ultralytics.models.yolo.segment",
        "description": "ultralytics.models.yolo.segment",
        "isExtraImport": true,
        "detail": "ultralytics.models.yolo.segment",
        "documentation": {}
    },
    {
        "label": "SegmentationValidator",
        "importPath": "ultralytics.models.yolo.segment",
        "description": "ultralytics.models.yolo.segment",
        "isExtraImport": true,
        "detail": "ultralytics.models.yolo.segment",
        "documentation": {}
    },
    {
        "label": "BasePredictor",
        "importPath": "ultralytics.engine.predictor",
        "description": "ultralytics.engine.predictor",
        "isExtraImport": true,
        "detail": "ultralytics.engine.predictor",
        "documentation": {}
    },
    {
        "label": "BasePredictor",
        "importPath": "ultralytics.engine.predictor",
        "description": "ultralytics.engine.predictor",
        "isExtraImport": true,
        "detail": "ultralytics.engine.predictor",
        "documentation": {}
    },
    {
        "label": "BasePredictor",
        "importPath": "ultralytics.engine.predictor",
        "description": "ultralytics.engine.predictor",
        "isExtraImport": true,
        "detail": "ultralytics.engine.predictor",
        "documentation": {}
    },
    {
        "label": "BasePredictor",
        "importPath": "ultralytics.engine.predictor",
        "description": "ultralytics.engine.predictor",
        "isExtraImport": true,
        "detail": "ultralytics.engine.predictor",
        "documentation": {}
    },
    {
        "label": "BasePredictor",
        "importPath": "ultralytics.engine.predictor",
        "description": "ultralytics.engine.predictor",
        "isExtraImport": true,
        "detail": "ultralytics.engine.predictor",
        "documentation": {}
    },
    {
        "label": "DetectionValidator",
        "importPath": "ultralytics.models.yolo.detect",
        "description": "ultralytics.models.yolo.detect",
        "isExtraImport": true,
        "detail": "ultralytics.models.yolo.detect",
        "documentation": {}
    },
    {
        "label": "DetectionTrainer",
        "importPath": "ultralytics.models.yolo.detect",
        "description": "ultralytics.models.yolo.detect",
        "isExtraImport": true,
        "detail": "ultralytics.models.yolo.detect",
        "documentation": {}
    },
    {
        "label": "DetectionValidator",
        "importPath": "ultralytics.models.yolo.detect",
        "description": "ultralytics.models.yolo.detect",
        "isExtraImport": true,
        "detail": "ultralytics.models.yolo.detect",
        "documentation": {}
    },
    {
        "label": "DetectionValidator",
        "importPath": "ultralytics.models.yolo.detect",
        "description": "ultralytics.models.yolo.detect",
        "isExtraImport": true,
        "detail": "ultralytics.models.yolo.detect",
        "documentation": {}
    },
    {
        "label": "DetectionValidator",
        "importPath": "ultralytics.models.yolo.detect",
        "description": "ultralytics.models.yolo.detect",
        "isExtraImport": true,
        "detail": "ultralytics.models.yolo.detect",
        "documentation": {}
    },
    {
        "label": "DetectionValidator",
        "importPath": "ultralytics.models.yolo.detect",
        "description": "ultralytics.models.yolo.detect",
        "isExtraImport": true,
        "detail": "ultralytics.models.yolo.detect",
        "documentation": {}
    },
    {
        "label": "torch.nn",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.nn",
        "description": "torch.nn",
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "functional",
        "importPath": "torch.nn",
        "description": "torch.nn",
        "isExtraImport": true,
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "torch.nn.functional",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.nn.functional",
        "description": "torch.nn.functional",
        "detail": "torch.nn.functional",
        "documentation": {}
    },
    {
        "label": "torch.utils.checkpoint",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.utils.checkpoint",
        "description": "torch.utils.checkpoint",
        "detail": "torch.utils.checkpoint",
        "documentation": {}
    },
    {
        "label": "FocalLoss",
        "importPath": "ultralytics.utils.loss",
        "description": "ultralytics.utils.loss",
        "isExtraImport": true,
        "detail": "ultralytics.utils.loss",
        "documentation": {}
    },
    {
        "label": "VarifocalLoss",
        "importPath": "ultralytics.utils.loss",
        "description": "ultralytics.utils.loss",
        "isExtraImport": true,
        "detail": "ultralytics.utils.loss",
        "documentation": {}
    },
    {
        "label": "E2EDetectLoss",
        "importPath": "ultralytics.utils.loss",
        "description": "ultralytics.utils.loss",
        "isExtraImport": true,
        "detail": "ultralytics.utils.loss",
        "documentation": {}
    },
    {
        "label": "v8ClassificationLoss",
        "importPath": "ultralytics.utils.loss",
        "description": "ultralytics.utils.loss",
        "isExtraImport": true,
        "detail": "ultralytics.utils.loss",
        "documentation": {}
    },
    {
        "label": "v8DetectionLoss",
        "importPath": "ultralytics.utils.loss",
        "description": "ultralytics.utils.loss",
        "isExtraImport": true,
        "detail": "ultralytics.utils.loss",
        "documentation": {}
    },
    {
        "label": "v8OBBLoss",
        "importPath": "ultralytics.utils.loss",
        "description": "ultralytics.utils.loss",
        "isExtraImport": true,
        "detail": "ultralytics.utils.loss",
        "documentation": {}
    },
    {
        "label": "v8PoseLoss",
        "importPath": "ultralytics.utils.loss",
        "description": "ultralytics.utils.loss",
        "isExtraImport": true,
        "detail": "ultralytics.utils.loss",
        "documentation": {}
    },
    {
        "label": "v8SegmentationLoss",
        "importPath": "ultralytics.utils.loss",
        "description": "ultralytics.utils.loss",
        "isExtraImport": true,
        "detail": "ultralytics.utils.loss",
        "documentation": {}
    },
    {
        "label": "linear_sum_assignment",
        "importPath": "scipy.optimize",
        "description": "scipy.optimize",
        "isExtraImport": true,
        "detail": "scipy.optimize",
        "documentation": {}
    },
    {
        "label": "BaseTrainer",
        "importPath": "ultralytics.engine.trainer",
        "description": "ultralytics.engine.trainer",
        "isExtraImport": true,
        "detail": "ultralytics.engine.trainer",
        "documentation": {}
    },
    {
        "label": "BaseTrainer",
        "importPath": "ultralytics.engine.trainer",
        "description": "ultralytics.engine.trainer",
        "isExtraImport": true,
        "detail": "ultralytics.engine.trainer",
        "documentation": {}
    },
    {
        "label": "yolo",
        "importPath": "ultralytics.models",
        "description": "ultralytics.models",
        "isExtraImport": true,
        "detail": "ultralytics.models",
        "documentation": {}
    },
    {
        "label": "yolo",
        "importPath": "ultralytics.models",
        "description": "ultralytics.models",
        "isExtraImport": true,
        "detail": "ultralytics.models",
        "documentation": {}
    },
    {
        "label": "yolo",
        "importPath": "ultralytics.models",
        "description": "ultralytics.models",
        "isExtraImport": true,
        "detail": "ultralytics.models",
        "documentation": {}
    },
    {
        "label": "yolo",
        "importPath": "ultralytics.models",
        "description": "ultralytics.models",
        "isExtraImport": true,
        "detail": "ultralytics.models",
        "documentation": {}
    },
    {
        "label": "yolo",
        "importPath": "ultralytics.models",
        "description": "ultralytics.models",
        "isExtraImport": true,
        "detail": "ultralytics.models",
        "documentation": {}
    },
    {
        "label": "yolo",
        "importPath": "ultralytics.models",
        "description": "ultralytics.models",
        "isExtraImport": true,
        "detail": "ultralytics.models",
        "documentation": {}
    },
    {
        "label": "yolo",
        "importPath": "ultralytics.models",
        "description": "ultralytics.models",
        "isExtraImport": true,
        "detail": "ultralytics.models",
        "documentation": {}
    },
    {
        "label": "BaseValidator",
        "importPath": "ultralytics.engine.validator",
        "description": "ultralytics.engine.validator",
        "isExtraImport": true,
        "detail": "ultralytics.engine.validator",
        "documentation": {}
    },
    {
        "label": "BaseValidator",
        "importPath": "ultralytics.engine.validator",
        "description": "ultralytics.engine.validator",
        "isExtraImport": true,
        "detail": "ultralytics.engine.validator",
        "documentation": {}
    },
    {
        "label": "DetectionPredictor",
        "importPath": "ultralytics.models.yolo.detect.predict",
        "description": "ultralytics.models.yolo.detect.predict",
        "isExtraImport": true,
        "detail": "ultralytics.models.yolo.detect.predict",
        "documentation": {}
    },
    {
        "label": "DetectionPredictor",
        "importPath": "ultralytics.models.yolo.detect.predict",
        "description": "ultralytics.models.yolo.detect.predict",
        "isExtraImport": true,
        "detail": "ultralytics.models.yolo.detect.predict",
        "documentation": {}
    },
    {
        "label": "DetectionPredictor",
        "importPath": "ultralytics.models.yolo.detect.predict",
        "description": "ultralytics.models.yolo.detect.predict",
        "isExtraImport": true,
        "detail": "ultralytics.models.yolo.detect.predict",
        "documentation": {}
    },
    {
        "label": "WorldTrainer",
        "importPath": "ultralytics.models.yolo.world",
        "description": "ultralytics.models.yolo.world",
        "isExtraImport": true,
        "detail": "ultralytics.models.yolo.world",
        "documentation": {}
    },
    {
        "label": "constant_",
        "importPath": "torch.nn.init",
        "description": "torch.nn.init",
        "isExtraImport": true,
        "detail": "torch.nn.init",
        "documentation": {}
    },
    {
        "label": "xavier_uniform_",
        "importPath": "torch.nn.init",
        "description": "torch.nn.init",
        "isExtraImport": true,
        "detail": "torch.nn.init",
        "documentation": {}
    },
    {
        "label": "constant_",
        "importPath": "torch.nn.init",
        "description": "torch.nn.init",
        "isExtraImport": true,
        "detail": "torch.nn.init",
        "documentation": {}
    },
    {
        "label": "xavier_uniform_",
        "importPath": "torch.nn.init",
        "description": "torch.nn.init",
        "isExtraImport": true,
        "detail": "torch.nn.init",
        "documentation": {}
    },
    {
        "label": "uniform_",
        "importPath": "torch.nn.init",
        "description": "torch.nn.init",
        "isExtraImport": true,
        "detail": "torch.nn.init",
        "documentation": {}
    },
    {
        "label": "TORCH_1_10",
        "importPath": "ultralytics.utils.tal",
        "description": "ultralytics.utils.tal",
        "isExtraImport": true,
        "detail": "ultralytics.utils.tal",
        "documentation": {}
    },
    {
        "label": "dist2bbox",
        "importPath": "ultralytics.utils.tal",
        "description": "ultralytics.utils.tal",
        "isExtraImport": true,
        "detail": "ultralytics.utils.tal",
        "documentation": {}
    },
    {
        "label": "dist2rbox",
        "importPath": "ultralytics.utils.tal",
        "description": "ultralytics.utils.tal",
        "isExtraImport": true,
        "detail": "ultralytics.utils.tal",
        "documentation": {}
    },
    {
        "label": "make_anchors",
        "importPath": "ultralytics.utils.tal",
        "description": "ultralytics.utils.tal",
        "isExtraImport": true,
        "detail": "ultralytics.utils.tal",
        "documentation": {}
    },
    {
        "label": "RotatedTaskAlignedAssigner",
        "importPath": "ultralytics.utils.tal",
        "description": "ultralytics.utils.tal",
        "isExtraImport": true,
        "detail": "ultralytics.utils.tal",
        "documentation": {}
    },
    {
        "label": "TaskAlignedAssigner",
        "importPath": "ultralytics.utils.tal",
        "description": "ultralytics.utils.tal",
        "isExtraImport": true,
        "detail": "ultralytics.utils.tal",
        "documentation": {}
    },
    {
        "label": "dist2bbox",
        "importPath": "ultralytics.utils.tal",
        "description": "ultralytics.utils.tal",
        "isExtraImport": true,
        "detail": "ultralytics.utils.tal",
        "documentation": {}
    },
    {
        "label": "dist2rbox",
        "importPath": "ultralytics.utils.tal",
        "description": "ultralytics.utils.tal",
        "isExtraImport": true,
        "detail": "ultralytics.utils.tal",
        "documentation": {}
    },
    {
        "label": "make_anchors",
        "importPath": "ultralytics.utils.tal",
        "description": "ultralytics.utils.tal",
        "isExtraImport": true,
        "detail": "ultralytics.utils.tal",
        "documentation": {}
    },
    {
        "label": "ast",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "ast",
        "description": "ast",
        "detail": "ast",
        "documentation": {}
    },
    {
        "label": "matplotlib.pyplot",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.pyplot",
        "description": "matplotlib.pyplot",
        "detail": "matplotlib.pyplot",
        "documentation": {}
    },
    {
        "label": "FigureCanvasAgg",
        "importPath": "matplotlib.backends.backend_agg",
        "description": "matplotlib.backends.backend_agg",
        "isExtraImport": true,
        "detail": "matplotlib.backends.backend_agg",
        "documentation": {}
    },
    {
        "label": "Figure",
        "importPath": "matplotlib.figure",
        "description": "matplotlib.figure",
        "isExtraImport": true,
        "detail": "matplotlib.figure",
        "documentation": {}
    },
    {
        "label": "scipy.linalg",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "scipy.linalg",
        "description": "scipy.linalg",
        "detail": "scipy.linalg",
        "documentation": {}
    },
    {
        "label": "scipy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "scipy",
        "description": "scipy",
        "detail": "scipy",
        "documentation": {}
    },
    {
        "label": "cdist",
        "importPath": "scipy.spatial.distance",
        "description": "scipy.spatial.distance",
        "isExtraImport": true,
        "detail": "scipy.spatial.distance",
        "documentation": {}
    },
    {
        "label": "torch.cuda",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.cuda",
        "description": "torch.cuda",
        "detail": "torch.cuda",
        "documentation": {}
    },
    {
        "label": "metadata",
        "importPath": "importlib",
        "description": "importlib",
        "isExtraImport": true,
        "detail": "importlib",
        "documentation": {}
    },
    {
        "label": "socket",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "socket",
        "description": "socket",
        "detail": "socket",
        "documentation": {}
    },
    {
        "label": "tempfile",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tempfile",
        "description": "tempfile",
        "detail": "tempfile",
        "documentation": {}
    },
    {
        "label": "Number",
        "importPath": "numbers",
        "description": "numbers",
        "isExtraImport": true,
        "detail": "numbers",
        "documentation": {}
    },
    {
        "label": "torch.distributed",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.distributed",
        "description": "torch.distributed",
        "detail": "torch.distributed",
        "documentation": {}
    },
    {
        "label": "CameraSetting",
        "kind": 6,
        "importPath": "api.app",
        "description": "api.app",
        "peekOfCode": "class CameraSetting(BaseModel):\n    type: str\n    local: str\n    url: str\nclass ConfigSetting:\n    model:str\n    camera_type: str\n    camera_local: str\n    camera_url: str\n    taocan_id: int",
        "detail": "api.app",
        "documentation": {}
    },
    {
        "label": "ConfigSetting",
        "kind": 6,
        "importPath": "api.app",
        "description": "api.app",
        "peekOfCode": "class ConfigSetting:\n    model:str\n    camera_type: str\n    camera_local: str\n    camera_url: str\n    taocan_id: int\n    data_type: str\n    video_source :str\n    video_target :str\napp = FastAPI()",
        "detail": "api.app",
        "documentation": {}
    },
    {
        "label": "ModeDataSourceRequest",
        "kind": 6,
        "importPath": "api.app",
        "description": "api.app",
        "peekOfCode": "class ModeDataSourceRequest(BaseModel):\n    mode: str = Field(default=\"huiji_detect\", enum=[\"huiji_detect\", \"person_detect\"])\n    data_source_type: str = Field(default=\"camera\", enum=[\"camera\", \"video_file\"])\n    data_source: str = Field(..., min_length=1, description=\"数据源不能为空\")\n@app.post(\"/mode_datasource\")\nasync def set_mode_datasource(request: ModeDataSourceRequest):\n    conf.current_mode = request.mode\n    def update_datasource(detect_config):\n        detect_config['data_source_type'] = request.data_source_type\n        if request.data_source_type == 'camera':",
        "detail": "api.app",
        "documentation": {}
    },
    {
        "label": "pad_frame",
        "kind": 2,
        "importPath": "api.app",
        "description": "api.app",
        "peekOfCode": "def pad_frame(frame):\n    return (b'--frame\\r\\n Content-Type: image/jpeg\\r\\n\\r\\n' + frame + b'\\r\\n')\n@app.get('/video_source_feed')\nasync def video_source_feed():\n    if conf.current_mode == 'huiji_detect':\n        img_stream = (pad_frame(r['orig_frame']) for r in video_srv.huiji_detect_frames())\n        return StreamingResponse(img_stream, media_type=\"multipart/x-mixed-replace; boundary=frame\")\n    else:\n        img_stream = (pad_frame(r['tracked_frame']) for r in video_srv.person_detect_frames())\n        return StreamingResponse(img_stream, media_type=\"multipart/x-mixed-replace; boundary=frame\")",
        "detail": "api.app",
        "documentation": {}
    },
    {
        "label": "app",
        "kind": 5,
        "importPath": "api.app",
        "description": "api.app",
        "peekOfCode": "app = FastAPI()\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"http://pinda.cn\",\"http://127.0.0.1:8000\"],\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n@app.get(\"/demo_huiji\")\nasync def demo_huiji():",
        "detail": "api.app",
        "documentation": {}
    },
    {
        "label": "app.router.lifespan_context",
        "kind": 5,
        "importPath": "api.app",
        "description": "api.app",
        "peekOfCode": "app.router.lifespan_context = lifespan\nif __name__ == \"__main__\":\n    import uvicorn\n    uvicorn.run(app, host=\"0.0.0.0\", port=6789, log_level=\"info\")",
        "detail": "api.app",
        "documentation": {}
    },
    {
        "label": "prepare_docs_markdown",
        "kind": 2,
        "importPath": "docs.build_docs",
        "description": "docs.build_docs",
        "peekOfCode": "def prepare_docs_markdown(clone_repos=True):\n    \"\"\"Build docs using mkdocs.\"\"\"\n    if SITE.exists():\n        print(f\"Removing existing {SITE}\")\n        shutil.rmtree(SITE)\n    # Get hub-sdk repo\n    if clone_repos:\n        repo = \"https://github.com/ultralytics/hub-sdk\"\n        local_dir = DOCS.parent / Path(repo).name\n        if not local_dir.exists():",
        "detail": "docs.build_docs",
        "documentation": {}
    },
    {
        "label": "update_page_title",
        "kind": 2,
        "importPath": "docs.build_docs",
        "description": "docs.build_docs",
        "peekOfCode": "def update_page_title(file_path: Path, new_title: str):\n    \"\"\"Update the title of an HTML file.\"\"\"\n    # Read the content of the file\n    with open(file_path, encoding=\"utf-8\") as file:\n        content = file.read()\n    # Replace the existing title with the new title\n    updated_content = re.sub(r\"<title>.*?</title>\", f\"<title>{new_title}</title>\", content)\n    # Write the updated content back to the file\n    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n        file.write(updated_content)",
        "detail": "docs.build_docs",
        "documentation": {}
    },
    {
        "label": "update_html_head",
        "kind": 2,
        "importPath": "docs.build_docs",
        "description": "docs.build_docs",
        "peekOfCode": "def update_html_head(script=\"\"):\n    \"\"\"Update the HTML head section of each file.\"\"\"\n    html_files = Path(SITE).rglob(\"*.html\")\n    for html_file in tqdm(html_files, desc=\"Processing HTML files\"):\n        with html_file.open(\"r\", encoding=\"utf-8\") as file:\n            html_content = file.read()\n        if script in html_content:  # script already in HTML file\n            return\n        head_end_index = html_content.lower().rfind(\"</head>\")\n        if head_end_index != -1:",
        "detail": "docs.build_docs",
        "documentation": {}
    },
    {
        "label": "update_subdir_edit_links",
        "kind": 2,
        "importPath": "docs.build_docs",
        "description": "docs.build_docs",
        "peekOfCode": "def update_subdir_edit_links(subdir=\"\", docs_url=\"\"):\n    \"\"\"Update the HTML head section of each file.\"\"\"\n    if str(subdir[0]) == \"/\":\n        subdir = str(subdir[0])[1:]\n    html_files = (SITE / subdir).rglob(\"*.html\")\n    for html_file in tqdm(html_files, desc=\"Processing subdir files\"):\n        with html_file.open(\"r\", encoding=\"utf-8\") as file:\n            soup = BeautifulSoup(file, \"html.parser\")\n        # Find the anchor tag and update its href attribute\n        a_tag = soup.find(\"a\", {\"class\": \"md-content__button md-icon\"})",
        "detail": "docs.build_docs",
        "documentation": {}
    },
    {
        "label": "update_markdown_files",
        "kind": 2,
        "importPath": "docs.build_docs",
        "description": "docs.build_docs",
        "peekOfCode": "def update_markdown_files(md_filepath: Path):\n    \"\"\"Creates or updates a Markdown file, ensuring frontmatter is present.\"\"\"\n    if md_filepath.exists():\n        content = md_filepath.read_text().strip()\n        # Replace apostrophes\n        content = content.replace(\"‘\", \"'\").replace(\"’\", \"'\")\n        # Add frontmatter if missing\n        if not content.strip().startswith(\"---\\n\"):\n            header = \"---\\ncomments: true\\ndescription: TODO ADD DESCRIPTION\\nkeywords: TODO ADD KEYWORDS\\n---\\n\\n\"\n            content = header + content",
        "detail": "docs.build_docs",
        "documentation": {}
    },
    {
        "label": "update_docs_html",
        "kind": 2,
        "importPath": "docs.build_docs",
        "description": "docs.build_docs",
        "peekOfCode": "def update_docs_html():\n    \"\"\"Updates titles, edit links, head sections, and converts plaintext links in HTML documentation.\"\"\"\n    update_page_title(SITE / \"404.html\", new_title=\"Ultralytics Docs - Not Found\")\n    # Update edit links\n    update_subdir_edit_links(\n        subdir=\"hub/sdk/\",  # do not use leading slash\n        docs_url=\"https://github.com/ultralytics/hub-sdk/tree/main/docs/\",\n    )\n    # Convert plaintext links to HTML hyperlinks\n    files_modified = 0",
        "detail": "docs.build_docs",
        "documentation": {}
    },
    {
        "label": "convert_plaintext_links_to_html",
        "kind": 2,
        "importPath": "docs.build_docs",
        "description": "docs.build_docs",
        "peekOfCode": "def convert_plaintext_links_to_html(content):\n    \"\"\"Convert plaintext links to HTML hyperlinks in the main content area only.\"\"\"\n    soup = BeautifulSoup(content, \"html.parser\")\n    # Find the main content area (adjust this selector based on your HTML structure)\n    main_content = soup.find(\"main\") or soup.find(\"div\", class_=\"md-content\")\n    if not main_content:\n        return content  # Return original content if main content area not found\n    modified = False\n    for paragraph in main_content.find_all([\"p\", \"li\"]):  # Focus on paragraphs and list items\n        for text_node in paragraph.find_all(string=True, recursive=False):",
        "detail": "docs.build_docs",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "docs.build_docs",
        "description": "docs.build_docs",
        "peekOfCode": "def main():\n    \"\"\"Builds docs, updates titles and edit links, and prints local server command.\"\"\"\n    prepare_docs_markdown()\n    # Build the main documentation\n    print(f\"Building docs from {DOCS}\")\n    subprocess.run(f\"mkdocs build -f {DOCS.parent}/mkdocs.yml --strict\", check=True, shell=True)\n    print(f\"Site built at {SITE}\")\n    # Update docs HTML pages\n    update_docs_html()\n    # Show command to serve built website",
        "detail": "docs.build_docs",
        "documentation": {}
    },
    {
        "label": "os.environ[\"JUPYTER_PLATFORM_DIRS\"]",
        "kind": 5,
        "importPath": "docs.build_docs",
        "description": "docs.build_docs",
        "peekOfCode": "os.environ[\"JUPYTER_PLATFORM_DIRS\"] = \"1\"  # fix DeprecationWarning: Jupyter is migrating to use standard platformdirs\nDOCS = Path(__file__).parent.resolve()\nSITE = DOCS.parent / \"site\"\ndef prepare_docs_markdown(clone_repos=True):\n    \"\"\"Build docs using mkdocs.\"\"\"\n    if SITE.exists():\n        print(f\"Removing existing {SITE}\")\n        shutil.rmtree(SITE)\n    # Get hub-sdk repo\n    if clone_repos:",
        "detail": "docs.build_docs",
        "documentation": {}
    },
    {
        "label": "DOCS",
        "kind": 5,
        "importPath": "docs.build_docs",
        "description": "docs.build_docs",
        "peekOfCode": "DOCS = Path(__file__).parent.resolve()\nSITE = DOCS.parent / \"site\"\ndef prepare_docs_markdown(clone_repos=True):\n    \"\"\"Build docs using mkdocs.\"\"\"\n    if SITE.exists():\n        print(f\"Removing existing {SITE}\")\n        shutil.rmtree(SITE)\n    # Get hub-sdk repo\n    if clone_repos:\n        repo = \"https://github.com/ultralytics/hub-sdk\"",
        "detail": "docs.build_docs",
        "documentation": {}
    },
    {
        "label": "SITE",
        "kind": 5,
        "importPath": "docs.build_docs",
        "description": "docs.build_docs",
        "peekOfCode": "SITE = DOCS.parent / \"site\"\ndef prepare_docs_markdown(clone_repos=True):\n    \"\"\"Build docs using mkdocs.\"\"\"\n    if SITE.exists():\n        print(f\"Removing existing {SITE}\")\n        shutil.rmtree(SITE)\n    # Get hub-sdk repo\n    if clone_repos:\n        repo = \"https://github.com/ultralytics/hub-sdk\"\n        local_dir = DOCS.parent / Path(repo).name",
        "detail": "docs.build_docs",
        "documentation": {}
    },
    {
        "label": "extract_classes_and_functions",
        "kind": 2,
        "importPath": "docs.build_reference",
        "description": "docs.build_reference",
        "peekOfCode": "def extract_classes_and_functions(filepath: Path) -> tuple:\n    \"\"\"Extracts class and function names from a given Python file.\"\"\"\n    content = filepath.read_text()\n    class_pattern = r\"(?:^|\\n)class\\s(\\w+)(?:\\(|:)\"\n    func_pattern = r\"(?:^|\\n)def\\s(\\w+)\\(\"\n    classes = re.findall(class_pattern, content)\n    functions = re.findall(func_pattern, content)\n    return classes, functions\ndef create_markdown(py_filepath: Path, module_path: str, classes: list, functions: list):\n    \"\"\"Creates a Markdown file containing the API reference for the given Python module.\"\"\"",
        "detail": "docs.build_reference",
        "documentation": {}
    },
    {
        "label": "create_markdown",
        "kind": 2,
        "importPath": "docs.build_reference",
        "description": "docs.build_reference",
        "peekOfCode": "def create_markdown(py_filepath: Path, module_path: str, classes: list, functions: list):\n    \"\"\"Creates a Markdown file containing the API reference for the given Python module.\"\"\"\n    md_filepath = py_filepath.with_suffix(\".md\")\n    exists = md_filepath.exists()\n    # Read existing content and keep header content between first two ---\n    header_content = \"\"\n    if exists:\n        existing_content = md_filepath.read_text()\n        header_parts = existing_content.split(\"---\")\n        for part in header_parts:",
        "detail": "docs.build_reference",
        "documentation": {}
    },
    {
        "label": "nested_dict",
        "kind": 2,
        "importPath": "docs.build_reference",
        "description": "docs.build_reference",
        "peekOfCode": "def nested_dict() -> defaultdict:\n    \"\"\"Creates and returns a nested defaultdict.\"\"\"\n    return defaultdict(nested_dict)\ndef sort_nested_dict(d: dict) -> dict:\n    \"\"\"Sorts a nested dictionary recursively.\"\"\"\n    return {key: sort_nested_dict(value) if isinstance(value, dict) else value for key, value in sorted(d.items())}\ndef create_nav_menu_yaml(nav_items: list, save: bool = False):\n    \"\"\"Creates a YAML file for the navigation menu based on the provided list of items.\"\"\"\n    nav_tree = nested_dict()\n    for item_str in nav_items:",
        "detail": "docs.build_reference",
        "documentation": {}
    },
    {
        "label": "sort_nested_dict",
        "kind": 2,
        "importPath": "docs.build_reference",
        "description": "docs.build_reference",
        "peekOfCode": "def sort_nested_dict(d: dict) -> dict:\n    \"\"\"Sorts a nested dictionary recursively.\"\"\"\n    return {key: sort_nested_dict(value) if isinstance(value, dict) else value for key, value in sorted(d.items())}\ndef create_nav_menu_yaml(nav_items: list, save: bool = False):\n    \"\"\"Creates a YAML file for the navigation menu based on the provided list of items.\"\"\"\n    nav_tree = nested_dict()\n    for item_str in nav_items:\n        item = Path(item_str)\n        parts = item.parts\n        current_level = nav_tree[\"reference\"]",
        "detail": "docs.build_reference",
        "documentation": {}
    },
    {
        "label": "create_nav_menu_yaml",
        "kind": 2,
        "importPath": "docs.build_reference",
        "description": "docs.build_reference",
        "peekOfCode": "def create_nav_menu_yaml(nav_items: list, save: bool = False):\n    \"\"\"Creates a YAML file for the navigation menu based on the provided list of items.\"\"\"\n    nav_tree = nested_dict()\n    for item_str in nav_items:\n        item = Path(item_str)\n        parts = item.parts\n        current_level = nav_tree[\"reference\"]\n        for part in parts[2:-1]:  # skip the first two parts (docs and reference) and the last part (filename)\n            current_level = current_level[part]\n        md_file_name = parts[-1].replace(\".md\", \"\")",
        "detail": "docs.build_reference",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "docs.build_reference",
        "description": "docs.build_reference",
        "peekOfCode": "def main():\n    \"\"\"Main function to extract class and function names, create Markdown files, and generate a YAML navigation menu.\"\"\"\n    nav_items = []\n    for py_filepath in PACKAGE_DIR.rglob(\"*.py\"):\n        classes, functions = extract_classes_and_functions(py_filepath)\n        if classes or functions:\n            py_filepath_rel = py_filepath.relative_to(PACKAGE_DIR)\n            md_filepath = REFERENCE_DIR / py_filepath_rel\n            module_path = f\"{PACKAGE_DIR.name}.{py_filepath_rel.with_suffix('').as_posix().replace('/', '.')}\"\n            md_rel_filepath = create_markdown(md_filepath, module_path, classes, functions)",
        "detail": "docs.build_reference",
        "documentation": {}
    },
    {
        "label": "hub_sdk",
        "kind": 5,
        "importPath": "docs.build_reference",
        "description": "docs.build_reference",
        "peekOfCode": "hub_sdk = False\nif hub_sdk:\n    PACKAGE_DIR = Path(\"/Users/glennjocher/PycharmProjects/hub-sdk/hub_sdk\")\n    REFERENCE_DIR = PACKAGE_DIR.parent / \"docs/reference\"\n    GITHUB_REPO = \"ultralytics/hub-sdk\"\nelse:\n    FILE = Path(__file__).resolve()\n    PACKAGE_DIR = FILE.parents[1] / \"ultralytics\"  # i.e. /Users/glennjocher/PycharmProjects/ultralytics/ultralytics\n    REFERENCE_DIR = PACKAGE_DIR.parent / \"docs/en/reference\"\n    GITHUB_REPO = \"ultralytics/ultralytics\"",
        "detail": "docs.build_reference",
        "documentation": {}
    },
    {
        "label": "TorchVisionVideoClassifier",
        "kind": 6,
        "importPath": "examples.YOLOv8-Action-Recognition.action_recognition",
        "description": "examples.YOLOv8-Action-Recognition.action_recognition",
        "peekOfCode": "class TorchVisionVideoClassifier:\n    \"\"\"Classifies videos using pretrained TorchVision models; see https://pytorch.org/vision/stable/.\"\"\"\n    from torchvision.models.video import (\n        MViT_V1_B_Weights,\n        MViT_V2_S_Weights,\n        R3D_18_Weights,\n        S3D_Weights,\n        Swin3D_B_Weights,\n        Swin3D_T_Weights,\n        mvit_v1_b,",
        "detail": "examples.YOLOv8-Action-Recognition.action_recognition",
        "documentation": {}
    },
    {
        "label": "HuggingFaceVideoClassifier",
        "kind": 6,
        "importPath": "examples.YOLOv8-Action-Recognition.action_recognition",
        "description": "examples.YOLOv8-Action-Recognition.action_recognition",
        "peekOfCode": "class HuggingFaceVideoClassifier:\n    \"\"\"Zero-shot video classifier using Hugging Face models for various devices.\"\"\"\n    def __init__(\n        self,\n        labels: List[str],\n        model_name: str = \"microsoft/xclip-base-patch16-zero-shot\",\n        device: str or torch.device = \"\",\n        fp16: bool = False,\n    ):\n        \"\"\"",
        "detail": "examples.YOLOv8-Action-Recognition.action_recognition",
        "documentation": {}
    },
    {
        "label": "crop_and_pad",
        "kind": 2,
        "importPath": "examples.YOLOv8-Action-Recognition.action_recognition",
        "description": "examples.YOLOv8-Action-Recognition.action_recognition",
        "peekOfCode": "def crop_and_pad(frame, box, margin_percent):\n    \"\"\"Crop box with margin and take square crop from frame.\"\"\"\n    x1, y1, x2, y2 = map(int, box)\n    w, h = x2 - x1, y2 - y1\n    # Add margin\n    margin_x, margin_y = int(w * margin_percent / 100), int(h * margin_percent / 100)\n    x1, y1 = max(0, x1 - margin_x), max(0, y1 - margin_y)\n    x2, y2 = min(frame.shape[1], x2 + margin_x), min(frame.shape[0], y2 + margin_y)\n    # Take square crop from frame\n    size = max(y2 - y1, x2 - x1)",
        "detail": "examples.YOLOv8-Action-Recognition.action_recognition",
        "documentation": {}
    },
    {
        "label": "run",
        "kind": 2,
        "importPath": "examples.YOLOv8-Action-Recognition.action_recognition",
        "description": "examples.YOLOv8-Action-Recognition.action_recognition",
        "peekOfCode": "def run(\n    weights: str = \"yolov8n.pt\",\n    device: str = \"\",\n    source: str = \"https://www.youtube.com/watch?v=dQw4w9WgXcQ\",\n    output_path: Optional[str] = None,\n    crop_margin_percentage: int = 10,\n    num_video_sequence_samples: int = 8,\n    skip_frame: int = 2,\n    video_cls_overlap_ratio: float = 0.25,\n    fp16: bool = False,",
        "detail": "examples.YOLOv8-Action-Recognition.action_recognition",
        "documentation": {}
    },
    {
        "label": "parse_opt",
        "kind": 2,
        "importPath": "examples.YOLOv8-Action-Recognition.action_recognition",
        "description": "examples.YOLOv8-Action-Recognition.action_recognition",
        "peekOfCode": "def parse_opt():\n    \"\"\"Parse command line arguments.\"\"\"\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--weights\", type=str, default=\"yolov8n.pt\", help=\"ultralytics detector model path\")\n    parser.add_argument(\"--device\", default=\"\", help='cuda device, i.e. 0 or 0,1,2,3 or cpu/mps, \"\" for auto-detection')\n    parser.add_argument(\n        \"--source\",\n        type=str,\n        default=\"https://www.youtube.com/watch?v=dQw4w9WgXcQ\",\n        help=\"video file path or youtube URL\",",
        "detail": "examples.YOLOv8-Action-Recognition.action_recognition",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "examples.YOLOv8-Action-Recognition.action_recognition",
        "description": "examples.YOLOv8-Action-Recognition.action_recognition",
        "peekOfCode": "def main(opt):\n    \"\"\"Main function.\"\"\"\n    run(**vars(opt))\nif __name__ == \"__main__\":\n    opt = parse_opt()\n    main(opt)",
        "detail": "examples.YOLOv8-Action-Recognition.action_recognition",
        "documentation": {}
    },
    {
        "label": "YOLOv8",
        "kind": 6,
        "importPath": "examples.YOLOv8-ONNXRuntime.main",
        "description": "examples.YOLOv8-ONNXRuntime.main",
        "peekOfCode": "class YOLOv8:\n    \"\"\"YOLOv8 object detection model class for handling inference and visualization.\"\"\"\n    def __init__(self, onnx_model, input_image, confidence_thres, iou_thres):\n        \"\"\"\n        Initializes an instance of the YOLOv8 class.\n        Args:\n            onnx_model: Path to the ONNX model.\n            input_image: Path to the input image.\n            confidence_thres: Confidence threshold for filtering detections.\n            iou_thres: IoU (Intersection over Union) threshold for non-maximum suppression.",
        "detail": "examples.YOLOv8-ONNXRuntime.main",
        "documentation": {}
    },
    {
        "label": "draw_bounding_box",
        "kind": 2,
        "importPath": "examples.YOLOv8-OpenCV-ONNX-Python.main",
        "description": "examples.YOLOv8-OpenCV-ONNX-Python.main",
        "peekOfCode": "def draw_bounding_box(img, class_id, confidence, x, y, x_plus_w, y_plus_h):\n    \"\"\"\n    Draws bounding boxes on the input image based on the provided arguments.\n    Args:\n        img (numpy.ndarray): The input image to draw the bounding box on.\n        class_id (int): Class ID of the detected object.\n        confidence (float): Confidence score of the detected object.\n        x (int): X-coordinate of the top-left corner of the bounding box.\n        y (int): Y-coordinate of the top-left corner of the bounding box.\n        x_plus_w (int): X-coordinate of the bottom-right corner of the bounding box.",
        "detail": "examples.YOLOv8-OpenCV-ONNX-Python.main",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "examples.YOLOv8-OpenCV-ONNX-Python.main",
        "description": "examples.YOLOv8-OpenCV-ONNX-Python.main",
        "peekOfCode": "def main(onnx_model, input_image):\n    \"\"\"\n    Main function to load ONNX model, perform inference, draw bounding boxes, and display the output image.\n    Args:\n        onnx_model (str): Path to the ONNX model.\n        input_image (str): Path to the input image.\n    Returns:\n        list: List of dictionaries containing detection information such as class_id, class_name, confidence, etc.\n    \"\"\"\n    # Load the ONNX model",
        "detail": "examples.YOLOv8-OpenCV-ONNX-Python.main",
        "documentation": {}
    },
    {
        "label": "CLASSES",
        "kind": 5,
        "importPath": "examples.YOLOv8-OpenCV-ONNX-Python.main",
        "description": "examples.YOLOv8-OpenCV-ONNX-Python.main",
        "peekOfCode": "CLASSES = yaml_load(check_yaml(\"coco8.yaml\"))[\"names\"]\ncolors = np.random.uniform(0, 255, size=(len(CLASSES), 3))\ndef draw_bounding_box(img, class_id, confidence, x, y, x_plus_w, y_plus_h):\n    \"\"\"\n    Draws bounding boxes on the input image based on the provided arguments.\n    Args:\n        img (numpy.ndarray): The input image to draw the bounding box on.\n        class_id (int): Class ID of the detected object.\n        confidence (float): Confidence score of the detected object.\n        x (int): X-coordinate of the top-left corner of the bounding box.",
        "detail": "examples.YOLOv8-OpenCV-ONNX-Python.main",
        "documentation": {}
    },
    {
        "label": "colors",
        "kind": 5,
        "importPath": "examples.YOLOv8-OpenCV-ONNX-Python.main",
        "description": "examples.YOLOv8-OpenCV-ONNX-Python.main",
        "peekOfCode": "colors = np.random.uniform(0, 255, size=(len(CLASSES), 3))\ndef draw_bounding_box(img, class_id, confidence, x, y, x_plus_w, y_plus_h):\n    \"\"\"\n    Draws bounding boxes on the input image based on the provided arguments.\n    Args:\n        img (numpy.ndarray): The input image to draw the bounding box on.\n        class_id (int): Class ID of the detected object.\n        confidence (float): Confidence score of the detected object.\n        x (int): X-coordinate of the top-left corner of the bounding box.\n        y (int): Y-coordinate of the top-left corner of the bounding box.",
        "detail": "examples.YOLOv8-OpenCV-ONNX-Python.main",
        "documentation": {}
    },
    {
        "label": "LetterBox",
        "kind": 6,
        "importPath": "examples.YOLOv8-OpenCV-int8-tflite-Python.main",
        "description": "examples.YOLOv8-OpenCV-int8-tflite-Python.main",
        "peekOfCode": "class LetterBox:\n    \"\"\"Resizes and reshapes images while maintaining aspect ratio by adding padding, suitable for YOLO models.\"\"\"\n    def __init__(\n        self, new_shape=(img_width, img_height), auto=False, scaleFill=False, scaleup=True, center=True, stride=32\n    ):\n        \"\"\"Initializes LetterBox with parameters for reshaping and transforming image while maintaining aspect ratio.\"\"\"\n        self.new_shape = new_shape\n        self.auto = auto\n        self.scaleFill = scaleFill\n        self.scaleup = scaleup",
        "detail": "examples.YOLOv8-OpenCV-int8-tflite-Python.main",
        "documentation": {}
    },
    {
        "label": "Yolov8TFLite",
        "kind": 6,
        "importPath": "examples.YOLOv8-OpenCV-int8-tflite-Python.main",
        "description": "examples.YOLOv8-OpenCV-int8-tflite-Python.main",
        "peekOfCode": "class Yolov8TFLite:\n    \"\"\"Class for performing object detection using YOLOv8 model converted to TensorFlow Lite format.\"\"\"\n    def __init__(self, tflite_model, input_image, confidence_thres, iou_thres):\n        \"\"\"\n        Initializes an instance of the Yolov8TFLite class.\n        Args:\n            tflite_model: Path to the TFLite model.\n            input_image: Path to the input image.\n            confidence_thres: Confidence threshold for filtering detections.\n            iou_thres: IoU (Intersection over Union) threshold for non-maximum suppression.",
        "detail": "examples.YOLOv8-OpenCV-int8-tflite-Python.main",
        "documentation": {}
    },
    {
        "label": "img_width",
        "kind": 5,
        "importPath": "examples.YOLOv8-OpenCV-int8-tflite-Python.main",
        "description": "examples.YOLOv8-OpenCV-int8-tflite-Python.main",
        "peekOfCode": "img_width = 640\nimg_height = 640\nclass LetterBox:\n    \"\"\"Resizes and reshapes images while maintaining aspect ratio by adding padding, suitable for YOLO models.\"\"\"\n    def __init__(\n        self, new_shape=(img_width, img_height), auto=False, scaleFill=False, scaleup=True, center=True, stride=32\n    ):\n        \"\"\"Initializes LetterBox with parameters for reshaping and transforming image while maintaining aspect ratio.\"\"\"\n        self.new_shape = new_shape\n        self.auto = auto",
        "detail": "examples.YOLOv8-OpenCV-int8-tflite-Python.main",
        "documentation": {}
    },
    {
        "label": "img_height",
        "kind": 5,
        "importPath": "examples.YOLOv8-OpenCV-int8-tflite-Python.main",
        "description": "examples.YOLOv8-OpenCV-int8-tflite-Python.main",
        "peekOfCode": "img_height = 640\nclass LetterBox:\n    \"\"\"Resizes and reshapes images while maintaining aspect ratio by adding padding, suitable for YOLO models.\"\"\"\n    def __init__(\n        self, new_shape=(img_width, img_height), auto=False, scaleFill=False, scaleup=True, center=True, stride=32\n    ):\n        \"\"\"Initializes LetterBox with parameters for reshaping and transforming image while maintaining aspect ratio.\"\"\"\n        self.new_shape = new_shape\n        self.auto = auto\n        self.scaleFill = scaleFill",
        "detail": "examples.YOLOv8-OpenCV-int8-tflite-Python.main",
        "documentation": {}
    },
    {
        "label": "mouse_callback",
        "kind": 2,
        "importPath": "examples.YOLOv8-Region-Counter.yolov8_region_counter",
        "description": "examples.YOLOv8-Region-Counter.yolov8_region_counter",
        "peekOfCode": "def mouse_callback(event, x, y, flags, param):\n    \"\"\"\n    Handles mouse events for region manipulation.\n    Parameters:\n        event (int): The mouse event type (e.g., cv2.EVENT_LBUTTONDOWN).\n        x (int): The x-coordinate of the mouse pointer.\n        y (int): The y-coordinate of the mouse pointer.\n        flags (int): Additional flags passed by OpenCV.\n        param: Additional parameters passed to the callback (not used in this function).\n    Global Variables:",
        "detail": "examples.YOLOv8-Region-Counter.yolov8_region_counter",
        "documentation": {}
    },
    {
        "label": "run",
        "kind": 2,
        "importPath": "examples.YOLOv8-Region-Counter.yolov8_region_counter",
        "description": "examples.YOLOv8-Region-Counter.yolov8_region_counter",
        "peekOfCode": "def run(\n    weights=\"yolov8n.pt\",\n    source=None,\n    device=\"cpu\",\n    view_img=False,\n    save_img=False,\n    exist_ok=False,\n    classes=None,\n    line_thickness=2,\n    track_thickness=2,",
        "detail": "examples.YOLOv8-Region-Counter.yolov8_region_counter",
        "documentation": {}
    },
    {
        "label": "parse_opt",
        "kind": 2,
        "importPath": "examples.YOLOv8-Region-Counter.yolov8_region_counter",
        "description": "examples.YOLOv8-Region-Counter.yolov8_region_counter",
        "peekOfCode": "def parse_opt():\n    \"\"\"Parse command line arguments.\"\"\"\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--weights\", type=str, default=\"yolov8n.pt\", help=\"initial weights path\")\n    parser.add_argument(\"--device\", default=\"\", help=\"cuda device, i.e. 0 or 0,1,2,3 or cpu\")\n    parser.add_argument(\"--source\", type=str, required=True, help=\"video file path\")\n    parser.add_argument(\"--view-img\", action=\"store_true\", help=\"show results\")\n    parser.add_argument(\"--save-img\", action=\"store_true\", help=\"save results\")\n    parser.add_argument(\"--exist-ok\", action=\"store_true\", help=\"existing project/name ok, do not increment\")\n    parser.add_argument(\"--classes\", nargs=\"+\", type=int, help=\"filter by class: --classes 0, or --classes 0 2 3\")",
        "detail": "examples.YOLOv8-Region-Counter.yolov8_region_counter",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "examples.YOLOv8-Region-Counter.yolov8_region_counter",
        "description": "examples.YOLOv8-Region-Counter.yolov8_region_counter",
        "peekOfCode": "def main(opt):\n    \"\"\"Main function.\"\"\"\n    run(**vars(opt))\nif __name__ == \"__main__\":\n    opt = parse_opt()\n    main(opt)",
        "detail": "examples.YOLOv8-Region-Counter.yolov8_region_counter",
        "documentation": {}
    },
    {
        "label": "track_history",
        "kind": 5,
        "importPath": "examples.YOLOv8-Region-Counter.yolov8_region_counter",
        "description": "examples.YOLOv8-Region-Counter.yolov8_region_counter",
        "peekOfCode": "track_history = defaultdict(list)\ncurrent_region = None\ncounting_regions = [\n    {\n        \"name\": \"YOLOv8 Polygon Region\",\n        \"polygon\": Polygon([(50, 80), (250, 20), (450, 80), (400, 350), (100, 350)]),  # Polygon points\n        \"counts\": 0,\n        \"dragging\": False,\n        \"region_color\": (255, 42, 4),  # BGR Value\n        \"text_color\": (255, 255, 255),  # Region Text Color",
        "detail": "examples.YOLOv8-Region-Counter.yolov8_region_counter",
        "documentation": {}
    },
    {
        "label": "current_region",
        "kind": 5,
        "importPath": "examples.YOLOv8-Region-Counter.yolov8_region_counter",
        "description": "examples.YOLOv8-Region-Counter.yolov8_region_counter",
        "peekOfCode": "current_region = None\ncounting_regions = [\n    {\n        \"name\": \"YOLOv8 Polygon Region\",\n        \"polygon\": Polygon([(50, 80), (250, 20), (450, 80), (400, 350), (100, 350)]),  # Polygon points\n        \"counts\": 0,\n        \"dragging\": False,\n        \"region_color\": (255, 42, 4),  # BGR Value\n        \"text_color\": (255, 255, 255),  # Region Text Color\n    },",
        "detail": "examples.YOLOv8-Region-Counter.yolov8_region_counter",
        "documentation": {}
    },
    {
        "label": "counting_regions",
        "kind": 5,
        "importPath": "examples.YOLOv8-Region-Counter.yolov8_region_counter",
        "description": "examples.YOLOv8-Region-Counter.yolov8_region_counter",
        "peekOfCode": "counting_regions = [\n    {\n        \"name\": \"YOLOv8 Polygon Region\",\n        \"polygon\": Polygon([(50, 80), (250, 20), (450, 80), (400, 350), (100, 350)]),  # Polygon points\n        \"counts\": 0,\n        \"dragging\": False,\n        \"region_color\": (255, 42, 4),  # BGR Value\n        \"text_color\": (255, 255, 255),  # Region Text Color\n    },\n    {",
        "detail": "examples.YOLOv8-Region-Counter.yolov8_region_counter",
        "documentation": {}
    },
    {
        "label": "run",
        "kind": 2,
        "importPath": "examples.YOLOv8-SAHI-Inference-Video.yolov8_sahi",
        "description": "examples.YOLOv8-SAHI-Inference-Video.yolov8_sahi",
        "peekOfCode": "def run(weights=\"yolov8n.pt\", source=\"test.mp4\", view_img=False, save_img=False, exist_ok=False):\n    \"\"\"\n    Run object detection on a video using YOLOv8 and SAHI.\n    Args:\n        weights (str): Model weights path.\n        source (str): Video file path.\n        view_img (bool): Show results.\n        save_img (bool): Save results.\n        exist_ok (bool): Overwrite existing files.\n    \"\"\"",
        "detail": "examples.YOLOv8-SAHI-Inference-Video.yolov8_sahi",
        "documentation": {}
    },
    {
        "label": "parse_opt",
        "kind": 2,
        "importPath": "examples.YOLOv8-SAHI-Inference-Video.yolov8_sahi",
        "description": "examples.YOLOv8-SAHI-Inference-Video.yolov8_sahi",
        "peekOfCode": "def parse_opt():\n    \"\"\"Parse command line arguments.\"\"\"\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--weights\", type=str, default=\"yolov8n.pt\", help=\"initial weights path\")\n    parser.add_argument(\"--source\", type=str, required=True, help=\"video file path\")\n    parser.add_argument(\"--view-img\", action=\"store_true\", help=\"show results\")\n    parser.add_argument(\"--save-img\", action=\"store_true\", help=\"save results\")\n    parser.add_argument(\"--exist-ok\", action=\"store_true\", help=\"existing project/name ok, do not increment\")\n    return parser.parse_args()\ndef main(opt):",
        "detail": "examples.YOLOv8-SAHI-Inference-Video.yolov8_sahi",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "examples.YOLOv8-SAHI-Inference-Video.yolov8_sahi",
        "description": "examples.YOLOv8-SAHI-Inference-Video.yolov8_sahi",
        "peekOfCode": "def main(opt):\n    \"\"\"Main function.\"\"\"\n    run(**vars(opt))\nif __name__ == \"__main__\":\n    opt = parse_opt()\n    main(opt)",
        "detail": "examples.YOLOv8-SAHI-Inference-Video.yolov8_sahi",
        "documentation": {}
    },
    {
        "label": "YOLOv8Seg",
        "kind": 6,
        "importPath": "examples.YOLOv8-Segmentation-ONNXRuntime-Python.main",
        "description": "examples.YOLOv8-Segmentation-ONNXRuntime-Python.main",
        "peekOfCode": "class YOLOv8Seg:\n    \"\"\"YOLOv8 segmentation model.\"\"\"\n    def __init__(self, onnx_model):\n        \"\"\"\n        Initialization.\n        Args:\n            onnx_model (str): Path to the ONNX model.\n        \"\"\"\n        # Build Ort session\n        self.session = ort.InferenceSession(",
        "detail": "examples.YOLOv8-Segmentation-ONNXRuntime-Python.main",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "examples.McDonlad_Demo",
        "description": "examples.McDonlad_Demo",
        "peekOfCode": "model = YOLO(\"yolov8n.pt\")  # load an official detection model\n# model = YOLO(\"yolov8n-seg.pt\")  # load an official segmentation model\n# Track with the modelp\n# source = sys.argv[1]\n# results = model.track(source=source, show=False,save=True,classes=[0])\n# source=1 ,代表从1号摄像头捕获数据\n#results = model.track(source=1, show=True, tracker=\"bytetrack.yaml\")\n# train model\nmodel.train(data=\"coco8.yaml\", epochs=3)\nmetrics = model.val()",
        "detail": "examples.McDonlad_Demo",
        "documentation": {}
    },
    {
        "label": "#results",
        "kind": 5,
        "importPath": "examples.McDonlad_Demo",
        "description": "examples.McDonlad_Demo",
        "peekOfCode": "#results = model.track(source=1, show=True, tracker=\"bytetrack.yaml\")\n# train model\nmodel.train(data=\"coco8.yaml\", epochs=3)\nmetrics = model.val()\nresults = model(\"https://ultralytics.com/images/bus.jpg\")\npath = model.export(format=\"onnx\")",
        "detail": "examples.McDonlad_Demo",
        "documentation": {}
    },
    {
        "label": "metrics",
        "kind": 5,
        "importPath": "examples.McDonlad_Demo",
        "description": "examples.McDonlad_Demo",
        "peekOfCode": "metrics = model.val()\nresults = model(\"https://ultralytics.com/images/bus.jpg\")\npath = model.export(format=\"onnx\")",
        "detail": "examples.McDonlad_Demo",
        "documentation": {}
    },
    {
        "label": "results",
        "kind": 5,
        "importPath": "examples.McDonlad_Demo",
        "description": "examples.McDonlad_Demo",
        "peekOfCode": "results = model(\"https://ultralytics.com/images/bus.jpg\")\npath = model.export(format=\"onnx\")",
        "detail": "examples.McDonlad_Demo",
        "documentation": {}
    },
    {
        "label": "path",
        "kind": 5,
        "importPath": "examples.McDonlad_Demo",
        "description": "examples.McDonlad_Demo",
        "peekOfCode": "path = model.export(format=\"onnx\")",
        "detail": "examples.McDonlad_Demo",
        "documentation": {}
    },
    {
        "label": "_Known",
        "kind": 6,
        "importPath": "gui.node_modules.flatted.python.flatted",
        "description": "gui.node_modules.flatted.python.flatted",
        "peekOfCode": "class _Known:\n    def __init__(self):\n        self.key = []\n        self.value = []\nclass _String:\n    def __init__(self, value):\n        self.value = value\ndef _array_keys(value):\n    keys = []\n    i = 0",
        "detail": "gui.node_modules.flatted.python.flatted",
        "documentation": {}
    },
    {
        "label": "_String",
        "kind": 6,
        "importPath": "gui.node_modules.flatted.python.flatted",
        "description": "gui.node_modules.flatted.python.flatted",
        "peekOfCode": "class _String:\n    def __init__(self, value):\n        self.value = value\ndef _array_keys(value):\n    keys = []\n    i = 0\n    for _ in value:\n        keys.append(i)\n        i += 1\n    return keys",
        "detail": "gui.node_modules.flatted.python.flatted",
        "documentation": {}
    },
    {
        "label": "parse",
        "kind": 2,
        "importPath": "gui.node_modules.flatted.python.flatted",
        "description": "gui.node_modules.flatted.python.flatted",
        "peekOfCode": "def parse(value, *args, **kwargs):\n    json = _json.loads(value, *args, **kwargs)\n    wrapped = []\n    for value in json:\n        wrapped.append(_wrap(value))\n    input = []\n    for value in wrapped:\n        if isinstance(value, _String):\n            input.append(value.value)\n        else:",
        "detail": "gui.node_modules.flatted.python.flatted",
        "documentation": {}
    },
    {
        "label": "stringify",
        "kind": 2,
        "importPath": "gui.node_modules.flatted.python.flatted",
        "description": "gui.node_modules.flatted.python.flatted",
        "peekOfCode": "def stringify(value, *args, **kwargs):\n    known = _Known()\n    input = []\n    output = []\n    i = int(_index(known, input, value))\n    while i < len(input):\n        output.append(_transform(known, input, input[i]))\n        i += 1\n    return _json.dumps(output, *args, **kwargs)",
        "detail": "gui.node_modules.flatted.python.flatted",
        "documentation": {}
    },
    {
        "label": "stringify",
        "kind": 2,
        "importPath": "gui.node_modules.flatted.python.test",
        "description": "gui.node_modules.flatted.python.test",
        "peekOfCode": "def stringify(value):\n    return _stringify(value, separators=(',', ':'))\nassert stringify([None, None]) == '[[null,null]]'\na = []\no = {}\nassert stringify(a) == '[[]]'\nassert stringify(o) == '[{}]'\na.append(a)\no['o'] = o\nassert stringify(a) == '[[\"0\"]]'",
        "detail": "gui.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "a",
        "kind": 5,
        "importPath": "gui.node_modules.flatted.python.test",
        "description": "gui.node_modules.flatted.python.test",
        "peekOfCode": "a = []\no = {}\nassert stringify(a) == '[[]]'\nassert stringify(o) == '[{}]'\na.append(a)\no['o'] = o\nassert stringify(a) == '[[\"0\"]]'\nassert stringify(o) == '[{\"o\":\"0\"}]'\nb = parse(stringify(a))\nassert isinstance(b, list) and b[0] == b",
        "detail": "gui.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "o",
        "kind": 5,
        "importPath": "gui.node_modules.flatted.python.test",
        "description": "gui.node_modules.flatted.python.test",
        "peekOfCode": "o = {}\nassert stringify(a) == '[[]]'\nassert stringify(o) == '[{}]'\na.append(a)\no['o'] = o\nassert stringify(a) == '[[\"0\"]]'\nassert stringify(o) == '[{\"o\":\"0\"}]'\nb = parse(stringify(a))\nassert isinstance(b, list) and b[0] == b\na.append(1)",
        "detail": "gui.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "o['o']",
        "kind": 5,
        "importPath": "gui.node_modules.flatted.python.test",
        "description": "gui.node_modules.flatted.python.test",
        "peekOfCode": "o['o'] = o\nassert stringify(a) == '[[\"0\"]]'\nassert stringify(o) == '[{\"o\":\"0\"}]'\nb = parse(stringify(a))\nassert isinstance(b, list) and b[0] == b\na.append(1)\na.append('two')\na.append(True)\no['one'] = 1\no['two'] = 'two'",
        "detail": "gui.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "b",
        "kind": 5,
        "importPath": "gui.node_modules.flatted.python.test",
        "description": "gui.node_modules.flatted.python.test",
        "peekOfCode": "b = parse(stringify(a))\nassert isinstance(b, list) and b[0] == b\na.append(1)\na.append('two')\na.append(True)\no['one'] = 1\no['two'] = 'two'\no['three'] = True\nassert stringify(a) == '[[\"0\",1,\"1\",true],\"two\"]'\nassert stringify(o) == '[{\"o\":\"0\",\"one\":1,\"two\":\"1\",\"three\":true},\"two\"]'",
        "detail": "gui.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "o['one']",
        "kind": 5,
        "importPath": "gui.node_modules.flatted.python.test",
        "description": "gui.node_modules.flatted.python.test",
        "peekOfCode": "o['one'] = 1\no['two'] = 'two'\no['three'] = True\nassert stringify(a) == '[[\"0\",1,\"1\",true],\"two\"]'\nassert stringify(o) == '[{\"o\":\"0\",\"one\":1,\"two\":\"1\",\"three\":true},\"two\"]'\na.append(o)\no['a'] = a\nassert stringify(a) == '[[\"0\",1,\"1\",true,\"2\"],\"two\",{\"o\":\"2\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"0\"}]'\nassert stringify(o) == '[{\"o\":\"0\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"2\"},\"two\",[\"2\",1,\"1\",true,\"0\"]]'\na.append({'test': 'OK'})",
        "detail": "gui.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "o['two']",
        "kind": 5,
        "importPath": "gui.node_modules.flatted.python.test",
        "description": "gui.node_modules.flatted.python.test",
        "peekOfCode": "o['two'] = 'two'\no['three'] = True\nassert stringify(a) == '[[\"0\",1,\"1\",true],\"two\"]'\nassert stringify(o) == '[{\"o\":\"0\",\"one\":1,\"two\":\"1\",\"three\":true},\"two\"]'\na.append(o)\no['a'] = a\nassert stringify(a) == '[[\"0\",1,\"1\",true,\"2\"],\"two\",{\"o\":\"2\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"0\"}]'\nassert stringify(o) == '[{\"o\":\"0\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"2\"},\"two\",[\"2\",1,\"1\",true,\"0\"]]'\na.append({'test': 'OK'})\na.append([1, 2, 3])",
        "detail": "gui.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "o['three']",
        "kind": 5,
        "importPath": "gui.node_modules.flatted.python.test",
        "description": "gui.node_modules.flatted.python.test",
        "peekOfCode": "o['three'] = True\nassert stringify(a) == '[[\"0\",1,\"1\",true],\"two\"]'\nassert stringify(o) == '[{\"o\":\"0\",\"one\":1,\"two\":\"1\",\"three\":true},\"two\"]'\na.append(o)\no['a'] = a\nassert stringify(a) == '[[\"0\",1,\"1\",true,\"2\"],\"two\",{\"o\":\"2\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"0\"}]'\nassert stringify(o) == '[{\"o\":\"0\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"2\"},\"two\",[\"2\",1,\"1\",true,\"0\"]]'\na.append({'test': 'OK'})\na.append([1, 2, 3])\no['test'] = {'test': 'OK'}",
        "detail": "gui.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "o['a']",
        "kind": 5,
        "importPath": "gui.node_modules.flatted.python.test",
        "description": "gui.node_modules.flatted.python.test",
        "peekOfCode": "o['a'] = a\nassert stringify(a) == '[[\"0\",1,\"1\",true,\"2\"],\"two\",{\"o\":\"2\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"0\"}]'\nassert stringify(o) == '[{\"o\":\"0\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"2\"},\"two\",[\"2\",1,\"1\",true,\"0\"]]'\na.append({'test': 'OK'})\na.append([1, 2, 3])\no['test'] = {'test': 'OK'}\no['array'] = [1, 2, 3]\nassert stringify(a) == '[[\"0\",1,\"1\",true,\"2\",\"3\",\"4\"],\"two\",{\"o\":\"2\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"0\",\"test\":\"3\",\"array\":\"4\"},{\"test\":\"5\"},[1,2,3],\"OK\"]'\nassert stringify(o) == '[{\"o\":\"0\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"2\",\"test\":\"3\",\"array\":\"4\"},\"two\",[\"2\",1,\"1\",true,\"0\",\"3\",\"4\"],{\"test\":\"5\"},[1,2,3],\"OK\"]'\na2 = parse(stringify(a));",
        "detail": "gui.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "o['test']",
        "kind": 5,
        "importPath": "gui.node_modules.flatted.python.test",
        "description": "gui.node_modules.flatted.python.test",
        "peekOfCode": "o['test'] = {'test': 'OK'}\no['array'] = [1, 2, 3]\nassert stringify(a) == '[[\"0\",1,\"1\",true,\"2\",\"3\",\"4\"],\"two\",{\"o\":\"2\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"0\",\"test\":\"3\",\"array\":\"4\"},{\"test\":\"5\"},[1,2,3],\"OK\"]'\nassert stringify(o) == '[{\"o\":\"0\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"2\",\"test\":\"3\",\"array\":\"4\"},\"two\",[\"2\",1,\"1\",true,\"0\",\"3\",\"4\"],{\"test\":\"5\"},[1,2,3],\"OK\"]'\na2 = parse(stringify(a));\no2 = parse(stringify(o));\nassert a2[0] == a2\nassert o2['o'] == o2\nassert a2[1] == 1 and a2[2] == 'two' and a2[3] == True and isinstance(a2[4], dict)\nassert a2[4] == a2[4]['o'] and a2 == a2[4]['o']['a']",
        "detail": "gui.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "o['array']",
        "kind": 5,
        "importPath": "gui.node_modules.flatted.python.test",
        "description": "gui.node_modules.flatted.python.test",
        "peekOfCode": "o['array'] = [1, 2, 3]\nassert stringify(a) == '[[\"0\",1,\"1\",true,\"2\",\"3\",\"4\"],\"two\",{\"o\":\"2\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"0\",\"test\":\"3\",\"array\":\"4\"},{\"test\":\"5\"},[1,2,3],\"OK\"]'\nassert stringify(o) == '[{\"o\":\"0\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"2\",\"test\":\"3\",\"array\":\"4\"},\"two\",[\"2\",1,\"1\",true,\"0\",\"3\",\"4\"],{\"test\":\"5\"},[1,2,3],\"OK\"]'\na2 = parse(stringify(a));\no2 = parse(stringify(o));\nassert a2[0] == a2\nassert o2['o'] == o2\nassert a2[1] == 1 and a2[2] == 'two' and a2[3] == True and isinstance(a2[4], dict)\nassert a2[4] == a2[4]['o'] and a2 == a2[4]['o']['a']\nstr = parse('[{\"prop\":\"1\",\"a\":\"2\",\"b\":\"3\"},{\"value\":123},[\"4\",\"5\"],{\"e\":\"6\",\"t\":\"7\",\"p\":4},{},{\"b\":\"8\"},\"f\",{\"a\":\"9\"},[\"10\"],\"sup\",{\"a\":1,\"d\":2,\"c\":\"7\",\"z\":\"11\",\"h\":1},{\"g\":2,\"a\":\"7\",\"b\":\"12\",\"f\":6},{\"r\":4,\"u\":\"7\",\"c\":5}]')",
        "detail": "gui.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "a2",
        "kind": 5,
        "importPath": "gui.node_modules.flatted.python.test",
        "description": "gui.node_modules.flatted.python.test",
        "peekOfCode": "a2 = parse(stringify(a));\no2 = parse(stringify(o));\nassert a2[0] == a2\nassert o2['o'] == o2\nassert a2[1] == 1 and a2[2] == 'two' and a2[3] == True and isinstance(a2[4], dict)\nassert a2[4] == a2[4]['o'] and a2 == a2[4]['o']['a']\nstr = parse('[{\"prop\":\"1\",\"a\":\"2\",\"b\":\"3\"},{\"value\":123},[\"4\",\"5\"],{\"e\":\"6\",\"t\":\"7\",\"p\":4},{},{\"b\":\"8\"},\"f\",{\"a\":\"9\"},[\"10\"],\"sup\",{\"a\":1,\"d\":2,\"c\":\"7\",\"z\":\"11\",\"h\":1},{\"g\":2,\"a\":\"7\",\"b\":\"12\",\"f\":6},{\"r\":4,\"u\":\"7\",\"c\":5}]')\nassert str['b']['t']['a'] == 'sup' and str['a'][1]['b'][0]['c'] == str['b']['t']\noo = parse('[{\"a\":\"1\",\"b\":\"0\",\"c\":\"2\"},{\"aa\":\"3\"},{\"ca\":\"4\",\"cb\":\"5\",\"cc\":\"6\",\"cd\":\"7\",\"ce\":\"8\",\"cf\":\"9\"},{\"aaa\":\"10\"},{\"caa\":\"4\"},{\"cba\":\"5\"},{\"cca\":\"2\"},{\"cda\":\"4\"},\"value2\",\"value3\",\"value1\"]');\nassert oo['a']['aa']['aaa'] == 'value1' and oo == oo['b'] and oo['c']['ca']['caa'] == oo['c']['ca']",
        "detail": "gui.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "o2",
        "kind": 5,
        "importPath": "gui.node_modules.flatted.python.test",
        "description": "gui.node_modules.flatted.python.test",
        "peekOfCode": "o2 = parse(stringify(o));\nassert a2[0] == a2\nassert o2['o'] == o2\nassert a2[1] == 1 and a2[2] == 'two' and a2[3] == True and isinstance(a2[4], dict)\nassert a2[4] == a2[4]['o'] and a2 == a2[4]['o']['a']\nstr = parse('[{\"prop\":\"1\",\"a\":\"2\",\"b\":\"3\"},{\"value\":123},[\"4\",\"5\"],{\"e\":\"6\",\"t\":\"7\",\"p\":4},{},{\"b\":\"8\"},\"f\",{\"a\":\"9\"},[\"10\"],\"sup\",{\"a\":1,\"d\":2,\"c\":\"7\",\"z\":\"11\",\"h\":1},{\"g\":2,\"a\":\"7\",\"b\":\"12\",\"f\":6},{\"r\":4,\"u\":\"7\",\"c\":5}]')\nassert str['b']['t']['a'] == 'sup' and str['a'][1]['b'][0]['c'] == str['b']['t']\noo = parse('[{\"a\":\"1\",\"b\":\"0\",\"c\":\"2\"},{\"aa\":\"3\"},{\"ca\":\"4\",\"cb\":\"5\",\"cc\":\"6\",\"cd\":\"7\",\"ce\":\"8\",\"cf\":\"9\"},{\"aaa\":\"10\"},{\"caa\":\"4\"},{\"cba\":\"5\"},{\"cca\":\"2\"},{\"cda\":\"4\"},\"value2\",\"value3\",\"value1\"]');\nassert oo['a']['aa']['aaa'] == 'value1' and oo == oo['b'] and oo['c']['ca']['caa'] == oo['c']['ca']\nprint('OK')",
        "detail": "gui.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "str",
        "kind": 5,
        "importPath": "gui.node_modules.flatted.python.test",
        "description": "gui.node_modules.flatted.python.test",
        "peekOfCode": "str = parse('[{\"prop\":\"1\",\"a\":\"2\",\"b\":\"3\"},{\"value\":123},[\"4\",\"5\"],{\"e\":\"6\",\"t\":\"7\",\"p\":4},{},{\"b\":\"8\"},\"f\",{\"a\":\"9\"},[\"10\"],\"sup\",{\"a\":1,\"d\":2,\"c\":\"7\",\"z\":\"11\",\"h\":1},{\"g\":2,\"a\":\"7\",\"b\":\"12\",\"f\":6},{\"r\":4,\"u\":\"7\",\"c\":5}]')\nassert str['b']['t']['a'] == 'sup' and str['a'][1]['b'][0]['c'] == str['b']['t']\noo = parse('[{\"a\":\"1\",\"b\":\"0\",\"c\":\"2\"},{\"aa\":\"3\"},{\"ca\":\"4\",\"cb\":\"5\",\"cc\":\"6\",\"cd\":\"7\",\"ce\":\"8\",\"cf\":\"9\"},{\"aaa\":\"10\"},{\"caa\":\"4\"},{\"cba\":\"5\"},{\"cca\":\"2\"},{\"cda\":\"4\"},\"value2\",\"value3\",\"value1\"]');\nassert oo['a']['aa']['aaa'] == 'value1' and oo == oo['b'] and oo['c']['ca']['caa'] == oo['c']['ca']\nprint('OK')",
        "detail": "gui.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "oo",
        "kind": 5,
        "importPath": "gui.node_modules.flatted.python.test",
        "description": "gui.node_modules.flatted.python.test",
        "peekOfCode": "oo = parse('[{\"a\":\"1\",\"b\":\"0\",\"c\":\"2\"},{\"aa\":\"3\"},{\"ca\":\"4\",\"cb\":\"5\",\"cc\":\"6\",\"cd\":\"7\",\"ce\":\"8\",\"cf\":\"9\"},{\"aaa\":\"10\"},{\"caa\":\"4\"},{\"cba\":\"5\"},{\"cca\":\"2\"},{\"cda\":\"4\"},\"value2\",\"value3\",\"value1\"]');\nassert oo['a']['aa']['aaa'] == 'value1' and oo == oo['b'] and oo['c']['ca']['caa'] == oo['c']['ca']\nprint('OK')",
        "detail": "gui.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "list_cameras",
        "kind": 2,
        "importPath": "mcd.camera",
        "description": "mcd.camera",
        "peekOfCode": "def list_cameras():\n    index = 0\n    arr = []\n    while True:\n        cap = cv2.VideoCapture(index)\n        if not cap.read()[0]:\n            break\n        else:\n            arr.append(index)\n        cap.release()",
        "detail": "mcd.camera",
        "documentation": {}
    },
    {
        "label": "get_cameras_windows",
        "kind": 2,
        "importPath": "mcd.camera",
        "description": "mcd.camera",
        "peekOfCode": "def get_cameras_windows():\n    import win32com.client\n    cameras = []\n    device_manager = win32com.client.Dispatch('WMICool.WMICool')\n    for device in device_manager.ExecQuery('SELECT * FROM Win32_PnPEntity'):\n        if 'camera' in device.Name.lower():\n            cameras.append((device.DeviceID, device.Name))\n    return cameras\ndef get_cameras_linux():\n    camera_list = []",
        "detail": "mcd.camera",
        "documentation": {}
    },
    {
        "label": "get_cameras_linux",
        "kind": 2,
        "importPath": "mcd.camera",
        "description": "mcd.camera",
        "peekOfCode": "def get_cameras_linux():\n    camera_list = []\n    # Try to open a large number of camera indices\n    for camera_id in range(10):\n        cap = cv2.VideoCapture(camera_id)\n        if cap.isOpened():\n            camera_name = f\"Camera {camera_id}\"\n            camera_list.append((camera_id, camera_name))\n            cap.release()\n    return camera_list",
        "detail": "mcd.camera",
        "documentation": {}
    },
    {
        "label": "get_cameras_mac",
        "kind": 2,
        "importPath": "mcd.camera",
        "description": "mcd.camera",
        "peekOfCode": "def get_cameras_mac():\n    try:\n        # Execute the command\n        result = subprocess.run(\n            'system_profiler SPCameraDataType',\n            shell=True,\n            check=True,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            text=True",
        "detail": "mcd.camera",
        "documentation": {}
    },
    {
        "label": "get_cameras",
        "kind": 2,
        "importPath": "mcd.camera",
        "description": "mcd.camera",
        "peekOfCode": "def get_cameras():\n    os_type = platform.system()\n    if os_type == \"Windows\":\n        return get_cameras_windows()\n    elif os_type == \"Linux\":\n        return get_cameras_linux()\n    elif os_type == \"Darwin\":  # macOS\n        return get_cameras_mac()\n    else:\n        print(f\"Unsupported OS: {os_type}\")",
        "detail": "mcd.camera",
        "documentation": {}
    },
    {
        "label": "load_config",
        "kind": 2,
        "importPath": "mcd.conf",
        "description": "mcd.conf",
        "peekOfCode": "def load_config():\n    if os.path.exists(config_file):\n        with open(config_file, 'r',encoding='utf-8') as config_file1:\n            conf = json.load(config_file1)\n            log.info(f'load {config_file}, conents:{conf}')\n        global current_mode,huiji_detect_config,person_detect_config\n        current_mode = conf['current_mode']\n        huiji_detect_config = conf['huiji_detect_config']\n        person_detect_config = conf['person_detect_config']\ndef save_config():",
        "detail": "mcd.conf",
        "documentation": {}
    },
    {
        "label": "save_config",
        "kind": 2,
        "importPath": "mcd.conf",
        "description": "mcd.conf",
        "peekOfCode": "def save_config():\n    conf = {\n        'current_mode': current_mode,\n        'huiji_detect_config': huiji_detect_config,\n        'person_detect_config': person_detect_config\n    }\n    with open(config_file, 'w',encoding='utf-8') as json_file:\n        json.dump(conf, json_file, indent=4,ensure_ascii=False)\n        log.info(f'save {config_file}, conents:{conf}')",
        "detail": "mcd.conf",
        "documentation": {}
    },
    {
        "label": "current_mode",
        "kind": 5,
        "importPath": "mcd.conf",
        "description": "mcd.conf",
        "peekOfCode": "current_mode = 'huiji_detect' \nhuiji_detect_config = {\n    # 数据源类型，只可以是: 摄像头(camera)/视频文件(video_file)\n    \"data_source_type\": \"camera\",\n    # 当前摄像头地址，本地为 0,1,2， 网络是 uri 地址\n    \"camera_source\": 0,\n    \"video_file\": \"\",\n    # 当前选中的套餐id\n    \"current_taocan_id\": 0,\n    #当前使用的模型",
        "detail": "mcd.conf",
        "documentation": {}
    },
    {
        "label": "huiji_detect_config",
        "kind": 5,
        "importPath": "mcd.conf",
        "description": "mcd.conf",
        "peekOfCode": "huiji_detect_config = {\n    # 数据源类型，只可以是: 摄像头(camera)/视频文件(video_file)\n    \"data_source_type\": \"camera\",\n    # 当前摄像头地址，本地为 0,1,2， 网络是 uri 地址\n    \"camera_source\": 0,\n    \"video_file\": \"\",\n    # 当前选中的套餐id\n    \"current_taocan_id\": 0,\n    #当前使用的模型\n    \"model\": \"mcd/huiji_detect_model.pt\",",
        "detail": "mcd.conf",
        "documentation": {}
    },
    {
        "label": "person_detect_config",
        "kind": 5,
        "importPath": "mcd.conf",
        "description": "mcd.conf",
        "peekOfCode": "person_detect_config = {\n    # 数据源类型，只可以是: 摄像头(camera)/视频文件(video_file)\n    \"data_source_type\": \"camera\",\n    # 当前摄像头地址，本地为 0,1,2， 网络是 uri 地址\n    \"camera_source\": 0,\n    \"video_file\": \"\",\n    \"model\": \"yolov8n.pt\"\n}\nconfig_file = 'mcd_conf.json'\ndef load_config():",
        "detail": "mcd.conf",
        "documentation": {}
    },
    {
        "label": "config_file",
        "kind": 5,
        "importPath": "mcd.conf",
        "description": "mcd.conf",
        "peekOfCode": "config_file = 'mcd_conf.json'\ndef load_config():\n    if os.path.exists(config_file):\n        with open(config_file, 'r',encoding='utf-8') as config_file1:\n            conf = json.load(config_file1)\n            log.info(f'load {config_file}, conents:{conf}')\n        global current_mode,huiji_detect_config,person_detect_config\n        current_mode = conf['current_mode']\n        huiji_detect_config = conf['huiji_detect_config']\n        person_detect_config = conf['person_detect_config']",
        "detail": "mcd.conf",
        "documentation": {}
    },
    {
        "label": "PersonResults",
        "kind": 6,
        "importPath": "mcd.custom_result",
        "description": "mcd.custom_result",
        "peekOfCode": "class PersonResults(Results):\n    id_info = {}\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n    # 覆盖基类的方法，否则复制对象时，类型信息又回去了\n    def new(self):\n        return PersonResults(orig_img=self.orig_img, path=self.path, names=self.names, speed=self.speed)\n    def plot(self,\n             conf=True,\n             line_width=None,",
        "detail": "mcd.custom_result",
        "documentation": {}
    },
    {
        "label": "log",
        "kind": 5,
        "importPath": "mcd.logger",
        "description": "mcd.logger",
        "peekOfCode": "log = logging.getLogger(\"mcd\")\nlog.setLevel(logging.INFO)\n# 创建控制台处理器，并设置日志级别\nconsole_handler = logging.StreamHandler()\nconsole_handler.setLevel(logging.DEBUG)\nconsole_handler.addFilter(logging.Filter('mcd'))\n# 创建日志格式器\nformatter = colorlog.ColoredFormatter(\n    '%(log_color)s[%(asctime)s] [%(levelname)s] [%(process)d %(filename)s:%(lineno)d] %(message)s',\n    log_colors={",
        "detail": "mcd.logger",
        "documentation": {}
    },
    {
        "label": "console_handler",
        "kind": 5,
        "importPath": "mcd.logger",
        "description": "mcd.logger",
        "peekOfCode": "console_handler = logging.StreamHandler()\nconsole_handler.setLevel(logging.DEBUG)\nconsole_handler.addFilter(logging.Filter('mcd'))\n# 创建日志格式器\nformatter = colorlog.ColoredFormatter(\n    '%(log_color)s[%(asctime)s] [%(levelname)s] [%(process)d %(filename)s:%(lineno)d] %(message)s',\n    log_colors={\n        'DEBUG': 'cyan',\n        'INFO': 'green',\n        'WARNING': 'yellow',",
        "detail": "mcd.logger",
        "documentation": {}
    },
    {
        "label": "formatter",
        "kind": 5,
        "importPath": "mcd.logger",
        "description": "mcd.logger",
        "peekOfCode": "formatter = colorlog.ColoredFormatter(\n    '%(log_color)s[%(asctime)s] [%(levelname)s] [%(process)d %(filename)s:%(lineno)d] %(message)s',\n    log_colors={\n        'DEBUG': 'cyan',\n        'INFO': 'green',\n        'WARNING': 'yellow',\n        'ERROR': 'red',\n        'CRITICAL': 'red,bg_white',\n    },\n)",
        "detail": "mcd.logger",
        "documentation": {}
    },
    {
        "label": "logfile",
        "kind": 5,
        "importPath": "mcd.logger",
        "description": "mcd.logger",
        "peekOfCode": "logfile = 'logs/mcd.log'\nos.makedirs(os.path.dirname(logfile),exist_ok=True)\nfile_handler = logging.FileHandler(filename=logfile)\nfile_handler.setFormatter(formatter)\n# 将控制台处理器添加到 logger\nlog.addHandler(console_handler)\nlog.addHandler(file_handler)\n# 示例日志消息\n# log.debug('This is a debug message')\n# log.info('This is an info message')",
        "detail": "mcd.logger",
        "documentation": {}
    },
    {
        "label": "file_handler",
        "kind": 5,
        "importPath": "mcd.logger",
        "description": "mcd.logger",
        "peekOfCode": "file_handler = logging.FileHandler(filename=logfile)\nfile_handler.setFormatter(formatter)\n# 将控制台处理器添加到 logger\nlog.addHandler(console_handler)\nlog.addHandler(file_handler)\n# 示例日志消息\n# log.debug('This is a debug message')\n# log.info('This is an info message')\n# log.warning('This is a warning message')\n# log.error('This is an error message')",
        "detail": "mcd.logger",
        "documentation": {}
    },
    {
        "label": "get_current_person_detect_result",
        "kind": 2,
        "importPath": "mcd.video",
        "description": "mcd.video",
        "peekOfCode": "def get_current_person_detect_result():\n    return {id:v['time_s'] for id,v in PersonResults.id_info.items()}\ndef person_detect_frames():\n    model = get_model(conf.person_detect_config['model'])\n    for result in model.track(source=data_source(), stream=True,verbose=False, classes=[0]):\n        orig_frame = result.orig_img  # 获取原始帧\n        # 编码原始帧为 JPEG\n        ret, orig_buffer = cv2.imencode('.jpg', orig_frame)\n        if not ret:\n            continue",
        "detail": "mcd.video",
        "documentation": {}
    },
    {
        "label": "person_detect_frames",
        "kind": 2,
        "importPath": "mcd.video",
        "description": "mcd.video",
        "peekOfCode": "def person_detect_frames():\n    model = get_model(conf.person_detect_config['model'])\n    for result in model.track(source=data_source(), stream=True,verbose=False, classes=[0]):\n        orig_frame = result.orig_img  # 获取原始帧\n        # 编码原始帧为 JPEG\n        ret, orig_buffer = cv2.imencode('.jpg', orig_frame)\n        if not ret:\n            continue\n        orig_frame = orig_buffer.tobytes()\n        result.__class__ = PersonResults",
        "detail": "mcd.video",
        "documentation": {}
    },
    {
        "label": "get_huiji_detect_items",
        "kind": 2,
        "importPath": "mcd.video",
        "description": "mcd.video",
        "peekOfCode": "def get_huiji_detect_items(detect_result):\n    taocan_id = conf.huiji_detect_config['current_taocan_id']\n    taocan =  [t for t in conf.huiji_detect_config['taocans'] if t['id'] == taocan_id]\n    if not taocan:\n        raise Exception(f\"can't find taocao with id:{taocan_id}\")\n    taocan = taocan[0]\n    in_tancan_results = [\n        {\n            'id': id,\n            'name': next((f'{cn_name} {en_name}' for m_id,en_name,cn_name in conf.huiji_detect_config['meals_info'] if m_id == id),None),",
        "detail": "mcd.video",
        "documentation": {}
    },
    {
        "label": "huiji_detect_results",
        "kind": 2,
        "importPath": "mcd.video",
        "description": "mcd.video",
        "peekOfCode": "def huiji_detect_results(results):\n    img=None\n    meal_result=None\n    meal_result = {}\n    for result in results:\n        # 提取每个检测结果的 id 和 class 信息\n        for obj in result.boxes:\n            obj_id = obj.id.item() if hasattr(obj, 'id') and obj.id else None\n            if not obj_id:\n                continue",
        "detail": "mcd.video",
        "documentation": {}
    },
    {
        "label": "huiji_detect_frames",
        "kind": 2,
        "importPath": "mcd.video",
        "description": "mcd.video",
        "peekOfCode": "def huiji_detect_frames():\n    model = get_model(conf.huiji_detect_config['model'])\n    for result in model.track(source=data_source(), stream=True,verbose=False):\n        orig_frame = result.orig_img  # 获取原始帧\n        # 编码原始帧为 JPEG\n        ret, orig_buffer = cv2.imencode('.jpg', orig_frame)\n        if not ret:\n            continue\n        orig_frame = orig_buffer.tobytes()\n        # 使用生成器同时返回两个流",
        "detail": "mcd.video",
        "documentation": {}
    },
    {
        "label": "data_source",
        "kind": 2,
        "importPath": "mcd.video",
        "description": "mcd.video",
        "peekOfCode": "def data_source():\n    def get_ds(detect_config):\n        data_source_type = detect_config['data_source_type']\n        if data_source_type == 'camera':\n            data_source = detect_config['camera_source']\n            if str(data_source).isdigit():\n                data_source = int(data_source)\n            return data_source\n        else:\n            return detect_config['video_file']",
        "detail": "mcd.video",
        "documentation": {}
    },
    {
        "label": "get_model",
        "kind": 2,
        "importPath": "mcd.video",
        "description": "mcd.video",
        "peekOfCode": "def get_model(model_path):\n    if not models.get(model_path):\n        models[model_path] = YOLO(model_path)\n    return models[model_path]\nget_model(conf.huiji_detect_config['model'])\ndef array2jpg(frame):\n    ret, buffer = cv2.imencode('.jpg', frame)\n    return buffer.tobytes()\ndef changed(detect_result):\n    return detect_result != last_taocan_check_result",
        "detail": "mcd.video",
        "documentation": {}
    },
    {
        "label": "array2jpg",
        "kind": 2,
        "importPath": "mcd.video",
        "description": "mcd.video",
        "peekOfCode": "def array2jpg(frame):\n    ret, buffer = cv2.imencode('.jpg', frame)\n    return buffer.tobytes()\ndef changed(detect_result):\n    return detect_result != last_taocan_check_result",
        "detail": "mcd.video",
        "documentation": {}
    },
    {
        "label": "changed",
        "kind": 2,
        "importPath": "mcd.video",
        "description": "mcd.video",
        "peekOfCode": "def changed(detect_result):\n    return detect_result != last_taocan_check_result",
        "detail": "mcd.video",
        "documentation": {}
    },
    {
        "label": "last_taocan_check_result",
        "kind": 5,
        "importPath": "mcd.video",
        "description": "mcd.video",
        "peekOfCode": "last_taocan_check_result = None\ncurrent_taocan_check_result = None\ndef huiji_detect_results(results):\n    img=None\n    meal_result=None\n    meal_result = {}\n    for result in results:\n        # 提取每个检测结果的 id 和 class 信息\n        for obj in result.boxes:\n            obj_id = obj.id.item() if hasattr(obj, 'id') and obj.id else None",
        "detail": "mcd.video",
        "documentation": {}
    },
    {
        "label": "current_taocan_check_result",
        "kind": 5,
        "importPath": "mcd.video",
        "description": "mcd.video",
        "peekOfCode": "current_taocan_check_result = None\ndef huiji_detect_results(results):\n    img=None\n    meal_result=None\n    meal_result = {}\n    for result in results:\n        # 提取每个检测结果的 id 和 class 信息\n        for obj in result.boxes:\n            obj_id = obj.id.item() if hasattr(obj, 'id') and obj.id else None\n            if not obj_id:",
        "detail": "mcd.video",
        "documentation": {}
    },
    {
        "label": "model_result_save_dir",
        "kind": 5,
        "importPath": "mcd.video",
        "description": "mcd.video",
        "peekOfCode": "model_result_save_dir = \"analysis_video_output\"\nimport os;os.makedirs(model_result_save_dir,exist_ok=True)\nfrom tests.test_python import test_nn_modules_block\ndef huiji_detect_frames():\n    model = get_model(conf.huiji_detect_config['model'])\n    for result in model.track(source=data_source(), stream=True,verbose=False):\n        orig_frame = result.orig_img  # 获取原始帧\n        # 编码原始帧为 JPEG\n        ret, orig_buffer = cv2.imencode('.jpg', orig_frame)\n        if not ret:",
        "detail": "mcd.video",
        "documentation": {}
    },
    {
        "label": "models",
        "kind": 5,
        "importPath": "mcd.video",
        "description": "mcd.video",
        "peekOfCode": "models = {}\ndef get_model(model_path):\n    if not models.get(model_path):\n        models[model_path] = YOLO(model_path)\n    return models[model_path]\nget_model(conf.huiji_detect_config['model'])\ndef array2jpg(frame):\n    ret, buffer = cv2.imencode('.jpg', frame)\n    return buffer.tobytes()\ndef changed(detect_result):",
        "detail": "mcd.video",
        "documentation": {}
    },
    {
        "label": "pytest_addoption",
        "kind": 2,
        "importPath": "tests.conftest",
        "description": "tests.conftest",
        "peekOfCode": "def pytest_addoption(parser):\n    \"\"\"\n    Add custom command-line options to pytest.\n    Args:\n        parser (pytest.config.Parser): The pytest parser object for adding custom command-line options.\n    Returns:\n        (None)\n    \"\"\"\n    parser.addoption(\"--slow\", action=\"store_true\", default=False, help=\"Run slow tests\")\ndef pytest_collection_modifyitems(config, items):",
        "detail": "tests.conftest",
        "documentation": {}
    },
    {
        "label": "pytest_collection_modifyitems",
        "kind": 2,
        "importPath": "tests.conftest",
        "description": "tests.conftest",
        "peekOfCode": "def pytest_collection_modifyitems(config, items):\n    \"\"\"\n    Modify the list of test items to exclude tests marked as slow if the --slow option is not specified.\n    Args:\n        config (pytest.config.Config): The pytest configuration object that provides access to command-line options.\n        items (list): The list of collected pytest item objects to be modified based on the presence of --slow option.\n    Returns:\n        (None) The function modifies the 'items' list in place, and does not return a value.\n    \"\"\"\n    if not config.getoption(\"--slow\"):",
        "detail": "tests.conftest",
        "documentation": {}
    },
    {
        "label": "pytest_sessionstart",
        "kind": 2,
        "importPath": "tests.conftest",
        "description": "tests.conftest",
        "peekOfCode": "def pytest_sessionstart(session):\n    \"\"\"\n    Initialize session configurations for pytest.\n    This function is automatically called by pytest after the 'Session' object has been created but before performing\n    test collection. It sets the initial seeds and prepares the temporary directory for the test session.\n    Args:\n        session (pytest.Session): The pytest session object.\n    Returns:\n        (None)\n    \"\"\"",
        "detail": "tests.conftest",
        "documentation": {}
    },
    {
        "label": "pytest_terminal_summary",
        "kind": 2,
        "importPath": "tests.conftest",
        "description": "tests.conftest",
        "peekOfCode": "def pytest_terminal_summary(terminalreporter, exitstatus, config):\n    \"\"\"\n    Cleanup operations after pytest session.\n    This function is automatically called by pytest at the end of the entire test session. It removes certain files\n    and directories used during testing.\n    Args:\n        terminalreporter (pytest.terminal.TerminalReporter): The terminal reporter object used for terminal output.\n        exitstatus (int): The exit status of the test run.\n        config (pytest.config.Config): The pytest config object.\n    Returns:",
        "detail": "tests.conftest",
        "documentation": {}
    },
    {
        "label": "test_switch_mode",
        "kind": 2,
        "importPath": "tests.test_appapi",
        "description": "tests.test_appapi",
        "peekOfCode": "def test_switch_mode():\n    response = client.get(\"/switch_mode?mode=huiji_detect\")\n    assert response.status_code == 200\n    json =  response.json()\n    assert json['code'] == 0\ndef test_available_cameras():\n    response = client.get(\"/available_cameras\")\n    assert response.status_code == 200\n    json =  response.json()\n    assert json['code'] == 0",
        "detail": "tests.test_appapi",
        "documentation": {}
    },
    {
        "label": "test_available_cameras",
        "kind": 2,
        "importPath": "tests.test_appapi",
        "description": "tests.test_appapi",
        "peekOfCode": "def test_available_cameras():\n    response = client.get(\"/available_cameras\")\n    assert response.status_code == 200\n    json =  response.json()\n    assert json['code'] == 0\n    assert len(json['data']) > 0\ndef test_mode_datasource():\n    response = client.post(\"/mode_datasource\",json={\n        'mode':'huiji_detect',\n        'data_source_type':'camera',",
        "detail": "tests.test_appapi",
        "documentation": {}
    },
    {
        "label": "test_mode_datasource",
        "kind": 2,
        "importPath": "tests.test_appapi",
        "description": "tests.test_appapi",
        "peekOfCode": "def test_mode_datasource():\n    response = client.post(\"/mode_datasource\",json={\n        'mode':'huiji_detect',\n        'data_source_type':'camera',\n        'data_source':'0'\n    })\n    assert response.status_code == 200\n    json =  response.json()\n    assert json['code'] == 0\n    response = client.get(\"/mode_datasource\")",
        "detail": "tests.test_appapi",
        "documentation": {}
    },
    {
        "label": "test_taocans",
        "kind": 2,
        "importPath": "tests.test_appapi",
        "description": "tests.test_appapi",
        "peekOfCode": "def test_taocans():\n    response = client.get(\"/taocans\")\n    assert response.status_code == 200\n    json =  response.json()\n    assert json['code'] == 0\n    assert len(json['data']['taocans']) == 2\n    assert json['data']['current_taocan_id'] == 0\ndef test_switch_taocan():\n    response = client.get(\"/switch_taocan?taocan_id=1\")\n    assert response.status_code == 200",
        "detail": "tests.test_appapi",
        "documentation": {}
    },
    {
        "label": "test_switch_taocan",
        "kind": 2,
        "importPath": "tests.test_appapi",
        "description": "tests.test_appapi",
        "peekOfCode": "def test_switch_taocan():\n    response = client.get(\"/switch_taocan?taocan_id=1\")\n    assert response.status_code == 200\n    json =  response.json()\n    assert json['code'] == 0\ndef test_taocan_analysis():\n    response = client.get(\"/taocan_analysis\")\n    assert response.status_code == 200\n    json =  response.json()\n    assert json['code'] == 0",
        "detail": "tests.test_appapi",
        "documentation": {}
    },
    {
        "label": "test_taocan_analysis",
        "kind": 2,
        "importPath": "tests.test_appapi",
        "description": "tests.test_appapi",
        "peekOfCode": "def test_taocan_analysis():\n    response = client.get(\"/taocan_analysis\")\n    assert response.status_code == 200\n    json =  response.json()\n    assert json['code'] == 0\n    results = json['data']['current_taocan_result']\n    print(results)\n    assert len(results) > 0\n    assert 'id' in results[0].keys()\n    assert 'name' in results[0].keys()",
        "detail": "tests.test_appapi",
        "documentation": {}
    },
    {
        "label": "test_person_analysis",
        "kind": 2,
        "importPath": "tests.test_appapi",
        "description": "tests.test_appapi",
        "peekOfCode": "def test_person_analysis():\n    response = client.get(\"/person_analysis\")\n    assert response.status_code == 200\n    json =  response.json()\n    assert json['code'] == 0\ndef test_huiji_video_taocan_detect_result():\n    response = client.get(\"/huiji_video_taocan_detect_result\")\n    assert response.status_code == 200\n    json =  response.json()\n    assert json['code'] == 1",
        "detail": "tests.test_appapi",
        "documentation": {}
    },
    {
        "label": "test_huiji_video_taocan_detect_result",
        "kind": 2,
        "importPath": "tests.test_appapi",
        "description": "tests.test_appapi",
        "peekOfCode": "def test_huiji_video_taocan_detect_result():\n    response = client.get(\"/huiji_video_taocan_detect_result\")\n    assert response.status_code == 200\n    json =  response.json()\n    assert json['code'] == 1\ndef test_upload_file():\n    file_path = \"assets/demo.mp4\"  # 替换为实际文件路径\n    with open(file_path, \"rb\") as file:\n        response = client.post(\"/single_upload\", files={\"file\": file})\n    assert response.status_code == 200",
        "detail": "tests.test_appapi",
        "documentation": {}
    },
    {
        "label": "test_upload_file",
        "kind": 2,
        "importPath": "tests.test_appapi",
        "description": "tests.test_appapi",
        "peekOfCode": "def test_upload_file():\n    file_path = \"assets/demo.mp4\"  # 替换为实际文件路径\n    with open(file_path, \"rb\") as file:\n        response = client.post(\"/single_upload\", files={\"file\": file})\n    assert response.status_code == 200\n    assert response.json()[\"filename\"] == \"demo.mp4\"\n    assert os.path.exists(\"uploads/demo.mp4\")\n    response = client.get(\"/mode_datasource\")\n    assert response.status_code == 200\n    json =  response.json()",
        "detail": "tests.test_appapi",
        "documentation": {}
    },
    {
        "label": "test_video_source_feed",
        "kind": 2,
        "importPath": "tests.test_appapi",
        "description": "tests.test_appapi",
        "peekOfCode": "def test_video_source_feed():\n    response = client.post(\"/mode_datasource\",json={\n        'mode':'huiji_detect',\n        'data_source_type':'video_file',\n        'data_source':'assets/demo.mp4'\n    })\n    assert response.status_code == 200\n    json =  response.json()\n    assert json['code'] == 0\n    assert conf.huiji_detect_config['video_file'] == 'assets/demo.mp4'",
        "detail": "tests.test_appapi",
        "documentation": {}
    },
    {
        "label": "client",
        "kind": 5,
        "importPath": "tests.test_appapi",
        "description": "tests.test_appapi",
        "peekOfCode": "client = TestClient(app)\ndef test_switch_mode():\n    response = client.get(\"/switch_mode?mode=huiji_detect\")\n    assert response.status_code == 200\n    json =  response.json()\n    assert json['code'] == 0\ndef test_available_cameras():\n    response = client.get(\"/available_cameras\")\n    assert response.status_code == 200\n    json =  response.json()",
        "detail": "tests.test_appapi",
        "documentation": {}
    },
    {
        "label": "run",
        "kind": 2,
        "importPath": "tests.test_cli",
        "description": "tests.test_cli",
        "peekOfCode": "def run(cmd):\n    \"\"\"Execute a shell command using subprocess.\"\"\"\n    subprocess.run(cmd.split(), check=True)\ndef test_special_modes():\n    \"\"\"Test various special command-line modes for YOLO functionality.\"\"\"\n    run(\"yolo help\")\n    run(\"yolo checks\")\n    run(\"yolo version\")\n    run(\"yolo settings reset\")\n    run(\"yolo cfg\")",
        "detail": "tests.test_cli",
        "documentation": {}
    },
    {
        "label": "test_special_modes",
        "kind": 2,
        "importPath": "tests.test_cli",
        "description": "tests.test_cli",
        "peekOfCode": "def test_special_modes():\n    \"\"\"Test various special command-line modes for YOLO functionality.\"\"\"\n    run(\"yolo help\")\n    run(\"yolo checks\")\n    run(\"yolo version\")\n    run(\"yolo settings reset\")\n    run(\"yolo cfg\")\n@pytest.mark.parametrize(\"task,model,data\", TASK_MODEL_DATA)\ndef test_train(task, model, data):\n    \"\"\"Test YOLO training for different tasks, models, and datasets.\"\"\"",
        "detail": "tests.test_cli",
        "documentation": {}
    },
    {
        "label": "test_train",
        "kind": 2,
        "importPath": "tests.test_cli",
        "description": "tests.test_cli",
        "peekOfCode": "def test_train(task, model, data):\n    \"\"\"Test YOLO training for different tasks, models, and datasets.\"\"\"\n    run(f\"yolo train {task} model={model} data={data} imgsz=32 epochs=1 cache=disk\")\n@pytest.mark.parametrize(\"task,model,data\", TASK_MODEL_DATA)\ndef test_val(task, model, data):\n    \"\"\"Test YOLO validation process for specified task, model, and data using a shell command.\"\"\"\n    run(f\"yolo val {task} model={model} data={data} imgsz=32 save_txt save_json\")\n@pytest.mark.parametrize(\"task,model,data\", TASK_MODEL_DATA)\ndef test_predict(task, model, data):\n    \"\"\"Test YOLO prediction on provided sample assets for specified task and model.\"\"\"",
        "detail": "tests.test_cli",
        "documentation": {}
    },
    {
        "label": "test_val",
        "kind": 2,
        "importPath": "tests.test_cli",
        "description": "tests.test_cli",
        "peekOfCode": "def test_val(task, model, data):\n    \"\"\"Test YOLO validation process for specified task, model, and data using a shell command.\"\"\"\n    run(f\"yolo val {task} model={model} data={data} imgsz=32 save_txt save_json\")\n@pytest.mark.parametrize(\"task,model,data\", TASK_MODEL_DATA)\ndef test_predict(task, model, data):\n    \"\"\"Test YOLO prediction on provided sample assets for specified task and model.\"\"\"\n    run(f\"yolo predict model={model} source={ASSETS} imgsz=32 save save_crop save_txt\")\n@pytest.mark.parametrize(\"model\", MODELS)\ndef test_export(model):\n    \"\"\"Test exporting a YOLO model to TorchScript format.\"\"\"",
        "detail": "tests.test_cli",
        "documentation": {}
    },
    {
        "label": "test_predict",
        "kind": 2,
        "importPath": "tests.test_cli",
        "description": "tests.test_cli",
        "peekOfCode": "def test_predict(task, model, data):\n    \"\"\"Test YOLO prediction on provided sample assets for specified task and model.\"\"\"\n    run(f\"yolo predict model={model} source={ASSETS} imgsz=32 save save_crop save_txt\")\n@pytest.mark.parametrize(\"model\", MODELS)\ndef test_export(model):\n    \"\"\"Test exporting a YOLO model to TorchScript format.\"\"\"\n    run(f\"yolo export model={model} format=torchscript imgsz=32\")\ndef test_rtdetr(task=\"detect\", model=\"yolov8n-rtdetr.yaml\", data=\"coco8.yaml\"):\n    \"\"\"Test the RTDETR functionality within Ultralytics for detection tasks using specified model and data.\"\"\"\n    # Warning: must use imgsz=640 (note also add coma, spaces, fraction=0.25 args to test single-image training)",
        "detail": "tests.test_cli",
        "documentation": {}
    },
    {
        "label": "test_export",
        "kind": 2,
        "importPath": "tests.test_cli",
        "description": "tests.test_cli",
        "peekOfCode": "def test_export(model):\n    \"\"\"Test exporting a YOLO model to TorchScript format.\"\"\"\n    run(f\"yolo export model={model} format=torchscript imgsz=32\")\ndef test_rtdetr(task=\"detect\", model=\"yolov8n-rtdetr.yaml\", data=\"coco8.yaml\"):\n    \"\"\"Test the RTDETR functionality within Ultralytics for detection tasks using specified model and data.\"\"\"\n    # Warning: must use imgsz=640 (note also add coma, spaces, fraction=0.25 args to test single-image training)\n    run(f\"yolo train {task} model={model} data={data} --imgsz= 160 epochs =1, cache = disk fraction=0.25\")\n    run(f\"yolo predict {task} model={model} source={ASSETS / 'bus.jpg'} imgsz=160 save save_crop save_txt\")\n@pytest.mark.skipif(checks.IS_PYTHON_3_12, reason=\"MobileSAM with CLIP is not supported in Python 3.12\")\ndef test_fastsam(task=\"segment\", model=WEIGHTS_DIR / \"FastSAM-s.pt\", data=\"coco8-seg.yaml\"):",
        "detail": "tests.test_cli",
        "documentation": {}
    },
    {
        "label": "test_rtdetr",
        "kind": 2,
        "importPath": "tests.test_cli",
        "description": "tests.test_cli",
        "peekOfCode": "def test_rtdetr(task=\"detect\", model=\"yolov8n-rtdetr.yaml\", data=\"coco8.yaml\"):\n    \"\"\"Test the RTDETR functionality within Ultralytics for detection tasks using specified model and data.\"\"\"\n    # Warning: must use imgsz=640 (note also add coma, spaces, fraction=0.25 args to test single-image training)\n    run(f\"yolo train {task} model={model} data={data} --imgsz= 160 epochs =1, cache = disk fraction=0.25\")\n    run(f\"yolo predict {task} model={model} source={ASSETS / 'bus.jpg'} imgsz=160 save save_crop save_txt\")\n@pytest.mark.skipif(checks.IS_PYTHON_3_12, reason=\"MobileSAM with CLIP is not supported in Python 3.12\")\ndef test_fastsam(task=\"segment\", model=WEIGHTS_DIR / \"FastSAM-s.pt\", data=\"coco8-seg.yaml\"):\n    \"\"\"Test FastSAM model for segmenting objects in images using various prompts within Ultralytics.\"\"\"\n    source = ASSETS / \"bus.jpg\"\n    run(f\"yolo segment val {task} model={model} data={data} imgsz=32\")",
        "detail": "tests.test_cli",
        "documentation": {}
    },
    {
        "label": "test_fastsam",
        "kind": 2,
        "importPath": "tests.test_cli",
        "description": "tests.test_cli",
        "peekOfCode": "def test_fastsam(task=\"segment\", model=WEIGHTS_DIR / \"FastSAM-s.pt\", data=\"coco8-seg.yaml\"):\n    \"\"\"Test FastSAM model for segmenting objects in images using various prompts within Ultralytics.\"\"\"\n    source = ASSETS / \"bus.jpg\"\n    run(f\"yolo segment val {task} model={model} data={data} imgsz=32\")\n    run(f\"yolo segment predict model={model} source={source} imgsz=32 save save_crop save_txt\")\n    from ultralytics import FastSAM\n    from ultralytics.models.fastsam import FastSAMPrompt\n    from ultralytics.models.sam import Predictor\n    # Create a FastSAM model\n    sam_model = FastSAM(model)  # or FastSAM-x.pt",
        "detail": "tests.test_cli",
        "documentation": {}
    },
    {
        "label": "test_mobilesam",
        "kind": 2,
        "importPath": "tests.test_cli",
        "description": "tests.test_cli",
        "peekOfCode": "def test_mobilesam():\n    \"\"\"Test MobileSAM segmentation with point prompts using Ultralytics.\"\"\"\n    from ultralytics import SAM\n    # Load the model\n    model = SAM(WEIGHTS_DIR / \"mobile_sam.pt\")\n    # Source\n    source = ASSETS / \"zidane.jpg\"\n    # Predict a segment based on a point prompt\n    model.predict(source, points=[900, 370], labels=[1])\n    # Predict a segment based on a box prompt",
        "detail": "tests.test_cli",
        "documentation": {}
    },
    {
        "label": "test_train_gpu",
        "kind": 2,
        "importPath": "tests.test_cli",
        "description": "tests.test_cli",
        "peekOfCode": "def test_train_gpu(task, model, data):\n    \"\"\"Test YOLO training on GPU(s) for various tasks and models.\"\"\"\n    run(f\"yolo train {task} model={model} data={data} imgsz=32 epochs=1 device=0\")  # single GPU\n    run(f\"yolo train {task} model={model} data={data} imgsz=32 epochs=1 device=0,1\")  # multi GPU",
        "detail": "tests.test_cli",
        "documentation": {}
    },
    {
        "label": "TASK_MODEL_DATA",
        "kind": 5,
        "importPath": "tests.test_cli",
        "description": "tests.test_cli",
        "peekOfCode": "TASK_MODEL_DATA = [(task, WEIGHTS_DIR / TASK2MODEL[task], TASK2DATA[task]) for task in TASKS]\nMODELS = [WEIGHTS_DIR / TASK2MODEL[task] for task in TASKS]\ndef run(cmd):\n    \"\"\"Execute a shell command using subprocess.\"\"\"\n    subprocess.run(cmd.split(), check=True)\ndef test_special_modes():\n    \"\"\"Test various special command-line modes for YOLO functionality.\"\"\"\n    run(\"yolo help\")\n    run(\"yolo checks\")\n    run(\"yolo version\")",
        "detail": "tests.test_cli",
        "documentation": {}
    },
    {
        "label": "MODELS",
        "kind": 5,
        "importPath": "tests.test_cli",
        "description": "tests.test_cli",
        "peekOfCode": "MODELS = [WEIGHTS_DIR / TASK2MODEL[task] for task in TASKS]\ndef run(cmd):\n    \"\"\"Execute a shell command using subprocess.\"\"\"\n    subprocess.run(cmd.split(), check=True)\ndef test_special_modes():\n    \"\"\"Test various special command-line modes for YOLO functionality.\"\"\"\n    run(\"yolo help\")\n    run(\"yolo checks\")\n    run(\"yolo version\")\n    run(\"yolo settings reset\")",
        "detail": "tests.test_cli",
        "documentation": {}
    },
    {
        "label": "test_checks",
        "kind": 2,
        "importPath": "tests.test_cuda",
        "description": "tests.test_cuda",
        "peekOfCode": "def test_checks():\n    \"\"\"Validate CUDA settings against torch CUDA functions.\"\"\"\n    assert torch.cuda.is_available() == CUDA_IS_AVAILABLE\n    assert torch.cuda.device_count() == CUDA_DEVICE_COUNT\n@pytest.mark.slow\n@pytest.mark.skipif(True, reason=\"CUDA export tests disabled pending additional Ultralytics GPU server availability\")\n@pytest.mark.skipif(not CUDA_IS_AVAILABLE, reason=\"CUDA is not available\")\n@pytest.mark.parametrize(\n    \"task, dynamic, int8, half, batch\",\n    [  # generate all combinations but exclude those where both int8 and half are True",
        "detail": "tests.test_cuda",
        "documentation": {}
    },
    {
        "label": "test_export_engine_matrix",
        "kind": 2,
        "importPath": "tests.test_cuda",
        "description": "tests.test_cuda",
        "peekOfCode": "def test_export_engine_matrix(task, dynamic, int8, half, batch):\n    \"\"\"Test YOLO model export to TensorRT format for various configurations and run inference.\"\"\"\n    file = YOLO(TASK2MODEL[task]).export(\n        format=\"engine\",\n        imgsz=32,\n        dynamic=dynamic,\n        int8=int8,\n        half=half,\n        batch=batch,\n        data=TASK2DATA[task],",
        "detail": "tests.test_cuda",
        "documentation": {}
    },
    {
        "label": "test_train",
        "kind": 2,
        "importPath": "tests.test_cuda",
        "description": "tests.test_cuda",
        "peekOfCode": "def test_train():\n    \"\"\"Test model training on a minimal dataset using available CUDA devices.\"\"\"\n    device = 0 if CUDA_DEVICE_COUNT == 1 else [0, 1]\n    YOLO(MODEL).train(data=\"coco8.yaml\", imgsz=64, epochs=1, device=device)  # requires imgsz>=64\n@pytest.mark.slow\n@pytest.mark.skipif(not CUDA_IS_AVAILABLE, reason=\"CUDA is not available\")\ndef test_predict_multiple_devices():\n    \"\"\"Validate model prediction consistency across CPU and CUDA devices.\"\"\"\n    model = YOLO(\"yolov8n.pt\")\n    model = model.cpu()",
        "detail": "tests.test_cuda",
        "documentation": {}
    },
    {
        "label": "test_predict_multiple_devices",
        "kind": 2,
        "importPath": "tests.test_cuda",
        "description": "tests.test_cuda",
        "peekOfCode": "def test_predict_multiple_devices():\n    \"\"\"Validate model prediction consistency across CPU and CUDA devices.\"\"\"\n    model = YOLO(\"yolov8n.pt\")\n    model = model.cpu()\n    assert str(model.device) == \"cpu\"\n    _ = model(SOURCE)  # CPU inference\n    assert str(model.device) == \"cpu\"\n    model = model.to(\"cuda:0\")\n    assert str(model.device) == \"cuda:0\"\n    _ = model(SOURCE)  # CUDA inference",
        "detail": "tests.test_cuda",
        "documentation": {}
    },
    {
        "label": "test_autobatch",
        "kind": 2,
        "importPath": "tests.test_cuda",
        "description": "tests.test_cuda",
        "peekOfCode": "def test_autobatch():\n    \"\"\"Check optimal batch size for YOLO model training using autobatch utility.\"\"\"\n    from ultralytics.utils.autobatch import check_train_batch_size\n    check_train_batch_size(YOLO(MODEL).model.cuda(), imgsz=128, amp=True)\n@pytest.mark.slow\n@pytest.mark.skipif(not CUDA_IS_AVAILABLE, reason=\"CUDA is not available\")\ndef test_utils_benchmarks():\n    \"\"\"Profile YOLO models for performance benchmarks.\"\"\"\n    from ultralytics.utils.benchmarks import ProfileModels\n    # Pre-export a dynamic engine model to use dynamic inference",
        "detail": "tests.test_cuda",
        "documentation": {}
    },
    {
        "label": "test_utils_benchmarks",
        "kind": 2,
        "importPath": "tests.test_cuda",
        "description": "tests.test_cuda",
        "peekOfCode": "def test_utils_benchmarks():\n    \"\"\"Profile YOLO models for performance benchmarks.\"\"\"\n    from ultralytics.utils.benchmarks import ProfileModels\n    # Pre-export a dynamic engine model to use dynamic inference\n    YOLO(MODEL).export(format=\"engine\", imgsz=32, dynamic=True, batch=1)\n    ProfileModels([MODEL], imgsz=32, half=False, min_time=1, num_timed_runs=3, num_warmup_runs=1).profile()\n@pytest.mark.skipif(not CUDA_IS_AVAILABLE, reason=\"CUDA is not available\")\ndef test_predict_sam():\n    \"\"\"Test SAM model predictions using different prompts, including bounding boxes and point annotations.\"\"\"\n    from ultralytics import SAM",
        "detail": "tests.test_cuda",
        "documentation": {}
    },
    {
        "label": "test_predict_sam",
        "kind": 2,
        "importPath": "tests.test_cuda",
        "description": "tests.test_cuda",
        "peekOfCode": "def test_predict_sam():\n    \"\"\"Test SAM model predictions using different prompts, including bounding boxes and point annotations.\"\"\"\n    from ultralytics import SAM\n    from ultralytics.models.sam import Predictor as SAMPredictor\n    # Load a model\n    model = SAM(WEIGHTS_DIR / \"sam_b.pt\")\n    # Display model information (optional)\n    model.info()\n    # Run inference\n    model(SOURCE, device=0)",
        "detail": "tests.test_cuda",
        "documentation": {}
    },
    {
        "label": "test_func",
        "kind": 2,
        "importPath": "tests.test_engine",
        "description": "tests.test_engine",
        "peekOfCode": "def test_func(*args):  # noqa\n    \"\"\"Test function callback for evaluating YOLO model performance metrics.\"\"\"\n    print(\"callback test passed\")\ndef test_export():\n    \"\"\"Tests the model exporting function by adding a callback and asserting its execution.\"\"\"\n    exporter = Exporter()\n    exporter.add_callback(\"on_export_start\", test_func)\n    assert test_func in exporter.callbacks[\"on_export_start\"], \"callback test failed\"\n    f = exporter(model=YOLO(\"yolov8n.yaml\").model)\n    YOLO(f)(ASSETS)  # exported model inference",
        "detail": "tests.test_engine",
        "documentation": {}
    },
    {
        "label": "test_export",
        "kind": 2,
        "importPath": "tests.test_engine",
        "description": "tests.test_engine",
        "peekOfCode": "def test_export():\n    \"\"\"Tests the model exporting function by adding a callback and asserting its execution.\"\"\"\n    exporter = Exporter()\n    exporter.add_callback(\"on_export_start\", test_func)\n    assert test_func in exporter.callbacks[\"on_export_start\"], \"callback test failed\"\n    f = exporter(model=YOLO(\"yolov8n.yaml\").model)\n    YOLO(f)(ASSETS)  # exported model inference\ndef test_detect():\n    \"\"\"Test YOLO object detection training, validation, and prediction functionality.\"\"\"\n    overrides = {\"data\": \"coco8.yaml\", \"model\": \"yolov8n.yaml\", \"imgsz\": 32, \"epochs\": 1, \"save\": False}",
        "detail": "tests.test_engine",
        "documentation": {}
    },
    {
        "label": "test_detect",
        "kind": 2,
        "importPath": "tests.test_engine",
        "description": "tests.test_engine",
        "peekOfCode": "def test_detect():\n    \"\"\"Test YOLO object detection training, validation, and prediction functionality.\"\"\"\n    overrides = {\"data\": \"coco8.yaml\", \"model\": \"yolov8n.yaml\", \"imgsz\": 32, \"epochs\": 1, \"save\": False}\n    cfg = get_cfg(DEFAULT_CFG)\n    cfg.data = \"coco8.yaml\"\n    cfg.imgsz = 32\n    # Trainer\n    trainer = detect.DetectionTrainer(overrides=overrides)\n    trainer.add_callback(\"on_train_start\", test_func)\n    assert test_func in trainer.callbacks[\"on_train_start\"], \"callback test failed\"",
        "detail": "tests.test_engine",
        "documentation": {}
    },
    {
        "label": "test_segment",
        "kind": 2,
        "importPath": "tests.test_engine",
        "description": "tests.test_engine",
        "peekOfCode": "def test_segment():\n    \"\"\"Tests image segmentation training, validation, and prediction pipelines using YOLO models.\"\"\"\n    overrides = {\"data\": \"coco8-seg.yaml\", \"model\": \"yolov8n-seg.yaml\", \"imgsz\": 32, \"epochs\": 1, \"save\": False}\n    cfg = get_cfg(DEFAULT_CFG)\n    cfg.data = \"coco8-seg.yaml\"\n    cfg.imgsz = 32\n    # YOLO(CFG_SEG).train(**overrides)  # works\n    # Trainer\n    trainer = segment.SegmentationTrainer(overrides=overrides)\n    trainer.add_callback(\"on_train_start\", test_func)",
        "detail": "tests.test_engine",
        "documentation": {}
    },
    {
        "label": "test_classify",
        "kind": 2,
        "importPath": "tests.test_engine",
        "description": "tests.test_engine",
        "peekOfCode": "def test_classify():\n    \"\"\"Test image classification including training, validation, and prediction phases.\"\"\"\n    overrides = {\"data\": \"imagenet10\", \"model\": \"yolov8n-cls.yaml\", \"imgsz\": 32, \"epochs\": 1, \"save\": False}\n    cfg = get_cfg(DEFAULT_CFG)\n    cfg.data = \"imagenet10\"\n    cfg.imgsz = 32\n    # YOLO(CFG_SEG).train(**overrides)  # works\n    # Trainer\n    trainer = classify.ClassificationTrainer(overrides=overrides)\n    trainer.add_callback(\"on_train_start\", test_func)",
        "detail": "tests.test_engine",
        "documentation": {}
    },
    {
        "label": "test_similarity",
        "kind": 2,
        "importPath": "tests.test_explorer",
        "description": "tests.test_explorer",
        "peekOfCode": "def test_similarity():\n    \"\"\"Test the correctness and response length of similarity calculations and SQL queries in the Explorer.\"\"\"\n    exp = Explorer(data=\"coco8.yaml\")\n    exp.create_embeddings_table()\n    similar = exp.get_similar(idx=1)\n    assert len(similar) == 4\n    similar = exp.get_similar(img=ASSETS / \"bus.jpg\")\n    assert len(similar) == 4\n    similar = exp.get_similar(idx=[1, 2], limit=2)\n    assert len(similar) == 2",
        "detail": "tests.test_explorer",
        "documentation": {}
    },
    {
        "label": "test_det",
        "kind": 2,
        "importPath": "tests.test_explorer",
        "description": "tests.test_explorer",
        "peekOfCode": "def test_det():\n    \"\"\"Test detection functionalities and verify embedding table includes bounding boxes.\"\"\"\n    exp = Explorer(data=\"coco8.yaml\", model=\"yolov8n.pt\")\n    exp.create_embeddings_table(force=True)\n    assert len(exp.table.head()[\"bboxes\"]) > 0\n    similar = exp.get_similar(idx=[1, 2], limit=10)\n    assert len(similar) > 0\n    # This is a loose test, just checks errors not correctness\n    similar = exp.plot_similar(idx=[1, 2], limit=10)\n    assert isinstance(similar, PIL.Image.Image)",
        "detail": "tests.test_explorer",
        "documentation": {}
    },
    {
        "label": "test_seg",
        "kind": 2,
        "importPath": "tests.test_explorer",
        "description": "tests.test_explorer",
        "peekOfCode": "def test_seg():\n    \"\"\"Test segmentation functionalities and ensure the embedding table includes segmentation masks.\"\"\"\n    exp = Explorer(data=\"coco8-seg.yaml\", model=\"yolov8n-seg.pt\")\n    exp.create_embeddings_table(force=True)\n    assert len(exp.table.head()[\"masks\"]) > 0\n    similar = exp.get_similar(idx=[1, 2], limit=10)\n    assert len(similar) > 0\n    similar = exp.plot_similar(idx=[1, 2], limit=10)\n    assert isinstance(similar, PIL.Image.Image)\n@pytest.mark.slow",
        "detail": "tests.test_explorer",
        "documentation": {}
    },
    {
        "label": "test_pose",
        "kind": 2,
        "importPath": "tests.test_explorer",
        "description": "tests.test_explorer",
        "peekOfCode": "def test_pose():\n    \"\"\"Test pose estimation functionality and verify the embedding table includes keypoints.\"\"\"\n    exp = Explorer(data=\"coco8-pose.yaml\", model=\"yolov8n-pose.pt\")\n    exp.create_embeddings_table(force=True)\n    assert len(exp.table.head()[\"keypoints\"]) > 0\n    similar = exp.get_similar(idx=[1, 2], limit=10)\n    assert len(similar) > 0\n    similar = exp.plot_similar(idx=[1, 2], limit=10)\n    assert isinstance(similar, PIL.Image.Image)",
        "detail": "tests.test_explorer",
        "documentation": {}
    },
    {
        "label": "test_export_torchscript",
        "kind": 2,
        "importPath": "tests.test_exports",
        "description": "tests.test_exports",
        "peekOfCode": "def test_export_torchscript():\n    \"\"\"Test YOLO model exporting to TorchScript format for compatibility and correctness.\"\"\"\n    file = YOLO(MODEL).export(format=\"torchscript\", optimize=False, imgsz=32)\n    YOLO(file)(SOURCE, imgsz=32)  # exported model inference\ndef test_export_onnx():\n    \"\"\"Test YOLO model export to ONNX format with dynamic axes.\"\"\"\n    file = YOLO(MODEL).export(format=\"onnx\", dynamic=True, imgsz=32)\n    YOLO(file)(SOURCE, imgsz=32)  # exported model inference\n@pytest.mark.skipif(checks.IS_PYTHON_3_12, reason=\"OpenVINO not supported in Python 3.12\")\n@pytest.mark.skipif(not TORCH_1_13, reason=\"OpenVINO requires torch>=1.13\")",
        "detail": "tests.test_exports",
        "documentation": {}
    },
    {
        "label": "test_export_onnx",
        "kind": 2,
        "importPath": "tests.test_exports",
        "description": "tests.test_exports",
        "peekOfCode": "def test_export_onnx():\n    \"\"\"Test YOLO model export to ONNX format with dynamic axes.\"\"\"\n    file = YOLO(MODEL).export(format=\"onnx\", dynamic=True, imgsz=32)\n    YOLO(file)(SOURCE, imgsz=32)  # exported model inference\n@pytest.mark.skipif(checks.IS_PYTHON_3_12, reason=\"OpenVINO not supported in Python 3.12\")\n@pytest.mark.skipif(not TORCH_1_13, reason=\"OpenVINO requires torch>=1.13\")\ndef test_export_openvino():\n    \"\"\"Test YOLO exports to OpenVINO format for model inference compatibility.\"\"\"\n    file = YOLO(MODEL).export(format=\"openvino\", imgsz=32)\n    YOLO(file)(SOURCE, imgsz=32)  # exported model inference",
        "detail": "tests.test_exports",
        "documentation": {}
    },
    {
        "label": "test_export_openvino",
        "kind": 2,
        "importPath": "tests.test_exports",
        "description": "tests.test_exports",
        "peekOfCode": "def test_export_openvino():\n    \"\"\"Test YOLO exports to OpenVINO format for model inference compatibility.\"\"\"\n    file = YOLO(MODEL).export(format=\"openvino\", imgsz=32)\n    YOLO(file)(SOURCE, imgsz=32)  # exported model inference\n@pytest.mark.slow\n@pytest.mark.skipif(checks.IS_PYTHON_3_12, reason=\"OpenVINO not supported in Python 3.12\")\n@pytest.mark.skipif(not TORCH_1_13, reason=\"OpenVINO requires torch>=1.13\")\n@pytest.mark.parametrize(\n    \"task, dynamic, int8, half, batch\",\n    [  # generate all combinations but exclude those where both int8 and half are True",
        "detail": "tests.test_exports",
        "documentation": {}
    },
    {
        "label": "test_export_openvino_matrix",
        "kind": 2,
        "importPath": "tests.test_exports",
        "description": "tests.test_exports",
        "peekOfCode": "def test_export_openvino_matrix(task, dynamic, int8, half, batch):\n    \"\"\"Test YOLO model exports to OpenVINO under various configuration matrix conditions.\"\"\"\n    file = YOLO(TASK2MODEL[task]).export(\n        format=\"openvino\",\n        imgsz=32,\n        dynamic=dynamic,\n        int8=int8,\n        half=half,\n        batch=batch,\n        data=TASK2DATA[task],",
        "detail": "tests.test_exports",
        "documentation": {}
    },
    {
        "label": "test_export_onnx_matrix",
        "kind": 2,
        "importPath": "tests.test_exports",
        "description": "tests.test_exports",
        "peekOfCode": "def test_export_onnx_matrix(task, dynamic, int8, half, batch, simplify):\n    \"\"\"Test YOLO exports to ONNX format with various configurations and parameters.\"\"\"\n    file = YOLO(TASK2MODEL[task]).export(\n        format=\"onnx\",\n        imgsz=32,\n        dynamic=dynamic,\n        int8=int8,\n        half=half,\n        batch=batch,\n        simplify=simplify,",
        "detail": "tests.test_exports",
        "documentation": {}
    },
    {
        "label": "test_export_torchscript_matrix",
        "kind": 2,
        "importPath": "tests.test_exports",
        "description": "tests.test_exports",
        "peekOfCode": "def test_export_torchscript_matrix(task, dynamic, int8, half, batch):\n    \"\"\"Tests YOLO model exports to TorchScript format under varied configurations.\"\"\"\n    file = YOLO(TASK2MODEL[task]).export(\n        format=\"torchscript\",\n        imgsz=32,\n        dynamic=dynamic,\n        int8=int8,\n        half=half,\n        batch=batch,\n    )",
        "detail": "tests.test_exports",
        "documentation": {}
    },
    {
        "label": "test_export_coreml_matrix",
        "kind": 2,
        "importPath": "tests.test_exports",
        "description": "tests.test_exports",
        "peekOfCode": "def test_export_coreml_matrix(task, dynamic, int8, half, batch):\n    \"\"\"Test YOLO exports to CoreML format with various parameter configurations.\"\"\"\n    file = YOLO(TASK2MODEL[task]).export(\n        format=\"coreml\",\n        imgsz=32,\n        dynamic=dynamic,\n        int8=int8,\n        half=half,\n        batch=batch,\n    )",
        "detail": "tests.test_exports",
        "documentation": {}
    },
    {
        "label": "test_export_tflite_matrix",
        "kind": 2,
        "importPath": "tests.test_exports",
        "description": "tests.test_exports",
        "peekOfCode": "def test_export_tflite_matrix(task, dynamic, int8, half, batch):\n    \"\"\"Test YOLO exports to TFLite format considering various export configurations.\"\"\"\n    file = YOLO(TASK2MODEL[task]).export(\n        format=\"tflite\",\n        imgsz=32,\n        dynamic=dynamic,\n        int8=int8,\n        half=half,\n        batch=batch,\n    )",
        "detail": "tests.test_exports",
        "documentation": {}
    },
    {
        "label": "test_export_coreml",
        "kind": 2,
        "importPath": "tests.test_exports",
        "description": "tests.test_exports",
        "peekOfCode": "def test_export_coreml():\n    \"\"\"Test YOLO exports to CoreML format, optimized for macOS only.\"\"\"\n    if MACOS:\n        file = YOLO(MODEL).export(format=\"coreml\", imgsz=32)\n        YOLO(file)(SOURCE, imgsz=32)  # model prediction only supported on macOS for nms=False models\n    else:\n        YOLO(MODEL).export(format=\"coreml\", nms=True, imgsz=32)\n@pytest.mark.skipif(not checks.IS_PYTHON_MINIMUM_3_10, reason=\"TFLite export requires Python>=3.10\")\n@pytest.mark.skipif(not LINUX, reason=\"Test disabled as TF suffers from install conflicts on Windows and macOS\")\ndef test_export_tflite():",
        "detail": "tests.test_exports",
        "documentation": {}
    },
    {
        "label": "test_export_tflite",
        "kind": 2,
        "importPath": "tests.test_exports",
        "description": "tests.test_exports",
        "peekOfCode": "def test_export_tflite():\n    \"\"\"Test YOLO exports to TFLite format under specific OS and Python version conditions.\"\"\"\n    model = YOLO(MODEL)\n    file = model.export(format=\"tflite\", imgsz=32)\n    YOLO(file)(SOURCE, imgsz=32)\n@pytest.mark.skipif(True, reason=\"Test disabled\")\n@pytest.mark.skipif(not LINUX, reason=\"TF suffers from install conflicts on Windows and macOS\")\ndef test_export_pb():\n    \"\"\"Test YOLO exports to TensorFlow's Protobuf (*.pb) format.\"\"\"\n    model = YOLO(MODEL)",
        "detail": "tests.test_exports",
        "documentation": {}
    },
    {
        "label": "test_export_pb",
        "kind": 2,
        "importPath": "tests.test_exports",
        "description": "tests.test_exports",
        "peekOfCode": "def test_export_pb():\n    \"\"\"Test YOLO exports to TensorFlow's Protobuf (*.pb) format.\"\"\"\n    model = YOLO(MODEL)\n    file = model.export(format=\"pb\", imgsz=32)\n    YOLO(file)(SOURCE, imgsz=32)\n@pytest.mark.skipif(True, reason=\"Test disabled as Paddle protobuf and ONNX protobuf requirementsk conflict.\")\ndef test_export_paddle():\n    \"\"\"Test YOLO exports to Paddle format, noting protobuf conflicts with ONNX.\"\"\"\n    YOLO(MODEL).export(format=\"paddle\", imgsz=32)\n@pytest.mark.slow",
        "detail": "tests.test_exports",
        "documentation": {}
    },
    {
        "label": "test_export_paddle",
        "kind": 2,
        "importPath": "tests.test_exports",
        "description": "tests.test_exports",
        "peekOfCode": "def test_export_paddle():\n    \"\"\"Test YOLO exports to Paddle format, noting protobuf conflicts with ONNX.\"\"\"\n    YOLO(MODEL).export(format=\"paddle\", imgsz=32)\n@pytest.mark.slow\ndef test_export_ncnn():\n    \"\"\"Test YOLO exports to NCNN format.\"\"\"\n    file = YOLO(MODEL).export(format=\"ncnn\", imgsz=32)\n    YOLO(file)(SOURCE, imgsz=32)  # exported model inference",
        "detail": "tests.test_exports",
        "documentation": {}
    },
    {
        "label": "test_export_ncnn",
        "kind": 2,
        "importPath": "tests.test_exports",
        "description": "tests.test_exports",
        "peekOfCode": "def test_export_ncnn():\n    \"\"\"Test YOLO exports to NCNN format.\"\"\"\n    file = YOLO(MODEL).export(format=\"ncnn\", imgsz=32)\n    YOLO(file)(SOURCE, imgsz=32)  # exported model inference",
        "detail": "tests.test_exports",
        "documentation": {}
    },
    {
        "label": "test_model_ray_tune",
        "kind": 2,
        "importPath": "tests.test_integrations",
        "description": "tests.test_integrations",
        "peekOfCode": "def test_model_ray_tune():\n    \"\"\"Tune YOLO model using Ray for hyperparameter optimization.\"\"\"\n    YOLO(\"yolov8n-cls.yaml\").tune(\n        use_ray=True, data=\"imagenet10\", grace_period=1, iterations=1, imgsz=32, epochs=1, plots=False, device=\"cpu\"\n    )\n@pytest.mark.skipif(not check_requirements(\"mlflow\", install=False), reason=\"mlflow not installed\")\ndef test_mlflow():\n    \"\"\"Test training with MLflow tracking enabled (see https://mlflow.org/ for details).\"\"\"\n    SETTINGS[\"mlflow\"] = True\n    YOLO(\"yolov8n-cls.yaml\").train(data=\"imagenet10\", imgsz=32, epochs=3, plots=False, device=\"cpu\")",
        "detail": "tests.test_integrations",
        "documentation": {}
    },
    {
        "label": "test_mlflow",
        "kind": 2,
        "importPath": "tests.test_integrations",
        "description": "tests.test_integrations",
        "peekOfCode": "def test_mlflow():\n    \"\"\"Test training with MLflow tracking enabled (see https://mlflow.org/ for details).\"\"\"\n    SETTINGS[\"mlflow\"] = True\n    YOLO(\"yolov8n-cls.yaml\").train(data=\"imagenet10\", imgsz=32, epochs=3, plots=False, device=\"cpu\")\n@pytest.mark.skipif(True, reason=\"Test failing in scheduled CI https://github.com/ultralytics/ultralytics/pull/8868\")\n@pytest.mark.skipif(not check_requirements(\"mlflow\", install=False), reason=\"mlflow not installed\")\ndef test_mlflow_keep_run_active():\n    \"\"\"Ensure MLflow run status matches MLFLOW_KEEP_RUN_ACTIVE environment variable settings.\"\"\"\n    import mlflow\n    SETTINGS[\"mlflow\"] = True",
        "detail": "tests.test_integrations",
        "documentation": {}
    },
    {
        "label": "test_mlflow_keep_run_active",
        "kind": 2,
        "importPath": "tests.test_integrations",
        "description": "tests.test_integrations",
        "peekOfCode": "def test_mlflow_keep_run_active():\n    \"\"\"Ensure MLflow run status matches MLFLOW_KEEP_RUN_ACTIVE environment variable settings.\"\"\"\n    import mlflow\n    SETTINGS[\"mlflow\"] = True\n    run_name = \"Test Run\"\n    os.environ[\"MLFLOW_RUN\"] = run_name\n    # Test with MLFLOW_KEEP_RUN_ACTIVE=True\n    os.environ[\"MLFLOW_KEEP_RUN_ACTIVE\"] = \"True\"\n    YOLO(\"yolov8n-cls.yaml\").train(data=\"imagenet10\", imgsz=32, epochs=1, plots=False, device=\"cpu\")\n    status = mlflow.active_run().info.status",
        "detail": "tests.test_integrations",
        "documentation": {}
    },
    {
        "label": "test_triton",
        "kind": 2,
        "importPath": "tests.test_integrations",
        "description": "tests.test_integrations",
        "peekOfCode": "def test_triton():\n    \"\"\"\n    Test NVIDIA Triton Server functionalities with YOLO model.\n    See https://catalog.ngc.nvidia.com/orgs/nvidia/containers/tritonserver.\n    \"\"\"\n    check_requirements(\"tritonclient[all]\")\n    from tritonclient.http import InferenceServerClient  # noqa\n    # Create variables\n    model_name = \"yolo\"\n    triton_repo = TMP / \"triton_repo\"  # Triton repo path",
        "detail": "tests.test_integrations",
        "documentation": {}
    },
    {
        "label": "test_pycocotools",
        "kind": 2,
        "importPath": "tests.test_integrations",
        "description": "tests.test_integrations",
        "peekOfCode": "def test_pycocotools():\n    \"\"\"Validate YOLO model predictions on COCO dataset using pycocotools.\"\"\"\n    from ultralytics.models.yolo.detect import DetectionValidator\n    from ultralytics.models.yolo.pose import PoseValidator\n    from ultralytics.models.yolo.segment import SegmentationValidator\n    # Download annotations after each dataset downloads first\n    url = \"https://github.com/ultralytics/assets/releases/download/v8.2.0/\"\n    args = {\"model\": \"yolov8n.pt\", \"data\": \"coco8.yaml\", \"save_json\": True, \"imgsz\": 64}\n    validator = DetectionValidator(args=args)\n    validator()",
        "detail": "tests.test_integrations",
        "documentation": {}
    },
    {
        "label": "test_model_forward",
        "kind": 2,
        "importPath": "tests.test_python",
        "description": "tests.test_python",
        "peekOfCode": "def test_model_forward():\n    \"\"\"Test the forward pass of the YOLO model.\"\"\"\n    model = YOLO(CFG)\n    model(source=None, imgsz=32, augment=True)  # also test no source and augment\ndef test_model_methods():\n    \"\"\"Test various methods and properties of the YOLO model to ensure correct functionality.\"\"\"\n    model = YOLO(MODEL)\n    # Model methods\n    model.info(verbose=True, detailed=True)\n    model = model.reset_weights()",
        "detail": "tests.test_python",
        "documentation": {}
    },
    {
        "label": "test_model_methods",
        "kind": 2,
        "importPath": "tests.test_python",
        "description": "tests.test_python",
        "peekOfCode": "def test_model_methods():\n    \"\"\"Test various methods and properties of the YOLO model to ensure correct functionality.\"\"\"\n    model = YOLO(MODEL)\n    # Model methods\n    model.info(verbose=True, detailed=True)\n    model = model.reset_weights()\n    model = model.load(MODEL)\n    model.to(\"cpu\")\n    model.fuse()\n    model.clear_callback(\"on_train_start\")",
        "detail": "tests.test_python",
        "documentation": {}
    },
    {
        "label": "test_model_profile",
        "kind": 2,
        "importPath": "tests.test_python",
        "description": "tests.test_python",
        "peekOfCode": "def test_model_profile():\n    \"\"\"Test profiling of the YOLO model with `profile=True` to assess performance and resource usage.\"\"\"\n    from ultralytics.nn.tasks import DetectionModel\n    model = DetectionModel()  # build model\n    im = torch.randn(1, 3, 64, 64)  # requires min imgsz=64\n    _ = model.predict(im, profile=True)\n@pytest.mark.skipif(not IS_TMP_WRITEABLE, reason=\"directory is not writeable\")\ndef test_predict_txt():\n    \"\"\"Tests YOLO predictions with file, directory, and pattern sources listed in a text file.\"\"\"\n    txt_file = TMP / \"sources.txt\"",
        "detail": "tests.test_python",
        "documentation": {}
    },
    {
        "label": "test_predict_txt",
        "kind": 2,
        "importPath": "tests.test_python",
        "description": "tests.test_python",
        "peekOfCode": "def test_predict_txt():\n    \"\"\"Tests YOLO predictions with file, directory, and pattern sources listed in a text file.\"\"\"\n    txt_file = TMP / \"sources.txt\"\n    with open(txt_file, \"w\") as f:\n        for x in [ASSETS / \"bus.jpg\", ASSETS, ASSETS / \"*\", ASSETS / \"**/*.jpg\"]:\n            f.write(f\"{x}\\n\")\n    _ = YOLO(MODEL)(source=txt_file, imgsz=32)\n@pytest.mark.parametrize(\"model_name\", MODELS)\ndef test_predict_img(model_name):\n    \"\"\"Test YOLO model predictions on various image input types and sources, including online images.\"\"\"",
        "detail": "tests.test_python",
        "documentation": {}
    },
    {
        "label": "test_predict_img",
        "kind": 2,
        "importPath": "tests.test_python",
        "description": "tests.test_python",
        "peekOfCode": "def test_predict_img(model_name):\n    \"\"\"Test YOLO model predictions on various image input types and sources, including online images.\"\"\"\n    model = YOLO(WEIGHTS_DIR / model_name)\n    im = cv2.imread(str(SOURCE))  # uint8 numpy array\n    assert len(model(source=Image.open(SOURCE), save=True, verbose=True, imgsz=32)) == 1  # PIL\n    assert len(model(source=im, save=True, save_txt=True, imgsz=32)) == 1  # ndarray\n    assert len(model(torch.rand((2, 3, 32, 32)), imgsz=32)) == 2  # batch-size 2 Tensor, FP32 0.0-1.0 RGB order\n    assert len(model(source=[im, im], save=True, save_txt=True, imgsz=32)) == 2  # batch\n    assert len(list(model(source=[im, im], save=True, stream=True, imgsz=32))) == 2  # stream\n    assert len(model(torch.zeros(320, 640, 3).numpy().astype(np.uint8), imgsz=32)) == 1  # tensor to numpy",
        "detail": "tests.test_python",
        "documentation": {}
    },
    {
        "label": "test_predict_visualize",
        "kind": 2,
        "importPath": "tests.test_python",
        "description": "tests.test_python",
        "peekOfCode": "def test_predict_visualize(model):\n    \"\"\"Test model prediction methods with 'visualize=True' to generate and display prediction visualizations.\"\"\"\n    YOLO(WEIGHTS_DIR / model)(SOURCE, imgsz=32, visualize=True)\ndef test_predict_grey_and_4ch():\n    \"\"\"Test YOLO prediction on SOURCE converted to greyscale and 4-channel images with various filenames.\"\"\"\n    im = Image.open(SOURCE)\n    directory = TMP / \"im4\"\n    directory.mkdir(parents=True, exist_ok=True)\n    source_greyscale = directory / \"greyscale.jpg\"\n    source_rgba = directory / \"4ch.png\"",
        "detail": "tests.test_python",
        "documentation": {}
    },
    {
        "label": "test_predict_grey_and_4ch",
        "kind": 2,
        "importPath": "tests.test_python",
        "description": "tests.test_python",
        "peekOfCode": "def test_predict_grey_and_4ch():\n    \"\"\"Test YOLO prediction on SOURCE converted to greyscale and 4-channel images with various filenames.\"\"\"\n    im = Image.open(SOURCE)\n    directory = TMP / \"im4\"\n    directory.mkdir(parents=True, exist_ok=True)\n    source_greyscale = directory / \"greyscale.jpg\"\n    source_rgba = directory / \"4ch.png\"\n    source_non_utf = directory / \"non_UTF_测试文件_tést_image.jpg\"\n    source_spaces = directory / \"image with spaces.jpg\"\n    im.convert(\"L\").save(source_greyscale)  # greyscale",
        "detail": "tests.test_python",
        "documentation": {}
    },
    {
        "label": "test_youtube",
        "kind": 2,
        "importPath": "tests.test_python",
        "description": "tests.test_python",
        "peekOfCode": "def test_youtube():\n    \"\"\"Test YOLO model on a YouTube video stream, handling potential network-related errors.\"\"\"\n    model = YOLO(MODEL)\n    try:\n        model.predict(\"https://youtu.be/G17sBkb38XQ\", imgsz=96, save=True)\n    # Handle internet connection errors and 'urllib.error.HTTPError: HTTP Error 429: Too Many Requests'\n    except (urllib.error.HTTPError, ConnectionError) as e:\n        LOGGER.warning(f\"WARNING: YouTube Test Error: {e}\")\n@pytest.mark.skipif(not ONLINE, reason=\"environment is offline\")\n@pytest.mark.skipif(not IS_TMP_WRITEABLE, reason=\"directory is not writeable\")",
        "detail": "tests.test_python",
        "documentation": {}
    },
    {
        "label": "test_track_stream",
        "kind": 2,
        "importPath": "tests.test_python",
        "description": "tests.test_python",
        "peekOfCode": "def test_track_stream():\n    \"\"\"\n    Tests streaming tracking on a short 10 frame video using ByteTrack tracker and different GMC methods.\n    Note imgsz=160 required for tracking for higher confidence and better matches.\n    \"\"\"\n    video_url = \"https://github.com/ultralytics/assets/releases/download/v0.0.0/decelera_portrait_min.mov\"\n    model = YOLO(MODEL)\n    model.track(video_url, imgsz=160, tracker=\"bytetrack.yaml\")\n    model.track(video_url, imgsz=160, tracker=\"botsort.yaml\", save_frames=True)  # test frame saving also\n    # Test Global Motion Compensation (GMC) methods",
        "detail": "tests.test_python",
        "documentation": {}
    },
    {
        "label": "test_val",
        "kind": 2,
        "importPath": "tests.test_python",
        "description": "tests.test_python",
        "peekOfCode": "def test_val():\n    \"\"\"Test the validation mode of the YOLO model.\"\"\"\n    YOLO(MODEL).val(data=\"coco8.yaml\", imgsz=32, save_hybrid=True)\ndef test_train_scratch():\n    \"\"\"Test training the YOLO model from scratch using the provided configuration.\"\"\"\n    model = YOLO(CFG)\n    model.train(data=\"coco8.yaml\", epochs=2, imgsz=32, cache=\"disk\", batch=-1, close_mosaic=1, name=\"model\")\n    model(SOURCE)\ndef test_train_pretrained():\n    \"\"\"Test training of the YOLO model starting from a pre-trained checkpoint.\"\"\"",
        "detail": "tests.test_python",
        "documentation": {}
    },
    {
        "label": "test_train_scratch",
        "kind": 2,
        "importPath": "tests.test_python",
        "description": "tests.test_python",
        "peekOfCode": "def test_train_scratch():\n    \"\"\"Test training the YOLO model from scratch using the provided configuration.\"\"\"\n    model = YOLO(CFG)\n    model.train(data=\"coco8.yaml\", epochs=2, imgsz=32, cache=\"disk\", batch=-1, close_mosaic=1, name=\"model\")\n    model(SOURCE)\ndef test_train_pretrained():\n    \"\"\"Test training of the YOLO model starting from a pre-trained checkpoint.\"\"\"\n    model = YOLO(WEIGHTS_DIR / \"yolov8n-seg.pt\")\n    model.train(data=\"coco8-seg.yaml\", epochs=1, imgsz=32, cache=\"ram\", copy_paste=0.5, mixup=0.5, name=0)\n    model(SOURCE)",
        "detail": "tests.test_python",
        "documentation": {}
    },
    {
        "label": "test_train_pretrained",
        "kind": 2,
        "importPath": "tests.test_python",
        "description": "tests.test_python",
        "peekOfCode": "def test_train_pretrained():\n    \"\"\"Test training of the YOLO model starting from a pre-trained checkpoint.\"\"\"\n    model = YOLO(WEIGHTS_DIR / \"yolov8n-seg.pt\")\n    model.train(data=\"coco8-seg.yaml\", epochs=1, imgsz=32, cache=\"ram\", copy_paste=0.5, mixup=0.5, name=0)\n    model(SOURCE)\ndef test_all_model_yamls():\n    \"\"\"Test YOLO model creation for all available YAML configurations in the `cfg/models` directory.\"\"\"\n    for m in (ROOT / \"cfg\" / \"models\").rglob(\"*.yaml\"):\n        if \"rtdetr\" in m.name:\n            if TORCH_1_9:  # torch<=1.8 issue - TypeError: __init__() got an unexpected keyword argument 'batch_first'",
        "detail": "tests.test_python",
        "documentation": {}
    },
    {
        "label": "test_all_model_yamls",
        "kind": 2,
        "importPath": "tests.test_python",
        "description": "tests.test_python",
        "peekOfCode": "def test_all_model_yamls():\n    \"\"\"Test YOLO model creation for all available YAML configurations in the `cfg/models` directory.\"\"\"\n    for m in (ROOT / \"cfg\" / \"models\").rglob(\"*.yaml\"):\n        if \"rtdetr\" in m.name:\n            if TORCH_1_9:  # torch<=1.8 issue - TypeError: __init__() got an unexpected keyword argument 'batch_first'\n                _ = RTDETR(m.name)(SOURCE, imgsz=640)  # must be 640\n        else:\n            YOLO(m.name)\ndef test_workflow():\n    \"\"\"Test the complete workflow including training, validation, prediction, and exporting.\"\"\"",
        "detail": "tests.test_python",
        "documentation": {}
    },
    {
        "label": "test_workflow",
        "kind": 2,
        "importPath": "tests.test_python",
        "description": "tests.test_python",
        "peekOfCode": "def test_workflow():\n    \"\"\"Test the complete workflow including training, validation, prediction, and exporting.\"\"\"\n    model = YOLO(MODEL)\n    model.train(data=\"coco8.yaml\", epochs=1, imgsz=32, optimizer=\"SGD\")\n    model.val(imgsz=32)\n    model.predict(SOURCE, imgsz=32)\n    model.export(format=\"torchscript\")\ndef test_predict_callback_and_setup():\n    \"\"\"Test callback functionality during YOLO prediction setup and execution.\"\"\"\n    def on_predict_batch_end(predictor):",
        "detail": "tests.test_python",
        "documentation": {}
    },
    {
        "label": "test_predict_callback_and_setup",
        "kind": 2,
        "importPath": "tests.test_python",
        "description": "tests.test_python",
        "peekOfCode": "def test_predict_callback_and_setup():\n    \"\"\"Test callback functionality during YOLO prediction setup and execution.\"\"\"\n    def on_predict_batch_end(predictor):\n        \"\"\"Callback function that handles operations at the end of a prediction batch.\"\"\"\n        path, im0s, _ = predictor.batch\n        im0s = im0s if isinstance(im0s, list) else [im0s]\n        bs = [predictor.dataset.bs for _ in range(len(path))]\n        predictor.results = zip(predictor.results, im0s, bs)  # results is List[batch_size]\n    model = YOLO(MODEL)\n    model.add_callback(\"on_predict_batch_end\", on_predict_batch_end)",
        "detail": "tests.test_python",
        "documentation": {}
    },
    {
        "label": "test_results",
        "kind": 2,
        "importPath": "tests.test_python",
        "description": "tests.test_python",
        "peekOfCode": "def test_results(model):\n    \"\"\"Ensure YOLO model predictions can be processed and printed in various formats.\"\"\"\n    results = YOLO(WEIGHTS_DIR / model)([SOURCE, SOURCE], imgsz=160)\n    for r in results:\n        r = r.cpu().numpy()\n        print(r, len(r), r.path)  # print numpy attributes\n        r = r.to(device=\"cpu\", dtype=torch.float32)\n        r.save_txt(txt_file=TMP / \"runs/tests/label.txt\", save_conf=True)\n        r.save_crop(save_dir=TMP / \"runs/tests/crops/\")\n        r.tojson(normalize=True)",
        "detail": "tests.test_python",
        "documentation": {}
    },
    {
        "label": "test_labels_and_crops",
        "kind": 2,
        "importPath": "tests.test_python",
        "description": "tests.test_python",
        "peekOfCode": "def test_labels_and_crops():\n    \"\"\"Test output from prediction args for saving YOLO detection labels and crops; ensures accurate saving.\"\"\"\n    imgs = [SOURCE, ASSETS / \"zidane.jpg\"]\n    results = YOLO(WEIGHTS_DIR / \"yolov8n.pt\")(imgs, imgsz=160, save_txt=True, save_crop=True)\n    save_path = Path(results[0].save_dir)\n    for r in results:\n        im_name = Path(r.path).stem\n        cls_idxs = r.boxes.cls.int().tolist()\n        # Check label path\n        labels = save_path / f\"labels/{im_name}.txt\"",
        "detail": "tests.test_python",
        "documentation": {}
    },
    {
        "label": "test_data_utils",
        "kind": 2,
        "importPath": "tests.test_python",
        "description": "tests.test_python",
        "peekOfCode": "def test_data_utils():\n    \"\"\"Test utility functions in ultralytics/data/utils.py, including dataset stats and auto-splitting.\"\"\"\n    from ultralytics.data.utils import HUBDatasetStats, autosplit\n    from ultralytics.utils.downloads import zip_directory\n    # from ultralytics.utils.files import WorkingDirectory\n    # with WorkingDirectory(ROOT.parent / 'tests'):\n    for task in TASKS:\n        file = Path(TASK2DATA[task]).with_suffix(\".zip\")  # i.e. coco8.zip\n        download(f\"https://github.com/ultralytics/hub/raw/main/example_datasets/{file}\", unzip=False, dir=TMP)\n        stats = HUBDatasetStats(TMP / file, task=task)",
        "detail": "tests.test_python",
        "documentation": {}
    },
    {
        "label": "test_data_converter",
        "kind": 2,
        "importPath": "tests.test_python",
        "description": "tests.test_python",
        "peekOfCode": "def test_data_converter():\n    \"\"\"Test dataset conversion functions from COCO to YOLO format and class mappings.\"\"\"\n    from ultralytics.data.converter import coco80_to_coco91_class, convert_coco\n    file = \"instances_val2017.json\"\n    download(f\"https://github.com/ultralytics/assets/releases/download/v0.0.0/{file}\", dir=TMP)\n    convert_coco(labels_dir=TMP, save_dir=TMP / \"yolo_labels\", use_segments=True, use_keypoints=False, cls91to80=True)\n    coco80_to_coco91_class()\ndef test_data_annotator():\n    \"\"\"Automatically annotate data using specified detection and segmentation models.\"\"\"\n    from ultralytics.data.annotator import auto_annotate",
        "detail": "tests.test_python",
        "documentation": {}
    },
    {
        "label": "test_data_annotator",
        "kind": 2,
        "importPath": "tests.test_python",
        "description": "tests.test_python",
        "peekOfCode": "def test_data_annotator():\n    \"\"\"Automatically annotate data using specified detection and segmentation models.\"\"\"\n    from ultralytics.data.annotator import auto_annotate\n    auto_annotate(\n        ASSETS,\n        det_model=WEIGHTS_DIR / \"yolov8n.pt\",\n        sam_model=WEIGHTS_DIR / \"mobile_sam.pt\",\n        output_dir=TMP / \"auto_annotate_labels\",\n    )\ndef test_events():",
        "detail": "tests.test_python",
        "documentation": {}
    },
    {
        "label": "test_events",
        "kind": 2,
        "importPath": "tests.test_python",
        "description": "tests.test_python",
        "peekOfCode": "def test_events():\n    \"\"\"Test event sending functionality.\"\"\"\n    from ultralytics.hub.utils import Events\n    events = Events()\n    events.enabled = True\n    cfg = copy(DEFAULT_CFG)  # does not require deepcopy\n    cfg.mode = \"test\"\n    events(cfg)\ndef test_cfg_init():\n    \"\"\"Test configuration initialization utilities from the 'ultralytics.cfg' module.\"\"\"",
        "detail": "tests.test_python",
        "documentation": {}
    },
    {
        "label": "test_cfg_init",
        "kind": 2,
        "importPath": "tests.test_python",
        "description": "tests.test_python",
        "peekOfCode": "def test_cfg_init():\n    \"\"\"Test configuration initialization utilities from the 'ultralytics.cfg' module.\"\"\"\n    from ultralytics.cfg import check_dict_alignment, copy_default_cfg, smart_value\n    with contextlib.suppress(SyntaxError):\n        check_dict_alignment({\"a\": 1}, {\"b\": 2})\n    copy_default_cfg()\n    (Path.cwd() / DEFAULT_CFG_PATH.name.replace(\".yaml\", \"_copy.yaml\")).unlink(missing_ok=False)\n    [smart_value(x) for x in [\"none\", \"true\", \"false\"]]\ndef test_utils_init():\n    \"\"\"Test initialization utilities in the Ultralytics library.\"\"\"",
        "detail": "tests.test_python",
        "documentation": {}
    },
    {
        "label": "test_utils_init",
        "kind": 2,
        "importPath": "tests.test_python",
        "description": "tests.test_python",
        "peekOfCode": "def test_utils_init():\n    \"\"\"Test initialization utilities in the Ultralytics library.\"\"\"\n    from ultralytics.utils import get_git_branch, get_git_origin_url, get_ubuntu_version, is_github_action_running\n    get_ubuntu_version()\n    is_github_action_running()\n    get_git_origin_url()\n    get_git_branch()\ndef test_utils_checks():\n    \"\"\"Test various utility checks for filenames, git status, requirements, image sizes, and versions.\"\"\"\n    checks.check_yolov5u_filename(\"yolov5n.pt\")",
        "detail": "tests.test_python",
        "documentation": {}
    },
    {
        "label": "test_utils_checks",
        "kind": 2,
        "importPath": "tests.test_python",
        "description": "tests.test_python",
        "peekOfCode": "def test_utils_checks():\n    \"\"\"Test various utility checks for filenames, git status, requirements, image sizes, and versions.\"\"\"\n    checks.check_yolov5u_filename(\"yolov5n.pt\")\n    checks.git_describe(ROOT)\n    checks.check_requirements()  # check requirements.txt\n    checks.check_imgsz([600, 600], max_dim=1)\n    checks.check_imshow(warn=True)\n    checks.check_version(\"ultralytics\", \"8.0.0\")\n    checks.print_args()\n@pytest.mark.skipif(WINDOWS, reason=\"Windows profiling is extremely slow (cause unknown)\")",
        "detail": "tests.test_python",
        "documentation": {}
    },
    {
        "label": "test_utils_benchmarks",
        "kind": 2,
        "importPath": "tests.test_python",
        "description": "tests.test_python",
        "peekOfCode": "def test_utils_benchmarks():\n    \"\"\"Benchmark model performance using 'ProfileModels' from 'ultralytics.utils.benchmarks'.\"\"\"\n    from ultralytics.utils.benchmarks import ProfileModels\n    ProfileModels([\"yolov8n.yaml\"], imgsz=32, min_time=1, num_timed_runs=3, num_warmup_runs=1).profile()\ndef test_utils_torchutils():\n    \"\"\"Test Torch utility functions including profiling and FLOP calculations.\"\"\"\n    from ultralytics.nn.modules.conv import Conv\n    from ultralytics.utils.torch_utils import get_flops_with_torch_profiler, profile, time_sync\n    x = torch.randn(1, 64, 20, 20)\n    m = Conv(64, 64, k=1, s=2)",
        "detail": "tests.test_python",
        "documentation": {}
    },
    {
        "label": "test_utils_torchutils",
        "kind": 2,
        "importPath": "tests.test_python",
        "description": "tests.test_python",
        "peekOfCode": "def test_utils_torchutils():\n    \"\"\"Test Torch utility functions including profiling and FLOP calculations.\"\"\"\n    from ultralytics.nn.modules.conv import Conv\n    from ultralytics.utils.torch_utils import get_flops_with_torch_profiler, profile, time_sync\n    x = torch.randn(1, 64, 20, 20)\n    m = Conv(64, 64, k=1, s=2)\n    profile(x, [m], n=3)\n    get_flops_with_torch_profiler(m)\n    time_sync()\n@pytest.mark.slow",
        "detail": "tests.test_python",
        "documentation": {}
    },
    {
        "label": "test_utils_downloads",
        "kind": 2,
        "importPath": "tests.test_python",
        "description": "tests.test_python",
        "peekOfCode": "def test_utils_downloads():\n    \"\"\"Test file download utilities from ultralytics.utils.downloads.\"\"\"\n    from ultralytics.utils.downloads import get_google_drive_file_info\n    get_google_drive_file_info(\"https://drive.google.com/file/d/1cqT-cJgANNrhIHCrEufUYhQ4RqiWG_lJ/view?usp=drive_link\")\ndef test_utils_ops():\n    \"\"\"Test utility operations functions for coordinate transformation and normalization.\"\"\"\n    from ultralytics.utils.ops import (\n        ltwh2xywh,\n        ltwh2xyxy,\n        make_divisible,",
        "detail": "tests.test_python",
        "documentation": {}
    },
    {
        "label": "test_utils_ops",
        "kind": 2,
        "importPath": "tests.test_python",
        "description": "tests.test_python",
        "peekOfCode": "def test_utils_ops():\n    \"\"\"Test utility operations functions for coordinate transformation and normalization.\"\"\"\n    from ultralytics.utils.ops import (\n        ltwh2xywh,\n        ltwh2xyxy,\n        make_divisible,\n        xywh2ltwh,\n        xywh2xyxy,\n        xywhn2xyxy,\n        xywhr2xyxyxyxy,",
        "detail": "tests.test_python",
        "documentation": {}
    },
    {
        "label": "test_utils_files",
        "kind": 2,
        "importPath": "tests.test_python",
        "description": "tests.test_python",
        "peekOfCode": "def test_utils_files():\n    \"\"\"Test file handling utilities including file age, date, and paths with spaces.\"\"\"\n    from ultralytics.utils.files import file_age, file_date, get_latest_run, spaces_in_path\n    file_age(SOURCE)\n    file_date(SOURCE)\n    get_latest_run(ROOT / \"runs\")\n    path = TMP / \"path/with spaces\"\n    path.mkdir(parents=True, exist_ok=True)\n    with spaces_in_path(path) as new_path:\n        print(new_path)",
        "detail": "tests.test_python",
        "documentation": {}
    },
    {
        "label": "test_utils_patches_torch_save",
        "kind": 2,
        "importPath": "tests.test_python",
        "description": "tests.test_python",
        "peekOfCode": "def test_utils_patches_torch_save():\n    \"\"\"Test torch_save backoff when _torch_save raises RuntimeError to ensure robustness.\"\"\"\n    from unittest.mock import MagicMock, patch\n    from ultralytics.utils.patches import torch_save\n    mock = MagicMock(side_effect=RuntimeError)\n    with patch(\"ultralytics.utils.patches._torch_save\", new=mock):\n        with pytest.raises(RuntimeError):\n            torch_save(torch.zeros(1), TMP / \"test.pt\")\n    assert mock.call_count == 4, \"torch_save was not attempted the expected number of times\"\ndef test_nn_modules_conv():",
        "detail": "tests.test_python",
        "documentation": {}
    },
    {
        "label": "test_nn_modules_conv",
        "kind": 2,
        "importPath": "tests.test_python",
        "description": "tests.test_python",
        "peekOfCode": "def test_nn_modules_conv():\n    \"\"\"Test Convolutional Neural Network modules including CBAM, Conv2, and ConvTranspose.\"\"\"\n    from ultralytics.nn.modules.conv import CBAM, Conv2, ConvTranspose, DWConvTranspose2d, Focus\n    c1, c2 = 8, 16  # input and output channels\n    x = torch.zeros(4, c1, 10, 10)  # BCHW\n    # Run all modules not otherwise covered in tests\n    DWConvTranspose2d(c1, c2)(x)\n    ConvTranspose(c1, c2)(x)\n    Focus(c1, c2)(x)\n    CBAM(c1)(x)",
        "detail": "tests.test_python",
        "documentation": {}
    },
    {
        "label": "test_nn_modules_block",
        "kind": 2,
        "importPath": "tests.test_python",
        "description": "tests.test_python",
        "peekOfCode": "def test_nn_modules_block():\n    \"\"\"Test various blocks in neural network modules including C1, C3TR, BottleneckCSP, C3Ghost, and C3x.\"\"\"\n    from ultralytics.nn.modules.block import C1, C3TR, BottleneckCSP, C3Ghost, C3x\n    c1, c2 = 8, 16  # input and output channels\n    x = torch.zeros(4, c1, 10, 10)  # BCHW\n    # Run all modules not otherwise covered in tests\n    C1(c1, c2)(x)\n    C3x(c1, c2)(x)\n    C3TR(c1, c2)(x)\n    C3Ghost(c1, c2)(x)",
        "detail": "tests.test_python",
        "documentation": {}
    },
    {
        "label": "test_hub",
        "kind": 2,
        "importPath": "tests.test_python",
        "description": "tests.test_python",
        "peekOfCode": "def test_hub():\n    \"\"\"Test Ultralytics HUB functionalities (e.g. export formats, logout).\"\"\"\n    from ultralytics.hub import export_fmts_hub, logout\n    from ultralytics.hub.utils import smart_request\n    export_fmts_hub()\n    logout()\n    smart_request(\"GET\", \"https://github.com\", progress=True)\n@pytest.fixture\ndef image():\n    \"\"\"Load and return an image from a predefined source using OpenCV.\"\"\"",
        "detail": "tests.test_python",
        "documentation": {}
    },
    {
        "label": "image",
        "kind": 2,
        "importPath": "tests.test_python",
        "description": "tests.test_python",
        "peekOfCode": "def image():\n    \"\"\"Load and return an image from a predefined source using OpenCV.\"\"\"\n    return cv2.imread(str(SOURCE))\n@pytest.mark.parametrize(\n    \"auto_augment, erasing, force_color_jitter\",\n    [\n        (None, 0.0, False),\n        (\"randaugment\", 0.5, True),\n        (\"augmix\", 0.2, False),\n        (\"autoaugment\", 0.0, True),",
        "detail": "tests.test_python",
        "documentation": {}
    },
    {
        "label": "test_classify_transforms_train",
        "kind": 2,
        "importPath": "tests.test_python",
        "description": "tests.test_python",
        "peekOfCode": "def test_classify_transforms_train(image, auto_augment, erasing, force_color_jitter):\n    \"\"\"Tests classification transforms during training with various augmentations to ensure proper functionality.\"\"\"\n    from ultralytics.data.augment import classify_augmentations\n    transform = classify_augmentations(\n        size=224,\n        mean=(0.5, 0.5, 0.5),\n        std=(0.5, 0.5, 0.5),\n        scale=(0.08, 1.0),\n        ratio=(3.0 / 4.0, 4.0 / 3.0),\n        hflip=0.5,",
        "detail": "tests.test_python",
        "documentation": {}
    },
    {
        "label": "test_model_tune",
        "kind": 2,
        "importPath": "tests.test_python",
        "description": "tests.test_python",
        "peekOfCode": "def test_model_tune():\n    \"\"\"Tune YOLO model for performance improvement.\"\"\"\n    YOLO(\"yolov8n-pose.pt\").tune(data=\"coco8-pose.yaml\", plots=False, imgsz=32, epochs=1, iterations=2, device=\"cpu\")\n    YOLO(\"yolov8n-cls.pt\").tune(data=\"imagenet10\", plots=False, imgsz=32, epochs=1, iterations=2, device=\"cpu\")\ndef test_model_embeddings():\n    \"\"\"Test YOLO model embeddings.\"\"\"\n    model_detect = YOLO(MODEL)\n    model_segment = YOLO(WEIGHTS_DIR / \"yolov8n-seg.pt\")\n    for batch in [SOURCE], [SOURCE, SOURCE]:  # test batch size 1 and 2\n        assert len(model_detect.embed(source=batch, imgsz=32)) == len(batch)",
        "detail": "tests.test_python",
        "documentation": {}
    },
    {
        "label": "test_model_embeddings",
        "kind": 2,
        "importPath": "tests.test_python",
        "description": "tests.test_python",
        "peekOfCode": "def test_model_embeddings():\n    \"\"\"Test YOLO model embeddings.\"\"\"\n    model_detect = YOLO(MODEL)\n    model_segment = YOLO(WEIGHTS_DIR / \"yolov8n-seg.pt\")\n    for batch in [SOURCE], [SOURCE, SOURCE]:  # test batch size 1 and 2\n        assert len(model_detect.embed(source=batch, imgsz=32)) == len(batch)\n        assert len(model_segment.embed(source=batch, imgsz=32)) == len(batch)\n@pytest.mark.skipif(checks.IS_PYTHON_3_12, reason=\"YOLOWorld with CLIP is not supported in Python 3.12\")\ndef test_yolo_world():\n    \"\"\"Tests YOLO world models with CLIP support, including detection and training scenarios.\"\"\"",
        "detail": "tests.test_python",
        "documentation": {}
    },
    {
        "label": "test_yolo_world",
        "kind": 2,
        "importPath": "tests.test_python",
        "description": "tests.test_python",
        "peekOfCode": "def test_yolo_world():\n    \"\"\"Tests YOLO world models with CLIP support, including detection and training scenarios.\"\"\"\n    model = YOLO(\"yolov8s-world.pt\")  # no YOLOv8n-world model yet\n    model.set_classes([\"tree\", \"window\"])\n    model(SOURCE, conf=0.01)\n    model = YOLO(\"yolov8s-worldv2.pt\")  # no YOLOv8n-world model yet\n    # Training from a pretrained model. Eval is included at the final stage of training.\n    # Use dota8.yaml which has fewer categories to reduce the inference time of CLIP model\n    model.train(\n        data=\"dota8.yaml\",",
        "detail": "tests.test_python",
        "documentation": {}
    },
    {
        "label": "test_yolov10",
        "kind": 2,
        "importPath": "tests.test_python",
        "description": "tests.test_python",
        "peekOfCode": "def test_yolov10():\n    \"\"\"Test YOLOv10 model training, validation, and prediction steps with minimal configurations.\"\"\"\n    model = YOLO(\"yolov10n.yaml\")\n    # train/val/predict\n    model.train(data=\"coco8.yaml\", epochs=1, imgsz=32, close_mosaic=1, cache=\"disk\")\n    model.val(data=\"coco8.yaml\", imgsz=32)\n    model.predict(imgsz=32, save_txt=True, save_crop=True, augment=True)\n    model(SOURCE)",
        "detail": "tests.test_python",
        "documentation": {}
    },
    {
        "label": "test_major_solutions",
        "kind": 2,
        "importPath": "tests.test_solutions",
        "description": "tests.test_solutions",
        "peekOfCode": "def test_major_solutions():\n    \"\"\"Test the object counting, heatmap, speed estimation and queue management solution.\"\"\"\n    safe_download(url=MAJOR_SOLUTIONS_DEMO)\n    model = YOLO(\"yolov8n.pt\")\n    names = model.names\n    cap = cv2.VideoCapture(\"solutions_ci_demo.mp4\")\n    assert cap.isOpened(), \"Error reading video file\"\n    region_points = [(20, 400), (1080, 404), (1080, 360), (20, 360)]\n    counter = solutions.ObjectCounter(reg_pts=region_points, names=names, view_img=False)\n    heatmap = solutions.Heatmap(colormap=cv2.COLORMAP_PARULA, names=names, view_img=False)",
        "detail": "tests.test_solutions",
        "documentation": {}
    },
    {
        "label": "test_aigym",
        "kind": 2,
        "importPath": "tests.test_solutions",
        "description": "tests.test_solutions",
        "peekOfCode": "def test_aigym():\n    \"\"\"Test the workouts monitoring solution.\"\"\"\n    safe_download(url=WORKOUTS_SOLUTION_DEMO)\n    model = YOLO(\"yolov8n-pose.pt\")\n    cap = cv2.VideoCapture(\"solution_ci_pose_demo.mp4\")\n    assert cap.isOpened(), \"Error reading video file\"\n    gym_object = solutions.AIGym(line_thickness=2, pose_type=\"squat\", kpts_to_check=[5, 11, 13])\n    while cap.isOpened():\n        success, im0 = cap.read()\n        if not success:",
        "detail": "tests.test_solutions",
        "documentation": {}
    },
    {
        "label": "test_instance_segmentation",
        "kind": 2,
        "importPath": "tests.test_solutions",
        "description": "tests.test_solutions",
        "peekOfCode": "def test_instance_segmentation():\n    \"\"\"Test the instance segmentation solution.\"\"\"\n    from ultralytics.utils.plotting import Annotator, colors\n    model = YOLO(\"yolov8n-seg.pt\")\n    names = model.names\n    cap = cv2.VideoCapture(\"solutions_ci_demo.mp4\")\n    assert cap.isOpened(), \"Error reading video file\"\n    while cap.isOpened():\n        success, im0 = cap.read()\n        if not success:",
        "detail": "tests.test_solutions",
        "documentation": {}
    },
    {
        "label": "test_streamlit_predict",
        "kind": 2,
        "importPath": "tests.test_solutions",
        "description": "tests.test_solutions",
        "peekOfCode": "def test_streamlit_predict():\n    \"\"\"Test streamlit predict live inference solution.\"\"\"\n    solutions.inference()",
        "detail": "tests.test_solutions",
        "documentation": {}
    },
    {
        "label": "MAJOR_SOLUTIONS_DEMO",
        "kind": 5,
        "importPath": "tests.test_solutions",
        "description": "tests.test_solutions",
        "peekOfCode": "MAJOR_SOLUTIONS_DEMO = \"https://github.com/ultralytics/assets/releases/download/v0.0.0/solutions_ci_demo.mp4\"\nWORKOUTS_SOLUTION_DEMO = \"https://github.com/ultralytics/assets/releases/download/v0.0.0/solution_ci_pose_demo.mp4\"\n@pytest.mark.slow\ndef test_major_solutions():\n    \"\"\"Test the object counting, heatmap, speed estimation and queue management solution.\"\"\"\n    safe_download(url=MAJOR_SOLUTIONS_DEMO)\n    model = YOLO(\"yolov8n.pt\")\n    names = model.names\n    cap = cv2.VideoCapture(\"solutions_ci_demo.mp4\")\n    assert cap.isOpened(), \"Error reading video file\"",
        "detail": "tests.test_solutions",
        "documentation": {}
    },
    {
        "label": "WORKOUTS_SOLUTION_DEMO",
        "kind": 5,
        "importPath": "tests.test_solutions",
        "description": "tests.test_solutions",
        "peekOfCode": "WORKOUTS_SOLUTION_DEMO = \"https://github.com/ultralytics/assets/releases/download/v0.0.0/solution_ci_pose_demo.mp4\"\n@pytest.mark.slow\ndef test_major_solutions():\n    \"\"\"Test the object counting, heatmap, speed estimation and queue management solution.\"\"\"\n    safe_download(url=MAJOR_SOLUTIONS_DEMO)\n    model = YOLO(\"yolov8n.pt\")\n    names = model.names\n    cap = cv2.VideoCapture(\"solutions_ci_demo.mp4\")\n    assert cap.isOpened(), \"Error reading video file\"\n    region_points = [(20, 400), (1080, 404), (1080, 360), (20, 360)]",
        "detail": "tests.test_solutions",
        "documentation": {}
    },
    {
        "label": "init_explorer_form",
        "kind": 2,
        "importPath": "ultralytics.data.explorer.gui.dash",
        "description": "ultralytics.data.explorer.gui.dash",
        "peekOfCode": "def init_explorer_form(data=None, model=None):\n    \"\"\"Initializes an Explorer instance and creates embeddings table with progress tracking.\"\"\"\n    if data is None:\n        datasets = ROOT / \"cfg\" / \"datasets\"\n        ds = [d.name for d in datasets.glob(\"*.yaml\")]\n    else:\n        ds = [data]\n    if model is None:\n        models = [\n            \"yolov8n.pt\",",
        "detail": "ultralytics.data.explorer.gui.dash",
        "documentation": {}
    },
    {
        "label": "query_form",
        "kind": 2,
        "importPath": "ultralytics.data.explorer.gui.dash",
        "description": "ultralytics.data.explorer.gui.dash",
        "peekOfCode": "def query_form():\n    \"\"\"Sets up a form in Streamlit to initialize Explorer with dataset and model selection.\"\"\"\n    with st.form(\"query_form\"):\n        col1, col2 = st.columns([0.8, 0.2])\n        with col1:\n            st.text_input(\n                \"Query\",\n                \"WHERE labels LIKE '%person%' AND labels LIKE '%dog%'\",\n                label_visibility=\"collapsed\",\n                key=\"query\",",
        "detail": "ultralytics.data.explorer.gui.dash",
        "documentation": {}
    },
    {
        "label": "ai_query_form",
        "kind": 2,
        "importPath": "ultralytics.data.explorer.gui.dash",
        "description": "ultralytics.data.explorer.gui.dash",
        "peekOfCode": "def ai_query_form():\n    \"\"\"Sets up a Streamlit form for user input to initialize Explorer with dataset and model selection.\"\"\"\n    with st.form(\"ai_query_form\"):\n        col1, col2 = st.columns([0.8, 0.2])\n        with col1:\n            st.text_input(\"Query\", \"Show images with 1 person and 1 dog\", label_visibility=\"collapsed\", key=\"ai_query\")\n        with col2:\n            st.form_submit_button(\"Ask AI\", on_click=run_ai_query)\ndef find_similar_imgs(imgs):\n    \"\"\"Initializes a Streamlit form for AI-based image querying with custom input.\"\"\"",
        "detail": "ultralytics.data.explorer.gui.dash",
        "documentation": {}
    },
    {
        "label": "find_similar_imgs",
        "kind": 2,
        "importPath": "ultralytics.data.explorer.gui.dash",
        "description": "ultralytics.data.explorer.gui.dash",
        "peekOfCode": "def find_similar_imgs(imgs):\n    \"\"\"Initializes a Streamlit form for AI-based image querying with custom input.\"\"\"\n    exp = st.session_state[\"explorer\"]\n    similar = exp.get_similar(img=imgs, limit=st.session_state.get(\"limit\"), return_type=\"arrow\")\n    paths = similar.to_pydict()[\"im_file\"]\n    st.session_state[\"imgs\"] = paths\n    st.session_state[\"res\"] = similar\ndef similarity_form(selected_imgs):\n    \"\"\"Initializes a form for AI-based image querying with custom input in Streamlit.\"\"\"\n    st.write(\"Similarity Search\")",
        "detail": "ultralytics.data.explorer.gui.dash",
        "documentation": {}
    },
    {
        "label": "similarity_form",
        "kind": 2,
        "importPath": "ultralytics.data.explorer.gui.dash",
        "description": "ultralytics.data.explorer.gui.dash",
        "peekOfCode": "def similarity_form(selected_imgs):\n    \"\"\"Initializes a form for AI-based image querying with custom input in Streamlit.\"\"\"\n    st.write(\"Similarity Search\")\n    with st.form(\"similarity_form\"):\n        subcol1, subcol2 = st.columns([1, 1])\n        with subcol1:\n            st.number_input(\n                \"limit\", min_value=None, max_value=None, value=25, label_visibility=\"collapsed\", key=\"limit\"\n            )\n        with subcol2:",
        "detail": "ultralytics.data.explorer.gui.dash",
        "documentation": {}
    },
    {
        "label": "run_sql_query",
        "kind": 2,
        "importPath": "ultralytics.data.explorer.gui.dash",
        "description": "ultralytics.data.explorer.gui.dash",
        "peekOfCode": "def run_sql_query():\n    \"\"\"Executes an SQL query and returns the results.\"\"\"\n    st.session_state[\"error\"] = None\n    query = st.session_state.get(\"query\")\n    if query.rstrip().lstrip():\n        exp = st.session_state[\"explorer\"]\n        res = exp.sql_query(query, return_type=\"arrow\")\n        st.session_state[\"imgs\"] = res.to_pydict()[\"im_file\"]\n        st.session_state[\"res\"] = res\ndef run_ai_query():",
        "detail": "ultralytics.data.explorer.gui.dash",
        "documentation": {}
    },
    {
        "label": "run_ai_query",
        "kind": 2,
        "importPath": "ultralytics.data.explorer.gui.dash",
        "description": "ultralytics.data.explorer.gui.dash",
        "peekOfCode": "def run_ai_query():\n    \"\"\"Execute SQL query and update session state with query results.\"\"\"\n    if not SETTINGS[\"openai_api_key\"]:\n        st.session_state[\"error\"] = (\n            'OpenAI API key not found in settings. Please run yolo settings openai_api_key=\"...\"'\n        )\n        return\n    import pandas  # scope for faster 'import ultralytics'\n    st.session_state[\"error\"] = None\n    query = st.session_state.get(\"ai_query\")",
        "detail": "ultralytics.data.explorer.gui.dash",
        "documentation": {}
    },
    {
        "label": "reset_explorer",
        "kind": 2,
        "importPath": "ultralytics.data.explorer.gui.dash",
        "description": "ultralytics.data.explorer.gui.dash",
        "peekOfCode": "def reset_explorer():\n    \"\"\"Resets the explorer to its initial state by clearing session variables.\"\"\"\n    st.session_state[\"explorer\"] = None\n    st.session_state[\"imgs\"] = None\n    st.session_state[\"error\"] = None\ndef utralytics_explorer_docs_callback():\n    \"\"\"Resets the explorer to its initial state by clearing session variables.\"\"\"\n    with st.container(border=True):\n        st.image(\n            \"https://raw.githubusercontent.com/ultralytics/assets/main/logo/Ultralytics_Logotype_Original.svg\",",
        "detail": "ultralytics.data.explorer.gui.dash",
        "documentation": {}
    },
    {
        "label": "utralytics_explorer_docs_callback",
        "kind": 2,
        "importPath": "ultralytics.data.explorer.gui.dash",
        "description": "ultralytics.data.explorer.gui.dash",
        "peekOfCode": "def utralytics_explorer_docs_callback():\n    \"\"\"Resets the explorer to its initial state by clearing session variables.\"\"\"\n    with st.container(border=True):\n        st.image(\n            \"https://raw.githubusercontent.com/ultralytics/assets/main/logo/Ultralytics_Logotype_Original.svg\",\n            width=100,\n        )\n        st.markdown(\n            \"<p>This demo is built using Ultralytics Explorer API. Visit <a href='https://docs.ultralytics.com/datasets/explorer/'>API docs</a> to try examples & learn more</p>\",\n            unsafe_allow_html=True,",
        "detail": "ultralytics.data.explorer.gui.dash",
        "documentation": {}
    },
    {
        "label": "layout",
        "kind": 2,
        "importPath": "ultralytics.data.explorer.gui.dash",
        "description": "ultralytics.data.explorer.gui.dash",
        "peekOfCode": "def layout(data=None, model=None):\n    \"\"\"Resets explorer session variables and provides documentation with a link to API docs.\"\"\"\n    st.set_page_config(layout=\"wide\", initial_sidebar_state=\"collapsed\")\n    st.markdown(\"<h1 style='text-align: center;'>Ultralytics Explorer Demo</h1>\", unsafe_allow_html=True)\n    if st.session_state.get(\"explorer\") is None:\n        init_explorer_form(data, model)\n        return\n    st.button(\":arrow_backward: Select Dataset\", on_click=reset_explorer)\n    exp = st.session_state.get(\"explorer\")\n    col1, col2 = st.columns([0.75, 0.25], gap=\"small\")",
        "detail": "ultralytics.data.explorer.gui.dash",
        "documentation": {}
    },
    {
        "label": "ExplorerDataset",
        "kind": 6,
        "importPath": "ultralytics.data.explorer.explorer",
        "description": "ultralytics.data.explorer.explorer",
        "peekOfCode": "class ExplorerDataset(YOLODataset):\n    \"\"\"Extends YOLODataset for advanced data exploration and manipulation in model training workflows.\"\"\"\n    def __init__(self, *args, data: dict = None, **kwargs) -> None:\n        \"\"\"Initializes the ExplorerDataset with the provided data arguments, extending the YOLODataset class.\"\"\"\n        super().__init__(*args, data=data, **kwargs)\n    def load_image(self, i: int) -> Union[Tuple[np.ndarray, Tuple[int, int], Tuple[int, int]], Tuple[None, None, None]]:\n        \"\"\"Loads 1 image from dataset index 'i' without any resize ops.\"\"\"\n        im, f, fn = self.ims[i], self.im_files[i], self.npy_files[i]\n        if im is None:  # not cached in RAM\n            if fn.exists():  # load npy",
        "detail": "ultralytics.data.explorer.explorer",
        "documentation": {}
    },
    {
        "label": "Explorer",
        "kind": 6,
        "importPath": "ultralytics.data.explorer.explorer",
        "description": "ultralytics.data.explorer.explorer",
        "peekOfCode": "class Explorer:\n    \"\"\"Utility class for image embedding, table creation, and similarity querying using LanceDB and YOLO models.\"\"\"\n    def __init__(\n        self,\n        data: Union[str, Path] = \"coco128.yaml\",\n        model: str = \"yolov8n.pt\",\n        uri: str = USER_CONFIG_DIR / \"explorer\",\n    ) -> None:\n        \"\"\"Initializes the Explorer class with dataset path, model, and URI for database connection.\"\"\"\n        # Note duckdb==0.10.0 bug https://github.com/ultralytics/ultralytics/pull/8181",
        "detail": "ultralytics.data.explorer.explorer",
        "documentation": {}
    },
    {
        "label": "get_table_schema",
        "kind": 2,
        "importPath": "ultralytics.data.explorer.utils",
        "description": "ultralytics.data.explorer.utils",
        "peekOfCode": "def get_table_schema(vector_size):\n    \"\"\"Extracts and returns the schema of a database table.\"\"\"\n    from lancedb.pydantic import LanceModel, Vector\n    class Schema(LanceModel):\n        im_file: str\n        labels: List[str]\n        cls: List[int]\n        bboxes: List[List[float]]\n        masks: List[List[List[int]]]\n        keypoints: List[List[List[float]]]",
        "detail": "ultralytics.data.explorer.utils",
        "documentation": {}
    },
    {
        "label": "get_sim_index_schema",
        "kind": 2,
        "importPath": "ultralytics.data.explorer.utils",
        "description": "ultralytics.data.explorer.utils",
        "peekOfCode": "def get_sim_index_schema():\n    \"\"\"Returns a LanceModel schema for a database table with specified vector size.\"\"\"\n    from lancedb.pydantic import LanceModel\n    class Schema(LanceModel):\n        idx: int\n        im_file: str\n        count: int\n        sim_im_files: List[str]\n    return Schema\ndef sanitize_batch(batch, dataset_info):",
        "detail": "ultralytics.data.explorer.utils",
        "documentation": {}
    },
    {
        "label": "sanitize_batch",
        "kind": 2,
        "importPath": "ultralytics.data.explorer.utils",
        "description": "ultralytics.data.explorer.utils",
        "peekOfCode": "def sanitize_batch(batch, dataset_info):\n    \"\"\"Sanitizes input batch for inference, ensuring correct format and dimensions.\"\"\"\n    batch[\"cls\"] = batch[\"cls\"].flatten().int().tolist()\n    box_cls_pair = sorted(zip(batch[\"bboxes\"].tolist(), batch[\"cls\"]), key=lambda x: x[1])\n    batch[\"bboxes\"] = [box for box, _ in box_cls_pair]\n    batch[\"cls\"] = [cls for _, cls in box_cls_pair]\n    batch[\"labels\"] = [dataset_info[\"names\"][i] for i in batch[\"cls\"]]\n    batch[\"masks\"] = batch[\"masks\"].tolist() if \"masks\" in batch else [[[]]]\n    batch[\"keypoints\"] = batch[\"keypoints\"].tolist() if \"keypoints\" in batch else [[[]]]\n    return batch",
        "detail": "ultralytics.data.explorer.utils",
        "documentation": {}
    },
    {
        "label": "plot_query_result",
        "kind": 2,
        "importPath": "ultralytics.data.explorer.utils",
        "description": "ultralytics.data.explorer.utils",
        "peekOfCode": "def plot_query_result(similar_set, plot_labels=True):\n    \"\"\"\n    Plot images from the similar set.\n    Args:\n        similar_set (list): Pyarrow or pandas object containing the similar data points\n        plot_labels (bool): Whether to plot labels or not\n    \"\"\"\n    import pandas  # scope for faster 'import ultralytics'\n    similar_set = (\n        similar_set.to_dict(orient=\"list\") if isinstance(similar_set, pandas.DataFrame) else similar_set.to_pydict()",
        "detail": "ultralytics.data.explorer.utils",
        "documentation": {}
    },
    {
        "label": "prompt_sql_query",
        "kind": 2,
        "importPath": "ultralytics.data.explorer.utils",
        "description": "ultralytics.data.explorer.utils",
        "peekOfCode": "def prompt_sql_query(query):\n    \"\"\"Plots images with optional labels from a similar data set.\"\"\"\n    check_requirements(\"openai>=1.6.1\")\n    from openai import OpenAI\n    if not SETTINGS[\"openai_api_key\"]:\n        logger.warning(\"OpenAI API key not found in settings. Please enter your API key below.\")\n        openai_api_key = getpass.getpass(\"OpenAI API key: \")\n        SETTINGS.update({\"openai_api_key\": openai_api_key})\n    openai = OpenAI(api_key=SETTINGS[\"openai_api_key\"])\n    messages = [",
        "detail": "ultralytics.data.explorer.utils",
        "documentation": {}
    },
    {
        "label": "auto_annotate",
        "kind": 2,
        "importPath": "ultralytics.data.annotator",
        "description": "ultralytics.data.annotator",
        "peekOfCode": "def auto_annotate(data, det_model=\"yolov8x.pt\", sam_model=\"sam_b.pt\", device=\"\", output_dir=None):\n    \"\"\"\n    Automatically annotates images using a YOLO object detection model and a SAM segmentation model.\n    This function processes images in a specified directory, detects objects using a YOLO model, and then generates\n    segmentation masks using a SAM model. The resulting annotations are saved as text files.\n    Args:\n        data (str): Path to a folder containing images to be annotated.\n        det_model (str): Path or name of the pre-trained YOLO detection model.\n        sam_model (str): Path or name of the pre-trained SAM segmentation model.\n        device (str): Device to run the models on (e.g., 'cpu', 'cuda', '0').",
        "detail": "ultralytics.data.annotator",
        "documentation": {}
    },
    {
        "label": "BaseTransform",
        "kind": 6,
        "importPath": "ultralytics.data.augment",
        "description": "ultralytics.data.augment",
        "peekOfCode": "class BaseTransform:\n    \"\"\"\n    Base class for image transformations in the Ultralytics library.\n    This class serves as a foundation for implementing various image processing operations, designed to be\n    compatible with both classification and semantic segmentation tasks.\n    Methods:\n        apply_image: Applies image transformations to labels.\n        apply_instances: Applies transformations to object instances in labels.\n        apply_semantic: Applies semantic segmentation to an image.\n        __call__: Applies all label transformations to an image, instances, and semantic masks.",
        "detail": "ultralytics.data.augment",
        "documentation": {}
    },
    {
        "label": "Compose",
        "kind": 6,
        "importPath": "ultralytics.data.augment",
        "description": "ultralytics.data.augment",
        "peekOfCode": "class Compose:\n    \"\"\"\n    A class for composing multiple image transformations.\n    Attributes:\n        transforms (List[Callable]): A list of transformation functions to be applied sequentially.\n    Methods:\n        __call__: Applies a series of transformations to input data.\n        append: Appends a new transform to the existing list of transforms.\n        insert: Inserts a new transform at a specified index in the list of transforms.\n        __getitem__: Retrieves a specific transform or a set of transforms using indexing.",
        "detail": "ultralytics.data.augment",
        "documentation": {}
    },
    {
        "label": "BaseMixTransform",
        "kind": 6,
        "importPath": "ultralytics.data.augment",
        "description": "ultralytics.data.augment",
        "peekOfCode": "class BaseMixTransform:\n    \"\"\"\n    Base class for mix transformations like MixUp and Mosaic.\n    This class provides a foundation for implementing mix transformations on datasets. It handles the\n    probability-based application of transforms and manages the mixing of multiple images and labels.\n    Attributes:\n        dataset (Any): The dataset object containing images and labels.\n        pre_transform (Callable | None): Optional transform to apply before mixing.\n        p (float): Probability of applying the mix transformation.\n    Methods:",
        "detail": "ultralytics.data.augment",
        "documentation": {}
    },
    {
        "label": "Mosaic",
        "kind": 6,
        "importPath": "ultralytics.data.augment",
        "description": "ultralytics.data.augment",
        "peekOfCode": "class Mosaic(BaseMixTransform):\n    \"\"\"\n    Mosaic augmentation for image datasets.\n    This class performs mosaic augmentation by combining multiple (4 or 9) images into a single mosaic image.\n    The augmentation is applied to a dataset with a given probability.\n    Attributes:\n        dataset: The dataset on which the mosaic augmentation is applied.\n        imgsz (int): Image size (height and width) after mosaic pipeline of a single image.\n        p (float): Probability of applying the mosaic augmentation. Must be in the range 0-1.\n        n (int): The grid size, either 4 (for 2x2) or 9 (for 3x3).",
        "detail": "ultralytics.data.augment",
        "documentation": {}
    },
    {
        "label": "MixUp",
        "kind": 6,
        "importPath": "ultralytics.data.augment",
        "description": "ultralytics.data.augment",
        "peekOfCode": "class MixUp(BaseMixTransform):\n    \"\"\"\n    Applies MixUp augmentation to image datasets.\n    This class implements the MixUp augmentation technique as described in the paper \"mixup: Beyond Empirical Risk\n    Minimization\" (https://arxiv.org/abs/1710.09412). MixUp combines two images and their labels using a random weight.\n    Attributes:\n        dataset (Any): The dataset to which MixUp augmentation will be applied.\n        pre_transform (Callable | None): Optional transform to apply before MixUp.\n        p (float): Probability of applying MixUp augmentation.\n    Methods:",
        "detail": "ultralytics.data.augment",
        "documentation": {}
    },
    {
        "label": "RandomPerspective",
        "kind": 6,
        "importPath": "ultralytics.data.augment",
        "description": "ultralytics.data.augment",
        "peekOfCode": "class RandomPerspective:\n    \"\"\"\n    Implements random perspective and affine transformations on images and corresponding annotations.\n    This class applies random rotations, translations, scaling, shearing, and perspective transformations\n    to images and their associated bounding boxes, segments, and keypoints. It can be used as part of an\n    augmentation pipeline for object detection and instance segmentation tasks.\n    Attributes:\n        degrees (float): Maximum absolute degree range for random rotations.\n        translate (float): Maximum translation as a fraction of the image size.\n        scale (float): Scaling factor range, e.g., scale=0.1 means 0.9-1.1.",
        "detail": "ultralytics.data.augment",
        "documentation": {}
    },
    {
        "label": "RandomHSV",
        "kind": 6,
        "importPath": "ultralytics.data.augment",
        "description": "ultralytics.data.augment",
        "peekOfCode": "class RandomHSV:\n    \"\"\"\n    Randomly adjusts the Hue, Saturation, and Value (HSV) channels of an image.\n    This class applies random HSV augmentation to images within predefined limits set by hgain, sgain, and vgain.\n    Attributes:\n        hgain (float): Maximum variation for hue. Range is typically [0, 1].\n        sgain (float): Maximum variation for saturation. Range is typically [0, 1].\n        vgain (float): Maximum variation for value. Range is typically [0, 1].\n    Methods:\n        __call__: Applies random HSV augmentation to an image.",
        "detail": "ultralytics.data.augment",
        "documentation": {}
    },
    {
        "label": "RandomFlip",
        "kind": 6,
        "importPath": "ultralytics.data.augment",
        "description": "ultralytics.data.augment",
        "peekOfCode": "class RandomFlip:\n    \"\"\"\n    Applies a random horizontal or vertical flip to an image with a given probability.\n    This class performs random image flipping and updates corresponding instance annotations such as\n    bounding boxes and keypoints.\n    Attributes:\n        p (float): Probability of applying the flip. Must be between 0 and 1.\n        direction (str): Direction of flip, either 'horizontal' or 'vertical'.\n        flip_idx (array-like): Index mapping for flipping keypoints, if applicable.\n    Methods:",
        "detail": "ultralytics.data.augment",
        "documentation": {}
    },
    {
        "label": "LetterBox",
        "kind": 6,
        "importPath": "ultralytics.data.augment",
        "description": "ultralytics.data.augment",
        "peekOfCode": "class LetterBox:\n    \"\"\"\n    Resize image and padding for detection, instance segmentation, pose.\n    This class resizes and pads images to a specified shape while preserving aspect ratio. It also updates\n    corresponding labels and bounding boxes.\n    Attributes:\n        new_shape (tuple): Target shape (height, width) for resizing.\n        auto (bool): Whether to use minimum rectangle.\n        scaleFill (bool): Whether to stretch the image to new_shape.\n        scaleup (bool): Whether to allow scaling up. If False, only scale down.",
        "detail": "ultralytics.data.augment",
        "documentation": {}
    },
    {
        "label": "CopyPaste",
        "kind": 6,
        "importPath": "ultralytics.data.augment",
        "description": "ultralytics.data.augment",
        "peekOfCode": "class CopyPaste:\n    \"\"\"\n    Implements Copy-Paste augmentation as described in https://arxiv.org/abs/2012.07177.\n    This class applies Copy-Paste augmentation on images and their corresponding instances.\n    Attributes:\n        p (float): Probability of applying the Copy-Paste augmentation. Must be between 0 and 1.\n    Methods:\n        __call__: Applies Copy-Paste augmentation to given image and instances.\n    Examples:\n        >>> copypaste = CopyPaste(p=0.5)",
        "detail": "ultralytics.data.augment",
        "documentation": {}
    },
    {
        "label": "Albumentations",
        "kind": 6,
        "importPath": "ultralytics.data.augment",
        "description": "ultralytics.data.augment",
        "peekOfCode": "class Albumentations:\n    \"\"\"\n    Albumentations transformations for image augmentation.\n    This class applies various image transformations using the Albumentations library. It includes operations such as\n    Blur, Median Blur, conversion to grayscale, Contrast Limited Adaptive Histogram Equalization (CLAHE), random changes\n    in brightness and contrast, RandomGamma, and image quality reduction through compression.\n    Attributes:\n        p (float): Probability of applying the transformations.\n        transform (albumentations.Compose): Composed Albumentations transforms.\n        contains_spatial (bool): Indicates if the transforms include spatial operations.",
        "detail": "ultralytics.data.augment",
        "documentation": {}
    },
    {
        "label": "Format",
        "kind": 6,
        "importPath": "ultralytics.data.augment",
        "description": "ultralytics.data.augment",
        "peekOfCode": "class Format:\n    \"\"\"\n    A class for formatting image annotations for object detection, instance segmentation, and pose estimation tasks.\n    This class standardizes image and instance annotations to be used by the `collate_fn` in PyTorch DataLoader.\n    Attributes:\n        bbox_format (str): Format for bounding boxes. Options are 'xywh' or 'xyxy'.\n        normalize (bool): Whether to normalize bounding boxes.\n        return_mask (bool): Whether to return instance masks for segmentation.\n        return_keypoint (bool): Whether to return keypoints for pose estimation.\n        return_obb (bool): Whether to return oriented bounding boxes.",
        "detail": "ultralytics.data.augment",
        "documentation": {}
    },
    {
        "label": "RandomLoadText",
        "kind": 6,
        "importPath": "ultralytics.data.augment",
        "description": "ultralytics.data.augment",
        "peekOfCode": "class RandomLoadText:\n    \"\"\"\n    Randomly samples positive and negative texts and updates class indices accordingly.\n    This class is responsible for sampling texts from a given set of class texts, including both positive\n    (present in the image) and negative (not present in the image) samples. It updates the class indices\n    to reflect the sampled texts and can optionally pad the text list to a fixed length.\n    Attributes:\n        prompt_format (str): Format string for text prompts.\n        neg_samples (Tuple[int, int]): Range for randomly sampling negative texts.\n        max_samples (int): Maximum number of different text samples in one image.",
        "detail": "ultralytics.data.augment",
        "documentation": {}
    },
    {
        "label": "ClassifyLetterBox",
        "kind": 6,
        "importPath": "ultralytics.data.augment",
        "description": "ultralytics.data.augment",
        "peekOfCode": "class ClassifyLetterBox:\n    \"\"\"\n    A class for resizing and padding images for classification tasks.\n    This class is designed to be part of a transformation pipeline, e.g., T.Compose([LetterBox(size), ToTensor()]).\n    It resizes and pads images to a specified size while maintaining the original aspect ratio.\n    Attributes:\n        h (int): Target height of the image.\n        w (int): Target width of the image.\n        auto (bool): If True, automatically calculates the short side using stride.\n        stride (int): The stride value, used when 'auto' is True.",
        "detail": "ultralytics.data.augment",
        "documentation": {}
    },
    {
        "label": "CenterCrop",
        "kind": 6,
        "importPath": "ultralytics.data.augment",
        "description": "ultralytics.data.augment",
        "peekOfCode": "class CenterCrop:\n    \"\"\"\n    Applies center cropping to images for classification tasks.\n    This class performs center cropping on input images, resizing them to a specified size while maintaining the aspect\n    ratio. It is designed to be part of a transformation pipeline, e.g., T.Compose([CenterCrop(size), ToTensor()]).\n    Attributes:\n        h (int): Target height of the cropped image.\n        w (int): Target width of the cropped image.\n    Methods:\n        __call__: Applies the center crop transformation to an input image.",
        "detail": "ultralytics.data.augment",
        "documentation": {}
    },
    {
        "label": "ToTensor",
        "kind": 6,
        "importPath": "ultralytics.data.augment",
        "description": "ultralytics.data.augment",
        "peekOfCode": "class ToTensor:\n    \"\"\"\n    Converts an image from a numpy array to a PyTorch tensor.\n    This class is designed to be part of a transformation pipeline, e.g., T.Compose([LetterBox(size), ToTensor()]).\n    Attributes:\n        half (bool): If True, converts the image to half precision (float16).\n    Methods:\n        __call__: Applies the tensor conversion to an input image.\n    Examples:\n        >>> transform = ToTensor(half=True)",
        "detail": "ultralytics.data.augment",
        "documentation": {}
    },
    {
        "label": "v8_transforms",
        "kind": 2,
        "importPath": "ultralytics.data.augment",
        "description": "ultralytics.data.augment",
        "peekOfCode": "def v8_transforms(dataset, imgsz, hyp, stretch=False):\n    \"\"\"\n    Applies a series of image transformations for YOLOv8 training.\n    This function creates a composition of image augmentation techniques to prepare images for YOLOv8 training.\n    It includes operations such as mosaic, copy-paste, random perspective, mixup, and various color adjustments.\n    Args:\n        dataset (Dataset): The dataset object containing image data and annotations.\n        imgsz (int): The target image size for resizing.\n        hyp (Dict): A dictionary of hyperparameters controlling various aspects of the transformations.\n        stretch (bool): If True, applies stretching to the image. If False, uses LetterBox resizing.",
        "detail": "ultralytics.data.augment",
        "documentation": {}
    },
    {
        "label": "classify_transforms",
        "kind": 2,
        "importPath": "ultralytics.data.augment",
        "description": "ultralytics.data.augment",
        "peekOfCode": "def classify_transforms(\n    size=224,\n    mean=DEFAULT_MEAN,\n    std=DEFAULT_STD,\n    interpolation=Image.BILINEAR,\n    crop_fraction: float = DEFAULT_CROP_FRACTION,\n):\n    \"\"\"\n    Creates a composition of image transforms for classification tasks.\n    This function generates a sequence of torchvision transforms suitable for preprocessing images",
        "detail": "ultralytics.data.augment",
        "documentation": {}
    },
    {
        "label": "classify_augmentations",
        "kind": 2,
        "importPath": "ultralytics.data.augment",
        "description": "ultralytics.data.augment",
        "peekOfCode": "def classify_augmentations(\n    size=224,\n    mean=DEFAULT_MEAN,\n    std=DEFAULT_STD,\n    scale=None,\n    ratio=None,\n    hflip=0.5,\n    vflip=0.0,\n    auto_augment=None,\n    hsv_h=0.015,  # image HSV-Hue augmentation (fraction)",
        "detail": "ultralytics.data.augment",
        "documentation": {}
    },
    {
        "label": "DEFAULT_MEAN",
        "kind": 5,
        "importPath": "ultralytics.data.augment",
        "description": "ultralytics.data.augment",
        "peekOfCode": "DEFAULT_MEAN = (0.0, 0.0, 0.0)\nDEFAULT_STD = (1.0, 1.0, 1.0)\nDEFAULT_CROP_FRACTION = 1.0\nclass BaseTransform:\n    \"\"\"\n    Base class for image transformations in the Ultralytics library.\n    This class serves as a foundation for implementing various image processing operations, designed to be\n    compatible with both classification and semantic segmentation tasks.\n    Methods:\n        apply_image: Applies image transformations to labels.",
        "detail": "ultralytics.data.augment",
        "documentation": {}
    },
    {
        "label": "DEFAULT_STD",
        "kind": 5,
        "importPath": "ultralytics.data.augment",
        "description": "ultralytics.data.augment",
        "peekOfCode": "DEFAULT_STD = (1.0, 1.0, 1.0)\nDEFAULT_CROP_FRACTION = 1.0\nclass BaseTransform:\n    \"\"\"\n    Base class for image transformations in the Ultralytics library.\n    This class serves as a foundation for implementing various image processing operations, designed to be\n    compatible with both classification and semantic segmentation tasks.\n    Methods:\n        apply_image: Applies image transformations to labels.\n        apply_instances: Applies transformations to object instances in labels.",
        "detail": "ultralytics.data.augment",
        "documentation": {}
    },
    {
        "label": "DEFAULT_CROP_FRACTION",
        "kind": 5,
        "importPath": "ultralytics.data.augment",
        "description": "ultralytics.data.augment",
        "peekOfCode": "DEFAULT_CROP_FRACTION = 1.0\nclass BaseTransform:\n    \"\"\"\n    Base class for image transformations in the Ultralytics library.\n    This class serves as a foundation for implementing various image processing operations, designed to be\n    compatible with both classification and semantic segmentation tasks.\n    Methods:\n        apply_image: Applies image transformations to labels.\n        apply_instances: Applies transformations to object instances in labels.\n        apply_semantic: Applies semantic segmentation to an image.",
        "detail": "ultralytics.data.augment",
        "documentation": {}
    },
    {
        "label": "BaseDataset",
        "kind": 6,
        "importPath": "ultralytics.data.base",
        "description": "ultralytics.data.base",
        "peekOfCode": "class BaseDataset(Dataset):\n    \"\"\"\n    Base dataset class for loading and processing image data.\n    Args:\n        img_path (str): Path to the folder containing images.\n        imgsz (int, optional): Image size. Defaults to 640.\n        cache (bool, optional): Cache images to RAM or disk during training. Defaults to False.\n        augment (bool, optional): If True, data augmentation is applied. Defaults to True.\n        hyp (dict, optional): Hyperparameters to apply data augmentation. Defaults to None.\n        prefix (str, optional): Prefix to print in log messages. Defaults to ''.",
        "detail": "ultralytics.data.base",
        "documentation": {}
    },
    {
        "label": "InfiniteDataLoader",
        "kind": 6,
        "importPath": "ultralytics.data.build",
        "description": "ultralytics.data.build",
        "peekOfCode": "class InfiniteDataLoader(dataloader.DataLoader):\n    \"\"\"\n    Dataloader that reuses workers.\n    Uses same syntax as vanilla DataLoader.\n    \"\"\"\n    def __init__(self, *args, **kwargs):\n        \"\"\"Dataloader that infinitely recycles workers, inherits from DataLoader.\"\"\"\n        super().__init__(*args, **kwargs)\n        object.__setattr__(self, \"batch_sampler\", _RepeatSampler(self.batch_sampler))\n        self.iterator = super().__iter__()",
        "detail": "ultralytics.data.build",
        "documentation": {}
    },
    {
        "label": "_RepeatSampler",
        "kind": 6,
        "importPath": "ultralytics.data.build",
        "description": "ultralytics.data.build",
        "peekOfCode": "class _RepeatSampler:\n    \"\"\"\n    Sampler that repeats forever.\n    Args:\n        sampler (Dataset.sampler): The sampler to repeat.\n    \"\"\"\n    def __init__(self, sampler):\n        \"\"\"Initializes an object that repeats a given sampler indefinitely.\"\"\"\n        self.sampler = sampler\n    def __iter__(self):",
        "detail": "ultralytics.data.build",
        "documentation": {}
    },
    {
        "label": "seed_worker",
        "kind": 2,
        "importPath": "ultralytics.data.build",
        "description": "ultralytics.data.build",
        "peekOfCode": "def seed_worker(worker_id):  # noqa\n    \"\"\"Set dataloader worker seed https://pytorch.org/docs/stable/notes/randomness.html#dataloader.\"\"\"\n    worker_seed = torch.initial_seed() % 2**32\n    np.random.seed(worker_seed)\n    random.seed(worker_seed)\ndef build_yolo_dataset(cfg, img_path, batch, data, mode=\"train\", rect=False, stride=32, multi_modal=False):\n    \"\"\"Build YOLO Dataset.\"\"\"\n    dataset = YOLOMultiModalDataset if multi_modal else YOLODataset\n    return dataset(\n        img_path=img_path,",
        "detail": "ultralytics.data.build",
        "documentation": {}
    },
    {
        "label": "build_yolo_dataset",
        "kind": 2,
        "importPath": "ultralytics.data.build",
        "description": "ultralytics.data.build",
        "peekOfCode": "def build_yolo_dataset(cfg, img_path, batch, data, mode=\"train\", rect=False, stride=32, multi_modal=False):\n    \"\"\"Build YOLO Dataset.\"\"\"\n    dataset = YOLOMultiModalDataset if multi_modal else YOLODataset\n    return dataset(\n        img_path=img_path,\n        imgsz=cfg.imgsz,\n        batch_size=batch,\n        augment=mode == \"train\",  # augmentation\n        hyp=cfg,  # TODO: probably add a get_hyps_from_cfg function\n        rect=cfg.rect or rect,  # rectangular batches",
        "detail": "ultralytics.data.build",
        "documentation": {}
    },
    {
        "label": "build_grounding",
        "kind": 2,
        "importPath": "ultralytics.data.build",
        "description": "ultralytics.data.build",
        "peekOfCode": "def build_grounding(cfg, img_path, json_file, batch, mode=\"train\", rect=False, stride=32):\n    \"\"\"Build YOLO Dataset.\"\"\"\n    return GroundingDataset(\n        img_path=img_path,\n        json_file=json_file,\n        imgsz=cfg.imgsz,\n        batch_size=batch,\n        augment=mode == \"train\",  # augmentation\n        hyp=cfg,  # TODO: probably add a get_hyps_from_cfg function\n        rect=cfg.rect or rect,  # rectangular batches",
        "detail": "ultralytics.data.build",
        "documentation": {}
    },
    {
        "label": "build_dataloader",
        "kind": 2,
        "importPath": "ultralytics.data.build",
        "description": "ultralytics.data.build",
        "peekOfCode": "def build_dataloader(dataset, batch, workers, shuffle=True, rank=-1):\n    \"\"\"Return an InfiniteDataLoader or DataLoader for training or validation set.\"\"\"\n    batch = min(batch, len(dataset))\n    nd = torch.cuda.device_count()  # number of CUDA devices\n    nw = min(os.cpu_count() // max(nd, 1), workers)  # number of workers\n    sampler = None if rank == -1 else distributed.DistributedSampler(dataset, shuffle=shuffle)\n    generator = torch.Generator()\n    generator.manual_seed(6148914691236517205 + RANK)\n    return InfiniteDataLoader(\n        dataset=dataset,",
        "detail": "ultralytics.data.build",
        "documentation": {}
    },
    {
        "label": "check_source",
        "kind": 2,
        "importPath": "ultralytics.data.build",
        "description": "ultralytics.data.build",
        "peekOfCode": "def check_source(source):\n    \"\"\"Check source type and return corresponding flag values.\"\"\"\n    webcam, screenshot, from_img, in_memory, tensor = False, False, False, False, False\n    if isinstance(source, (str, int, Path)):  # int for local usb camera\n        source = str(source)\n        is_file = Path(source).suffix[1:] in (IMG_FORMATS | VID_FORMATS)\n        is_url = source.lower().startswith((\"https://\", \"http://\", \"rtsp://\", \"rtmp://\", \"tcp://\"))\n        webcam = source.isnumeric() or source.endswith(\".streams\") or (is_url and not is_file)\n        screenshot = source.lower() == \"screen\"\n        if is_url and is_file:",
        "detail": "ultralytics.data.build",
        "documentation": {}
    },
    {
        "label": "load_inference_source",
        "kind": 2,
        "importPath": "ultralytics.data.build",
        "description": "ultralytics.data.build",
        "peekOfCode": "def load_inference_source(source=None, batch=1, vid_stride=1, buffer=False):\n    \"\"\"\n    Loads an inference source for object detection and applies necessary transformations.\n    Args:\n        source (str, Path, Tensor, PIL.Image, np.ndarray): The input source for inference.\n        batch (int, optional): Batch size for dataloaders. Default is 1.\n        vid_stride (int, optional): The frame interval for video sources. Default is 1.\n        buffer (bool, optional): Determined whether stream frames will be buffered. Default is False.\n    Returns:\n        dataset (Dataset): A dataset object for the specified input source.",
        "detail": "ultralytics.data.build",
        "documentation": {}
    },
    {
        "label": "coco91_to_coco80_class",
        "kind": 2,
        "importPath": "ultralytics.data.converter",
        "description": "ultralytics.data.converter",
        "peekOfCode": "def coco91_to_coco80_class():\n    \"\"\"\n    Converts 91-index COCO class IDs to 80-index COCO class IDs.\n    Returns:\n        (list): A list of 91 class IDs where the index represents the 80-index class ID and the value is the\n            corresponding 91-index class ID.\n    \"\"\"\n    return [\n        0,\n        1,",
        "detail": "ultralytics.data.converter",
        "documentation": {}
    },
    {
        "label": "coco80_to_coco91_class",
        "kind": 2,
        "importPath": "ultralytics.data.converter",
        "description": "ultralytics.data.converter",
        "peekOfCode": "def coco80_to_coco91_class():\n    \"\"\"\n    Converts 80-index (val2014) to 91-index (paper).\n    For details see https://tech.amikelive.com/node-718/what-object-categories-labels-are-in-coco-dataset/.\n    Example:\n        ```python\n        import numpy as np\n        a = np.loadtxt('data/coco.names', dtype='str', delimiter='\\n')\n        b = np.loadtxt('data/coco_paper.names', dtype='str', delimiter='\\n')\n        x1 = [list(a[i] == b).index(True) + 1 for i in range(80)]  # darknet to coco",
        "detail": "ultralytics.data.converter",
        "documentation": {}
    },
    {
        "label": "convert_coco",
        "kind": 2,
        "importPath": "ultralytics.data.converter",
        "description": "ultralytics.data.converter",
        "peekOfCode": "def convert_coco(\n    labels_dir=\"../coco/annotations/\",\n    save_dir=\"coco_converted/\",\n    use_segments=False,\n    use_keypoints=False,\n    cls91to80=True,\n    lvis=False,\n):\n    \"\"\"\n    Converts COCO dataset annotations to a YOLO annotation format  suitable for training YOLO models.",
        "detail": "ultralytics.data.converter",
        "documentation": {}
    },
    {
        "label": "convert_dota_to_yolo_obb",
        "kind": 2,
        "importPath": "ultralytics.data.converter",
        "description": "ultralytics.data.converter",
        "peekOfCode": "def convert_dota_to_yolo_obb(dota_root_path: str):\n    \"\"\"\n    Converts DOTA dataset annotations to YOLO OBB (Oriented Bounding Box) format.\n    The function processes images in the 'train' and 'val' folders of the DOTA dataset. For each image, it reads the\n    associated label from the original labels directory and writes new labels in YOLO OBB format to a new directory.\n    Args:\n        dota_root_path (str): The root directory path of the DOTA dataset.\n    Example:\n        ```python\n        from ultralytics.data.converter import convert_dota_to_yolo_obb",
        "detail": "ultralytics.data.converter",
        "documentation": {}
    },
    {
        "label": "min_index",
        "kind": 2,
        "importPath": "ultralytics.data.converter",
        "description": "ultralytics.data.converter",
        "peekOfCode": "def min_index(arr1, arr2):\n    \"\"\"\n    Find a pair of indexes with the shortest distance between two arrays of 2D points.\n    Args:\n        arr1 (np.ndarray): A NumPy array of shape (N, 2) representing N 2D points.\n        arr2 (np.ndarray): A NumPy array of shape (M, 2) representing M 2D points.\n    Returns:\n        (tuple): A tuple containing the indexes of the points with the shortest distance in arr1 and arr2 respectively.\n    \"\"\"\n    dis = ((arr1[:, None, :] - arr2[None, :, :]) ** 2).sum(-1)",
        "detail": "ultralytics.data.converter",
        "documentation": {}
    },
    {
        "label": "merge_multi_segment",
        "kind": 2,
        "importPath": "ultralytics.data.converter",
        "description": "ultralytics.data.converter",
        "peekOfCode": "def merge_multi_segment(segments):\n    \"\"\"\n    Merge multiple segments into one list by connecting the coordinates with the minimum distance between each segment.\n    This function connects these coordinates with a thin line to merge all segments into one.\n    Args:\n        segments (List[List]): Original segmentations in COCO's JSON file.\n                               Each element is a list of coordinates, like [segmentation1, segmentation2,...].\n    Returns:\n        s (List[np.ndarray]): A list of connected segments represented as NumPy arrays.\n    \"\"\"",
        "detail": "ultralytics.data.converter",
        "documentation": {}
    },
    {
        "label": "yolo_bbox2segment",
        "kind": 2,
        "importPath": "ultralytics.data.converter",
        "description": "ultralytics.data.converter",
        "peekOfCode": "def yolo_bbox2segment(im_dir, save_dir=None, sam_model=\"sam_b.pt\"):\n    \"\"\"\n    Converts existing object detection dataset (bounding boxes) to segmentation dataset or oriented bounding box (OBB)\n    in YOLO format. Generates segmentation data using SAM auto-annotator as needed.\n    Args:\n        im_dir (str | Path): Path to image directory to convert.\n        save_dir (str | Path): Path to save the generated labels, labels will be saved\n            into `labels-segment` in the same directory level of `im_dir` if save_dir is None. Default: None.\n        sam_model (str): Segmentation model to use for intermediate segmentation data; optional.\n    Notes:",
        "detail": "ultralytics.data.converter",
        "documentation": {}
    },
    {
        "label": "YOLODataset",
        "kind": 6,
        "importPath": "ultralytics.data.dataset",
        "description": "ultralytics.data.dataset",
        "peekOfCode": "class YOLODataset(BaseDataset):\n    \"\"\"\n    Dataset class for loading object detection and/or segmentation labels in YOLO format.\n    Args:\n        data (dict, optional): A dataset YAML dictionary. Defaults to None.\n        task (str): An explicit arg to point current task, Defaults to 'detect'.\n    Returns:\n        (torch.utils.data.Dataset): A PyTorch dataset object that can be used for training an object detection model.\n    \"\"\"\n    def __init__(self, *args, data=None, task=\"detect\", **kwargs):",
        "detail": "ultralytics.data.dataset",
        "documentation": {}
    },
    {
        "label": "YOLOMultiModalDataset",
        "kind": 6,
        "importPath": "ultralytics.data.dataset",
        "description": "ultralytics.data.dataset",
        "peekOfCode": "class YOLOMultiModalDataset(YOLODataset):\n    \"\"\"\n    Dataset class for loading object detection and/or segmentation labels in YOLO format.\n    Args:\n        data (dict, optional): A dataset YAML dictionary. Defaults to None.\n        task (str): An explicit arg to point current task, Defaults to 'detect'.\n    Returns:\n        (torch.utils.data.Dataset): A PyTorch dataset object that can be used for training an object detection model.\n    \"\"\"\n    def __init__(self, *args, data=None, task=\"detect\", **kwargs):",
        "detail": "ultralytics.data.dataset",
        "documentation": {}
    },
    {
        "label": "GroundingDataset",
        "kind": 6,
        "importPath": "ultralytics.data.dataset",
        "description": "ultralytics.data.dataset",
        "peekOfCode": "class GroundingDataset(YOLODataset):\n    \"\"\"Handles object detection tasks by loading annotations from a specified JSON file, supporting YOLO format.\"\"\"\n    def __init__(self, *args, task=\"detect\", json_file, **kwargs):\n        \"\"\"Initializes a GroundingDataset for object detection, loading annotations from a specified JSON file.\"\"\"\n        assert task == \"detect\", \"`GroundingDataset` only support `detect` task for now!\"\n        self.json_file = json_file\n        super().__init__(*args, task=task, data={}, **kwargs)\n    def get_img_files(self, img_path):\n        \"\"\"The image files would be read in `get_labels` function, return empty list here.\"\"\"\n        return []",
        "detail": "ultralytics.data.dataset",
        "documentation": {}
    },
    {
        "label": "YOLOConcatDataset",
        "kind": 6,
        "importPath": "ultralytics.data.dataset",
        "description": "ultralytics.data.dataset",
        "peekOfCode": "class YOLOConcatDataset(ConcatDataset):\n    \"\"\"\n    Dataset as a concatenation of multiple datasets.\n    This class is useful to assemble different existing datasets.\n    \"\"\"\n    @staticmethod\n    def collate_fn(batch):\n        \"\"\"Collates data samples into batches.\"\"\"\n        return YOLODataset.collate_fn(batch)\n# TODO: support semantic segmentation",
        "detail": "ultralytics.data.dataset",
        "documentation": {}
    },
    {
        "label": "SemanticDataset",
        "kind": 6,
        "importPath": "ultralytics.data.dataset",
        "description": "ultralytics.data.dataset",
        "peekOfCode": "class SemanticDataset(BaseDataset):\n    \"\"\"\n    Semantic Segmentation Dataset.\n    This class is responsible for handling datasets used for semantic segmentation tasks. It inherits functionalities\n    from the BaseDataset class.\n    Note:\n        This class is currently a placeholder and needs to be populated with methods and attributes for supporting\n        semantic segmentation tasks.\n    \"\"\"\n    def __init__(self):",
        "detail": "ultralytics.data.dataset",
        "documentation": {}
    },
    {
        "label": "ClassificationDataset",
        "kind": 6,
        "importPath": "ultralytics.data.dataset",
        "description": "ultralytics.data.dataset",
        "peekOfCode": "class ClassificationDataset:\n    \"\"\"\n    Extends torchvision ImageFolder to support YOLO classification tasks, offering functionalities like image\n    augmentation, caching, and verification. It's designed to efficiently handle large datasets for training deep\n    learning models, with optional image transformations and caching mechanisms to speed up training.\n    This class allows for augmentations using both torchvision and Albumentations libraries, and supports caching images\n    in RAM or on disk to reduce IO overhead during training. Additionally, it implements a robust verification process\n    to ensure data integrity and consistency.\n    Attributes:\n        cache_ram (bool): Indicates if caching in RAM is enabled.",
        "detail": "ultralytics.data.dataset",
        "documentation": {}
    },
    {
        "label": "DATASET_CACHE_VERSION",
        "kind": 5,
        "importPath": "ultralytics.data.dataset",
        "description": "ultralytics.data.dataset",
        "peekOfCode": "DATASET_CACHE_VERSION = \"1.0.3\"\nclass YOLODataset(BaseDataset):\n    \"\"\"\n    Dataset class for loading object detection and/or segmentation labels in YOLO format.\n    Args:\n        data (dict, optional): A dataset YAML dictionary. Defaults to None.\n        task (str): An explicit arg to point current task, Defaults to 'detect'.\n    Returns:\n        (torch.utils.data.Dataset): A PyTorch dataset object that can be used for training an object detection model.\n    \"\"\"",
        "detail": "ultralytics.data.dataset",
        "documentation": {}
    },
    {
        "label": "SourceTypes",
        "kind": 6,
        "importPath": "ultralytics.data.loaders",
        "description": "ultralytics.data.loaders",
        "peekOfCode": "class SourceTypes:\n    \"\"\"Class to represent various types of input sources for predictions.\"\"\"\n    stream: bool = False\n    screenshot: bool = False\n    from_img: bool = False\n    tensor: bool = False\nclass LoadStreams:\n    \"\"\"\n    Stream Loader for various types of video streams, Supports RTSP, RTMP, HTTP, and TCP streams.\n    Attributes:",
        "detail": "ultralytics.data.loaders",
        "documentation": {}
    },
    {
        "label": "LoadStreams",
        "kind": 6,
        "importPath": "ultralytics.data.loaders",
        "description": "ultralytics.data.loaders",
        "peekOfCode": "class LoadStreams:\n    \"\"\"\n    Stream Loader for various types of video streams, Supports RTSP, RTMP, HTTP, and TCP streams.\n    Attributes:\n        sources (str): The source input paths or URLs for the video streams.\n        vid_stride (int): Video frame-rate stride, defaults to 1.\n        buffer (bool): Whether to buffer input streams, defaults to False.\n        running (bool): Flag to indicate if the streaming thread is running.\n        mode (str): Set to 'stream' indicating real-time capture.\n        imgs (list): List of image frames for each stream.",
        "detail": "ultralytics.data.loaders",
        "documentation": {}
    },
    {
        "label": "LoadScreenshots",
        "kind": 6,
        "importPath": "ultralytics.data.loaders",
        "description": "ultralytics.data.loaders",
        "peekOfCode": "class LoadScreenshots:\n    \"\"\"\n    YOLOv8 screenshot dataloader.\n    This class manages the loading of screenshot images for processing with YOLOv8.\n    Suitable for use with `yolo predict source=screen`.\n    Attributes:\n        source (str): The source input indicating which screen to capture.\n        screen (int): The screen number to capture.\n        left (int): The left coordinate for screen capture area.\n        top (int): The top coordinate for screen capture area.",
        "detail": "ultralytics.data.loaders",
        "documentation": {}
    },
    {
        "label": "LoadImagesAndVideos",
        "kind": 6,
        "importPath": "ultralytics.data.loaders",
        "description": "ultralytics.data.loaders",
        "peekOfCode": "class LoadImagesAndVideos:\n    \"\"\"\n    YOLOv8 image/video dataloader.\n    This class manages the loading and pre-processing of image and video data for YOLOv8. It supports loading from\n    various formats, including single image files, video files, and lists of image and video paths.\n    Attributes:\n        files (list): List of image and video file paths.\n        nf (int): Total number of files (images and videos).\n        video_flag (list): Flags indicating whether a file is a video (True) or an image (False).\n        mode (str): Current mode, 'image' or 'video'.",
        "detail": "ultralytics.data.loaders",
        "documentation": {}
    },
    {
        "label": "LoadPilAndNumpy",
        "kind": 6,
        "importPath": "ultralytics.data.loaders",
        "description": "ultralytics.data.loaders",
        "peekOfCode": "class LoadPilAndNumpy:\n    \"\"\"\n    Load images from PIL and Numpy arrays for batch processing.\n    This class is designed to manage loading and pre-processing of image data from both PIL and Numpy formats.\n    It performs basic validation and format conversion to ensure that the images are in the required format for\n    downstream processing.\n    Attributes:\n        paths (list): List of image paths or autogenerated filenames.\n        im0 (list): List of images stored as Numpy arrays.\n        mode (str): Type of data being processed, defaults to 'image'.",
        "detail": "ultralytics.data.loaders",
        "documentation": {}
    },
    {
        "label": "LoadTensor",
        "kind": 6,
        "importPath": "ultralytics.data.loaders",
        "description": "ultralytics.data.loaders",
        "peekOfCode": "class LoadTensor:\n    \"\"\"\n    Load images from torch.Tensor data.\n    This class manages the loading and pre-processing of image data from PyTorch tensors for further processing.\n    Attributes:\n        im0 (torch.Tensor): The input tensor containing the image(s).\n        bs (int): Batch size, inferred from the shape of `im0`.\n        mode (str): Current mode, set to 'image'.\n        paths (list): List of image paths or filenames.\n        count (int): Counter for iteration, initialized at 0 during `__iter__()`.",
        "detail": "ultralytics.data.loaders",
        "documentation": {}
    },
    {
        "label": "autocast_list",
        "kind": 2,
        "importPath": "ultralytics.data.loaders",
        "description": "ultralytics.data.loaders",
        "peekOfCode": "def autocast_list(source):\n    \"\"\"Merges a list of source of different types into a list of numpy arrays or PIL images.\"\"\"\n    files = []\n    for im in source:\n        if isinstance(im, (str, Path)):  # filename or uri\n            files.append(Image.open(requests.get(im, stream=True).raw if str(im).startswith(\"http\") else im))\n        elif isinstance(im, (Image.Image, np.ndarray)):  # PIL or np Image\n            files.append(im)\n        else:\n            raise TypeError(",
        "detail": "ultralytics.data.loaders",
        "documentation": {}
    },
    {
        "label": "get_best_youtube_url",
        "kind": 2,
        "importPath": "ultralytics.data.loaders",
        "description": "ultralytics.data.loaders",
        "peekOfCode": "def get_best_youtube_url(url, method=\"pytube\"):\n    \"\"\"\n    Retrieves the URL of the best quality MP4 video stream from a given YouTube video.\n    This function uses the specified method to extract the video info from YouTube. It supports the following methods:\n    - \"pytube\": Uses the pytube library to fetch the video streams.\n    - \"pafy\": Uses the pafy library to fetch the video streams.\n    - \"yt-dlp\": Uses the yt-dlp library to fetch the video streams.\n    The function then finds the highest quality MP4 format that has a video codec but no audio codec, and returns the\n    URL of this video stream.\n    Args:",
        "detail": "ultralytics.data.loaders",
        "documentation": {}
    },
    {
        "label": "LOADERS",
        "kind": 5,
        "importPath": "ultralytics.data.loaders",
        "description": "ultralytics.data.loaders",
        "peekOfCode": "LOADERS = (LoadStreams, LoadPilAndNumpy, LoadImagesAndVideos, LoadScreenshots)",
        "detail": "ultralytics.data.loaders",
        "documentation": {}
    },
    {
        "label": "bbox_iof",
        "kind": 2,
        "importPath": "ultralytics.data.split_dota",
        "description": "ultralytics.data.split_dota",
        "peekOfCode": "def bbox_iof(polygon1, bbox2, eps=1e-6):\n    \"\"\"\n    Calculate iofs between bbox1 and bbox2.\n    Args:\n        polygon1 (np.ndarray): Polygon coordinates, (n, 8).\n        bbox2 (np.ndarray): Bounding boxes, (n ,4).\n    \"\"\"\n    polygon1 = polygon1.reshape(-1, 4, 2)\n    lt_point = np.min(polygon1, axis=-2)  # left-top\n    rb_point = np.max(polygon1, axis=-2)  # right-bottom",
        "detail": "ultralytics.data.split_dota",
        "documentation": {}
    },
    {
        "label": "load_yolo_dota",
        "kind": 2,
        "importPath": "ultralytics.data.split_dota",
        "description": "ultralytics.data.split_dota",
        "peekOfCode": "def load_yolo_dota(data_root, split=\"train\"):\n    \"\"\"\n    Load DOTA dataset.\n    Args:\n        data_root (str): Data root.\n        split (str): The split data set, could be train or val.\n    Notes:\n        The directory structure assumed for the DOTA dataset:\n            - data_root\n                - images",
        "detail": "ultralytics.data.split_dota",
        "documentation": {}
    },
    {
        "label": "get_windows",
        "kind": 2,
        "importPath": "ultralytics.data.split_dota",
        "description": "ultralytics.data.split_dota",
        "peekOfCode": "def get_windows(im_size, crop_sizes=(1024,), gaps=(200,), im_rate_thr=0.6, eps=0.01):\n    \"\"\"\n    Get the coordinates of windows.\n    Args:\n        im_size (tuple): Original image size, (h, w).\n        crop_sizes (List(int)): Crop size of windows.\n        gaps (List(int)): Gap between crops.\n        im_rate_thr (float): Threshold of windows areas divided by image ares.\n        eps (float): Epsilon value for math operations.\n    \"\"\"",
        "detail": "ultralytics.data.split_dota",
        "documentation": {}
    },
    {
        "label": "get_window_obj",
        "kind": 2,
        "importPath": "ultralytics.data.split_dota",
        "description": "ultralytics.data.split_dota",
        "peekOfCode": "def get_window_obj(anno, windows, iof_thr=0.7):\n    \"\"\"Get objects for each window.\"\"\"\n    h, w = anno[\"ori_size\"]\n    label = anno[\"label\"]\n    if len(label):\n        label[:, 1::2] *= w\n        label[:, 2::2] *= h\n        iofs = bbox_iof(label[:, 1:], windows)\n        # Unnormalized and misaligned coordinates\n        return [(label[iofs[:, i] >= iof_thr]) for i in range(len(windows))]  # window_anns",
        "detail": "ultralytics.data.split_dota",
        "documentation": {}
    },
    {
        "label": "crop_and_save",
        "kind": 2,
        "importPath": "ultralytics.data.split_dota",
        "description": "ultralytics.data.split_dota",
        "peekOfCode": "def crop_and_save(anno, windows, window_objs, im_dir, lb_dir):\n    \"\"\"\n    Crop images and save new labels.\n    Args:\n        anno (dict): Annotation dict, including `filepath`, `label`, `ori_size` as its keys.\n        windows (list): A list of windows coordinates.\n        window_objs (list): A list of labels inside each window.\n        im_dir (str): The output directory path of images.\n        lb_dir (str): The output directory path of labels.\n    Notes:",
        "detail": "ultralytics.data.split_dota",
        "documentation": {}
    },
    {
        "label": "split_images_and_labels",
        "kind": 2,
        "importPath": "ultralytics.data.split_dota",
        "description": "ultralytics.data.split_dota",
        "peekOfCode": "def split_images_and_labels(data_root, save_dir, split=\"train\", crop_sizes=(1024,), gaps=(200,)):\n    \"\"\"\n    Split both images and labels.\n    Notes:\n        The directory structure assumed for the DOTA dataset:\n            - data_root\n                - images\n                    - split\n                - labels\n                    - split",
        "detail": "ultralytics.data.split_dota",
        "documentation": {}
    },
    {
        "label": "split_trainval",
        "kind": 2,
        "importPath": "ultralytics.data.split_dota",
        "description": "ultralytics.data.split_dota",
        "peekOfCode": "def split_trainval(data_root, save_dir, crop_size=1024, gap=200, rates=(1.0,)):\n    \"\"\"\n    Split train and val set of DOTA.\n    Notes:\n        The directory structure assumed for the DOTA dataset:\n            - data_root\n                - images\n                    - train\n                    - val\n                - labels",
        "detail": "ultralytics.data.split_dota",
        "documentation": {}
    },
    {
        "label": "split_test",
        "kind": 2,
        "importPath": "ultralytics.data.split_dota",
        "description": "ultralytics.data.split_dota",
        "peekOfCode": "def split_test(data_root, save_dir, crop_size=1024, gap=200, rates=(1.0,)):\n    \"\"\"\n    Split test set of DOTA, labels are not included within this set.\n    Notes:\n        The directory structure assumed for the DOTA dataset:\n            - data_root\n                - images\n                    - test\n        and the output directory structure is:\n            - save_dir",
        "detail": "ultralytics.data.split_dota",
        "documentation": {}
    },
    {
        "label": "HUBDatasetStats",
        "kind": 6,
        "importPath": "ultralytics.data.utils",
        "description": "ultralytics.data.utils",
        "peekOfCode": "class HUBDatasetStats:\n    \"\"\"\n    A class for generating HUB dataset JSON and `-hub` dataset directory.\n    Args:\n        path (str): Path to data.yaml or data.zip (with data.yaml inside data.zip). Default is 'coco8.yaml'.\n        task (str): Dataset task. Options are 'detect', 'segment', 'pose', 'classify'. Default is 'detect'.\n        autodownload (bool): Attempt to download dataset if not found locally. Default is False.\n    Example:\n        Download *.zip files from https://github.com/ultralytics/hub/tree/main/example_datasets\n            i.e. https://github.com/ultralytics/hub/raw/main/example_datasets/coco8.zip for coco8.zip.",
        "detail": "ultralytics.data.utils",
        "documentation": {}
    },
    {
        "label": "img2label_paths",
        "kind": 2,
        "importPath": "ultralytics.data.utils",
        "description": "ultralytics.data.utils",
        "peekOfCode": "def img2label_paths(img_paths):\n    \"\"\"Define label paths as a function of image paths.\"\"\"\n    sa, sb = f\"{os.sep}images{os.sep}\", f\"{os.sep}labels{os.sep}\"  # /images/, /labels/ substrings\n    return [sb.join(x.rsplit(sa, 1)).rsplit(\".\", 1)[0] + \".txt\" for x in img_paths]\ndef get_hash(paths):\n    \"\"\"Returns a single hash value of a list of paths (files or dirs).\"\"\"\n    size = sum(os.path.getsize(p) for p in paths if os.path.exists(p))  # sizes\n    h = hashlib.sha256(str(size).encode())  # hash sizes\n    h.update(\"\".join(paths).encode())  # hash paths\n    return h.hexdigest()  # return hash",
        "detail": "ultralytics.data.utils",
        "documentation": {}
    },
    {
        "label": "get_hash",
        "kind": 2,
        "importPath": "ultralytics.data.utils",
        "description": "ultralytics.data.utils",
        "peekOfCode": "def get_hash(paths):\n    \"\"\"Returns a single hash value of a list of paths (files or dirs).\"\"\"\n    size = sum(os.path.getsize(p) for p in paths if os.path.exists(p))  # sizes\n    h = hashlib.sha256(str(size).encode())  # hash sizes\n    h.update(\"\".join(paths).encode())  # hash paths\n    return h.hexdigest()  # return hash\ndef exif_size(img: Image.Image):\n    \"\"\"Returns exif-corrected PIL size.\"\"\"\n    s = img.size  # (width, height)\n    if img.format == \"JPEG\":  # only support JPEG images",
        "detail": "ultralytics.data.utils",
        "documentation": {}
    },
    {
        "label": "exif_size",
        "kind": 2,
        "importPath": "ultralytics.data.utils",
        "description": "ultralytics.data.utils",
        "peekOfCode": "def exif_size(img: Image.Image):\n    \"\"\"Returns exif-corrected PIL size.\"\"\"\n    s = img.size  # (width, height)\n    if img.format == \"JPEG\":  # only support JPEG images\n        with contextlib.suppress(Exception):\n            exif = img.getexif()\n            if exif:\n                rotation = exif.get(274, None)  # the EXIF key for the orientation tag is 274\n                if rotation in {6, 8}:  # rotation 270 or 90\n                    s = s[1], s[0]",
        "detail": "ultralytics.data.utils",
        "documentation": {}
    },
    {
        "label": "verify_image",
        "kind": 2,
        "importPath": "ultralytics.data.utils",
        "description": "ultralytics.data.utils",
        "peekOfCode": "def verify_image(args):\n    \"\"\"Verify one image.\"\"\"\n    (im_file, cls), prefix = args\n    # Number (found, corrupt), message\n    nf, nc, msg = 0, 0, \"\"\n    try:\n        im = Image.open(im_file)\n        im.verify()  # PIL verify\n        shape = exif_size(im)  # image size\n        shape = (shape[1], shape[0])  # hw",
        "detail": "ultralytics.data.utils",
        "documentation": {}
    },
    {
        "label": "verify_image_label",
        "kind": 2,
        "importPath": "ultralytics.data.utils",
        "description": "ultralytics.data.utils",
        "peekOfCode": "def verify_image_label(args):\n    \"\"\"Verify one image-label pair.\"\"\"\n    im_file, lb_file, prefix, keypoint, num_cls, nkpt, ndim = args\n    # Number (missing, found, empty, corrupt), message, segments, keypoints\n    nm, nf, ne, nc, msg, segments, keypoints = 0, 0, 0, 0, \"\", [], None\n    try:\n        # Verify images\n        im = Image.open(im_file)\n        im.verify()  # PIL verify\n        shape = exif_size(im)  # image size",
        "detail": "ultralytics.data.utils",
        "documentation": {}
    },
    {
        "label": "polygon2mask",
        "kind": 2,
        "importPath": "ultralytics.data.utils",
        "description": "ultralytics.data.utils",
        "peekOfCode": "def polygon2mask(imgsz, polygons, color=1, downsample_ratio=1):\n    \"\"\"\n    Convert a list of polygons to a binary mask of the specified image size.\n    Args:\n        imgsz (tuple): The size of the image as (height, width).\n        polygons (list[np.ndarray]): A list of polygons. Each polygon is an array with shape [N, M], where\n                                     N is the number of polygons, and M is the number of points such that M % 2 = 0.\n        color (int, optional): The color value to fill in the polygons on the mask. Defaults to 1.\n        downsample_ratio (int, optional): Factor by which to downsample the mask. Defaults to 1.\n    Returns:",
        "detail": "ultralytics.data.utils",
        "documentation": {}
    },
    {
        "label": "polygons2masks",
        "kind": 2,
        "importPath": "ultralytics.data.utils",
        "description": "ultralytics.data.utils",
        "peekOfCode": "def polygons2masks(imgsz, polygons, color, downsample_ratio=1):\n    \"\"\"\n    Convert a list of polygons to a set of binary masks of the specified image size.\n    Args:\n        imgsz (tuple): The size of the image as (height, width).\n        polygons (list[np.ndarray]): A list of polygons. Each polygon is an array with shape [N, M], where\n                                     N is the number of polygons, and M is the number of points such that M % 2 = 0.\n        color (int): The color value to fill in the polygons on the masks.\n        downsample_ratio (int, optional): Factor by which to downsample each mask. Defaults to 1.\n    Returns:",
        "detail": "ultralytics.data.utils",
        "documentation": {}
    },
    {
        "label": "polygons2masks_overlap",
        "kind": 2,
        "importPath": "ultralytics.data.utils",
        "description": "ultralytics.data.utils",
        "peekOfCode": "def polygons2masks_overlap(imgsz, segments, downsample_ratio=1):\n    \"\"\"Return a (640, 640) overlap mask.\"\"\"\n    masks = np.zeros(\n        (imgsz[0] // downsample_ratio, imgsz[1] // downsample_ratio),\n        dtype=np.int32 if len(segments) > 255 else np.uint8,\n    )\n    areas = []\n    ms = []\n    for si in range(len(segments)):\n        mask = polygon2mask(imgsz, [segments[si].reshape(-1)], downsample_ratio=downsample_ratio, color=1)",
        "detail": "ultralytics.data.utils",
        "documentation": {}
    },
    {
        "label": "find_dataset_yaml",
        "kind": 2,
        "importPath": "ultralytics.data.utils",
        "description": "ultralytics.data.utils",
        "peekOfCode": "def find_dataset_yaml(path: Path) -> Path:\n    \"\"\"\n    Find and return the YAML file associated with a Detect, Segment or Pose dataset.\n    This function searches for a YAML file at the root level of the provided directory first, and if not found, it\n    performs a recursive search. It prefers YAML files that have the same stem as the provided path. An AssertionError\n    is raised if no YAML file is found or if multiple YAML files are found.\n    Args:\n        path (Path): The directory path to search for the YAML file.\n    Returns:\n        (Path): The path of the found YAML file.",
        "detail": "ultralytics.data.utils",
        "documentation": {}
    },
    {
        "label": "check_det_dataset",
        "kind": 2,
        "importPath": "ultralytics.data.utils",
        "description": "ultralytics.data.utils",
        "peekOfCode": "def check_det_dataset(dataset, autodownload=True):\n    \"\"\"\n    Download, verify, and/or unzip a dataset if not found locally.\n    This function checks the availability of a specified dataset, and if not found, it has the option to download and\n    unzip the dataset. It then reads and parses the accompanying YAML data, ensuring key requirements are met and also\n    resolves paths related to the dataset.\n    Args:\n        dataset (str): Path to the dataset or dataset descriptor (like a YAML file).\n        autodownload (bool, optional): Whether to automatically download the dataset if not found. Defaults to True.\n    Returns:",
        "detail": "ultralytics.data.utils",
        "documentation": {}
    },
    {
        "label": "check_cls_dataset",
        "kind": 2,
        "importPath": "ultralytics.data.utils",
        "description": "ultralytics.data.utils",
        "peekOfCode": "def check_cls_dataset(dataset, split=\"\"):\n    \"\"\"\n    Checks a classification dataset such as Imagenet.\n    This function accepts a `dataset` name and attempts to retrieve the corresponding dataset information.\n    If the dataset is not found locally, it attempts to download the dataset from the internet and save it locally.\n    Args:\n        dataset (str | Path): The name of the dataset.\n        split (str, optional): The split of the dataset. Either 'val', 'test', or ''. Defaults to ''.\n    Returns:\n        (dict): A dictionary containing the following keys:",
        "detail": "ultralytics.data.utils",
        "documentation": {}
    },
    {
        "label": "compress_one_image",
        "kind": 2,
        "importPath": "ultralytics.data.utils",
        "description": "ultralytics.data.utils",
        "peekOfCode": "def compress_one_image(f, f_new=None, max_dim=1920, quality=50):\n    \"\"\"\n    Compresses a single image file to reduced size while preserving its aspect ratio and quality using either the Python\n    Imaging Library (PIL) or OpenCV library. If the input image is smaller than the maximum dimension, it will not be\n    resized.\n    Args:\n        f (str): The path to the input image file.\n        f_new (str, optional): The path to the output image file. If not specified, the input file will be overwritten.\n        max_dim (int, optional): The maximum dimension (width or height) of the output image. Default is 1920 pixels.\n        quality (int, optional): The image compression quality as a percentage. Default is 50%.",
        "detail": "ultralytics.data.utils",
        "documentation": {}
    },
    {
        "label": "autosplit",
        "kind": 2,
        "importPath": "ultralytics.data.utils",
        "description": "ultralytics.data.utils",
        "peekOfCode": "def autosplit(path=DATASETS_DIR / \"coco8/images\", weights=(0.9, 0.1, 0.0), annotated_only=False):\n    \"\"\"\n    Automatically split a dataset into train/val/test splits and save the resulting splits into autosplit_*.txt files.\n    Args:\n        path (Path, optional): Path to images directory. Defaults to DATASETS_DIR / 'coco8/images'.\n        weights (list | tuple, optional): Train, validation, and test split fractions. Defaults to (0.9, 0.1, 0.0).\n        annotated_only (bool, optional): If True, only images with an associated txt file are used. Defaults to False.\n    Example:\n        ```python\n        from ultralytics.data.utils import autosplit",
        "detail": "ultralytics.data.utils",
        "documentation": {}
    },
    {
        "label": "load_dataset_cache_file",
        "kind": 2,
        "importPath": "ultralytics.data.utils",
        "description": "ultralytics.data.utils",
        "peekOfCode": "def load_dataset_cache_file(path):\n    \"\"\"Load an Ultralytics *.cache dictionary from path.\"\"\"\n    import gc\n    gc.disable()  # reduce pickle load time https://github.com/ultralytics/ultralytics/pull/1585\n    cache = np.load(str(path), allow_pickle=True).item()  # load dict\n    gc.enable()\n    return cache\ndef save_dataset_cache_file(prefix, path, x, version):\n    \"\"\"Save an Ultralytics dataset *.cache dictionary x to path.\"\"\"\n    x[\"version\"] = version  # add cache version",
        "detail": "ultralytics.data.utils",
        "documentation": {}
    },
    {
        "label": "save_dataset_cache_file",
        "kind": 2,
        "importPath": "ultralytics.data.utils",
        "description": "ultralytics.data.utils",
        "peekOfCode": "def save_dataset_cache_file(prefix, path, x, version):\n    \"\"\"Save an Ultralytics dataset *.cache dictionary x to path.\"\"\"\n    x[\"version\"] = version  # add cache version\n    if is_dir_writeable(path.parent):\n        if path.exists():\n            path.unlink()  # remove *.cache file if exists\n        np.save(str(path), x)  # save cache for next time\n        path.with_suffix(\".cache.npy\").rename(path)  # remove .npy suffix\n        LOGGER.info(f\"{prefix}New cache created: {path}\")\n    else:",
        "detail": "ultralytics.data.utils",
        "documentation": {}
    },
    {
        "label": "HELP_URL",
        "kind": 5,
        "importPath": "ultralytics.data.utils",
        "description": "ultralytics.data.utils",
        "peekOfCode": "HELP_URL = \"See https://docs.ultralytics.com/datasets for dataset formatting guidance.\"\nIMG_FORMATS = {\"bmp\", \"dng\", \"jpeg\", \"jpg\", \"mpo\", \"png\", \"tif\", \"tiff\", \"webp\", \"pfm\"}  # image suffixes\nVID_FORMATS = {\"asf\", \"avi\", \"gif\", \"m4v\", \"mkv\", \"mov\", \"mp4\", \"mpeg\", \"mpg\", \"ts\", \"wmv\", \"webm\"}  # video suffixes\nPIN_MEMORY = str(os.getenv(\"PIN_MEMORY\", True)).lower() == \"true\"  # global pin_memory for dataloaders\nFORMATS_HELP_MSG = f\"Supported formats are:\\nimages: {IMG_FORMATS}\\nvideos: {VID_FORMATS}\"\ndef img2label_paths(img_paths):\n    \"\"\"Define label paths as a function of image paths.\"\"\"\n    sa, sb = f\"{os.sep}images{os.sep}\", f\"{os.sep}labels{os.sep}\"  # /images/, /labels/ substrings\n    return [sb.join(x.rsplit(sa, 1)).rsplit(\".\", 1)[0] + \".txt\" for x in img_paths]\ndef get_hash(paths):",
        "detail": "ultralytics.data.utils",
        "documentation": {}
    },
    {
        "label": "IMG_FORMATS",
        "kind": 5,
        "importPath": "ultralytics.data.utils",
        "description": "ultralytics.data.utils",
        "peekOfCode": "IMG_FORMATS = {\"bmp\", \"dng\", \"jpeg\", \"jpg\", \"mpo\", \"png\", \"tif\", \"tiff\", \"webp\", \"pfm\"}  # image suffixes\nVID_FORMATS = {\"asf\", \"avi\", \"gif\", \"m4v\", \"mkv\", \"mov\", \"mp4\", \"mpeg\", \"mpg\", \"ts\", \"wmv\", \"webm\"}  # video suffixes\nPIN_MEMORY = str(os.getenv(\"PIN_MEMORY\", True)).lower() == \"true\"  # global pin_memory for dataloaders\nFORMATS_HELP_MSG = f\"Supported formats are:\\nimages: {IMG_FORMATS}\\nvideos: {VID_FORMATS}\"\ndef img2label_paths(img_paths):\n    \"\"\"Define label paths as a function of image paths.\"\"\"\n    sa, sb = f\"{os.sep}images{os.sep}\", f\"{os.sep}labels{os.sep}\"  # /images/, /labels/ substrings\n    return [sb.join(x.rsplit(sa, 1)).rsplit(\".\", 1)[0] + \".txt\" for x in img_paths]\ndef get_hash(paths):\n    \"\"\"Returns a single hash value of a list of paths (files or dirs).\"\"\"",
        "detail": "ultralytics.data.utils",
        "documentation": {}
    },
    {
        "label": "VID_FORMATS",
        "kind": 5,
        "importPath": "ultralytics.data.utils",
        "description": "ultralytics.data.utils",
        "peekOfCode": "VID_FORMATS = {\"asf\", \"avi\", \"gif\", \"m4v\", \"mkv\", \"mov\", \"mp4\", \"mpeg\", \"mpg\", \"ts\", \"wmv\", \"webm\"}  # video suffixes\nPIN_MEMORY = str(os.getenv(\"PIN_MEMORY\", True)).lower() == \"true\"  # global pin_memory for dataloaders\nFORMATS_HELP_MSG = f\"Supported formats are:\\nimages: {IMG_FORMATS}\\nvideos: {VID_FORMATS}\"\ndef img2label_paths(img_paths):\n    \"\"\"Define label paths as a function of image paths.\"\"\"\n    sa, sb = f\"{os.sep}images{os.sep}\", f\"{os.sep}labels{os.sep}\"  # /images/, /labels/ substrings\n    return [sb.join(x.rsplit(sa, 1)).rsplit(\".\", 1)[0] + \".txt\" for x in img_paths]\ndef get_hash(paths):\n    \"\"\"Returns a single hash value of a list of paths (files or dirs).\"\"\"\n    size = sum(os.path.getsize(p) for p in paths if os.path.exists(p))  # sizes",
        "detail": "ultralytics.data.utils",
        "documentation": {}
    },
    {
        "label": "PIN_MEMORY",
        "kind": 5,
        "importPath": "ultralytics.data.utils",
        "description": "ultralytics.data.utils",
        "peekOfCode": "PIN_MEMORY = str(os.getenv(\"PIN_MEMORY\", True)).lower() == \"true\"  # global pin_memory for dataloaders\nFORMATS_HELP_MSG = f\"Supported formats are:\\nimages: {IMG_FORMATS}\\nvideos: {VID_FORMATS}\"\ndef img2label_paths(img_paths):\n    \"\"\"Define label paths as a function of image paths.\"\"\"\n    sa, sb = f\"{os.sep}images{os.sep}\", f\"{os.sep}labels{os.sep}\"  # /images/, /labels/ substrings\n    return [sb.join(x.rsplit(sa, 1)).rsplit(\".\", 1)[0] + \".txt\" for x in img_paths]\ndef get_hash(paths):\n    \"\"\"Returns a single hash value of a list of paths (files or dirs).\"\"\"\n    size = sum(os.path.getsize(p) for p in paths if os.path.exists(p))  # sizes\n    h = hashlib.sha256(str(size).encode())  # hash sizes",
        "detail": "ultralytics.data.utils",
        "documentation": {}
    },
    {
        "label": "FORMATS_HELP_MSG",
        "kind": 5,
        "importPath": "ultralytics.data.utils",
        "description": "ultralytics.data.utils",
        "peekOfCode": "FORMATS_HELP_MSG = f\"Supported formats are:\\nimages: {IMG_FORMATS}\\nvideos: {VID_FORMATS}\"\ndef img2label_paths(img_paths):\n    \"\"\"Define label paths as a function of image paths.\"\"\"\n    sa, sb = f\"{os.sep}images{os.sep}\", f\"{os.sep}labels{os.sep}\"  # /images/, /labels/ substrings\n    return [sb.join(x.rsplit(sa, 1)).rsplit(\".\", 1)[0] + \".txt\" for x in img_paths]\ndef get_hash(paths):\n    \"\"\"Returns a single hash value of a list of paths (files or dirs).\"\"\"\n    size = sum(os.path.getsize(p) for p in paths if os.path.exists(p))  # sizes\n    h = hashlib.sha256(str(size).encode())  # hash sizes\n    h.update(\"\".join(paths).encode())  # hash paths",
        "detail": "ultralytics.data.utils",
        "documentation": {}
    },
    {
        "label": "Exporter",
        "kind": 6,
        "importPath": "ultralytics.engine.exporter",
        "description": "ultralytics.engine.exporter",
        "peekOfCode": "class Exporter:\n    \"\"\"\n    A class for exporting a model.\n    Attributes:\n        args (SimpleNamespace): Configuration for the exporter.\n        callbacks (list, optional): List of callback functions. Defaults to None.\n    \"\"\"\n    def __init__(self, cfg=DEFAULT_CFG, overrides=None, _callbacks=None):\n        \"\"\"\n        Initializes the Exporter class.",
        "detail": "ultralytics.engine.exporter",
        "documentation": {}
    },
    {
        "label": "IOSDetectModel",
        "kind": 6,
        "importPath": "ultralytics.engine.exporter",
        "description": "ultralytics.engine.exporter",
        "peekOfCode": "class IOSDetectModel(torch.nn.Module):\n    \"\"\"Wrap an Ultralytics YOLO model for Apple iOS CoreML export.\"\"\"\n    def __init__(self, model, im):\n        \"\"\"Initialize the IOSDetectModel class with a YOLO model and example image.\"\"\"\n        super().__init__()\n        _, _, h, w = im.shape  # batch, channel, height, width\n        self.model = model\n        self.nc = len(model.names)  # number of classes\n        if w == h:\n            self.normalize = 1.0 / w  # scalar",
        "detail": "ultralytics.engine.exporter",
        "documentation": {}
    },
    {
        "label": "export_formats",
        "kind": 2,
        "importPath": "ultralytics.engine.exporter",
        "description": "ultralytics.engine.exporter",
        "peekOfCode": "def export_formats():\n    \"\"\"YOLOv8 export formats.\"\"\"\n    import pandas  # scope for faster 'import ultralytics'\n    x = [\n        [\"PyTorch\", \"-\", \".pt\", True, True],\n        [\"TorchScript\", \"torchscript\", \".torchscript\", True, True],\n        [\"ONNX\", \"onnx\", \".onnx\", True, True],\n        [\"OpenVINO\", \"openvino\", \"_openvino_model\", True, False],\n        [\"TensorRT\", \"engine\", \".engine\", False, True],\n        [\"CoreML\", \"coreml\", \".mlpackage\", True, False],",
        "detail": "ultralytics.engine.exporter",
        "documentation": {}
    },
    {
        "label": "gd_outputs",
        "kind": 2,
        "importPath": "ultralytics.engine.exporter",
        "description": "ultralytics.engine.exporter",
        "peekOfCode": "def gd_outputs(gd):\n    \"\"\"TensorFlow GraphDef model output node names.\"\"\"\n    name_list, input_list = [], []\n    for node in gd.node:  # tensorflow.core.framework.node_def_pb2.NodeDef\n        name_list.append(node.name)\n        input_list.extend(node.input)\n    return sorted(f\"{x}:0\" for x in list(set(name_list) - set(input_list)) if not x.startswith(\"NoOp\"))\ndef try_export(inner_func):\n    \"\"\"YOLOv8 export decorator, i.e. @try_export.\"\"\"\n    inner_args = get_default_args(inner_func)",
        "detail": "ultralytics.engine.exporter",
        "documentation": {}
    },
    {
        "label": "try_export",
        "kind": 2,
        "importPath": "ultralytics.engine.exporter",
        "description": "ultralytics.engine.exporter",
        "peekOfCode": "def try_export(inner_func):\n    \"\"\"YOLOv8 export decorator, i.e. @try_export.\"\"\"\n    inner_args = get_default_args(inner_func)\n    def outer_func(*args, **kwargs):\n        \"\"\"Export a model.\"\"\"\n        prefix = inner_args[\"prefix\"]\n        try:\n            with Profile() as dt:\n                f, model = inner_func(*args, **kwargs)\n            LOGGER.info(f\"{prefix} export success ✅ {dt.t:.1f}s, saved as '{f}' ({file_size(f):.1f} MB)\")",
        "detail": "ultralytics.engine.exporter",
        "documentation": {}
    },
    {
        "label": "Model",
        "kind": 6,
        "importPath": "ultralytics.engine.model",
        "description": "ultralytics.engine.model",
        "peekOfCode": "class Model(nn.Module):\n    \"\"\"\n    A base class for implementing YOLO models, unifying APIs across different model types.\n    This class provides a common interface for various operations related to YOLO models, such as training,\n    validation, prediction, exporting, and benchmarking. It handles different types of models, including those\n    loaded from local files, Ultralytics HUB, or Triton Server.\n    Attributes:\n        callbacks (Dict): A dictionary of callback functions for various events during model operations.\n        predictor (BasePredictor): The predictor object used for making predictions.\n        model (nn.Module): The underlying PyTorch model.",
        "detail": "ultralytics.engine.model",
        "documentation": {}
    },
    {
        "label": "BasePredictor",
        "kind": 6,
        "importPath": "ultralytics.engine.predictor",
        "description": "ultralytics.engine.predictor",
        "peekOfCode": "class BasePredictor:\n    \"\"\"\n    BasePredictor.\n    A base class for creating predictors.\n    Attributes:\n        args (SimpleNamespace): Configuration for the predictor.\n        save_dir (Path): Directory to save results.\n        done_warmup (bool): Whether the predictor has finished setup.\n        model (nn.Module): Model used for prediction.\n        data (dict): Data configuration.",
        "detail": "ultralytics.engine.predictor",
        "documentation": {}
    },
    {
        "label": "STREAM_WARNING",
        "kind": 5,
        "importPath": "ultralytics.engine.predictor",
        "description": "ultralytics.engine.predictor",
        "peekOfCode": "STREAM_WARNING = \"\"\"\nWARNING ⚠️ inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\nerrors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\nExample:\n    results = model(source=..., stream=True)  # generator of Results objects\n    for r in results:\n        boxes = r.boxes  # Boxes object for bbox outputs\n        masks = r.masks  # Masks object for segment masks outputs\n        probs = r.probs  # Class probabilities for classification outputs\n\"\"\"",
        "detail": "ultralytics.engine.predictor",
        "documentation": {}
    },
    {
        "label": "BaseTensor",
        "kind": 6,
        "importPath": "ultralytics.engine.results",
        "description": "ultralytics.engine.results",
        "peekOfCode": "class BaseTensor(SimpleClass):\n    \"\"\"\n    Base tensor class with additional methods for easy manipulation and device handling.\n    Attributes:\n        data (torch.Tensor | np.ndarray): Prediction data such as bounding boxes, masks, or keypoints.\n        orig_shape (Tuple[int, int]): Original shape of the image, typically in the format (height, width).\n    Methods:\n        cpu: Return a copy of the tensor stored in CPU memory.\n        numpy: Returns a copy of the tensor as a numpy array.\n        cuda: Moves the tensor to GPU memory, returning a new instance if necessary.",
        "detail": "ultralytics.engine.results",
        "documentation": {}
    },
    {
        "label": "Results",
        "kind": 6,
        "importPath": "ultralytics.engine.results",
        "description": "ultralytics.engine.results",
        "peekOfCode": "class Results(SimpleClass):\n    \"\"\"\n    A class for storing and manipulating inference results.\n    This class encapsulates the functionality for handling detection, segmentation, pose estimation,\n    and classification results from YOLO models.\n    Attributes:\n        orig_img (numpy.ndarray): Original image as a numpy array.\n        orig_shape (Tuple[int, int]): Original image shape in (height, width) format.\n        boxes (Boxes | None): Object containing detection bounding boxes.\n        masks (Masks | None): Object containing detection masks.",
        "detail": "ultralytics.engine.results",
        "documentation": {}
    },
    {
        "label": "Boxes",
        "kind": 6,
        "importPath": "ultralytics.engine.results",
        "description": "ultralytics.engine.results",
        "peekOfCode": "class Boxes(BaseTensor):\n    \"\"\"\n    A class for managing and manipulating detection boxes.\n    This class provides functionality for handling detection boxes, including their coordinates, confidence scores,\n    class labels, and optional tracking IDs. It supports various box formats and offers methods for easy manipulation\n    and conversion between different coordinate systems.\n    Attributes:\n        data (torch.Tensor | numpy.ndarray): The raw tensor containing detection boxes and associated data.\n        orig_shape (Tuple[int, int]): The original image dimensions (height, width).\n        is_track (bool): Indicates whether tracking IDs are included in the box data.",
        "detail": "ultralytics.engine.results",
        "documentation": {}
    },
    {
        "label": "Masks",
        "kind": 6,
        "importPath": "ultralytics.engine.results",
        "description": "ultralytics.engine.results",
        "peekOfCode": "class Masks(BaseTensor):\n    \"\"\"\n    A class for storing and manipulating detection masks.\n    This class extends BaseTensor and provides functionality for handling segmentation masks,\n    including methods for converting between pixel and normalized coordinates.\n    Attributes:\n        data (torch.Tensor | numpy.ndarray): The raw tensor or array containing mask data.\n        orig_shape (tuple): Original image shape in (height, width) format.\n        xy (List[numpy.ndarray]): A list of segments in pixel coordinates.\n        xyn (List[numpy.ndarray]): A list of normalized segments.",
        "detail": "ultralytics.engine.results",
        "documentation": {}
    },
    {
        "label": "Keypoints",
        "kind": 6,
        "importPath": "ultralytics.engine.results",
        "description": "ultralytics.engine.results",
        "peekOfCode": "class Keypoints(BaseTensor):\n    \"\"\"\n    A class for storing and manipulating detection keypoints.\n    This class encapsulates functionality for handling keypoint data, including coordinate manipulation,\n    normalization, and confidence values.\n    Attributes:\n        data (torch.Tensor): The raw tensor containing keypoint data.\n        orig_shape (Tuple[int, int]): The original image dimensions (height, width).\n        has_visible (bool): Indicates whether visibility information is available for keypoints.\n        xy (torch.Tensor): Keypoint coordinates in [x, y] format.",
        "detail": "ultralytics.engine.results",
        "documentation": {}
    },
    {
        "label": "Probs",
        "kind": 6,
        "importPath": "ultralytics.engine.results",
        "description": "ultralytics.engine.results",
        "peekOfCode": "class Probs(BaseTensor):\n    \"\"\"\n    A class for storing and manipulating classification probabilities.\n    This class extends BaseTensor and provides methods for accessing and manipulating\n    classification probabilities, including top-1 and top-5 predictions.\n    Attributes:\n        data (torch.Tensor | numpy.ndarray): The raw tensor or array containing classification probabilities.\n        orig_shape (tuple | None): The original image shape as (height, width). Not used in this class.\n        top1 (int): Index of the class with the highest probability.\n        top5 (List[int]): Indices of the top 5 classes by probability.",
        "detail": "ultralytics.engine.results",
        "documentation": {}
    },
    {
        "label": "OBB",
        "kind": 6,
        "importPath": "ultralytics.engine.results",
        "description": "ultralytics.engine.results",
        "peekOfCode": "class OBB(BaseTensor):\n    \"\"\"\n    A class for storing and manipulating Oriented Bounding Boxes (OBB).\n    This class provides functionality to handle oriented bounding boxes, including conversion between\n    different formats, normalization, and access to various properties of the boxes.\n    Attributes:\n        data (torch.Tensor): The raw OBB tensor containing box coordinates and associated data.\n        orig_shape (tuple): Original image size as (height, width).\n        is_track (bool): Indicates whether tracking IDs are included in the box data.\n        xywhr (torch.Tensor | numpy.ndarray): Boxes in [x_center, y_center, width, height, rotation] format.",
        "detail": "ultralytics.engine.results",
        "documentation": {}
    },
    {
        "label": "BaseTrainer",
        "kind": 6,
        "importPath": "ultralytics.engine.trainer",
        "description": "ultralytics.engine.trainer",
        "peekOfCode": "class BaseTrainer:\n    \"\"\"\n    BaseTrainer.\n    A base class for creating trainers.\n    Attributes:\n        args (SimpleNamespace): Configuration for the trainer.\n        validator (BaseValidator): Validator instance.\n        model (nn.Module): Model instance.\n        callbacks (defaultdict): Dictionary of callbacks.\n        save_dir (Path): Directory to save results.",
        "detail": "ultralytics.engine.trainer",
        "documentation": {}
    },
    {
        "label": "Tuner",
        "kind": 6,
        "importPath": "ultralytics.engine.tuner",
        "description": "ultralytics.engine.tuner",
        "peekOfCode": "class Tuner:\n    \"\"\"\n    Class responsible for hyperparameter tuning of YOLO models.\n    The class evolves YOLO model hyperparameters over a given number of iterations\n    by mutating them according to the search space and retraining the model to evaluate their performance.\n    Attributes:\n        space (dict): Hyperparameter search space containing bounds and scaling factors for mutation.\n        tune_dir (Path): Directory where evolution logs and results will be saved.\n        tune_csv (Path): Path to the CSV file where evolution logs are saved.\n    Methods:",
        "detail": "ultralytics.engine.tuner",
        "documentation": {}
    },
    {
        "label": "BaseValidator",
        "kind": 6,
        "importPath": "ultralytics.engine.validator",
        "description": "ultralytics.engine.validator",
        "peekOfCode": "class BaseValidator:\n    \"\"\"\n    BaseValidator.\n    A base class for creating validators.\n    Attributes:\n        args (SimpleNamespace): Configuration for the validator.\n        dataloader (DataLoader): Dataloader to use for validation.\n        pbar (tqdm): Progress bar to update during validation.\n        model (nn.Module): Model to validate.\n        data (dict): Data dictionary.",
        "detail": "ultralytics.engine.validator",
        "documentation": {}
    },
    {
        "label": "Auth",
        "kind": 6,
        "importPath": "ultralytics.hub.auth",
        "description": "ultralytics.hub.auth",
        "peekOfCode": "class Auth:\n    \"\"\"\n    Manages authentication processes including API key handling, cookie-based authentication, and header generation.\n    The class supports different methods of authentication:\n    1. Directly using an API key.\n    2. Authenticating using browser cookies (specifically in Google Colab).\n    3. Prompting the user to enter an API key.\n    Attributes:\n        id_token (str or bool): Token used for identity verification, initialized as False.\n        api_key (str or bool): API key for authentication, initialized as False.",
        "detail": "ultralytics.hub.auth",
        "documentation": {}
    },
    {
        "label": "API_KEY_URL",
        "kind": 5,
        "importPath": "ultralytics.hub.auth",
        "description": "ultralytics.hub.auth",
        "peekOfCode": "API_KEY_URL = f\"{HUB_WEB_ROOT}/settings?tab=api+keys\"\nclass Auth:\n    \"\"\"\n    Manages authentication processes including API key handling, cookie-based authentication, and header generation.\n    The class supports different methods of authentication:\n    1. Directly using an API key.\n    2. Authenticating using browser cookies (specifically in Google Colab).\n    3. Prompting the user to enter an API key.\n    Attributes:\n        id_token (str or bool): Token used for identity verification, initialized as False.",
        "detail": "ultralytics.hub.auth",
        "documentation": {}
    },
    {
        "label": "HUBTrainingSession",
        "kind": 6,
        "importPath": "ultralytics.hub.session",
        "description": "ultralytics.hub.session",
        "peekOfCode": "class HUBTrainingSession:\n    \"\"\"\n    HUB training session for Ultralytics HUB YOLO models. Handles model initialization, heartbeats, and checkpointing.\n    Attributes:\n        model_id (str): Identifier for the YOLO model being trained.\n        model_url (str): URL for the model in Ultralytics HUB.\n        rate_limits (dict): Rate limits for different API calls (in seconds).\n        timers (dict): Timers for rate limiting.\n        metrics_queue (dict): Queue for the model's metrics.\n        model (dict): Model data fetched from Ultralytics HUB.",
        "detail": "ultralytics.hub.session",
        "documentation": {}
    },
    {
        "label": "AGENT_NAME",
        "kind": 5,
        "importPath": "ultralytics.hub.session",
        "description": "ultralytics.hub.session",
        "peekOfCode": "AGENT_NAME = f\"python-{__version__}-colab\" if IS_COLAB else f\"python-{__version__}-local\"\nclass HUBTrainingSession:\n    \"\"\"\n    HUB training session for Ultralytics HUB YOLO models. Handles model initialization, heartbeats, and checkpointing.\n    Attributes:\n        model_id (str): Identifier for the YOLO model being trained.\n        model_url (str): URL for the model in Ultralytics HUB.\n        rate_limits (dict): Rate limits for different API calls (in seconds).\n        timers (dict): Timers for rate limiting.\n        metrics_queue (dict): Queue for the model's metrics.",
        "detail": "ultralytics.hub.session",
        "documentation": {}
    },
    {
        "label": "Events",
        "kind": 6,
        "importPath": "ultralytics.hub.utils",
        "description": "ultralytics.hub.utils",
        "peekOfCode": "class Events:\n    \"\"\"\n    A class for collecting anonymous event analytics. Event analytics are enabled when sync=True in settings and\n    disabled when sync=False. Run 'yolo settings' to see and update settings YAML file.\n    Attributes:\n        url (str): The URL to send anonymous events.\n        rate_limit (float): The rate limit in seconds for sending events.\n        metadata (dict): A dictionary containing metadata about the environment.\n        enabled (bool): A flag to enable or disable Events based on certain conditions.\n    \"\"\"",
        "detail": "ultralytics.hub.utils",
        "documentation": {}
    },
    {
        "label": "request_with_credentials",
        "kind": 2,
        "importPath": "ultralytics.hub.utils",
        "description": "ultralytics.hub.utils",
        "peekOfCode": "def request_with_credentials(url: str) -> any:\n    \"\"\"\n    Make an AJAX request with cookies attached in a Google Colab environment.\n    Args:\n        url (str): The URL to make the request to.\n    Returns:\n        (any): The response data from the AJAX request.\n    Raises:\n        OSError: If the function is not run in a Google Colab environment.\n    \"\"\"",
        "detail": "ultralytics.hub.utils",
        "documentation": {}
    },
    {
        "label": "requests_with_progress",
        "kind": 2,
        "importPath": "ultralytics.hub.utils",
        "description": "ultralytics.hub.utils",
        "peekOfCode": "def requests_with_progress(method, url, **kwargs):\n    \"\"\"\n    Make an HTTP request using the specified method and URL, with an optional progress bar.\n    Args:\n        method (str): The HTTP method to use (e.g. 'GET', 'POST').\n        url (str): The URL to send the request to.\n        **kwargs (any): Additional keyword arguments to pass to the underlying `requests.request` function.\n    Returns:\n        (requests.Response): The response object from the HTTP request.\n    Note:",
        "detail": "ultralytics.hub.utils",
        "documentation": {}
    },
    {
        "label": "smart_request",
        "kind": 2,
        "importPath": "ultralytics.hub.utils",
        "description": "ultralytics.hub.utils",
        "peekOfCode": "def smart_request(method, url, retry=3, timeout=30, thread=True, code=-1, verbose=True, progress=False, **kwargs):\n    \"\"\"\n    Makes an HTTP request using the 'requests' library, with exponential backoff retries up to a specified timeout.\n    Args:\n        method (str): The HTTP method to use for the request. Choices are 'post' and 'get'.\n        url (str): The URL to make the request to.\n        retry (int, optional): Number of retries to attempt before giving up. Default is 3.\n        timeout (int, optional): Timeout in seconds after which the function will give up retrying. Default is 30.\n        thread (bool, optional): Whether to execute the request in a separate daemon thread. Default is True.\n        code (int, optional): An identifier for the request, used for logging purposes. Default is -1.",
        "detail": "ultralytics.hub.utils",
        "documentation": {}
    },
    {
        "label": "HUB_API_ROOT",
        "kind": 5,
        "importPath": "ultralytics.hub.utils",
        "description": "ultralytics.hub.utils",
        "peekOfCode": "HUB_API_ROOT = os.environ.get(\"ULTRALYTICS_HUB_API\", \"https://api.ultralytics.com\")\nHUB_WEB_ROOT = os.environ.get(\"ULTRALYTICS_HUB_WEB\", \"https://hub.ultralytics.com\")\nPREFIX = colorstr(\"Ultralytics HUB: \")\nHELP_MSG = \"If this issue persists please visit https://github.com/ultralytics/hub/issues for assistance.\"\ndef request_with_credentials(url: str) -> any:\n    \"\"\"\n    Make an AJAX request with cookies attached in a Google Colab environment.\n    Args:\n        url (str): The URL to make the request to.\n    Returns:",
        "detail": "ultralytics.hub.utils",
        "documentation": {}
    },
    {
        "label": "HUB_WEB_ROOT",
        "kind": 5,
        "importPath": "ultralytics.hub.utils",
        "description": "ultralytics.hub.utils",
        "peekOfCode": "HUB_WEB_ROOT = os.environ.get(\"ULTRALYTICS_HUB_WEB\", \"https://hub.ultralytics.com\")\nPREFIX = colorstr(\"Ultralytics HUB: \")\nHELP_MSG = \"If this issue persists please visit https://github.com/ultralytics/hub/issues for assistance.\"\ndef request_with_credentials(url: str) -> any:\n    \"\"\"\n    Make an AJAX request with cookies attached in a Google Colab environment.\n    Args:\n        url (str): The URL to make the request to.\n    Returns:\n        (any): The response data from the AJAX request.",
        "detail": "ultralytics.hub.utils",
        "documentation": {}
    },
    {
        "label": "PREFIX",
        "kind": 5,
        "importPath": "ultralytics.hub.utils",
        "description": "ultralytics.hub.utils",
        "peekOfCode": "PREFIX = colorstr(\"Ultralytics HUB: \")\nHELP_MSG = \"If this issue persists please visit https://github.com/ultralytics/hub/issues for assistance.\"\ndef request_with_credentials(url: str) -> any:\n    \"\"\"\n    Make an AJAX request with cookies attached in a Google Colab environment.\n    Args:\n        url (str): The URL to make the request to.\n    Returns:\n        (any): The response data from the AJAX request.\n    Raises:",
        "detail": "ultralytics.hub.utils",
        "documentation": {}
    },
    {
        "label": "HELP_MSG",
        "kind": 5,
        "importPath": "ultralytics.hub.utils",
        "description": "ultralytics.hub.utils",
        "peekOfCode": "HELP_MSG = \"If this issue persists please visit https://github.com/ultralytics/hub/issues for assistance.\"\ndef request_with_credentials(url: str) -> any:\n    \"\"\"\n    Make an AJAX request with cookies attached in a Google Colab environment.\n    Args:\n        url (str): The URL to make the request to.\n    Returns:\n        (any): The response data from the AJAX request.\n    Raises:\n        OSError: If the function is not run in a Google Colab environment.",
        "detail": "ultralytics.hub.utils",
        "documentation": {}
    },
    {
        "label": "events",
        "kind": 5,
        "importPath": "ultralytics.hub.utils",
        "description": "ultralytics.hub.utils",
        "peekOfCode": "events = Events()",
        "detail": "ultralytics.hub.utils",
        "documentation": {}
    },
    {
        "label": "FastSAM",
        "kind": 6,
        "importPath": "ultralytics.models.fastsam.model",
        "description": "ultralytics.models.fastsam.model",
        "peekOfCode": "class FastSAM(Model):\n    \"\"\"\n    FastSAM model interface.\n    Example:\n        ```python\n        from ultralytics import FastSAM\n        model = FastSAM('last.pt')\n        results = model.predict('ultralytics/assets/bus.jpg')\n        ```\n    \"\"\"",
        "detail": "ultralytics.models.fastsam.model",
        "documentation": {}
    },
    {
        "label": "FastSAMPredictor",
        "kind": 6,
        "importPath": "ultralytics.models.fastsam.predict",
        "description": "ultralytics.models.fastsam.predict",
        "peekOfCode": "class FastSAMPredictor(SegmentationPredictor):\n    \"\"\"\n    FastSAMPredictor is specialized for fast SAM (Segment Anything Model) segmentation prediction tasks in Ultralytics\n    YOLO framework.\n    This class extends the SegmentationPredictor, customizing the prediction pipeline specifically for fast SAM. It\n    adjusts post-processing steps to incorporate mask prediction and non-max suppression while optimizing for single-\n    class segmentation.\n    \"\"\"\n    def postprocess(self, preds, img, orig_imgs):\n        \"\"\"Applies box postprocess for FastSAM predictions.\"\"\"",
        "detail": "ultralytics.models.fastsam.predict",
        "documentation": {}
    },
    {
        "label": "FastSAMPrompt",
        "kind": 6,
        "importPath": "ultralytics.models.fastsam.prompt",
        "description": "ultralytics.models.fastsam.prompt",
        "peekOfCode": "class FastSAMPrompt:\n    \"\"\"\n    Fast Segment Anything Model class for image annotation and visualization.\n    Attributes:\n        device (str): Computing device ('cuda' or 'cpu').\n        results: Object detection or segmentation results.\n        source: Source image or image path.\n        clip: CLIP model for linear assignment.\n    \"\"\"\n    def __init__(self, source, results, device=\"cuda\") -> None:",
        "detail": "ultralytics.models.fastsam.prompt",
        "documentation": {}
    },
    {
        "label": "adjust_bboxes_to_image_border",
        "kind": 2,
        "importPath": "ultralytics.models.fastsam.utils",
        "description": "ultralytics.models.fastsam.utils",
        "peekOfCode": "def adjust_bboxes_to_image_border(boxes, image_shape, threshold=20):\n    \"\"\"\n    Adjust bounding boxes to stick to image border if they are within a certain threshold.\n    Args:\n        boxes (torch.Tensor): (n, 4)\n        image_shape (tuple): (height, width)\n        threshold (int): pixel threshold\n    Returns:\n        adjusted_boxes (torch.Tensor): adjusted bounding boxes\n    \"\"\"",
        "detail": "ultralytics.models.fastsam.utils",
        "documentation": {}
    },
    {
        "label": "FastSAMValidator",
        "kind": 6,
        "importPath": "ultralytics.models.fastsam.val",
        "description": "ultralytics.models.fastsam.val",
        "peekOfCode": "class FastSAMValidator(SegmentationValidator):\n    \"\"\"\n    Custom validation class for fast SAM (Segment Anything Model) segmentation in Ultralytics YOLO framework.\n    Extends the SegmentationValidator class, customizing the validation process specifically for fast SAM. This class\n    sets the task to 'segment' and uses the SegmentMetrics for evaluation. Additionally, plotting features are disabled\n    to avoid errors during validation.\n    Attributes:\n        dataloader: The data loader object used for validation.\n        save_dir (str): The directory where validation results will be saved.\n        pbar: A progress bar object.",
        "detail": "ultralytics.models.fastsam.val",
        "documentation": {}
    },
    {
        "label": "NAS",
        "kind": 6,
        "importPath": "ultralytics.models.nas.model",
        "description": "ultralytics.models.nas.model",
        "peekOfCode": "class NAS(Model):\n    \"\"\"\n    YOLO NAS model for object detection.\n    This class provides an interface for the YOLO-NAS models and extends the `Model` class from Ultralytics engine.\n    It is designed to facilitate the task of object detection using pre-trained or custom-trained YOLO-NAS models.\n    Example:\n        ```python\n        from ultralytics import NAS\n        model = NAS('yolo_nas_s')\n        results = model.predict('ultralytics/assets/bus.jpg')",
        "detail": "ultralytics.models.nas.model",
        "documentation": {}
    },
    {
        "label": "NASPredictor",
        "kind": 6,
        "importPath": "ultralytics.models.nas.predict",
        "description": "ultralytics.models.nas.predict",
        "peekOfCode": "class NASPredictor(BasePredictor):\n    \"\"\"\n    Ultralytics YOLO NAS Predictor for object detection.\n    This class extends the `BasePredictor` from Ultralytics engine and is responsible for post-processing the\n    raw predictions generated by the YOLO NAS models. It applies operations like non-maximum suppression and\n    scaling the bounding boxes to fit the original image dimensions.\n    Attributes:\n        args (Namespace): Namespace containing various configurations for post-processing.\n    Example:\n        ```python",
        "detail": "ultralytics.models.nas.predict",
        "documentation": {}
    },
    {
        "label": "NASValidator",
        "kind": 6,
        "importPath": "ultralytics.models.nas.val",
        "description": "ultralytics.models.nas.val",
        "peekOfCode": "class NASValidator(DetectionValidator):\n    \"\"\"\n    Ultralytics YOLO NAS Validator for object detection.\n    Extends `DetectionValidator` from the Ultralytics models package and is designed to post-process the raw predictions\n    generated by YOLO NAS models. It performs non-maximum suppression to remove overlapping and low-confidence boxes,\n    ultimately producing the final detections.\n    Attributes:\n        args (Namespace): Namespace containing various configurations for post-processing, such as confidence and IoU.\n        lb (torch.Tensor): Optional tensor for multilabel NMS.\n    Example:",
        "detail": "ultralytics.models.nas.val",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "ultralytics.models.nas.val",
        "description": "ultralytics.models.nas.val",
        "peekOfCode": "__all__ = [\"NASValidator\"]\nclass NASValidator(DetectionValidator):\n    \"\"\"\n    Ultralytics YOLO NAS Validator for object detection.\n    Extends `DetectionValidator` from the Ultralytics models package and is designed to post-process the raw predictions\n    generated by YOLO NAS models. It performs non-maximum suppression to remove overlapping and low-confidence boxes,\n    ultimately producing the final detections.\n    Attributes:\n        args (Namespace): Namespace containing various configurations for post-processing, such as confidence and IoU.\n        lb (torch.Tensor): Optional tensor for multilabel NMS.",
        "detail": "ultralytics.models.nas.val",
        "documentation": {}
    },
    {
        "label": "RTDETR",
        "kind": 6,
        "importPath": "ultralytics.models.rtdetr.model",
        "description": "ultralytics.models.rtdetr.model",
        "peekOfCode": "class RTDETR(Model):\n    \"\"\"\n    Interface for Baidu's RT-DETR model. This Vision Transformer-based object detector provides real-time performance\n    with high accuracy. It supports efficient hybrid encoding, IoU-aware query selection, and adaptable inference speed.\n    Attributes:\n        model (str): Path to the pre-trained model. Defaults to 'rtdetr-l.pt'.\n    \"\"\"\n    def __init__(self, model=\"rtdetr-l.pt\") -> None:\n        \"\"\"\n        Initializes the RT-DETR model with the given pre-trained model file. Supports .pt and .yaml formats.",
        "detail": "ultralytics.models.rtdetr.model",
        "documentation": {}
    },
    {
        "label": "RTDETRPredictor",
        "kind": 6,
        "importPath": "ultralytics.models.rtdetr.predict",
        "description": "ultralytics.models.rtdetr.predict",
        "peekOfCode": "class RTDETRPredictor(BasePredictor):\n    \"\"\"\n    RT-DETR (Real-Time Detection Transformer) Predictor extending the BasePredictor class for making predictions using\n    Baidu's RT-DETR model.\n    This class leverages the power of Vision Transformers to provide real-time object detection while maintaining\n    high accuracy. It supports key features like efficient hybrid encoding and IoU-aware query selection.\n    Example:\n        ```python\n        from ultralytics.utils import ASSETS\n        from ultralytics.models.rtdetr import RTDETRPredictor",
        "detail": "ultralytics.models.rtdetr.predict",
        "documentation": {}
    },
    {
        "label": "RTDETRTrainer",
        "kind": 6,
        "importPath": "ultralytics.models.rtdetr.train",
        "description": "ultralytics.models.rtdetr.train",
        "peekOfCode": "class RTDETRTrainer(DetectionTrainer):\n    \"\"\"\n    Trainer class for the RT-DETR model developed by Baidu for real-time object detection. Extends the DetectionTrainer\n    class for YOLO to adapt to the specific features and architecture of RT-DETR. This model leverages Vision\n    Transformers and has capabilities like IoU-aware query selection and adaptable inference speed.\n    Notes:\n        - F.grid_sample used in RT-DETR does not support the `deterministic=True` argument.\n        - AMP training can lead to NaN outputs and may produce errors during bipartite graph matching.\n    Example:\n        ```python",
        "detail": "ultralytics.models.rtdetr.train",
        "documentation": {}
    },
    {
        "label": "RTDETRDataset",
        "kind": 6,
        "importPath": "ultralytics.models.rtdetr.val",
        "description": "ultralytics.models.rtdetr.val",
        "peekOfCode": "class RTDETRDataset(YOLODataset):\n    \"\"\"\n    Real-Time DEtection and TRacking (RT-DETR) dataset class extending the base YOLODataset class.\n    This specialized dataset class is designed for use with the RT-DETR object detection model and is optimized for\n    real-time detection and tracking tasks.\n    \"\"\"\n    def __init__(self, *args, data=None, **kwargs):\n        \"\"\"Initialize the RTDETRDataset class by inheriting from the YOLODataset class.\"\"\"\n        super().__init__(*args, data=data, **kwargs)\n    # NOTE: add stretch version load_image for RTDETR mosaic",
        "detail": "ultralytics.models.rtdetr.val",
        "documentation": {}
    },
    {
        "label": "RTDETRValidator",
        "kind": 6,
        "importPath": "ultralytics.models.rtdetr.val",
        "description": "ultralytics.models.rtdetr.val",
        "peekOfCode": "class RTDETRValidator(DetectionValidator):\n    \"\"\"\n    RTDETRValidator extends the DetectionValidator class to provide validation capabilities specifically tailored for\n    the RT-DETR (Real-Time DETR) object detection model.\n    The class allows building of an RTDETR-specific dataset for validation, applies Non-maximum suppression for\n    post-processing, and updates evaluation metrics accordingly.\n    Example:\n        ```python\n        from ultralytics.models.rtdetr import RTDETRValidator\n        args = dict(model='rtdetr-l.pt', data='coco8.yaml')",
        "detail": "ultralytics.models.rtdetr.val",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "ultralytics.models.rtdetr.val",
        "description": "ultralytics.models.rtdetr.val",
        "peekOfCode": "__all__ = (\"RTDETRValidator\",)  # tuple or list\nclass RTDETRDataset(YOLODataset):\n    \"\"\"\n    Real-Time DEtection and TRacking (RT-DETR) dataset class extending the base YOLODataset class.\n    This specialized dataset class is designed for use with the RT-DETR object detection model and is optimized for\n    real-time detection and tracking tasks.\n    \"\"\"\n    def __init__(self, *args, data=None, **kwargs):\n        \"\"\"Initialize the RTDETRDataset class by inheriting from the YOLODataset class.\"\"\"\n        super().__init__(*args, data=data, **kwargs)",
        "detail": "ultralytics.models.rtdetr.val",
        "documentation": {}
    },
    {
        "label": "MaskDecoder",
        "kind": 6,
        "importPath": "ultralytics.models.sam.modules.decoders",
        "description": "ultralytics.models.sam.modules.decoders",
        "peekOfCode": "class MaskDecoder(nn.Module):\n    \"\"\"\n    Decoder module for generating masks and their associated quality scores, using a transformer architecture to predict\n    masks given image and prompt embeddings.\n    Attributes:\n        transformer_dim (int): Channel dimension for the transformer module.\n        transformer (nn.Module): The transformer module used for mask prediction.\n        num_multimask_outputs (int): Number of masks to predict for disambiguating masks.\n        iou_token (nn.Embedding): Embedding for the IoU token.\n        num_mask_tokens (int): Number of mask tokens.",
        "detail": "ultralytics.models.sam.modules.decoders",
        "documentation": {}
    },
    {
        "label": "MLP",
        "kind": 6,
        "importPath": "ultralytics.models.sam.modules.decoders",
        "description": "ultralytics.models.sam.modules.decoders",
        "peekOfCode": "class MLP(nn.Module):\n    \"\"\"\n    MLP (Multi-Layer Perceptron) model lightly adapted from\n    https://github.com/facebookresearch/MaskFormer/blob/main/mask_former/modeling/transformer/transformer_predictor.py\n    \"\"\"\n    def __init__(\n        self,\n        input_dim: int,\n        hidden_dim: int,\n        output_dim: int,",
        "detail": "ultralytics.models.sam.modules.decoders",
        "documentation": {}
    },
    {
        "label": "ImageEncoderViT",
        "kind": 6,
        "importPath": "ultralytics.models.sam.modules.encoders",
        "description": "ultralytics.models.sam.modules.encoders",
        "peekOfCode": "class ImageEncoderViT(nn.Module):\n    \"\"\"\n    An image encoder using Vision Transformer (ViT) architecture for encoding an image into a compact latent space. The\n    encoder takes an image, splits it into patches, and processes these patches through a series of transformer blocks.\n    The encoded patches are then processed through a neck to generate the final encoded representation.\n    This class and its supporting functions below lightly adapted from the ViTDet backbone available at\n    https://github.com/facebookresearch/detectron2/blob/main/detectron2/modeling/backbone/vit.py.\n    Attributes:\n        img_size (int): Dimension of input images, assumed to be square.\n        patch_embed (PatchEmbed): Module for patch embedding.",
        "detail": "ultralytics.models.sam.modules.encoders",
        "documentation": {}
    },
    {
        "label": "PromptEncoder",
        "kind": 6,
        "importPath": "ultralytics.models.sam.modules.encoders",
        "description": "ultralytics.models.sam.modules.encoders",
        "peekOfCode": "class PromptEncoder(nn.Module):\n    \"\"\"\n    Encodes different types of prompts, including points, boxes, and masks, for input to SAM's mask decoder. The encoder\n    produces both sparse and dense embeddings for the input prompts.\n    Attributes:\n        embed_dim (int): Dimension of the embeddings.\n        input_image_size (Tuple[int, int]): Size of the input image as (H, W).\n        image_embedding_size (Tuple[int, int]): Spatial size of the image embedding as (H, W).\n        pe_layer (PositionEmbeddingRandom): Module for random position embedding.\n        num_point_embeddings (int): Number of point embeddings for different types of points.",
        "detail": "ultralytics.models.sam.modules.encoders",
        "documentation": {}
    },
    {
        "label": "PositionEmbeddingRandom",
        "kind": 6,
        "importPath": "ultralytics.models.sam.modules.encoders",
        "description": "ultralytics.models.sam.modules.encoders",
        "peekOfCode": "class PositionEmbeddingRandom(nn.Module):\n    \"\"\"Positional encoding using random spatial frequencies.\"\"\"\n    def __init__(self, num_pos_feats: int = 64, scale: Optional[float] = None) -> None:\n        \"\"\"Initializes a position embedding using random spatial frequencies.\"\"\"\n        super().__init__()\n        if scale is None or scale <= 0.0:\n            scale = 1.0\n        self.register_buffer(\"positional_encoding_gaussian_matrix\", scale * torch.randn((2, num_pos_feats)))\n        # Set non-deterministic for forward() error 'cumsum_cuda_kernel does not have a deterministic implementation'\n        torch.use_deterministic_algorithms(False)",
        "detail": "ultralytics.models.sam.modules.encoders",
        "documentation": {}
    },
    {
        "label": "Block",
        "kind": 6,
        "importPath": "ultralytics.models.sam.modules.encoders",
        "description": "ultralytics.models.sam.modules.encoders",
        "peekOfCode": "class Block(nn.Module):\n    \"\"\"Transformer blocks with support of window attention and residual propagation blocks.\"\"\"\n    def __init__(\n        self,\n        dim: int,\n        num_heads: int,\n        mlp_ratio: float = 4.0,\n        qkv_bias: bool = True,\n        norm_layer: Type[nn.Module] = nn.LayerNorm,\n        act_layer: Type[nn.Module] = nn.GELU,",
        "detail": "ultralytics.models.sam.modules.encoders",
        "documentation": {}
    },
    {
        "label": "Attention",
        "kind": 6,
        "importPath": "ultralytics.models.sam.modules.encoders",
        "description": "ultralytics.models.sam.modules.encoders",
        "peekOfCode": "class Attention(nn.Module):\n    \"\"\"Multi-head Attention block with relative position embeddings.\"\"\"\n    def __init__(\n        self,\n        dim: int,\n        num_heads: int = 8,\n        qkv_bias: bool = True,\n        use_rel_pos: bool = False,\n        rel_pos_zero_init: bool = True,\n        input_size: Optional[Tuple[int, int]] = None,",
        "detail": "ultralytics.models.sam.modules.encoders",
        "documentation": {}
    },
    {
        "label": "PatchEmbed",
        "kind": 6,
        "importPath": "ultralytics.models.sam.modules.encoders",
        "description": "ultralytics.models.sam.modules.encoders",
        "peekOfCode": "class PatchEmbed(nn.Module):\n    \"\"\"Image to Patch Embedding.\"\"\"\n    def __init__(\n        self,\n        kernel_size: Tuple[int, int] = (16, 16),\n        stride: Tuple[int, int] = (16, 16),\n        padding: Tuple[int, int] = (0, 0),\n        in_chans: int = 3,\n        embed_dim: int = 768,\n    ) -> None:",
        "detail": "ultralytics.models.sam.modules.encoders",
        "documentation": {}
    },
    {
        "label": "window_partition",
        "kind": 2,
        "importPath": "ultralytics.models.sam.modules.encoders",
        "description": "ultralytics.models.sam.modules.encoders",
        "peekOfCode": "def window_partition(x: torch.Tensor, window_size: int) -> Tuple[torch.Tensor, Tuple[int, int]]:\n    \"\"\"\n    Partition into non-overlapping windows with padding if needed.\n    Args:\n        x (tensor): input tokens with [B, H, W, C].\n        window_size (int): window size.\n    Returns:\n        windows: windows after partition with [B * num_windows, window_size, window_size, C].\n        (Hp, Wp): padded height and width before partition\n    \"\"\"",
        "detail": "ultralytics.models.sam.modules.encoders",
        "documentation": {}
    },
    {
        "label": "window_unpartition",
        "kind": 2,
        "importPath": "ultralytics.models.sam.modules.encoders",
        "description": "ultralytics.models.sam.modules.encoders",
        "peekOfCode": "def window_unpartition(\n    windows: torch.Tensor, window_size: int, pad_hw: Tuple[int, int], hw: Tuple[int, int]\n) -> torch.Tensor:\n    \"\"\"\n    Window unpartition into original sequences and removing padding.\n    Args:\n        windows (tensor): input tokens with [B * num_windows, window_size, window_size, C].\n        window_size (int): window size.\n        pad_hw (Tuple): padded height and width (Hp, Wp).\n        hw (Tuple): original height and width (H, W) before padding.",
        "detail": "ultralytics.models.sam.modules.encoders",
        "documentation": {}
    },
    {
        "label": "get_rel_pos",
        "kind": 2,
        "importPath": "ultralytics.models.sam.modules.encoders",
        "description": "ultralytics.models.sam.modules.encoders",
        "peekOfCode": "def get_rel_pos(q_size: int, k_size: int, rel_pos: torch.Tensor) -> torch.Tensor:\n    \"\"\"\n    Get relative positional embeddings according to the relative positions of query and key sizes.\n    Args:\n        q_size (int): size of query q.\n        k_size (int): size of key k.\n        rel_pos (Tensor): relative position embeddings (L, C).\n    Returns:\n        Extracted positional embeddings according to relative positions.\n    \"\"\"",
        "detail": "ultralytics.models.sam.modules.encoders",
        "documentation": {}
    },
    {
        "label": "add_decomposed_rel_pos",
        "kind": 2,
        "importPath": "ultralytics.models.sam.modules.encoders",
        "description": "ultralytics.models.sam.modules.encoders",
        "peekOfCode": "def add_decomposed_rel_pos(\n    attn: torch.Tensor,\n    q: torch.Tensor,\n    rel_pos_h: torch.Tensor,\n    rel_pos_w: torch.Tensor,\n    q_size: Tuple[int, int],\n    k_size: Tuple[int, int],\n) -> torch.Tensor:\n    \"\"\"\n    Calculate decomposed Relative Positional Embeddings from mvitv2 paper at",
        "detail": "ultralytics.models.sam.modules.encoders",
        "documentation": {}
    },
    {
        "label": "Sam",
        "kind": 6,
        "importPath": "ultralytics.models.sam.modules.sam",
        "description": "ultralytics.models.sam.modules.sam",
        "peekOfCode": "class Sam(nn.Module):\n    \"\"\"\n    Sam (Segment Anything Model) is designed for object segmentation tasks. It uses image encoders to generate image\n    embeddings, and prompt encoders to encode various types of input prompts. These embeddings are then used by the mask\n    decoder to predict object masks.\n    Attributes:\n        mask_threshold (float): Threshold value for mask prediction.\n        image_format (str): Format of the input image, default is 'RGB'.\n        image_encoder (ImageEncoderViT): The backbone used to encode the image into embeddings.\n        prompt_encoder (PromptEncoder): Encodes various types of input prompts.",
        "detail": "ultralytics.models.sam.modules.sam",
        "documentation": {}
    },
    {
        "label": "Conv2d_BN",
        "kind": 6,
        "importPath": "ultralytics.models.sam.modules.tiny_encoder",
        "description": "ultralytics.models.sam.modules.tiny_encoder",
        "peekOfCode": "class Conv2d_BN(torch.nn.Sequential):\n    \"\"\"A sequential container that performs 2D convolution followed by batch normalization.\"\"\"\n    def __init__(self, a, b, ks=1, stride=1, pad=0, dilation=1, groups=1, bn_weight_init=1):\n        \"\"\"Initializes the MBConv model with given input channels, output channels, expansion ratio, activation, and\n        drop path.\n        \"\"\"\n        super().__init__()\n        self.add_module(\"c\", torch.nn.Conv2d(a, b, ks, stride, pad, dilation, groups, bias=False))\n        bn = torch.nn.BatchNorm2d(b)\n        torch.nn.init.constant_(bn.weight, bn_weight_init)",
        "detail": "ultralytics.models.sam.modules.tiny_encoder",
        "documentation": {}
    },
    {
        "label": "PatchEmbed",
        "kind": 6,
        "importPath": "ultralytics.models.sam.modules.tiny_encoder",
        "description": "ultralytics.models.sam.modules.tiny_encoder",
        "peekOfCode": "class PatchEmbed(nn.Module):\n    \"\"\"Embeds images into patches and projects them into a specified embedding dimension.\"\"\"\n    def __init__(self, in_chans, embed_dim, resolution, activation):\n        \"\"\"Initialize the PatchMerging class with specified input, output dimensions, resolution and activation\n        function.\n        \"\"\"\n        super().__init__()\n        img_size: Tuple[int, int] = to_2tuple(resolution)\n        self.patches_resolution = (img_size[0] // 4, img_size[1] // 4)\n        self.num_patches = self.patches_resolution[0] * self.patches_resolution[1]",
        "detail": "ultralytics.models.sam.modules.tiny_encoder",
        "documentation": {}
    },
    {
        "label": "MBConv",
        "kind": 6,
        "importPath": "ultralytics.models.sam.modules.tiny_encoder",
        "description": "ultralytics.models.sam.modules.tiny_encoder",
        "peekOfCode": "class MBConv(nn.Module):\n    \"\"\"Mobile Inverted Bottleneck Conv (MBConv) layer, part of the EfficientNet architecture.\"\"\"\n    def __init__(self, in_chans, out_chans, expand_ratio, activation, drop_path):\n        \"\"\"Initializes a convolutional layer with specified dimensions, input resolution, depth, and activation\n        function.\n        \"\"\"\n        super().__init__()\n        self.in_chans = in_chans\n        self.hidden_chans = int(in_chans * expand_ratio)\n        self.out_chans = out_chans",
        "detail": "ultralytics.models.sam.modules.tiny_encoder",
        "documentation": {}
    },
    {
        "label": "PatchMerging",
        "kind": 6,
        "importPath": "ultralytics.models.sam.modules.tiny_encoder",
        "description": "ultralytics.models.sam.modules.tiny_encoder",
        "peekOfCode": "class PatchMerging(nn.Module):\n    \"\"\"Merges neighboring patches in the feature map and projects to a new dimension.\"\"\"\n    def __init__(self, input_resolution, dim, out_dim, activation):\n        \"\"\"Initializes the ConvLayer with specific dimension, input resolution, depth, activation, drop path, and other\n        optional parameters.\n        \"\"\"\n        super().__init__()\n        self.input_resolution = input_resolution\n        self.dim = dim\n        self.out_dim = out_dim",
        "detail": "ultralytics.models.sam.modules.tiny_encoder",
        "documentation": {}
    },
    {
        "label": "ConvLayer",
        "kind": 6,
        "importPath": "ultralytics.models.sam.modules.tiny_encoder",
        "description": "ultralytics.models.sam.modules.tiny_encoder",
        "peekOfCode": "class ConvLayer(nn.Module):\n    \"\"\"\n    Convolutional Layer featuring multiple MobileNetV3-style inverted bottleneck convolutions (MBConv).\n    Optionally applies downsample operations to the output, and provides support for gradient checkpointing.\n    \"\"\"\n    def __init__(\n        self,\n        dim,\n        input_resolution,\n        depth,",
        "detail": "ultralytics.models.sam.modules.tiny_encoder",
        "documentation": {}
    },
    {
        "label": "Mlp",
        "kind": 6,
        "importPath": "ultralytics.models.sam.modules.tiny_encoder",
        "description": "ultralytics.models.sam.modules.tiny_encoder",
        "peekOfCode": "class Mlp(nn.Module):\n    \"\"\"\n    Multi-layer Perceptron (MLP) for transformer architectures.\n    This layer takes an input with in_features, applies layer normalization and two fully-connected layers.\n    \"\"\"\n    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.GELU, drop=0.0):\n        \"\"\"Initializes Attention module with the given parameters including dimension, key_dim, number of heads, etc.\"\"\"\n        super().__init__()\n        out_features = out_features or in_features\n        hidden_features = hidden_features or in_features",
        "detail": "ultralytics.models.sam.modules.tiny_encoder",
        "documentation": {}
    },
    {
        "label": "Attention",
        "kind": 6,
        "importPath": "ultralytics.models.sam.modules.tiny_encoder",
        "description": "ultralytics.models.sam.modules.tiny_encoder",
        "peekOfCode": "class Attention(torch.nn.Module):\n    \"\"\"\n    Multi-head attention module with support for spatial awareness, applying attention biases based on spatial\n    resolution. Implements trainable attention biases for each unique offset between spatial positions in the resolution\n    grid.\n    Attributes:\n        ab (Tensor, optional): Cached attention biases for inference, deleted during training.\n    \"\"\"\n    def __init__(\n        self,",
        "detail": "ultralytics.models.sam.modules.tiny_encoder",
        "documentation": {}
    },
    {
        "label": "TinyViTBlock",
        "kind": 6,
        "importPath": "ultralytics.models.sam.modules.tiny_encoder",
        "description": "ultralytics.models.sam.modules.tiny_encoder",
        "peekOfCode": "class TinyViTBlock(nn.Module):\n    \"\"\"TinyViT Block that applies self-attention and a local convolution to the input.\"\"\"\n    def __init__(\n        self,\n        dim,\n        input_resolution,\n        num_heads,\n        window_size=7,\n        mlp_ratio=4.0,\n        drop=0.0,",
        "detail": "ultralytics.models.sam.modules.tiny_encoder",
        "documentation": {}
    },
    {
        "label": "BasicLayer",
        "kind": 6,
        "importPath": "ultralytics.models.sam.modules.tiny_encoder",
        "description": "ultralytics.models.sam.modules.tiny_encoder",
        "peekOfCode": "class BasicLayer(nn.Module):\n    \"\"\"A basic TinyViT layer for one stage in a TinyViT architecture.\"\"\"\n    def __init__(\n        self,\n        dim,\n        input_resolution,\n        depth,\n        num_heads,\n        window_size,\n        mlp_ratio=4.0,",
        "detail": "ultralytics.models.sam.modules.tiny_encoder",
        "documentation": {}
    },
    {
        "label": "LayerNorm2d",
        "kind": 6,
        "importPath": "ultralytics.models.sam.modules.tiny_encoder",
        "description": "ultralytics.models.sam.modules.tiny_encoder",
        "peekOfCode": "class LayerNorm2d(nn.Module):\n    \"\"\"A PyTorch implementation of Layer Normalization in 2D.\"\"\"\n    def __init__(self, num_channels: int, eps: float = 1e-6) -> None:\n        \"\"\"Initialize LayerNorm2d with the number of channels and an optional epsilon.\"\"\"\n        super().__init__()\n        self.weight = nn.Parameter(torch.ones(num_channels))\n        self.bias = nn.Parameter(torch.zeros(num_channels))\n        self.eps = eps\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"Perform a forward pass, normalizing the input tensor.\"\"\"",
        "detail": "ultralytics.models.sam.modules.tiny_encoder",
        "documentation": {}
    },
    {
        "label": "TinyViT",
        "kind": 6,
        "importPath": "ultralytics.models.sam.modules.tiny_encoder",
        "description": "ultralytics.models.sam.modules.tiny_encoder",
        "peekOfCode": "class TinyViT(nn.Module):\n    \"\"\"\n    The TinyViT architecture for vision tasks.\n    Attributes:\n        img_size (int): Input image size.\n        in_chans (int): Number of input channels.\n        num_classes (int): Number of classification classes.\n        embed_dims (List[int]): List of embedding dimensions for each layer.\n        depths (List[int]): List of depths for each layer.\n        num_heads (List[int]): List of number of attention heads for each layer.",
        "detail": "ultralytics.models.sam.modules.tiny_encoder",
        "documentation": {}
    },
    {
        "label": "TwoWayTransformer",
        "kind": 6,
        "importPath": "ultralytics.models.sam.modules.transformer",
        "description": "ultralytics.models.sam.modules.transformer",
        "peekOfCode": "class TwoWayTransformer(nn.Module):\n    \"\"\"\n    A Two-Way Transformer module that enables the simultaneous attention to both image and query points. This class\n    serves as a specialized transformer decoder that attends to an input image using queries whose positional embedding\n    is supplied. This is particularly useful for tasks like object detection, image segmentation, and point cloud\n    processing.\n    Attributes:\n        depth (int): The number of layers in the transformer.\n        embedding_dim (int): The channel dimension for the input embeddings.\n        num_heads (int): The number of heads for multihead attention.",
        "detail": "ultralytics.models.sam.modules.transformer",
        "documentation": {}
    },
    {
        "label": "TwoWayAttentionBlock",
        "kind": 6,
        "importPath": "ultralytics.models.sam.modules.transformer",
        "description": "ultralytics.models.sam.modules.transformer",
        "peekOfCode": "class TwoWayAttentionBlock(nn.Module):\n    \"\"\"\n    An attention block that performs both self-attention and cross-attention in two directions: queries to keys and\n    keys to queries. This block consists of four main layers: (1) self-attention on sparse inputs, (2) cross-attention\n    of sparse inputs to dense inputs, (3) an MLP block on sparse inputs, and (4) cross-attention of dense inputs to\n    sparse inputs.\n    Attributes:\n        self_attn (Attention): The self-attention layer for the queries.\n        norm1 (nn.LayerNorm): Layer normalization following the first attention block.\n        cross_attn_token_to_image (Attention): Cross-attention layer from queries to keys.",
        "detail": "ultralytics.models.sam.modules.transformer",
        "documentation": {}
    },
    {
        "label": "Attention",
        "kind": 6,
        "importPath": "ultralytics.models.sam.modules.transformer",
        "description": "ultralytics.models.sam.modules.transformer",
        "peekOfCode": "class Attention(nn.Module):\n    \"\"\"An attention layer that allows for downscaling the size of the embedding after projection to queries, keys, and\n    values.\n    \"\"\"\n    def __init__(\n        self,\n        embedding_dim: int,\n        num_heads: int,\n        downsample_rate: int = 1,\n    ) -> None:",
        "detail": "ultralytics.models.sam.modules.transformer",
        "documentation": {}
    },
    {
        "label": "is_box_near_crop_edge",
        "kind": 2,
        "importPath": "ultralytics.models.sam.amg",
        "description": "ultralytics.models.sam.amg",
        "peekOfCode": "def is_box_near_crop_edge(\n    boxes: torch.Tensor, crop_box: List[int], orig_box: List[int], atol: float = 20.0\n) -> torch.Tensor:\n    \"\"\"Return a boolean tensor indicating if boxes are near the crop edge.\"\"\"\n    crop_box_torch = torch.as_tensor(crop_box, dtype=torch.float, device=boxes.device)\n    orig_box_torch = torch.as_tensor(orig_box, dtype=torch.float, device=boxes.device)\n    boxes = uncrop_boxes_xyxy(boxes, crop_box).float()\n    near_crop_edge = torch.isclose(boxes, crop_box_torch[None, :], atol=atol, rtol=0)\n    near_image_edge = torch.isclose(boxes, orig_box_torch[None, :], atol=atol, rtol=0)\n    near_crop_edge = torch.logical_and(near_crop_edge, ~near_image_edge)",
        "detail": "ultralytics.models.sam.amg",
        "documentation": {}
    },
    {
        "label": "batch_iterator",
        "kind": 2,
        "importPath": "ultralytics.models.sam.amg",
        "description": "ultralytics.models.sam.amg",
        "peekOfCode": "def batch_iterator(batch_size: int, *args) -> Generator[List[Any], None, None]:\n    \"\"\"Yield batches of data from the input arguments.\"\"\"\n    assert args and all(len(a) == len(args[0]) for a in args), \"Batched iteration must have same-size inputs.\"\n    n_batches = len(args[0]) // batch_size + int(len(args[0]) % batch_size != 0)\n    for b in range(n_batches):\n        yield [arg[b * batch_size : (b + 1) * batch_size] for arg in args]\ndef calculate_stability_score(masks: torch.Tensor, mask_threshold: float, threshold_offset: float) -> torch.Tensor:\n    \"\"\"\n    Computes the stability score for a batch of masks.\n    The stability score is the IoU between the binary masks obtained by thresholding the predicted mask logits at high",
        "detail": "ultralytics.models.sam.amg",
        "documentation": {}
    },
    {
        "label": "calculate_stability_score",
        "kind": 2,
        "importPath": "ultralytics.models.sam.amg",
        "description": "ultralytics.models.sam.amg",
        "peekOfCode": "def calculate_stability_score(masks: torch.Tensor, mask_threshold: float, threshold_offset: float) -> torch.Tensor:\n    \"\"\"\n    Computes the stability score for a batch of masks.\n    The stability score is the IoU between the binary masks obtained by thresholding the predicted mask logits at high\n    and low values.\n    Notes:\n        - One mask is always contained inside the other.\n        - Save memory by preventing unnecessary cast to torch.int64\n    \"\"\"\n    intersections = (masks > (mask_threshold + threshold_offset)).sum(-1, dtype=torch.int16).sum(-1, dtype=torch.int32)",
        "detail": "ultralytics.models.sam.amg",
        "documentation": {}
    },
    {
        "label": "build_point_grid",
        "kind": 2,
        "importPath": "ultralytics.models.sam.amg",
        "description": "ultralytics.models.sam.amg",
        "peekOfCode": "def build_point_grid(n_per_side: int) -> np.ndarray:\n    \"\"\"Generate a 2D grid of evenly spaced points in the range [0,1]x[0,1].\"\"\"\n    offset = 1 / (2 * n_per_side)\n    points_one_side = np.linspace(offset, 1 - offset, n_per_side)\n    points_x = np.tile(points_one_side[None, :], (n_per_side, 1))\n    points_y = np.tile(points_one_side[:, None], (1, n_per_side))\n    return np.stack([points_x, points_y], axis=-1).reshape(-1, 2)\ndef build_all_layer_point_grids(n_per_side: int, n_layers: int, scale_per_layer: int) -> List[np.ndarray]:\n    \"\"\"Generate point grids for all crop layers.\"\"\"\n    return [build_point_grid(int(n_per_side / (scale_per_layer**i))) for i in range(n_layers + 1)]",
        "detail": "ultralytics.models.sam.amg",
        "documentation": {}
    },
    {
        "label": "build_all_layer_point_grids",
        "kind": 2,
        "importPath": "ultralytics.models.sam.amg",
        "description": "ultralytics.models.sam.amg",
        "peekOfCode": "def build_all_layer_point_grids(n_per_side: int, n_layers: int, scale_per_layer: int) -> List[np.ndarray]:\n    \"\"\"Generate point grids for all crop layers.\"\"\"\n    return [build_point_grid(int(n_per_side / (scale_per_layer**i))) for i in range(n_layers + 1)]\ndef generate_crop_boxes(\n    im_size: Tuple[int, ...], n_layers: int, overlap_ratio: float\n) -> Tuple[List[List[int]], List[int]]:\n    \"\"\"\n    Generates a list of crop boxes of different sizes.\n    Each layer has (2**i)**2 boxes for the ith layer.\n    \"\"\"",
        "detail": "ultralytics.models.sam.amg",
        "documentation": {}
    },
    {
        "label": "generate_crop_boxes",
        "kind": 2,
        "importPath": "ultralytics.models.sam.amg",
        "description": "ultralytics.models.sam.amg",
        "peekOfCode": "def generate_crop_boxes(\n    im_size: Tuple[int, ...], n_layers: int, overlap_ratio: float\n) -> Tuple[List[List[int]], List[int]]:\n    \"\"\"\n    Generates a list of crop boxes of different sizes.\n    Each layer has (2**i)**2 boxes for the ith layer.\n    \"\"\"\n    crop_boxes, layer_idxs = [], []\n    im_h, im_w = im_size\n    short_side = min(im_h, im_w)",
        "detail": "ultralytics.models.sam.amg",
        "documentation": {}
    },
    {
        "label": "uncrop_boxes_xyxy",
        "kind": 2,
        "importPath": "ultralytics.models.sam.amg",
        "description": "ultralytics.models.sam.amg",
        "peekOfCode": "def uncrop_boxes_xyxy(boxes: torch.Tensor, crop_box: List[int]) -> torch.Tensor:\n    \"\"\"Uncrop bounding boxes by adding the crop box offset.\"\"\"\n    x0, y0, _, _ = crop_box\n    offset = torch.tensor([[x0, y0, x0, y0]], device=boxes.device)\n    # Check if boxes has a channel dimension\n    if len(boxes.shape) == 3:\n        offset = offset.unsqueeze(1)\n    return boxes + offset\ndef uncrop_points(points: torch.Tensor, crop_box: List[int]) -> torch.Tensor:\n    \"\"\"Uncrop points by adding the crop box offset.\"\"\"",
        "detail": "ultralytics.models.sam.amg",
        "documentation": {}
    },
    {
        "label": "uncrop_points",
        "kind": 2,
        "importPath": "ultralytics.models.sam.amg",
        "description": "ultralytics.models.sam.amg",
        "peekOfCode": "def uncrop_points(points: torch.Tensor, crop_box: List[int]) -> torch.Tensor:\n    \"\"\"Uncrop points by adding the crop box offset.\"\"\"\n    x0, y0, _, _ = crop_box\n    offset = torch.tensor([[x0, y0]], device=points.device)\n    # Check if points has a channel dimension\n    if len(points.shape) == 3:\n        offset = offset.unsqueeze(1)\n    return points + offset\ndef uncrop_masks(masks: torch.Tensor, crop_box: List[int], orig_h: int, orig_w: int) -> torch.Tensor:\n    \"\"\"Uncrop masks by padding them to the original image size.\"\"\"",
        "detail": "ultralytics.models.sam.amg",
        "documentation": {}
    },
    {
        "label": "uncrop_masks",
        "kind": 2,
        "importPath": "ultralytics.models.sam.amg",
        "description": "ultralytics.models.sam.amg",
        "peekOfCode": "def uncrop_masks(masks: torch.Tensor, crop_box: List[int], orig_h: int, orig_w: int) -> torch.Tensor:\n    \"\"\"Uncrop masks by padding them to the original image size.\"\"\"\n    x0, y0, x1, y1 = crop_box\n    if x0 == 0 and y0 == 0 and x1 == orig_w and y1 == orig_h:\n        return masks\n    # Coordinate transform masks\n    pad_x, pad_y = orig_w - (x1 - x0), orig_h - (y1 - y0)\n    pad = (x0, pad_x - x0, y0, pad_y - y0)\n    return torch.nn.functional.pad(masks, pad, value=0)\ndef remove_small_regions(mask: np.ndarray, area_thresh: float, mode: str) -> Tuple[np.ndarray, bool]:",
        "detail": "ultralytics.models.sam.amg",
        "documentation": {}
    },
    {
        "label": "remove_small_regions",
        "kind": 2,
        "importPath": "ultralytics.models.sam.amg",
        "description": "ultralytics.models.sam.amg",
        "peekOfCode": "def remove_small_regions(mask: np.ndarray, area_thresh: float, mode: str) -> Tuple[np.ndarray, bool]:\n    \"\"\"Remove small disconnected regions or holes in a mask, returning the mask and a modification indicator.\"\"\"\n    import cv2  # type: ignore\n    assert mode in {\"holes\", \"islands\"}, f\"Provided mode {mode} is invalid\"\n    correct_holes = mode == \"holes\"\n    working_mask = (correct_holes ^ mask).astype(np.uint8)\n    n_labels, regions, stats, _ = cv2.connectedComponentsWithStats(working_mask, 8)\n    sizes = stats[:, -1][1:]  # Row 0 is background label\n    small_regions = [i + 1 for i, s in enumerate(sizes) if s < area_thresh]\n    if not small_regions:",
        "detail": "ultralytics.models.sam.amg",
        "documentation": {}
    },
    {
        "label": "batched_mask_to_box",
        "kind": 2,
        "importPath": "ultralytics.models.sam.amg",
        "description": "ultralytics.models.sam.amg",
        "peekOfCode": "def batched_mask_to_box(masks: torch.Tensor) -> torch.Tensor:\n    \"\"\"\n    Calculates boxes in XYXY format around masks.\n    Return [0,0,0,0] for an empty mask. For input shape C1xC2x...xHxW, the output shape is C1xC2x...x4.\n    \"\"\"\n    # torch.max below raises an error on empty inputs, just skip in this case\n    if torch.numel(masks) == 0:\n        return torch.zeros(*masks.shape[:-2], 4, device=masks.device)\n    # Normalize shape to CxHxW\n    shape = masks.shape",
        "detail": "ultralytics.models.sam.amg",
        "documentation": {}
    },
    {
        "label": "build_sam_vit_h",
        "kind": 2,
        "importPath": "ultralytics.models.sam.build",
        "description": "ultralytics.models.sam.build",
        "peekOfCode": "def build_sam_vit_h(checkpoint=None):\n    \"\"\"Build and return a Segment Anything Model (SAM) h-size model.\"\"\"\n    return _build_sam(\n        encoder_embed_dim=1280,\n        encoder_depth=32,\n        encoder_num_heads=16,\n        encoder_global_attn_indexes=[7, 15, 23, 31],\n        checkpoint=checkpoint,\n    )\ndef build_sam_vit_l(checkpoint=None):",
        "detail": "ultralytics.models.sam.build",
        "documentation": {}
    },
    {
        "label": "build_sam_vit_l",
        "kind": 2,
        "importPath": "ultralytics.models.sam.build",
        "description": "ultralytics.models.sam.build",
        "peekOfCode": "def build_sam_vit_l(checkpoint=None):\n    \"\"\"Build and return a Segment Anything Model (SAM) l-size model.\"\"\"\n    return _build_sam(\n        encoder_embed_dim=1024,\n        encoder_depth=24,\n        encoder_num_heads=16,\n        encoder_global_attn_indexes=[5, 11, 17, 23],\n        checkpoint=checkpoint,\n    )\ndef build_sam_vit_b(checkpoint=None):",
        "detail": "ultralytics.models.sam.build",
        "documentation": {}
    },
    {
        "label": "build_sam_vit_b",
        "kind": 2,
        "importPath": "ultralytics.models.sam.build",
        "description": "ultralytics.models.sam.build",
        "peekOfCode": "def build_sam_vit_b(checkpoint=None):\n    \"\"\"Build and return a Segment Anything Model (SAM) b-size model.\"\"\"\n    return _build_sam(\n        encoder_embed_dim=768,\n        encoder_depth=12,\n        encoder_num_heads=12,\n        encoder_global_attn_indexes=[2, 5, 8, 11],\n        checkpoint=checkpoint,\n    )\ndef build_mobile_sam(checkpoint=None):",
        "detail": "ultralytics.models.sam.build",
        "documentation": {}
    },
    {
        "label": "build_mobile_sam",
        "kind": 2,
        "importPath": "ultralytics.models.sam.build",
        "description": "ultralytics.models.sam.build",
        "peekOfCode": "def build_mobile_sam(checkpoint=None):\n    \"\"\"Build and return Mobile Segment Anything Model (Mobile-SAM).\"\"\"\n    return _build_sam(\n        encoder_embed_dim=[64, 128, 160, 320],\n        encoder_depth=[2, 2, 6, 2],\n        encoder_num_heads=[2, 4, 5, 10],\n        encoder_global_attn_indexes=None,\n        mobile_sam=True,\n        checkpoint=checkpoint,\n    )",
        "detail": "ultralytics.models.sam.build",
        "documentation": {}
    },
    {
        "label": "build_sam",
        "kind": 2,
        "importPath": "ultralytics.models.sam.build",
        "description": "ultralytics.models.sam.build",
        "peekOfCode": "def build_sam(ckpt=\"sam_b.pt\"):\n    \"\"\"Build a SAM model specified by ckpt.\"\"\"\n    model_builder = None\n    ckpt = str(ckpt)  # to allow Path ckpt types\n    for k in sam_model_map.keys():\n        if ckpt.endswith(k):\n            model_builder = sam_model_map.get(k)\n    if not model_builder:\n        raise FileNotFoundError(f\"{ckpt} is not a supported SAM model. Available models are: \\n {sam_model_map.keys()}\")\n    return model_builder(ckpt)",
        "detail": "ultralytics.models.sam.build",
        "documentation": {}
    },
    {
        "label": "sam_model_map",
        "kind": 5,
        "importPath": "ultralytics.models.sam.build",
        "description": "ultralytics.models.sam.build",
        "peekOfCode": "sam_model_map = {\n    \"sam_h.pt\": build_sam_vit_h,\n    \"sam_l.pt\": build_sam_vit_l,\n    \"sam_b.pt\": build_sam_vit_b,\n    \"mobile_sam.pt\": build_mobile_sam,\n}\ndef build_sam(ckpt=\"sam_b.pt\"):\n    \"\"\"Build a SAM model specified by ckpt.\"\"\"\n    model_builder = None\n    ckpt = str(ckpt)  # to allow Path ckpt types",
        "detail": "ultralytics.models.sam.build",
        "documentation": {}
    },
    {
        "label": "SAM",
        "kind": 6,
        "importPath": "ultralytics.models.sam.model",
        "description": "ultralytics.models.sam.model",
        "peekOfCode": "class SAM(Model):\n    \"\"\"\n    SAM (Segment Anything Model) interface class.\n    SAM is designed for promptable real-time image segmentation. It can be used with a variety of prompts such as\n    bounding boxes, points, or labels. The model has capabilities for zero-shot performance and is trained on the SA-1B\n    dataset.\n    \"\"\"\n    def __init__(self, model=\"sam_b.pt\") -> None:\n        \"\"\"\n        Initializes the SAM model with a pre-trained model file.",
        "detail": "ultralytics.models.sam.model",
        "documentation": {}
    },
    {
        "label": "Predictor",
        "kind": 6,
        "importPath": "ultralytics.models.sam.predict",
        "description": "ultralytics.models.sam.predict",
        "peekOfCode": "class Predictor(BasePredictor):\n    \"\"\"\n    Predictor class for the Segment Anything Model (SAM), extending BasePredictor.\n    The class provides an interface for model inference tailored to image segmentation tasks.\n    With advanced architecture and promptable segmentation capabilities, it facilitates flexible and real-time\n    mask generation. The class is capable of working with various types of prompts such as bounding boxes,\n    points, and low-resolution masks.\n    Attributes:\n        cfg (dict): Configuration dictionary specifying model and task-related parameters.\n        overrides (dict): Dictionary containing values that override the default configuration.",
        "detail": "ultralytics.models.sam.predict",
        "documentation": {}
    },
    {
        "label": "DETRLoss",
        "kind": 6,
        "importPath": "ultralytics.models.utils.loss",
        "description": "ultralytics.models.utils.loss",
        "peekOfCode": "class DETRLoss(nn.Module):\n    \"\"\"\n    DETR (DEtection TRansformer) Loss class. This class calculates and returns the different loss components for the\n    DETR object detection model. It computes classification loss, bounding box loss, GIoU loss, and optionally auxiliary\n    losses.\n    Attributes:\n        nc (int): The number of classes.\n        loss_gain (dict): Coefficients for different loss components.\n        aux_loss (bool): Whether to compute auxiliary losses.\n        use_fl (bool): Use FocalLoss or not.",
        "detail": "ultralytics.models.utils.loss",
        "documentation": {}
    },
    {
        "label": "RTDETRDetectionLoss",
        "kind": 6,
        "importPath": "ultralytics.models.utils.loss",
        "description": "ultralytics.models.utils.loss",
        "peekOfCode": "class RTDETRDetectionLoss(DETRLoss):\n    \"\"\"\n    Real-Time DeepTracker (RT-DETR) Detection Loss class that extends the DETRLoss.\n    This class computes the detection loss for the RT-DETR model, which includes the standard detection loss as well as\n    an additional denoising training loss when provided with denoising metadata.\n    \"\"\"\n    def forward(self, preds, batch, dn_bboxes=None, dn_scores=None, dn_meta=None):\n        \"\"\"\n        Forward pass to compute the detection loss.\n        Args:",
        "detail": "ultralytics.models.utils.loss",
        "documentation": {}
    },
    {
        "label": "HungarianMatcher",
        "kind": 6,
        "importPath": "ultralytics.models.utils.ops",
        "description": "ultralytics.models.utils.ops",
        "peekOfCode": "class HungarianMatcher(nn.Module):\n    \"\"\"\n    A module implementing the HungarianMatcher, which is a differentiable module to solve the assignment problem in an\n    end-to-end fashion.\n    HungarianMatcher performs optimal assignment over the predicted and ground truth bounding boxes using a cost\n    function that considers classification scores, bounding box coordinates, and optionally, mask predictions.\n    Attributes:\n        cost_gain (dict): Dictionary of cost coefficients: 'class', 'bbox', 'giou', 'mask', and 'dice'.\n        use_fl (bool): Indicates whether to use Focal Loss for the classification cost calculation.\n        with_mask (bool): Indicates whether the model makes mask predictions.",
        "detail": "ultralytics.models.utils.ops",
        "documentation": {}
    },
    {
        "label": "get_cdn_group",
        "kind": 2,
        "importPath": "ultralytics.models.utils.ops",
        "description": "ultralytics.models.utils.ops",
        "peekOfCode": "def get_cdn_group(\n    batch, num_classes, num_queries, class_embed, num_dn=100, cls_noise_ratio=0.5, box_noise_scale=1.0, training=False\n):\n    \"\"\"\n    Get contrastive denoising training group. This function creates a contrastive denoising training group with positive\n    and negative samples from the ground truths (gt). It applies noise to the class labels and bounding box coordinates,\n    and returns the modified labels, bounding boxes, attention mask and meta information.\n    Args:\n        batch (dict): A dict that includes 'gt_cls' (torch.Tensor with shape [num_gts, ]), 'gt_bboxes'\n            (torch.Tensor with shape [num_gts, 4]), 'gt_groups' (List(int)) which is a list of batch size length",
        "detail": "ultralytics.models.utils.ops",
        "documentation": {}
    },
    {
        "label": "ClassificationPredictor",
        "kind": 6,
        "importPath": "ultralytics.models.yolo.classify.predict",
        "description": "ultralytics.models.yolo.classify.predict",
        "peekOfCode": "class ClassificationPredictor(BasePredictor):\n    \"\"\"\n    A class extending the BasePredictor class for prediction based on a classification model.\n    Notes:\n        - Torchvision classification models can also be passed to the 'model' argument, i.e. model='resnet18'.\n    Example:\n        ```python\n        from ultralytics.utils import ASSETS\n        from ultralytics.models.yolo.classify import ClassificationPredictor\n        args = dict(model='yolov8n-cls.pt', source=ASSETS)",
        "detail": "ultralytics.models.yolo.classify.predict",
        "documentation": {}
    },
    {
        "label": "ClassificationTrainer",
        "kind": 6,
        "importPath": "ultralytics.models.yolo.classify.train",
        "description": "ultralytics.models.yolo.classify.train",
        "peekOfCode": "class ClassificationTrainer(BaseTrainer):\n    \"\"\"\n    A class extending the BaseTrainer class for training based on a classification model.\n    Notes:\n        - Torchvision classification models can also be passed to the 'model' argument, i.e. model='resnet18'.\n    Example:\n        ```python\n        from ultralytics.models.yolo.classify import ClassificationTrainer\n        args = dict(model='yolov8n-cls.pt', data='imagenet10', epochs=3)\n        trainer = ClassificationTrainer(overrides=args)",
        "detail": "ultralytics.models.yolo.classify.train",
        "documentation": {}
    },
    {
        "label": "ClassificationValidator",
        "kind": 6,
        "importPath": "ultralytics.models.yolo.classify.val",
        "description": "ultralytics.models.yolo.classify.val",
        "peekOfCode": "class ClassificationValidator(BaseValidator):\n    \"\"\"\n    A class extending the BaseValidator class for validation based on a classification model.\n    Notes:\n        - Torchvision classification models can also be passed to the 'model' argument, i.e. model='resnet18'.\n    Example:\n        ```python\n        from ultralytics.models.yolo.classify import ClassificationValidator\n        args = dict(model='yolov8n-cls.pt', data='imagenet10')\n        validator = ClassificationValidator(args=args)",
        "detail": "ultralytics.models.yolo.classify.val",
        "documentation": {}
    },
    {
        "label": "DetectionPredictor",
        "kind": 6,
        "importPath": "ultralytics.models.yolo.detect.predict",
        "description": "ultralytics.models.yolo.detect.predict",
        "peekOfCode": "class DetectionPredictor(BasePredictor):\n    \"\"\"\n    A class extending the BasePredictor class for prediction based on a detection model.\n    Example:\n        ```python\n        from ultralytics.utils import ASSETS\n        from ultralytics.models.yolo.detect import DetectionPredictor\n        args = dict(model='yolov8n.pt', source=ASSETS)\n        predictor = DetectionPredictor(overrides=args)\n        predictor.predict_cli()",
        "detail": "ultralytics.models.yolo.detect.predict",
        "documentation": {}
    },
    {
        "label": "DetectionTrainer",
        "kind": 6,
        "importPath": "ultralytics.models.yolo.detect.train",
        "description": "ultralytics.models.yolo.detect.train",
        "peekOfCode": "class DetectionTrainer(BaseTrainer):\n    \"\"\"\n    A class extending the BaseTrainer class for training based on a detection model.\n    Example:\n        ```python\n        from ultralytics.models.yolo.detect import DetectionTrainer\n        args = dict(model='yolov8n.pt', data='coco8.yaml', epochs=3)\n        trainer = DetectionTrainer(overrides=args)\n        trainer.train()\n        ```",
        "detail": "ultralytics.models.yolo.detect.train",
        "documentation": {}
    },
    {
        "label": "DetectionValidator",
        "kind": 6,
        "importPath": "ultralytics.models.yolo.detect.val",
        "description": "ultralytics.models.yolo.detect.val",
        "peekOfCode": "class DetectionValidator(BaseValidator):\n    \"\"\"\n    A class extending the BaseValidator class for validation based on a detection model.\n    Example:\n        ```python\n        from ultralytics.models.yolo.detect import DetectionValidator\n        args = dict(model='yolov8n.pt', data='coco8.yaml')\n        validator = DetectionValidator(args=args)\n        validator()\n        ```",
        "detail": "ultralytics.models.yolo.detect.val",
        "documentation": {}
    },
    {
        "label": "OBBPredictor",
        "kind": 6,
        "importPath": "ultralytics.models.yolo.obb.predict",
        "description": "ultralytics.models.yolo.obb.predict",
        "peekOfCode": "class OBBPredictor(DetectionPredictor):\n    \"\"\"\n    A class extending the DetectionPredictor class for prediction based on an Oriented Bounding Box (OBB) model.\n    Example:\n        ```python\n        from ultralytics.utils import ASSETS\n        from ultralytics.models.yolo.obb import OBBPredictor\n        args = dict(model='yolov8n-obb.pt', source=ASSETS)\n        predictor = OBBPredictor(overrides=args)\n        predictor.predict_cli()",
        "detail": "ultralytics.models.yolo.obb.predict",
        "documentation": {}
    },
    {
        "label": "OBBTrainer",
        "kind": 6,
        "importPath": "ultralytics.models.yolo.obb.train",
        "description": "ultralytics.models.yolo.obb.train",
        "peekOfCode": "class OBBTrainer(yolo.detect.DetectionTrainer):\n    \"\"\"\n    A class extending the DetectionTrainer class for training based on an Oriented Bounding Box (OBB) model.\n    Example:\n        ```python\n        from ultralytics.models.yolo.obb import OBBTrainer\n        args = dict(model='yolov8n-obb.pt', data='dota8.yaml', epochs=3)\n        trainer = OBBTrainer(overrides=args)\n        trainer.train()\n        ```",
        "detail": "ultralytics.models.yolo.obb.train",
        "documentation": {}
    },
    {
        "label": "OBBValidator",
        "kind": 6,
        "importPath": "ultralytics.models.yolo.obb.val",
        "description": "ultralytics.models.yolo.obb.val",
        "peekOfCode": "class OBBValidator(DetectionValidator):\n    \"\"\"\n    A class extending the DetectionValidator class for validation based on an Oriented Bounding Box (OBB) model.\n    Example:\n        ```python\n        from ultralytics.models.yolo.obb import OBBValidator\n        args = dict(model='yolov8n-obb.pt', data='dota8.yaml')\n        validator = OBBValidator(args=args)\n        validator(model=args['model'])\n        ```",
        "detail": "ultralytics.models.yolo.obb.val",
        "documentation": {}
    },
    {
        "label": "PosePredictor",
        "kind": 6,
        "importPath": "ultralytics.models.yolo.pose.predict",
        "description": "ultralytics.models.yolo.pose.predict",
        "peekOfCode": "class PosePredictor(DetectionPredictor):\n    \"\"\"\n    A class extending the DetectionPredictor class for prediction based on a pose model.\n    Example:\n        ```python\n        from ultralytics.utils import ASSETS\n        from ultralytics.models.yolo.pose import PosePredictor\n        args = dict(model='yolov8n-pose.pt', source=ASSETS)\n        predictor = PosePredictor(overrides=args)\n        predictor.predict_cli()",
        "detail": "ultralytics.models.yolo.pose.predict",
        "documentation": {}
    },
    {
        "label": "PoseTrainer",
        "kind": 6,
        "importPath": "ultralytics.models.yolo.pose.train",
        "description": "ultralytics.models.yolo.pose.train",
        "peekOfCode": "class PoseTrainer(yolo.detect.DetectionTrainer):\n    \"\"\"\n    A class extending the DetectionTrainer class for training based on a pose model.\n    Example:\n        ```python\n        from ultralytics.models.yolo.pose import PoseTrainer\n        args = dict(model='yolov8n-pose.pt', data='coco8-pose.yaml', epochs=3)\n        trainer = PoseTrainer(overrides=args)\n        trainer.train()\n        ```",
        "detail": "ultralytics.models.yolo.pose.train",
        "documentation": {}
    },
    {
        "label": "PoseValidator",
        "kind": 6,
        "importPath": "ultralytics.models.yolo.pose.val",
        "description": "ultralytics.models.yolo.pose.val",
        "peekOfCode": "class PoseValidator(DetectionValidator):\n    \"\"\"\n    A class extending the DetectionValidator class for validation based on a pose model.\n    Example:\n        ```python\n        from ultralytics.models.yolo.pose import PoseValidator\n        args = dict(model='yolov8n-pose.pt', data='coco8-pose.yaml')\n        validator = PoseValidator(args=args)\n        validator()\n        ```",
        "detail": "ultralytics.models.yolo.pose.val",
        "documentation": {}
    },
    {
        "label": "SegmentationPredictor",
        "kind": 6,
        "importPath": "ultralytics.models.yolo.segment.predict",
        "description": "ultralytics.models.yolo.segment.predict",
        "peekOfCode": "class SegmentationPredictor(DetectionPredictor):\n    \"\"\"\n    A class extending the DetectionPredictor class for prediction based on a segmentation model.\n    Example:\n        ```python\n        from ultralytics.utils import ASSETS\n        from ultralytics.models.yolo.segment import SegmentationPredictor\n        args = dict(model='yolov8n-seg.pt', source=ASSETS)\n        predictor = SegmentationPredictor(overrides=args)\n        predictor.predict_cli()",
        "detail": "ultralytics.models.yolo.segment.predict",
        "documentation": {}
    },
    {
        "label": "SegmentationTrainer",
        "kind": 6,
        "importPath": "ultralytics.models.yolo.segment.train",
        "description": "ultralytics.models.yolo.segment.train",
        "peekOfCode": "class SegmentationTrainer(yolo.detect.DetectionTrainer):\n    \"\"\"\n    A class extending the DetectionTrainer class for training based on a segmentation model.\n    Example:\n        ```python\n        from ultralytics.models.yolo.segment import SegmentationTrainer\n        args = dict(model='yolov8n-seg.pt', data='coco8-seg.yaml', epochs=3)\n        trainer = SegmentationTrainer(overrides=args)\n        trainer.train()\n        ```",
        "detail": "ultralytics.models.yolo.segment.train",
        "documentation": {}
    },
    {
        "label": "SegmentationValidator",
        "kind": 6,
        "importPath": "ultralytics.models.yolo.segment.val",
        "description": "ultralytics.models.yolo.segment.val",
        "peekOfCode": "class SegmentationValidator(DetectionValidator):\n    \"\"\"\n    A class extending the DetectionValidator class for validation based on a segmentation model.\n    Example:\n        ```python\n        from ultralytics.models.yolo.segment import SegmentationValidator\n        args = dict(model='yolov8n-seg.pt', data='coco8-seg.yaml')\n        validator = SegmentationValidator(args=args)\n        validator()\n        ```",
        "detail": "ultralytics.models.yolo.segment.val",
        "documentation": {}
    },
    {
        "label": "WorldTrainer",
        "kind": 6,
        "importPath": "ultralytics.models.yolo.world.train",
        "description": "ultralytics.models.yolo.world.train",
        "peekOfCode": "class WorldTrainer(yolo.detect.DetectionTrainer):\n    \"\"\"\n    A class to fine-tune a world model on a close-set dataset.\n    Example:\n        ```python\n        from ultralytics.models.yolo.world import WorldModel\n        args = dict(model='yolov8s-world.pt', data='coco8.yaml', epochs=3)\n        trainer = WorldTrainer(overrides=args)\n        trainer.train()\n        ```",
        "detail": "ultralytics.models.yolo.world.train",
        "documentation": {}
    },
    {
        "label": "on_pretrain_routine_end",
        "kind": 2,
        "importPath": "ultralytics.models.yolo.world.train",
        "description": "ultralytics.models.yolo.world.train",
        "peekOfCode": "def on_pretrain_routine_end(trainer):\n    \"\"\"Callback.\"\"\"\n    if RANK in {-1, 0}:\n        # NOTE: for evaluation\n        names = [name.split(\"/\")[0] for name in list(trainer.test_loader.dataset.data[\"names\"].values())]\n        de_parallel(trainer.ema.ema).set_classes(names, cache_clip_model=False)\n    device = next(trainer.model.parameters()).device\n    trainer.text_model, _ = trainer.clip.load(\"ViT-B/32\", device=device)\n    for p in trainer.text_model.parameters():\n        p.requires_grad_(False)",
        "detail": "ultralytics.models.yolo.world.train",
        "documentation": {}
    },
    {
        "label": "WorldTrainerFromScratch",
        "kind": 6,
        "importPath": "ultralytics.models.yolo.world.train_world",
        "description": "ultralytics.models.yolo.world.train_world",
        "peekOfCode": "class WorldTrainerFromScratch(WorldTrainer):\n    \"\"\"\n    A class extending the WorldTrainer class for training a world model from scratch on open-set dataset.\n    Example:\n        ```python\n        from ultralytics.models.yolo.world.train_world import WorldTrainerFromScratch\n        from ultralytics import YOLOWorld\n        data = dict(\n            train=dict(\n                yolo_data=[\"Objects365.yaml\"],",
        "detail": "ultralytics.models.yolo.world.train_world",
        "documentation": {}
    },
    {
        "label": "YOLO",
        "kind": 6,
        "importPath": "ultralytics.models.yolo.model",
        "description": "ultralytics.models.yolo.model",
        "peekOfCode": "class YOLO(Model):\n    \"\"\"YOLO (You Only Look Once) object detection model.\"\"\"\n    def __init__(self, model=\"yolov8n.pt\", task=None, verbose=False):\n        \"\"\"Initialize YOLO model, switching to YOLOWorld if model filename contains '-world'.\"\"\"\n        path = Path(model)\n        if \"-world\" in path.stem and path.suffix in {\".pt\", \".yaml\", \".yml\"}:  # if YOLOWorld PyTorch model\n            new_instance = YOLOWorld(path, verbose=verbose)\n            self.__class__ = type(new_instance)\n            self.__dict__ = new_instance.__dict__\n        else:",
        "detail": "ultralytics.models.yolo.model",
        "documentation": {}
    },
    {
        "label": "YOLOWorld",
        "kind": 6,
        "importPath": "ultralytics.models.yolo.model",
        "description": "ultralytics.models.yolo.model",
        "peekOfCode": "class YOLOWorld(Model):\n    \"\"\"YOLO-World object detection model.\"\"\"\n    def __init__(self, model=\"yolov8s-world.pt\", verbose=False) -> None:\n        \"\"\"\n        Initializes the YOLOv8-World model with the given pre-trained model file. Supports *.pt and *.yaml formats.\n        Args:\n            model (str | Path): Path to the pre-trained model. Defaults to 'yolov8s-world.pt'.\n        \"\"\"\n        super().__init__(model=model, task=\"detect\", verbose=verbose)\n        # Assign default COCO class names when there are no custom names",
        "detail": "ultralytics.models.yolo.model",
        "documentation": {}
    },
    {
        "label": "DFL",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.block",
        "description": "ultralytics.nn.modules.block",
        "peekOfCode": "class DFL(nn.Module):\n    \"\"\"\n    Integral module of Distribution Focal Loss (DFL).\n    Proposed in Generalized Focal Loss https://ieeexplore.ieee.org/document/9792391\n    \"\"\"\n    def __init__(self, c1=16):\n        \"\"\"Initialize a convolutional layer with a given number of input channels.\"\"\"\n        super().__init__()\n        self.conv = nn.Conv2d(c1, 1, 1, bias=False).requires_grad_(False)\n        x = torch.arange(c1, dtype=torch.float)",
        "detail": "ultralytics.nn.modules.block",
        "documentation": {}
    },
    {
        "label": "Proto",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.block",
        "description": "ultralytics.nn.modules.block",
        "peekOfCode": "class Proto(nn.Module):\n    \"\"\"YOLOv8 mask Proto module for segmentation models.\"\"\"\n    def __init__(self, c1, c_=256, c2=32):\n        \"\"\"\n        Initializes the YOLOv8 mask Proto module with specified number of protos and masks.\n        Input arguments are ch_in, number of protos, number of masks.\n        \"\"\"\n        super().__init__()\n        self.cv1 = Conv(c1, c_, k=3)\n        self.upsample = nn.ConvTranspose2d(c_, c_, 2, 2, 0, bias=True)  # nn.Upsample(scale_factor=2, mode='nearest')",
        "detail": "ultralytics.nn.modules.block",
        "documentation": {}
    },
    {
        "label": "HGStem",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.block",
        "description": "ultralytics.nn.modules.block",
        "peekOfCode": "class HGStem(nn.Module):\n    \"\"\"\n    StemBlock of PPHGNetV2 with 5 convolutions and one maxpool2d.\n    https://github.com/PaddlePaddle/PaddleDetection/blob/develop/ppdet/modeling/backbones/hgnet_v2.py\n    \"\"\"\n    def __init__(self, c1, cm, c2):\n        \"\"\"Initialize the SPP layer with input/output channels and specified kernel sizes for max pooling.\"\"\"\n        super().__init__()\n        self.stem1 = Conv(c1, cm, 3, 2, act=nn.ReLU())\n        self.stem2a = Conv(cm, cm // 2, 2, 1, 0, act=nn.ReLU())",
        "detail": "ultralytics.nn.modules.block",
        "documentation": {}
    },
    {
        "label": "HGBlock",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.block",
        "description": "ultralytics.nn.modules.block",
        "peekOfCode": "class HGBlock(nn.Module):\n    \"\"\"\n    HG_Block of PPHGNetV2 with 2 convolutions and LightConv.\n    https://github.com/PaddlePaddle/PaddleDetection/blob/develop/ppdet/modeling/backbones/hgnet_v2.py\n    \"\"\"\n    def __init__(self, c1, cm, c2, k=3, n=6, lightconv=False, shortcut=False, act=nn.ReLU()):\n        \"\"\"Initializes a CSP Bottleneck with 1 convolution using specified input and output channels.\"\"\"\n        super().__init__()\n        block = LightConv if lightconv else Conv\n        self.m = nn.ModuleList(block(c1 if i == 0 else cm, cm, k=k, act=act) for i in range(n))",
        "detail": "ultralytics.nn.modules.block",
        "documentation": {}
    },
    {
        "label": "SPP",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.block",
        "description": "ultralytics.nn.modules.block",
        "peekOfCode": "class SPP(nn.Module):\n    \"\"\"Spatial Pyramid Pooling (SPP) layer https://arxiv.org/abs/1406.4729.\"\"\"\n    def __init__(self, c1, c2, k=(5, 9, 13)):\n        \"\"\"Initialize the SPP layer with input/output channels and pooling kernel sizes.\"\"\"\n        super().__init__()\n        c_ = c1 // 2  # hidden channels\n        self.cv1 = Conv(c1, c_, 1, 1)\n        self.cv2 = Conv(c_ * (len(k) + 1), c2, 1, 1)\n        self.m = nn.ModuleList([nn.MaxPool2d(kernel_size=x, stride=1, padding=x // 2) for x in k])\n    def forward(self, x):",
        "detail": "ultralytics.nn.modules.block",
        "documentation": {}
    },
    {
        "label": "SPPF",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.block",
        "description": "ultralytics.nn.modules.block",
        "peekOfCode": "class SPPF(nn.Module):\n    \"\"\"Spatial Pyramid Pooling - Fast (SPPF) layer for YOLOv5 by Glenn Jocher.\"\"\"\n    def __init__(self, c1, c2, k=5):\n        \"\"\"\n        Initializes the SPPF layer with given input/output channels and kernel size.\n        This module is equivalent to SPP(k=(5, 9, 13)).\n        \"\"\"\n        super().__init__()\n        c_ = c1 // 2  # hidden channels\n        self.cv1 = Conv(c1, c_, 1, 1)",
        "detail": "ultralytics.nn.modules.block",
        "documentation": {}
    },
    {
        "label": "C1",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.block",
        "description": "ultralytics.nn.modules.block",
        "peekOfCode": "class C1(nn.Module):\n    \"\"\"CSP Bottleneck with 1 convolution.\"\"\"\n    def __init__(self, c1, c2, n=1):\n        \"\"\"Initializes the CSP Bottleneck with configurations for 1 convolution with arguments ch_in, ch_out, number.\"\"\"\n        super().__init__()\n        self.cv1 = Conv(c1, c2, 1, 1)\n        self.m = nn.Sequential(*(Conv(c2, c2, 3) for _ in range(n)))\n    def forward(self, x):\n        \"\"\"Applies cross-convolutions to input in the C3 module.\"\"\"\n        y = self.cv1(x)",
        "detail": "ultralytics.nn.modules.block",
        "documentation": {}
    },
    {
        "label": "C2",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.block",
        "description": "ultralytics.nn.modules.block",
        "peekOfCode": "class C2(nn.Module):\n    \"\"\"CSP Bottleneck with 2 convolutions.\"\"\"\n    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):\n        \"\"\"Initializes the CSP Bottleneck with 2 convolutions module with arguments ch_in, ch_out, number, shortcut,\n        groups, expansion.\n        \"\"\"\n        super().__init__()\n        self.c = int(c2 * e)  # hidden channels\n        self.cv1 = Conv(c1, 2 * self.c, 1, 1)\n        self.cv2 = Conv(2 * self.c, c2, 1)  # optional act=FReLU(c2)",
        "detail": "ultralytics.nn.modules.block",
        "documentation": {}
    },
    {
        "label": "C2f",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.block",
        "description": "ultralytics.nn.modules.block",
        "peekOfCode": "class C2f(nn.Module):\n    \"\"\"Faster Implementation of CSP Bottleneck with 2 convolutions.\"\"\"\n    def __init__(self, c1, c2, n=1, shortcut=False, g=1, e=0.5):\n        \"\"\"Initialize CSP bottleneck layer with two convolutions with arguments ch_in, ch_out, number, shortcut, groups,\n        expansion.\n        \"\"\"\n        super().__init__()\n        self.c = int(c2 * e)  # hidden channels\n        self.cv1 = Conv(c1, 2 * self.c, 1, 1)\n        self.cv2 = Conv((2 + n) * self.c, c2, 1)  # optional act=FReLU(c2)",
        "detail": "ultralytics.nn.modules.block",
        "documentation": {}
    },
    {
        "label": "C3",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.block",
        "description": "ultralytics.nn.modules.block",
        "peekOfCode": "class C3(nn.Module):\n    \"\"\"CSP Bottleneck with 3 convolutions.\"\"\"\n    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):\n        \"\"\"Initialize the CSP Bottleneck with given channels, number, shortcut, groups, and expansion values.\"\"\"\n        super().__init__()\n        c_ = int(c2 * e)  # hidden channels\n        self.cv1 = Conv(c1, c_, 1, 1)\n        self.cv2 = Conv(c1, c_, 1, 1)\n        self.cv3 = Conv(2 * c_, c2, 1)  # optional act=FReLU(c2)\n        self.m = nn.Sequential(*(Bottleneck(c_, c_, shortcut, g, k=((1, 1), (3, 3)), e=1.0) for _ in range(n)))",
        "detail": "ultralytics.nn.modules.block",
        "documentation": {}
    },
    {
        "label": "C3x",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.block",
        "description": "ultralytics.nn.modules.block",
        "peekOfCode": "class C3x(C3):\n    \"\"\"C3 module with cross-convolutions.\"\"\"\n    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):\n        \"\"\"Initialize C3TR instance and set default parameters.\"\"\"\n        super().__init__(c1, c2, n, shortcut, g, e)\n        self.c_ = int(c2 * e)\n        self.m = nn.Sequential(*(Bottleneck(self.c_, self.c_, shortcut, g, k=((1, 3), (3, 1)), e=1) for _ in range(n)))\nclass RepC3(nn.Module):\n    \"\"\"Rep C3.\"\"\"\n    def __init__(self, c1, c2, n=3, e=1.0):",
        "detail": "ultralytics.nn.modules.block",
        "documentation": {}
    },
    {
        "label": "RepC3",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.block",
        "description": "ultralytics.nn.modules.block",
        "peekOfCode": "class RepC3(nn.Module):\n    \"\"\"Rep C3.\"\"\"\n    def __init__(self, c1, c2, n=3, e=1.0):\n        \"\"\"Initialize CSP Bottleneck with a single convolution using input channels, output channels, and number.\"\"\"\n        super().__init__()\n        c_ = int(c2 * e)  # hidden channels\n        self.cv1 = Conv(c1, c2, 1, 1)\n        self.cv2 = Conv(c1, c2, 1, 1)\n        self.m = nn.Sequential(*[RepConv(c_, c_) for _ in range(n)])\n        self.cv3 = Conv(c_, c2, 1, 1) if c_ != c2 else nn.Identity()",
        "detail": "ultralytics.nn.modules.block",
        "documentation": {}
    },
    {
        "label": "C3TR",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.block",
        "description": "ultralytics.nn.modules.block",
        "peekOfCode": "class C3TR(C3):\n    \"\"\"C3 module with TransformerBlock().\"\"\"\n    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):\n        \"\"\"Initialize C3Ghost module with GhostBottleneck().\"\"\"\n        super().__init__(c1, c2, n, shortcut, g, e)\n        c_ = int(c2 * e)\n        self.m = TransformerBlock(c_, c_, 4, n)\nclass C3Ghost(C3):\n    \"\"\"C3 module with GhostBottleneck().\"\"\"\n    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):",
        "detail": "ultralytics.nn.modules.block",
        "documentation": {}
    },
    {
        "label": "C3Ghost",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.block",
        "description": "ultralytics.nn.modules.block",
        "peekOfCode": "class C3Ghost(C3):\n    \"\"\"C3 module with GhostBottleneck().\"\"\"\n    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):\n        \"\"\"Initialize 'SPP' module with various pooling sizes for spatial pyramid pooling.\"\"\"\n        super().__init__(c1, c2, n, shortcut, g, e)\n        c_ = int(c2 * e)  # hidden channels\n        self.m = nn.Sequential(*(GhostBottleneck(c_, c_) for _ in range(n)))\nclass GhostBottleneck(nn.Module):\n    \"\"\"Ghost Bottleneck https://github.com/huawei-noah/ghostnet.\"\"\"\n    def __init__(self, c1, c2, k=3, s=1):",
        "detail": "ultralytics.nn.modules.block",
        "documentation": {}
    },
    {
        "label": "GhostBottleneck",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.block",
        "description": "ultralytics.nn.modules.block",
        "peekOfCode": "class GhostBottleneck(nn.Module):\n    \"\"\"Ghost Bottleneck https://github.com/huawei-noah/ghostnet.\"\"\"\n    def __init__(self, c1, c2, k=3, s=1):\n        \"\"\"Initializes GhostBottleneck module with arguments ch_in, ch_out, kernel, stride.\"\"\"\n        super().__init__()\n        c_ = c2 // 2\n        self.conv = nn.Sequential(\n            GhostConv(c1, c_, 1, 1),  # pw\n            DWConv(c_, c_, k, s, act=False) if s == 2 else nn.Identity(),  # dw\n            GhostConv(c_, c2, 1, 1, act=False),  # pw-linear",
        "detail": "ultralytics.nn.modules.block",
        "documentation": {}
    },
    {
        "label": "Bottleneck",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.block",
        "description": "ultralytics.nn.modules.block",
        "peekOfCode": "class Bottleneck(nn.Module):\n    \"\"\"Standard bottleneck.\"\"\"\n    def __init__(self, c1, c2, shortcut=True, g=1, k=(3, 3), e=0.5):\n        \"\"\"Initializes a bottleneck module with given input/output channels, shortcut option, group, kernels, and\n        expansion.\n        \"\"\"\n        super().__init__()\n        c_ = int(c2 * e)  # hidden channels\n        self.cv1 = Conv(c1, c_, k[0], 1)\n        self.cv2 = Conv(c_, c2, k[1], 1, g=g)",
        "detail": "ultralytics.nn.modules.block",
        "documentation": {}
    },
    {
        "label": "BottleneckCSP",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.block",
        "description": "ultralytics.nn.modules.block",
        "peekOfCode": "class BottleneckCSP(nn.Module):\n    \"\"\"CSP Bottleneck https://github.com/WongKinYiu/CrossStagePartialNetworks.\"\"\"\n    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):\n        \"\"\"Initializes the CSP Bottleneck given arguments for ch_in, ch_out, number, shortcut, groups, expansion.\"\"\"\n        super().__init__()\n        c_ = int(c2 * e)  # hidden channels\n        self.cv1 = Conv(c1, c_, 1, 1)\n        self.cv2 = nn.Conv2d(c1, c_, 1, 1, bias=False)\n        self.cv3 = nn.Conv2d(c_, c_, 1, 1, bias=False)\n        self.cv4 = Conv(2 * c_, c2, 1, 1)",
        "detail": "ultralytics.nn.modules.block",
        "documentation": {}
    },
    {
        "label": "ResNetBlock",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.block",
        "description": "ultralytics.nn.modules.block",
        "peekOfCode": "class ResNetBlock(nn.Module):\n    \"\"\"ResNet block with standard convolution layers.\"\"\"\n    def __init__(self, c1, c2, s=1, e=4):\n        \"\"\"Initialize convolution with given parameters.\"\"\"\n        super().__init__()\n        c3 = e * c2\n        self.cv1 = Conv(c1, c2, k=1, s=1, act=True)\n        self.cv2 = Conv(c2, c2, k=3, s=s, p=1, act=True)\n        self.cv3 = Conv(c2, c3, k=1, act=False)\n        self.shortcut = nn.Sequential(Conv(c1, c3, k=1, s=s, act=False)) if s != 1 or c1 != c3 else nn.Identity()",
        "detail": "ultralytics.nn.modules.block",
        "documentation": {}
    },
    {
        "label": "ResNetLayer",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.block",
        "description": "ultralytics.nn.modules.block",
        "peekOfCode": "class ResNetLayer(nn.Module):\n    \"\"\"ResNet layer with multiple ResNet blocks.\"\"\"\n    def __init__(self, c1, c2, s=1, is_first=False, n=1, e=4):\n        \"\"\"Initializes the ResNetLayer given arguments.\"\"\"\n        super().__init__()\n        self.is_first = is_first\n        if self.is_first:\n            self.layer = nn.Sequential(\n                Conv(c1, c2, k=7, s=2, p=3, act=True), nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n            )",
        "detail": "ultralytics.nn.modules.block",
        "documentation": {}
    },
    {
        "label": "MaxSigmoidAttnBlock",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.block",
        "description": "ultralytics.nn.modules.block",
        "peekOfCode": "class MaxSigmoidAttnBlock(nn.Module):\n    \"\"\"Max Sigmoid attention block.\"\"\"\n    def __init__(self, c1, c2, nh=1, ec=128, gc=512, scale=False):\n        \"\"\"Initializes MaxSigmoidAttnBlock with specified arguments.\"\"\"\n        super().__init__()\n        self.nh = nh\n        self.hc = c2 // nh\n        self.ec = Conv(c1, ec, k=1, act=False) if c1 != ec else None\n        self.gl = nn.Linear(gc, ec)\n        self.bias = nn.Parameter(torch.zeros(nh))",
        "detail": "ultralytics.nn.modules.block",
        "documentation": {}
    },
    {
        "label": "C2fAttn",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.block",
        "description": "ultralytics.nn.modules.block",
        "peekOfCode": "class C2fAttn(nn.Module):\n    \"\"\"C2f module with an additional attn module.\"\"\"\n    def __init__(self, c1, c2, n=1, ec=128, nh=1, gc=512, shortcut=False, g=1, e=0.5):\n        \"\"\"Initialize CSP bottleneck layer with two convolutions with arguments ch_in, ch_out, number, shortcut, groups,\n        expansion.\n        \"\"\"\n        super().__init__()\n        self.c = int(c2 * e)  # hidden channels\n        self.cv1 = Conv(c1, 2 * self.c, 1, 1)\n        self.cv2 = Conv((3 + n) * self.c, c2, 1)  # optional act=FReLU(c2)",
        "detail": "ultralytics.nn.modules.block",
        "documentation": {}
    },
    {
        "label": "ImagePoolingAttn",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.block",
        "description": "ultralytics.nn.modules.block",
        "peekOfCode": "class ImagePoolingAttn(nn.Module):\n    \"\"\"ImagePoolingAttn: Enhance the text embeddings with image-aware information.\"\"\"\n    def __init__(self, ec=256, ch=(), ct=512, nh=8, k=3, scale=False):\n        \"\"\"Initializes ImagePoolingAttn with specified arguments.\"\"\"\n        super().__init__()\n        nf = len(ch)\n        self.query = nn.Sequential(nn.LayerNorm(ct), nn.Linear(ct, ec))\n        self.key = nn.Sequential(nn.LayerNorm(ec), nn.Linear(ec, ec))\n        self.value = nn.Sequential(nn.LayerNorm(ec), nn.Linear(ec, ec))\n        self.proj = nn.Linear(ec, ct)",
        "detail": "ultralytics.nn.modules.block",
        "documentation": {}
    },
    {
        "label": "ContrastiveHead",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.block",
        "description": "ultralytics.nn.modules.block",
        "peekOfCode": "class ContrastiveHead(nn.Module):\n    \"\"\"Contrastive Head for YOLO-World compute the region-text scores according to the similarity between image and text\n    features.\n    \"\"\"\n    def __init__(self):\n        \"\"\"Initializes ContrastiveHead with specified region-text similarity parameters.\"\"\"\n        super().__init__()\n        # NOTE: use -10.0 to keep the init cls loss consistency with other losses\n        self.bias = nn.Parameter(torch.tensor([-10.0]))\n        self.logit_scale = nn.Parameter(torch.ones([]) * torch.tensor(1 / 0.07).log())",
        "detail": "ultralytics.nn.modules.block",
        "documentation": {}
    },
    {
        "label": "BNContrastiveHead",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.block",
        "description": "ultralytics.nn.modules.block",
        "peekOfCode": "class BNContrastiveHead(nn.Module):\n    \"\"\"\n    Batch Norm Contrastive Head for YOLO-World using batch norm instead of l2-normalization.\n    Args:\n        embed_dims (int): Embed dimensions of text and image features.\n    \"\"\"\n    def __init__(self, embed_dims: int):\n        \"\"\"Initialize ContrastiveHead with region-text similarity parameters.\"\"\"\n        super().__init__()\n        self.norm = nn.BatchNorm2d(embed_dims)",
        "detail": "ultralytics.nn.modules.block",
        "documentation": {}
    },
    {
        "label": "RepBottleneck",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.block",
        "description": "ultralytics.nn.modules.block",
        "peekOfCode": "class RepBottleneck(Bottleneck):\n    \"\"\"Rep bottleneck.\"\"\"\n    def __init__(self, c1, c2, shortcut=True, g=1, k=(3, 3), e=0.5):\n        \"\"\"Initializes a RepBottleneck module with customizable in/out channels, shortcut option, groups and expansion\n        ratio.\n        \"\"\"\n        super().__init__(c1, c2, shortcut, g, k, e)\n        c_ = int(c2 * e)  # hidden channels\n        self.cv1 = RepConv(c1, c_, k[0], 1)\nclass RepCSP(C3):",
        "detail": "ultralytics.nn.modules.block",
        "documentation": {}
    },
    {
        "label": "RepCSP",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.block",
        "description": "ultralytics.nn.modules.block",
        "peekOfCode": "class RepCSP(C3):\n    \"\"\"Rep CSP Bottleneck with 3 convolutions.\"\"\"\n    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):\n        \"\"\"Initializes RepCSP layer with given channels, repetitions, shortcut, groups and expansion ratio.\"\"\"\n        super().__init__(c1, c2, n, shortcut, g, e)\n        c_ = int(c2 * e)  # hidden channels\n        self.m = nn.Sequential(*(RepBottleneck(c_, c_, shortcut, g, e=1.0) for _ in range(n)))\nclass RepNCSPELAN4(nn.Module):\n    \"\"\"CSP-ELAN.\"\"\"\n    def __init__(self, c1, c2, c3, c4, n=1):",
        "detail": "ultralytics.nn.modules.block",
        "documentation": {}
    },
    {
        "label": "RepNCSPELAN4",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.block",
        "description": "ultralytics.nn.modules.block",
        "peekOfCode": "class RepNCSPELAN4(nn.Module):\n    \"\"\"CSP-ELAN.\"\"\"\n    def __init__(self, c1, c2, c3, c4, n=1):\n        \"\"\"Initializes CSP-ELAN layer with specified channel sizes, repetitions, and convolutions.\"\"\"\n        super().__init__()\n        self.c = c3 // 2\n        self.cv1 = Conv(c1, c3, 1, 1)\n        self.cv2 = nn.Sequential(RepCSP(c3 // 2, c4, n), Conv(c4, c4, 3, 1))\n        self.cv3 = nn.Sequential(RepCSP(c4, c4, n), Conv(c4, c4, 3, 1))\n        self.cv4 = Conv(c3 + (2 * c4), c2, 1, 1)",
        "detail": "ultralytics.nn.modules.block",
        "documentation": {}
    },
    {
        "label": "ELAN1",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.block",
        "description": "ultralytics.nn.modules.block",
        "peekOfCode": "class ELAN1(RepNCSPELAN4):\n    \"\"\"ELAN1 module with 4 convolutions.\"\"\"\n    def __init__(self, c1, c2, c3, c4):\n        \"\"\"Initializes ELAN1 layer with specified channel sizes.\"\"\"\n        super().__init__(c1, c2, c3, c4)\n        self.c = c3 // 2\n        self.cv1 = Conv(c1, c3, 1, 1)\n        self.cv2 = Conv(c3 // 2, c4, 3, 1)\n        self.cv3 = Conv(c4, c4, 3, 1)\n        self.cv4 = Conv(c3 + (2 * c4), c2, 1, 1)",
        "detail": "ultralytics.nn.modules.block",
        "documentation": {}
    },
    {
        "label": "AConv",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.block",
        "description": "ultralytics.nn.modules.block",
        "peekOfCode": "class AConv(nn.Module):\n    \"\"\"AConv.\"\"\"\n    def __init__(self, c1, c2):\n        \"\"\"Initializes AConv module with convolution layers.\"\"\"\n        super().__init__()\n        self.cv1 = Conv(c1, c2, 3, 2, 1)\n    def forward(self, x):\n        \"\"\"Forward pass through AConv layer.\"\"\"\n        x = torch.nn.functional.avg_pool2d(x, 2, 1, 0, False, True)\n        return self.cv1(x)",
        "detail": "ultralytics.nn.modules.block",
        "documentation": {}
    },
    {
        "label": "ADown",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.block",
        "description": "ultralytics.nn.modules.block",
        "peekOfCode": "class ADown(nn.Module):\n    \"\"\"ADown.\"\"\"\n    def __init__(self, c1, c2):\n        \"\"\"Initializes ADown module with convolution layers to downsample input from channels c1 to c2.\"\"\"\n        super().__init__()\n        self.c = c2 // 2\n        self.cv1 = Conv(c1 // 2, self.c, 3, 2, 1)\n        self.cv2 = Conv(c1 // 2, self.c, 1, 1, 0)\n    def forward(self, x):\n        \"\"\"Forward pass through ADown layer.\"\"\"",
        "detail": "ultralytics.nn.modules.block",
        "documentation": {}
    },
    {
        "label": "SPPELAN",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.block",
        "description": "ultralytics.nn.modules.block",
        "peekOfCode": "class SPPELAN(nn.Module):\n    \"\"\"SPP-ELAN.\"\"\"\n    def __init__(self, c1, c2, c3, k=5):\n        \"\"\"Initializes SPP-ELAN block with convolution and max pooling layers for spatial pyramid pooling.\"\"\"\n        super().__init__()\n        self.c = c3\n        self.cv1 = Conv(c1, c3, 1, 1)\n        self.cv2 = nn.MaxPool2d(kernel_size=k, stride=1, padding=k // 2)\n        self.cv3 = nn.MaxPool2d(kernel_size=k, stride=1, padding=k // 2)\n        self.cv4 = nn.MaxPool2d(kernel_size=k, stride=1, padding=k // 2)",
        "detail": "ultralytics.nn.modules.block",
        "documentation": {}
    },
    {
        "label": "CBLinear",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.block",
        "description": "ultralytics.nn.modules.block",
        "peekOfCode": "class CBLinear(nn.Module):\n    \"\"\"CBLinear.\"\"\"\n    def __init__(self, c1, c2s, k=1, s=1, p=None, g=1):\n        \"\"\"Initializes the CBLinear module, passing inputs unchanged.\"\"\"\n        super(CBLinear, self).__init__()\n        self.c2s = c2s\n        self.conv = nn.Conv2d(c1, sum(c2s), k, s, autopad(k, p), groups=g, bias=True)\n    def forward(self, x):\n        \"\"\"Forward pass through CBLinear layer.\"\"\"\n        return self.conv(x).split(self.c2s, dim=1)",
        "detail": "ultralytics.nn.modules.block",
        "documentation": {}
    },
    {
        "label": "CBFuse",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.block",
        "description": "ultralytics.nn.modules.block",
        "peekOfCode": "class CBFuse(nn.Module):\n    \"\"\"CBFuse.\"\"\"\n    def __init__(self, idx):\n        \"\"\"Initializes CBFuse module with layer index for selective feature fusion.\"\"\"\n        super(CBFuse, self).__init__()\n        self.idx = idx\n    def forward(self, xs):\n        \"\"\"Forward pass through CBFuse layer.\"\"\"\n        target_size = xs[-1].shape[2:]\n        res = [F.interpolate(x[self.idx[i]], size=target_size, mode=\"nearest\") for i, x in enumerate(xs[:-1])]",
        "detail": "ultralytics.nn.modules.block",
        "documentation": {}
    },
    {
        "label": "RepVGGDW",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.block",
        "description": "ultralytics.nn.modules.block",
        "peekOfCode": "class RepVGGDW(torch.nn.Module):\n    \"\"\"RepVGGDW is a class that represents a depth wise separable convolutional block in RepVGG architecture.\"\"\"\n    def __init__(self, ed) -> None:\n        \"\"\"Initializes RepVGGDW with depthwise separable convolutional layers for efficient processing.\"\"\"\n        super().__init__()\n        self.conv = Conv(ed, ed, 7, 1, 3, g=ed, act=False)\n        self.conv1 = Conv(ed, ed, 3, 1, 1, g=ed, act=False)\n        self.dim = ed\n        self.act = nn.SiLU()\n    def forward(self, x):",
        "detail": "ultralytics.nn.modules.block",
        "documentation": {}
    },
    {
        "label": "CIB",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.block",
        "description": "ultralytics.nn.modules.block",
        "peekOfCode": "class CIB(nn.Module):\n    \"\"\"\n    Conditional Identity Block (CIB) module.\n    Args:\n        c1 (int): Number of input channels.\n        c2 (int): Number of output channels.\n        shortcut (bool, optional): Whether to add a shortcut connection. Defaults to True.\n        e (float, optional): Scaling factor for the hidden channels. Defaults to 0.5.\n        lk (bool, optional): Whether to use RepVGGDW for the third convolutional layer. Defaults to False.\n    \"\"\"",
        "detail": "ultralytics.nn.modules.block",
        "documentation": {}
    },
    {
        "label": "C2fCIB",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.block",
        "description": "ultralytics.nn.modules.block",
        "peekOfCode": "class C2fCIB(C2f):\n    \"\"\"\n    C2fCIB class represents a convolutional block with C2f and CIB modules.\n    Args:\n        c1 (int): Number of input channels.\n        c2 (int): Number of output channels.\n        n (int, optional): Number of CIB modules to stack. Defaults to 1.\n        shortcut (bool, optional): Whether to use shortcut connection. Defaults to False.\n        lk (bool, optional): Whether to use local key connection. Defaults to False.\n        g (int, optional): Number of groups for grouped convolution. Defaults to 1.",
        "detail": "ultralytics.nn.modules.block",
        "documentation": {}
    },
    {
        "label": "Attention",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.block",
        "description": "ultralytics.nn.modules.block",
        "peekOfCode": "class Attention(nn.Module):\n    \"\"\"\n    Attention module that performs self-attention on the input tensor.\n    Args:\n        dim (int): The input tensor dimension.\n        num_heads (int): The number of attention heads.\n        attn_ratio (float): The ratio of the attention key dimension to the head dimension.\n    Attributes:\n        num_heads (int): The number of attention heads.\n        head_dim (int): The dimension of each attention head.",
        "detail": "ultralytics.nn.modules.block",
        "documentation": {}
    },
    {
        "label": "PSA",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.block",
        "description": "ultralytics.nn.modules.block",
        "peekOfCode": "class PSA(nn.Module):\n    \"\"\"\n    Position-wise Spatial Attention module.\n    Args:\n        c1 (int): Number of input channels.\n        c2 (int): Number of output channels.\n        e (float): Expansion factor for the intermediate channels. Default is 0.5.\n    Attributes:\n        c (int): Number of intermediate channels.\n        cv1 (Conv): 1x1 convolution layer to reduce the number of input channels to 2*c.",
        "detail": "ultralytics.nn.modules.block",
        "documentation": {}
    },
    {
        "label": "SCDown",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.block",
        "description": "ultralytics.nn.modules.block",
        "peekOfCode": "class SCDown(nn.Module):\n    \"\"\"Spatial Channel Downsample (SCDown) module for reducing spatial and channel dimensions.\"\"\"\n    def __init__(self, c1, c2, k, s):\n        \"\"\"\n        Spatial Channel Downsample (SCDown) module.\n        Args:\n            c1 (int): Number of input channels.\n            c2 (int): Number of output channels.\n            k (int): Kernel size for the convolutional layer.\n            s (int): Stride for the convolutional layer.",
        "detail": "ultralytics.nn.modules.block",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "ultralytics.nn.modules.block",
        "description": "ultralytics.nn.modules.block",
        "peekOfCode": "__all__ = (\n    \"DFL\",\n    \"HGBlock\",\n    \"HGStem\",\n    \"SPP\",\n    \"SPPF\",\n    \"C1\",\n    \"C2\",\n    \"C3\",\n    \"C2f\",",
        "detail": "ultralytics.nn.modules.block",
        "documentation": {}
    },
    {
        "label": "Conv",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.conv",
        "description": "ultralytics.nn.modules.conv",
        "peekOfCode": "class Conv(nn.Module):\n    \"\"\"Standard convolution with args(ch_in, ch_out, kernel, stride, padding, groups, dilation, activation).\"\"\"\n    default_act = nn.SiLU()  # default activation\n    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, d=1, act=True):\n        \"\"\"Initialize Conv layer with given arguments including activation.\"\"\"\n        super().__init__()\n        self.conv = nn.Conv2d(c1, c2, k, s, autopad(k, p, d), groups=g, dilation=d, bias=False)\n        self.bn = nn.BatchNorm2d(c2)\n        self.act = self.default_act if act is True else act if isinstance(act, nn.Module) else nn.Identity()\n    def forward(self, x):",
        "detail": "ultralytics.nn.modules.conv",
        "documentation": {}
    },
    {
        "label": "Conv2",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.conv",
        "description": "ultralytics.nn.modules.conv",
        "peekOfCode": "class Conv2(Conv):\n    \"\"\"Simplified RepConv module with Conv fusing.\"\"\"\n    def __init__(self, c1, c2, k=3, s=1, p=None, g=1, d=1, act=True):\n        \"\"\"Initialize Conv layer with given arguments including activation.\"\"\"\n        super().__init__(c1, c2, k, s, p, g=g, d=d, act=act)\n        self.cv2 = nn.Conv2d(c1, c2, 1, s, autopad(1, p, d), groups=g, dilation=d, bias=False)  # add 1x1 conv\n    def forward(self, x):\n        \"\"\"Apply convolution, batch normalization and activation to input tensor.\"\"\"\n        return self.act(self.bn(self.conv(x) + self.cv2(x)))\n    def forward_fuse(self, x):",
        "detail": "ultralytics.nn.modules.conv",
        "documentation": {}
    },
    {
        "label": "LightConv",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.conv",
        "description": "ultralytics.nn.modules.conv",
        "peekOfCode": "class LightConv(nn.Module):\n    \"\"\"\n    Light convolution with args(ch_in, ch_out, kernel).\n    https://github.com/PaddlePaddle/PaddleDetection/blob/develop/ppdet/modeling/backbones/hgnet_v2.py\n    \"\"\"\n    def __init__(self, c1, c2, k=1, act=nn.ReLU()):\n        \"\"\"Initialize Conv layer with given arguments including activation.\"\"\"\n        super().__init__()\n        self.conv1 = Conv(c1, c2, 1, act=False)\n        self.conv2 = DWConv(c2, c2, k, act=act)",
        "detail": "ultralytics.nn.modules.conv",
        "documentation": {}
    },
    {
        "label": "DWConv",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.conv",
        "description": "ultralytics.nn.modules.conv",
        "peekOfCode": "class DWConv(Conv):\n    \"\"\"Depth-wise convolution.\"\"\"\n    def __init__(self, c1, c2, k=1, s=1, d=1, act=True):  # ch_in, ch_out, kernel, stride, dilation, activation\n        \"\"\"Initialize Depth-wise convolution with given parameters.\"\"\"\n        super().__init__(c1, c2, k, s, g=math.gcd(c1, c2), d=d, act=act)\nclass DWConvTranspose2d(nn.ConvTranspose2d):\n    \"\"\"Depth-wise transpose convolution.\"\"\"\n    def __init__(self, c1, c2, k=1, s=1, p1=0, p2=0):  # ch_in, ch_out, kernel, stride, padding, padding_out\n        \"\"\"Initialize DWConvTranspose2d class with given parameters.\"\"\"\n        super().__init__(c1, c2, k, s, p1, p2, groups=math.gcd(c1, c2))",
        "detail": "ultralytics.nn.modules.conv",
        "documentation": {}
    },
    {
        "label": "DWConvTranspose2d",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.conv",
        "description": "ultralytics.nn.modules.conv",
        "peekOfCode": "class DWConvTranspose2d(nn.ConvTranspose2d):\n    \"\"\"Depth-wise transpose convolution.\"\"\"\n    def __init__(self, c1, c2, k=1, s=1, p1=0, p2=0):  # ch_in, ch_out, kernel, stride, padding, padding_out\n        \"\"\"Initialize DWConvTranspose2d class with given parameters.\"\"\"\n        super().__init__(c1, c2, k, s, p1, p2, groups=math.gcd(c1, c2))\nclass ConvTranspose(nn.Module):\n    \"\"\"Convolution transpose 2d layer.\"\"\"\n    default_act = nn.SiLU()  # default activation\n    def __init__(self, c1, c2, k=2, s=2, p=0, bn=True, act=True):\n        \"\"\"Initialize ConvTranspose2d layer with batch normalization and activation function.\"\"\"",
        "detail": "ultralytics.nn.modules.conv",
        "documentation": {}
    },
    {
        "label": "ConvTranspose",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.conv",
        "description": "ultralytics.nn.modules.conv",
        "peekOfCode": "class ConvTranspose(nn.Module):\n    \"\"\"Convolution transpose 2d layer.\"\"\"\n    default_act = nn.SiLU()  # default activation\n    def __init__(self, c1, c2, k=2, s=2, p=0, bn=True, act=True):\n        \"\"\"Initialize ConvTranspose2d layer with batch normalization and activation function.\"\"\"\n        super().__init__()\n        self.conv_transpose = nn.ConvTranspose2d(c1, c2, k, s, p, bias=not bn)\n        self.bn = nn.BatchNorm2d(c2) if bn else nn.Identity()\n        self.act = self.default_act if act is True else act if isinstance(act, nn.Module) else nn.Identity()\n    def forward(self, x):",
        "detail": "ultralytics.nn.modules.conv",
        "documentation": {}
    },
    {
        "label": "Focus",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.conv",
        "description": "ultralytics.nn.modules.conv",
        "peekOfCode": "class Focus(nn.Module):\n    \"\"\"Focus wh information into c-space.\"\"\"\n    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, act=True):\n        \"\"\"Initializes Focus object with user defined channel, convolution, padding, group and activation values.\"\"\"\n        super().__init__()\n        self.conv = Conv(c1 * 4, c2, k, s, p, g, act=act)\n        # self.contract = Contract(gain=2)\n    def forward(self, x):\n        \"\"\"\n        Applies convolution to concatenated tensor and returns the output.",
        "detail": "ultralytics.nn.modules.conv",
        "documentation": {}
    },
    {
        "label": "GhostConv",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.conv",
        "description": "ultralytics.nn.modules.conv",
        "peekOfCode": "class GhostConv(nn.Module):\n    \"\"\"Ghost Convolution https://github.com/huawei-noah/ghostnet.\"\"\"\n    def __init__(self, c1, c2, k=1, s=1, g=1, act=True):\n        \"\"\"Initializes the GhostConv object with input channels, output channels, kernel size, stride, groups and\n        activation.\n        \"\"\"\n        super().__init__()\n        c_ = c2 // 2  # hidden channels\n        self.cv1 = Conv(c1, c_, k, s, None, g, act=act)\n        self.cv2 = Conv(c_, c_, 5, 1, None, c_, act=act)",
        "detail": "ultralytics.nn.modules.conv",
        "documentation": {}
    },
    {
        "label": "RepConv",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.conv",
        "description": "ultralytics.nn.modules.conv",
        "peekOfCode": "class RepConv(nn.Module):\n    \"\"\"\n    RepConv is a basic rep-style block, including training and deploy status.\n    This module is used in RT-DETR.\n    Based on https://github.com/DingXiaoH/RepVGG/blob/main/repvgg.py\n    \"\"\"\n    default_act = nn.SiLU()  # default activation\n    def __init__(self, c1, c2, k=3, s=1, p=1, g=1, d=1, act=True, bn=False, deploy=False):\n        \"\"\"Initializes Light Convolution layer with inputs, outputs & optional activation function.\"\"\"\n        super().__init__()",
        "detail": "ultralytics.nn.modules.conv",
        "documentation": {}
    },
    {
        "label": "ChannelAttention",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.conv",
        "description": "ultralytics.nn.modules.conv",
        "peekOfCode": "class ChannelAttention(nn.Module):\n    \"\"\"Channel-attention module https://github.com/open-mmlab/mmdetection/tree/v3.0.0rc1/configs/rtmdet.\"\"\"\n    def __init__(self, channels: int) -> None:\n        \"\"\"Initializes the class and sets the basic configurations and instance variables required.\"\"\"\n        super().__init__()\n        self.pool = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Conv2d(channels, channels, 1, 1, 0, bias=True)\n        self.act = nn.Sigmoid()\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"Applies forward pass using activation on convolutions of the input, optionally using batch normalization.\"\"\"",
        "detail": "ultralytics.nn.modules.conv",
        "documentation": {}
    },
    {
        "label": "SpatialAttention",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.conv",
        "description": "ultralytics.nn.modules.conv",
        "peekOfCode": "class SpatialAttention(nn.Module):\n    \"\"\"Spatial-attention module.\"\"\"\n    def __init__(self, kernel_size=7):\n        \"\"\"Initialize Spatial-attention module with kernel size argument.\"\"\"\n        super().__init__()\n        assert kernel_size in {3, 7}, \"kernel size must be 3 or 7\"\n        padding = 3 if kernel_size == 7 else 1\n        self.cv1 = nn.Conv2d(2, 1, kernel_size, padding=padding, bias=False)\n        self.act = nn.Sigmoid()\n    def forward(self, x):",
        "detail": "ultralytics.nn.modules.conv",
        "documentation": {}
    },
    {
        "label": "CBAM",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.conv",
        "description": "ultralytics.nn.modules.conv",
        "peekOfCode": "class CBAM(nn.Module):\n    \"\"\"Convolutional Block Attention Module.\"\"\"\n    def __init__(self, c1, kernel_size=7):\n        \"\"\"Initialize CBAM with given input channel (c1) and kernel size.\"\"\"\n        super().__init__()\n        self.channel_attention = ChannelAttention(c1)\n        self.spatial_attention = SpatialAttention(kernel_size)\n    def forward(self, x):\n        \"\"\"Applies the forward pass through C1 module.\"\"\"\n        return self.spatial_attention(self.channel_attention(x))",
        "detail": "ultralytics.nn.modules.conv",
        "documentation": {}
    },
    {
        "label": "Concat",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.conv",
        "description": "ultralytics.nn.modules.conv",
        "peekOfCode": "class Concat(nn.Module):\n    \"\"\"Concatenate a list of tensors along dimension.\"\"\"\n    def __init__(self, dimension=1):\n        \"\"\"Concatenates a list of tensors along a specified dimension.\"\"\"\n        super().__init__()\n        self.d = dimension\n    def forward(self, x):\n        \"\"\"Forward pass for the YOLOv8 mask Proto module.\"\"\"\n        return torch.cat(x, self.d)",
        "detail": "ultralytics.nn.modules.conv",
        "documentation": {}
    },
    {
        "label": "autopad",
        "kind": 2,
        "importPath": "ultralytics.nn.modules.conv",
        "description": "ultralytics.nn.modules.conv",
        "peekOfCode": "def autopad(k, p=None, d=1):  # kernel, padding, dilation\n    \"\"\"Pad to 'same' shape outputs.\"\"\"\n    if d > 1:\n        k = d * (k - 1) + 1 if isinstance(k, int) else [d * (x - 1) + 1 for x in k]  # actual kernel-size\n    if p is None:\n        p = k // 2 if isinstance(k, int) else [x // 2 for x in k]  # auto-pad\n    return p\nclass Conv(nn.Module):\n    \"\"\"Standard convolution with args(ch_in, ch_out, kernel, stride, padding, groups, dilation, activation).\"\"\"\n    default_act = nn.SiLU()  # default activation",
        "detail": "ultralytics.nn.modules.conv",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "ultralytics.nn.modules.conv",
        "description": "ultralytics.nn.modules.conv",
        "peekOfCode": "__all__ = (\n    \"Conv\",\n    \"Conv2\",\n    \"LightConv\",\n    \"DWConv\",\n    \"DWConvTranspose2d\",\n    \"ConvTranspose\",\n    \"Focus\",\n    \"GhostConv\",\n    \"ChannelAttention\",",
        "detail": "ultralytics.nn.modules.conv",
        "documentation": {}
    },
    {
        "label": "Detect",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.head",
        "description": "ultralytics.nn.modules.head",
        "peekOfCode": "class Detect(nn.Module):\n    \"\"\"YOLOv8 Detect head for detection models.\"\"\"\n    dynamic = False  # force grid reconstruction\n    export = False  # export mode\n    end2end = False  # end2end\n    max_det = 300  # max_det\n    shape = None\n    anchors = torch.empty(0)  # init\n    strides = torch.empty(0)  # init\n    def __init__(self, nc=80, ch=()):",
        "detail": "ultralytics.nn.modules.head",
        "documentation": {}
    },
    {
        "label": "Segment",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.head",
        "description": "ultralytics.nn.modules.head",
        "peekOfCode": "class Segment(Detect):\n    \"\"\"YOLOv8 Segment head for segmentation models.\"\"\"\n    def __init__(self, nc=80, nm=32, npr=256, ch=()):\n        \"\"\"Initialize the YOLO model attributes such as the number of masks, prototypes, and the convolution layers.\"\"\"\n        super().__init__(nc, ch)\n        self.nm = nm  # number of masks\n        self.npr = npr  # number of protos\n        self.proto = Proto(ch[0], self.npr, self.nm)  # protos\n        c4 = max(ch[0] // 4, self.nm)\n        self.cv4 = nn.ModuleList(nn.Sequential(Conv(x, c4, 3), Conv(c4, c4, 3), nn.Conv2d(c4, self.nm, 1)) for x in ch)",
        "detail": "ultralytics.nn.modules.head",
        "documentation": {}
    },
    {
        "label": "OBB",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.head",
        "description": "ultralytics.nn.modules.head",
        "peekOfCode": "class OBB(Detect):\n    \"\"\"YOLOv8 OBB detection head for detection with rotation models.\"\"\"\n    def __init__(self, nc=80, ne=1, ch=()):\n        \"\"\"Initialize OBB with number of classes `nc` and layer channels `ch`.\"\"\"\n        super().__init__(nc, ch)\n        self.ne = ne  # number of extra parameters\n        c4 = max(ch[0] // 4, self.ne)\n        self.cv4 = nn.ModuleList(nn.Sequential(Conv(x, c4, 3), Conv(c4, c4, 3), nn.Conv2d(c4, self.ne, 1)) for x in ch)\n    def forward(self, x):\n        \"\"\"Concatenates and returns predicted bounding boxes and class probabilities.\"\"\"",
        "detail": "ultralytics.nn.modules.head",
        "documentation": {}
    },
    {
        "label": "Pose",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.head",
        "description": "ultralytics.nn.modules.head",
        "peekOfCode": "class Pose(Detect):\n    \"\"\"YOLOv8 Pose head for keypoints models.\"\"\"\n    def __init__(self, nc=80, kpt_shape=(17, 3), ch=()):\n        \"\"\"Initialize YOLO network with default parameters and Convolutional Layers.\"\"\"\n        super().__init__(nc, ch)\n        self.kpt_shape = kpt_shape  # number of keypoints, number of dims (2 for x,y or 3 for x,y,visible)\n        self.nk = kpt_shape[0] * kpt_shape[1]  # number of keypoints total\n        c4 = max(ch[0] // 4, self.nk)\n        self.cv4 = nn.ModuleList(nn.Sequential(Conv(x, c4, 3), Conv(c4, c4, 3), nn.Conv2d(c4, self.nk, 1)) for x in ch)\n    def forward(self, x):",
        "detail": "ultralytics.nn.modules.head",
        "documentation": {}
    },
    {
        "label": "Classify",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.head",
        "description": "ultralytics.nn.modules.head",
        "peekOfCode": "class Classify(nn.Module):\n    \"\"\"YOLOv8 classification head, i.e. x(b,c1,20,20) to x(b,c2).\"\"\"\n    def __init__(self, c1, c2, k=1, s=1, p=None, g=1):\n        \"\"\"Initializes YOLOv8 classification head with specified input and output channels, kernel size, stride,\n        padding, and groups.\n        \"\"\"\n        super().__init__()\n        c_ = 1280  # efficientnet_b0 size\n        self.conv = Conv(c1, c_, k, s, p, g)\n        self.pool = nn.AdaptiveAvgPool2d(1)  # to x(b,c_,1,1)",
        "detail": "ultralytics.nn.modules.head",
        "documentation": {}
    },
    {
        "label": "WorldDetect",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.head",
        "description": "ultralytics.nn.modules.head",
        "peekOfCode": "class WorldDetect(Detect):\n    \"\"\"Head for integrating YOLOv8 detection models with semantic understanding from text embeddings.\"\"\"\n    def __init__(self, nc=80, embed=512, with_bn=False, ch=()):\n        \"\"\"Initialize YOLOv8 detection layer with nc classes and layer channels ch.\"\"\"\n        super().__init__(nc, ch)\n        c3 = max(ch[0], min(self.nc, 100))\n        self.cv3 = nn.ModuleList(nn.Sequential(Conv(x, c3, 3), Conv(c3, c3, 3), nn.Conv2d(c3, embed, 1)) for x in ch)\n        self.cv4 = nn.ModuleList(BNContrastiveHead(embed) if with_bn else ContrastiveHead() for _ in ch)\n    def forward(self, x, text):\n        \"\"\"Concatenates and returns predicted bounding boxes and class probabilities.\"\"\"",
        "detail": "ultralytics.nn.modules.head",
        "documentation": {}
    },
    {
        "label": "RTDETRDecoder",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.head",
        "description": "ultralytics.nn.modules.head",
        "peekOfCode": "class RTDETRDecoder(nn.Module):\n    \"\"\"\n    Real-Time Deformable Transformer Decoder (RTDETRDecoder) module for object detection.\n    This decoder module utilizes Transformer architecture along with deformable convolutions to predict bounding boxes\n    and class labels for objects in an image. It integrates features from multiple layers and runs through a series of\n    Transformer decoder layers to output the final predictions.\n    \"\"\"\n    export = False  # export mode\n    def __init__(\n        self,",
        "detail": "ultralytics.nn.modules.head",
        "documentation": {}
    },
    {
        "label": "v10Detect",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.head",
        "description": "ultralytics.nn.modules.head",
        "peekOfCode": "class v10Detect(Detect):\n    \"\"\"\n    v10 Detection head from https://arxiv.org/pdf/2405.14458\n    Args:\n        nc (int): Number of classes.\n        ch (tuple): Tuple of channel sizes.\n    Attributes:\n        max_det (int): Maximum number of detections.\n    Methods:\n        __init__(self, nc=80, ch=()): Initializes the v10Detect object.",
        "detail": "ultralytics.nn.modules.head",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "ultralytics.nn.modules.head",
        "description": "ultralytics.nn.modules.head",
        "peekOfCode": "__all__ = \"Detect\", \"Segment\", \"Pose\", \"Classify\", \"OBB\", \"RTDETRDecoder\", \"v10Detect\"\nclass Detect(nn.Module):\n    \"\"\"YOLOv8 Detect head for detection models.\"\"\"\n    dynamic = False  # force grid reconstruction\n    export = False  # export mode\n    end2end = False  # end2end\n    max_det = 300  # max_det\n    shape = None\n    anchors = torch.empty(0)  # init\n    strides = torch.empty(0)  # init",
        "detail": "ultralytics.nn.modules.head",
        "documentation": {}
    },
    {
        "label": "TransformerEncoderLayer",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.transformer",
        "description": "ultralytics.nn.modules.transformer",
        "peekOfCode": "class TransformerEncoderLayer(nn.Module):\n    \"\"\"Defines a single layer of the transformer encoder.\"\"\"\n    def __init__(self, c1, cm=2048, num_heads=8, dropout=0.0, act=nn.GELU(), normalize_before=False):\n        \"\"\"Initialize the TransformerEncoderLayer with specified parameters.\"\"\"\n        super().__init__()\n        from ...utils.torch_utils import TORCH_1_9\n        if not TORCH_1_9:\n            raise ModuleNotFoundError(\n                \"TransformerEncoderLayer() requires torch>=1.9 to use nn.MultiheadAttention(batch_first=True).\"\n            )",
        "detail": "ultralytics.nn.modules.transformer",
        "documentation": {}
    },
    {
        "label": "AIFI",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.transformer",
        "description": "ultralytics.nn.modules.transformer",
        "peekOfCode": "class AIFI(TransformerEncoderLayer):\n    \"\"\"Defines the AIFI transformer layer.\"\"\"\n    def __init__(self, c1, cm=2048, num_heads=8, dropout=0, act=nn.GELU(), normalize_before=False):\n        \"\"\"Initialize the AIFI instance with specified parameters.\"\"\"\n        super().__init__(c1, cm, num_heads, dropout, act, normalize_before)\n    def forward(self, x):\n        \"\"\"Forward pass for the AIFI transformer layer.\"\"\"\n        c, h, w = x.shape[1:]\n        pos_embed = self.build_2d_sincos_position_embedding(w, h, c)\n        # Flatten [B, C, H, W] to [B, HxW, C]",
        "detail": "ultralytics.nn.modules.transformer",
        "documentation": {}
    },
    {
        "label": "TransformerLayer",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.transformer",
        "description": "ultralytics.nn.modules.transformer",
        "peekOfCode": "class TransformerLayer(nn.Module):\n    \"\"\"Transformer layer https://arxiv.org/abs/2010.11929 (LayerNorm layers removed for better performance).\"\"\"\n    def __init__(self, c, num_heads):\n        \"\"\"Initializes a self-attention mechanism using linear transformations and multi-head attention.\"\"\"\n        super().__init__()\n        self.q = nn.Linear(c, c, bias=False)\n        self.k = nn.Linear(c, c, bias=False)\n        self.v = nn.Linear(c, c, bias=False)\n        self.ma = nn.MultiheadAttention(embed_dim=c, num_heads=num_heads)\n        self.fc1 = nn.Linear(c, c, bias=False)",
        "detail": "ultralytics.nn.modules.transformer",
        "documentation": {}
    },
    {
        "label": "TransformerBlock",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.transformer",
        "description": "ultralytics.nn.modules.transformer",
        "peekOfCode": "class TransformerBlock(nn.Module):\n    \"\"\"Vision Transformer https://arxiv.org/abs/2010.11929.\"\"\"\n    def __init__(self, c1, c2, num_heads, num_layers):\n        \"\"\"Initialize a Transformer module with position embedding and specified number of heads and layers.\"\"\"\n        super().__init__()\n        self.conv = None\n        if c1 != c2:\n            self.conv = Conv(c1, c2)\n        self.linear = nn.Linear(c2, c2)  # learnable position embedding\n        self.tr = nn.Sequential(*(TransformerLayer(c2, num_heads) for _ in range(num_layers)))",
        "detail": "ultralytics.nn.modules.transformer",
        "documentation": {}
    },
    {
        "label": "MLPBlock",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.transformer",
        "description": "ultralytics.nn.modules.transformer",
        "peekOfCode": "class MLPBlock(nn.Module):\n    \"\"\"Implements a single block of a multi-layer perceptron.\"\"\"\n    def __init__(self, embedding_dim, mlp_dim, act=nn.GELU):\n        \"\"\"Initialize the MLPBlock with specified embedding dimension, MLP dimension, and activation function.\"\"\"\n        super().__init__()\n        self.lin1 = nn.Linear(embedding_dim, mlp_dim)\n        self.lin2 = nn.Linear(mlp_dim, embedding_dim)\n        self.act = act()\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"Forward pass for the MLPBlock.\"\"\"",
        "detail": "ultralytics.nn.modules.transformer",
        "documentation": {}
    },
    {
        "label": "MLP",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.transformer",
        "description": "ultralytics.nn.modules.transformer",
        "peekOfCode": "class MLP(nn.Module):\n    \"\"\"Implements a simple multi-layer perceptron (also called FFN).\"\"\"\n    def __init__(self, input_dim, hidden_dim, output_dim, num_layers):\n        \"\"\"Initialize the MLP with specified input, hidden, output dimensions and number of layers.\"\"\"\n        super().__init__()\n        self.num_layers = num_layers\n        h = [hidden_dim] * (num_layers - 1)\n        self.layers = nn.ModuleList(nn.Linear(n, k) for n, k in zip([input_dim] + h, h + [output_dim]))\n    def forward(self, x):\n        \"\"\"Forward pass for the entire MLP.\"\"\"",
        "detail": "ultralytics.nn.modules.transformer",
        "documentation": {}
    },
    {
        "label": "LayerNorm2d",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.transformer",
        "description": "ultralytics.nn.modules.transformer",
        "peekOfCode": "class LayerNorm2d(nn.Module):\n    \"\"\"\n    2D Layer Normalization module inspired by Detectron2 and ConvNeXt implementations.\n    Original implementations in\n    https://github.com/facebookresearch/detectron2/blob/main/detectron2/layers/batch_norm.py\n    and\n    https://github.com/facebookresearch/ConvNeXt/blob/main/models/convnext.py.\n    \"\"\"\n    def __init__(self, num_channels, eps=1e-6):\n        \"\"\"Initialize LayerNorm2d with the given parameters.\"\"\"",
        "detail": "ultralytics.nn.modules.transformer",
        "documentation": {}
    },
    {
        "label": "MSDeformAttn",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.transformer",
        "description": "ultralytics.nn.modules.transformer",
        "peekOfCode": "class MSDeformAttn(nn.Module):\n    \"\"\"\n    Multiscale Deformable Attention Module based on Deformable-DETR and PaddleDetection implementations.\n    https://github.com/fundamentalvision/Deformable-DETR/blob/main/models/ops/modules/ms_deform_attn.py\n    \"\"\"\n    def __init__(self, d_model=256, n_levels=4, n_heads=8, n_points=4):\n        \"\"\"Initialize MSDeformAttn with the given parameters.\"\"\"\n        super().__init__()\n        if d_model % n_heads != 0:\n            raise ValueError(f\"d_model must be divisible by n_heads, but got {d_model} and {n_heads}\")",
        "detail": "ultralytics.nn.modules.transformer",
        "documentation": {}
    },
    {
        "label": "DeformableTransformerDecoderLayer",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.transformer",
        "description": "ultralytics.nn.modules.transformer",
        "peekOfCode": "class DeformableTransformerDecoderLayer(nn.Module):\n    \"\"\"\n    Deformable Transformer Decoder Layer inspired by PaddleDetection and Deformable-DETR implementations.\n    https://github.com/PaddlePaddle/PaddleDetection/blob/develop/ppdet/modeling/transformers/deformable_transformer.py\n    https://github.com/fundamentalvision/Deformable-DETR/blob/main/models/deformable_transformer.py\n    \"\"\"\n    def __init__(self, d_model=256, n_heads=8, d_ffn=1024, dropout=0.0, act=nn.ReLU(), n_levels=4, n_points=4):\n        \"\"\"Initialize the DeformableTransformerDecoderLayer with the given parameters.\"\"\"\n        super().__init__()\n        # Self attention",
        "detail": "ultralytics.nn.modules.transformer",
        "documentation": {}
    },
    {
        "label": "DeformableTransformerDecoder",
        "kind": 6,
        "importPath": "ultralytics.nn.modules.transformer",
        "description": "ultralytics.nn.modules.transformer",
        "peekOfCode": "class DeformableTransformerDecoder(nn.Module):\n    \"\"\"\n    Implementation of Deformable Transformer Decoder based on PaddleDetection.\n    https://github.com/PaddlePaddle/PaddleDetection/blob/develop/ppdet/modeling/transformers/deformable_transformer.py\n    \"\"\"\n    def __init__(self, hidden_dim, decoder_layer, num_layers, eval_idx=-1):\n        \"\"\"Initialize the DeformableTransformerDecoder with the given parameters.\"\"\"\n        super().__init__()\n        self.layers = _get_clones(decoder_layer, num_layers)\n        self.num_layers = num_layers",
        "detail": "ultralytics.nn.modules.transformer",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "ultralytics.nn.modules.transformer",
        "description": "ultralytics.nn.modules.transformer",
        "peekOfCode": "__all__ = (\n    \"TransformerEncoderLayer\",\n    \"TransformerLayer\",\n    \"TransformerBlock\",\n    \"MLPBlock\",\n    \"LayerNorm2d\",\n    \"AIFI\",\n    \"DeformableTransformerDecoder\",\n    \"DeformableTransformerDecoderLayer\",\n    \"MSDeformAttn\",",
        "detail": "ultralytics.nn.modules.transformer",
        "documentation": {}
    },
    {
        "label": "bias_init_with_prob",
        "kind": 2,
        "importPath": "ultralytics.nn.modules.utils",
        "description": "ultralytics.nn.modules.utils",
        "peekOfCode": "def bias_init_with_prob(prior_prob=0.01):\n    \"\"\"Initialize conv/fc bias value according to a given probability value.\"\"\"\n    return float(-np.log((1 - prior_prob) / prior_prob))  # return bias_init\ndef linear_init(module):\n    \"\"\"Initialize the weights and biases of a linear module.\"\"\"\n    bound = 1 / math.sqrt(module.weight.shape[0])\n    uniform_(module.weight, -bound, bound)\n    if hasattr(module, \"bias\") and module.bias is not None:\n        uniform_(module.bias, -bound, bound)\ndef inverse_sigmoid(x, eps=1e-5):",
        "detail": "ultralytics.nn.modules.utils",
        "documentation": {}
    },
    {
        "label": "linear_init",
        "kind": 2,
        "importPath": "ultralytics.nn.modules.utils",
        "description": "ultralytics.nn.modules.utils",
        "peekOfCode": "def linear_init(module):\n    \"\"\"Initialize the weights and biases of a linear module.\"\"\"\n    bound = 1 / math.sqrt(module.weight.shape[0])\n    uniform_(module.weight, -bound, bound)\n    if hasattr(module, \"bias\") and module.bias is not None:\n        uniform_(module.bias, -bound, bound)\ndef inverse_sigmoid(x, eps=1e-5):\n    \"\"\"Calculate the inverse sigmoid function for a tensor.\"\"\"\n    x = x.clamp(min=0, max=1)\n    x1 = x.clamp(min=eps)",
        "detail": "ultralytics.nn.modules.utils",
        "documentation": {}
    },
    {
        "label": "inverse_sigmoid",
        "kind": 2,
        "importPath": "ultralytics.nn.modules.utils",
        "description": "ultralytics.nn.modules.utils",
        "peekOfCode": "def inverse_sigmoid(x, eps=1e-5):\n    \"\"\"Calculate the inverse sigmoid function for a tensor.\"\"\"\n    x = x.clamp(min=0, max=1)\n    x1 = x.clamp(min=eps)\n    x2 = (1 - x).clamp(min=eps)\n    return torch.log(x1 / x2)\ndef multi_scale_deformable_attn_pytorch(\n    value: torch.Tensor,\n    value_spatial_shapes: torch.Tensor,\n    sampling_locations: torch.Tensor,",
        "detail": "ultralytics.nn.modules.utils",
        "documentation": {}
    },
    {
        "label": "multi_scale_deformable_attn_pytorch",
        "kind": 2,
        "importPath": "ultralytics.nn.modules.utils",
        "description": "ultralytics.nn.modules.utils",
        "peekOfCode": "def multi_scale_deformable_attn_pytorch(\n    value: torch.Tensor,\n    value_spatial_shapes: torch.Tensor,\n    sampling_locations: torch.Tensor,\n    attention_weights: torch.Tensor,\n) -> torch.Tensor:\n    \"\"\"\n    Multiscale deformable attention.\n    https://github.com/IDEA-Research/detrex/blob/main/detrex/layers/multi_scale_deform_attn.py\n    \"\"\"",
        "detail": "ultralytics.nn.modules.utils",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "ultralytics.nn.modules.utils",
        "description": "ultralytics.nn.modules.utils",
        "peekOfCode": "__all__ = \"multi_scale_deformable_attn_pytorch\", \"inverse_sigmoid\"\ndef _get_clones(module, n):\n    \"\"\"Create a list of cloned modules from the given module.\"\"\"\n    return nn.ModuleList([copy.deepcopy(module) for _ in range(n)])\ndef bias_init_with_prob(prior_prob=0.01):\n    \"\"\"Initialize conv/fc bias value according to a given probability value.\"\"\"\n    return float(-np.log((1 - prior_prob) / prior_prob))  # return bias_init\ndef linear_init(module):\n    \"\"\"Initialize the weights and biases of a linear module.\"\"\"\n    bound = 1 / math.sqrt(module.weight.shape[0])",
        "detail": "ultralytics.nn.modules.utils",
        "documentation": {}
    },
    {
        "label": "AutoBackend",
        "kind": 6,
        "importPath": "ultralytics.nn.autobackend",
        "description": "ultralytics.nn.autobackend",
        "peekOfCode": "class AutoBackend(nn.Module):\n    \"\"\"\n    Handles dynamic backend selection for running inference using Ultralytics YOLO models.\n    The AutoBackend class is designed to provide an abstraction layer for various inference engines. It supports a wide\n    range of formats, each with specific naming conventions as outlined below:\n        Supported Formats and Naming Conventions:\n            | Format                | File Suffix      |\n            |-----------------------|------------------|\n            | PyTorch               | *.pt             |\n            | TorchScript           | *.torchscript    |",
        "detail": "ultralytics.nn.autobackend",
        "documentation": {}
    },
    {
        "label": "check_class_names",
        "kind": 2,
        "importPath": "ultralytics.nn.autobackend",
        "description": "ultralytics.nn.autobackend",
        "peekOfCode": "def check_class_names(names):\n    \"\"\"\n    Check class names.\n    Map imagenet class codes to human-readable names if required. Convert lists to dicts.\n    \"\"\"\n    if isinstance(names, list):  # names is a list\n        names = dict(enumerate(names))  # convert to dict\n    if isinstance(names, dict):\n        # Convert 1) string keys to int, i.e. '0' to 0, and non-string values to strings, i.e. True to 'True'\n        names = {int(k): str(v) for k, v in names.items()}",
        "detail": "ultralytics.nn.autobackend",
        "documentation": {}
    },
    {
        "label": "default_class_names",
        "kind": 2,
        "importPath": "ultralytics.nn.autobackend",
        "description": "ultralytics.nn.autobackend",
        "peekOfCode": "def default_class_names(data=None):\n    \"\"\"Applies default class names to an input YAML file or returns numerical class names.\"\"\"\n    if data:\n        with contextlib.suppress(Exception):\n            return yaml_load(check_yaml(data))[\"names\"]\n    return {i: f\"class{i}\" for i in range(999)}  # return default if above errors\nclass AutoBackend(nn.Module):\n    \"\"\"\n    Handles dynamic backend selection for running inference using Ultralytics YOLO models.\n    The AutoBackend class is designed to provide an abstraction layer for various inference engines. It supports a wide",
        "detail": "ultralytics.nn.autobackend",
        "documentation": {}
    },
    {
        "label": "BaseModel",
        "kind": 6,
        "importPath": "ultralytics.nn.tasks",
        "description": "ultralytics.nn.tasks",
        "peekOfCode": "class BaseModel(nn.Module):\n    \"\"\"The BaseModel class serves as a base class for all the models in the Ultralytics YOLO family.\"\"\"\n    def forward(self, x, *args, **kwargs):\n        \"\"\"\n        Forward pass of the model on a single scale. Wrapper for `_forward_once` method.\n        Args:\n            x (torch.Tensor | dict): The input image tensor or a dict including image tensor and gt labels.\n        Returns:\n            (torch.Tensor): The output of the network.\n        \"\"\"",
        "detail": "ultralytics.nn.tasks",
        "documentation": {}
    },
    {
        "label": "DetectionModel",
        "kind": 6,
        "importPath": "ultralytics.nn.tasks",
        "description": "ultralytics.nn.tasks",
        "peekOfCode": "class DetectionModel(BaseModel):\n    \"\"\"YOLOv8 detection model.\"\"\"\n    def __init__(self, cfg=\"yolov8n.yaml\", ch=3, nc=None, verbose=True):  # model, input channels, number of classes\n        \"\"\"Initialize the YOLOv8 detection model with the given config and parameters.\"\"\"\n        super().__init__()\n        self.yaml = cfg if isinstance(cfg, dict) else yaml_model_load(cfg)  # cfg dict\n        if self.yaml[\"backbone\"][0][2] == \"Silence\":\n            LOGGER.warning(\n                \"WARNING ⚠️ YOLOv9 `Silence` module is deprecated in favor of nn.Identity. \"\n                \"Please delete local *.pt file and re-download the latest model checkpoint.\"",
        "detail": "ultralytics.nn.tasks",
        "documentation": {}
    },
    {
        "label": "OBBModel",
        "kind": 6,
        "importPath": "ultralytics.nn.tasks",
        "description": "ultralytics.nn.tasks",
        "peekOfCode": "class OBBModel(DetectionModel):\n    \"\"\"YOLOv8 Oriented Bounding Box (OBB) model.\"\"\"\n    def __init__(self, cfg=\"yolov8n-obb.yaml\", ch=3, nc=None, verbose=True):\n        \"\"\"Initialize YOLOv8 OBB model with given config and parameters.\"\"\"\n        super().__init__(cfg=cfg, ch=ch, nc=nc, verbose=verbose)\n    def init_criterion(self):\n        \"\"\"Initialize the loss criterion for the model.\"\"\"\n        return v8OBBLoss(self)\nclass SegmentationModel(DetectionModel):\n    \"\"\"YOLOv8 segmentation model.\"\"\"",
        "detail": "ultralytics.nn.tasks",
        "documentation": {}
    },
    {
        "label": "SegmentationModel",
        "kind": 6,
        "importPath": "ultralytics.nn.tasks",
        "description": "ultralytics.nn.tasks",
        "peekOfCode": "class SegmentationModel(DetectionModel):\n    \"\"\"YOLOv8 segmentation model.\"\"\"\n    def __init__(self, cfg=\"yolov8n-seg.yaml\", ch=3, nc=None, verbose=True):\n        \"\"\"Initialize YOLOv8 segmentation model with given config and parameters.\"\"\"\n        super().__init__(cfg=cfg, ch=ch, nc=nc, verbose=verbose)\n    def init_criterion(self):\n        \"\"\"Initialize the loss criterion for the SegmentationModel.\"\"\"\n        return v8SegmentationLoss(self)\nclass PoseModel(DetectionModel):\n    \"\"\"YOLOv8 pose model.\"\"\"",
        "detail": "ultralytics.nn.tasks",
        "documentation": {}
    },
    {
        "label": "PoseModel",
        "kind": 6,
        "importPath": "ultralytics.nn.tasks",
        "description": "ultralytics.nn.tasks",
        "peekOfCode": "class PoseModel(DetectionModel):\n    \"\"\"YOLOv8 pose model.\"\"\"\n    def __init__(self, cfg=\"yolov8n-pose.yaml\", ch=3, nc=None, data_kpt_shape=(None, None), verbose=True):\n        \"\"\"Initialize YOLOv8 Pose model.\"\"\"\n        if not isinstance(cfg, dict):\n            cfg = yaml_model_load(cfg)  # load model YAML\n        if any(data_kpt_shape) and list(data_kpt_shape) != list(cfg[\"kpt_shape\"]):\n            LOGGER.info(f\"Overriding model.yaml kpt_shape={cfg['kpt_shape']} with kpt_shape={data_kpt_shape}\")\n            cfg[\"kpt_shape\"] = data_kpt_shape\n        super().__init__(cfg=cfg, ch=ch, nc=nc, verbose=verbose)",
        "detail": "ultralytics.nn.tasks",
        "documentation": {}
    },
    {
        "label": "ClassificationModel",
        "kind": 6,
        "importPath": "ultralytics.nn.tasks",
        "description": "ultralytics.nn.tasks",
        "peekOfCode": "class ClassificationModel(BaseModel):\n    \"\"\"YOLOv8 classification model.\"\"\"\n    def __init__(self, cfg=\"yolov8n-cls.yaml\", ch=3, nc=None, verbose=True):\n        \"\"\"Init ClassificationModel with YAML, channels, number of classes, verbose flag.\"\"\"\n        super().__init__()\n        self._from_yaml(cfg, ch, nc, verbose)\n    def _from_yaml(self, cfg, ch, nc, verbose):\n        \"\"\"Set YOLOv8 model configurations and define the model architecture.\"\"\"\n        self.yaml = cfg if isinstance(cfg, dict) else yaml_model_load(cfg)  # cfg dict\n        # Define model",
        "detail": "ultralytics.nn.tasks",
        "documentation": {}
    },
    {
        "label": "RTDETRDetectionModel",
        "kind": 6,
        "importPath": "ultralytics.nn.tasks",
        "description": "ultralytics.nn.tasks",
        "peekOfCode": "class RTDETRDetectionModel(DetectionModel):\n    \"\"\"\n    RTDETR (Real-time DEtection and Tracking using Transformers) Detection Model class.\n    This class is responsible for constructing the RTDETR architecture, defining loss functions, and facilitating both\n    the training and inference processes. RTDETR is an object detection and tracking model that extends from the\n    DetectionModel base class.\n    Attributes:\n        cfg (str): The configuration file path or preset string. Default is 'rtdetr-l.yaml'.\n        ch (int): Number of input channels. Default is 3 (RGB).\n        nc (int, optional): Number of classes for object detection. Default is None.",
        "detail": "ultralytics.nn.tasks",
        "documentation": {}
    },
    {
        "label": "WorldModel",
        "kind": 6,
        "importPath": "ultralytics.nn.tasks",
        "description": "ultralytics.nn.tasks",
        "peekOfCode": "class WorldModel(DetectionModel):\n    \"\"\"YOLOv8 World Model.\"\"\"\n    def __init__(self, cfg=\"yolov8s-world.yaml\", ch=3, nc=None, verbose=True):\n        \"\"\"Initialize YOLOv8 world model with given config and parameters.\"\"\"\n        self.txt_feats = torch.randn(1, nc or 80, 512)  # features placeholder\n        self.clip_model = None  # CLIP model placeholder\n        super().__init__(cfg=cfg, ch=ch, nc=nc, verbose=verbose)\n    def set_classes(self, text, batch=80, cache_clip_model=True):\n        \"\"\"Set classes in advance so that model could do offline-inference without clip model.\"\"\"\n        try:",
        "detail": "ultralytics.nn.tasks",
        "documentation": {}
    },
    {
        "label": "Ensemble",
        "kind": 6,
        "importPath": "ultralytics.nn.tasks",
        "description": "ultralytics.nn.tasks",
        "peekOfCode": "class Ensemble(nn.ModuleList):\n    \"\"\"Ensemble of models.\"\"\"\n    def __init__(self):\n        \"\"\"Initialize an ensemble of models.\"\"\"\n        super().__init__()\n    def forward(self, x, augment=False, profile=False, visualize=False):\n        \"\"\"Function generates the YOLO network's final layer.\"\"\"\n        y = [module(x, augment, profile, visualize)[0] for module in self]\n        # y = torch.stack(y).max(0)[0]  # max ensemble\n        # y = torch.stack(y).mean(0)  # mean ensemble",
        "detail": "ultralytics.nn.tasks",
        "documentation": {}
    },
    {
        "label": "temporary_modules",
        "kind": 2,
        "importPath": "ultralytics.nn.tasks",
        "description": "ultralytics.nn.tasks",
        "peekOfCode": "def temporary_modules(modules=None, attributes=None):\n    \"\"\"\n    Context manager for temporarily adding or modifying modules in Python's module cache (`sys.modules`).\n    This function can be used to change the module paths during runtime. It's useful when refactoring code,\n    where you've moved a module from one location to another, but you still want to support the old import\n    paths for backwards compatibility.\n    Args:\n        modules (dict, optional): A dictionary mapping old module paths to new module paths.\n        attributes (dict, optional): A dictionary mapping old module attributes to new module attributes.\n    Example:",
        "detail": "ultralytics.nn.tasks",
        "documentation": {}
    },
    {
        "label": "torch_safe_load",
        "kind": 2,
        "importPath": "ultralytics.nn.tasks",
        "description": "ultralytics.nn.tasks",
        "peekOfCode": "def torch_safe_load(weight):\n    \"\"\"\n    This function attempts to load a PyTorch model with the torch.load() function. If a ModuleNotFoundError is raised,\n    it catches the error, logs a warning message, and attempts to install the missing module via the\n    check_requirements() function. After installation, the function again attempts to load the model using torch.load().\n    Args:\n        weight (str): The file path of the PyTorch model.\n    Returns:\n        (dict): The loaded PyTorch model.\n    \"\"\"",
        "detail": "ultralytics.nn.tasks",
        "documentation": {}
    },
    {
        "label": "attempt_load_weights",
        "kind": 2,
        "importPath": "ultralytics.nn.tasks",
        "description": "ultralytics.nn.tasks",
        "peekOfCode": "def attempt_load_weights(weights, device=None, inplace=True, fuse=False):\n    \"\"\"Loads an ensemble of models weights=[a,b,c] or a single model weights=[a] or weights=a.\"\"\"\n    ensemble = Ensemble()\n    for w in weights if isinstance(weights, list) else [weights]:\n        ckpt, w = torch_safe_load(w)  # load ckpt\n        args = {**DEFAULT_CFG_DICT, **ckpt[\"train_args\"]} if \"train_args\" in ckpt else None  # combined args\n        model = (ckpt.get(\"ema\") or ckpt[\"model\"]).to(device).float()  # FP32 model\n        # Model compatibility updates\n        model.args = args  # attach args to model\n        model.pt_path = w  # attach *.pt file path to model",
        "detail": "ultralytics.nn.tasks",
        "documentation": {}
    },
    {
        "label": "attempt_load_one_weight",
        "kind": 2,
        "importPath": "ultralytics.nn.tasks",
        "description": "ultralytics.nn.tasks",
        "peekOfCode": "def attempt_load_one_weight(weight, device=None, inplace=True, fuse=False):\n    \"\"\"Loads a single model weights.\"\"\"\n    ckpt, weight = torch_safe_load(weight)  # load ckpt\n    args = {**DEFAULT_CFG_DICT, **(ckpt.get(\"train_args\", {}))}  # combine model and default args, preferring model args\n    model = (ckpt.get(\"ema\") or ckpt[\"model\"]).to(device).float()  # FP32 model\n    # Model compatibility updates\n    model.args = {k: v for k, v in args.items() if k in DEFAULT_CFG_KEYS}  # attach args to model\n    model.pt_path = weight  # attach *.pt file path to model\n    model.task = guess_model_task(model)\n    if not hasattr(model, \"stride\"):",
        "detail": "ultralytics.nn.tasks",
        "documentation": {}
    },
    {
        "label": "parse_model",
        "kind": 2,
        "importPath": "ultralytics.nn.tasks",
        "description": "ultralytics.nn.tasks",
        "peekOfCode": "def parse_model(d, ch, verbose=True):  # model_dict, input_channels(3)\n    \"\"\"Parse a YOLO model.yaml dictionary into a PyTorch model.\"\"\"\n    import ast\n    # Args\n    max_channels = float(\"inf\")\n    nc, act, scales = (d.get(x) for x in (\"nc\", \"activation\", \"scales\"))\n    depth, width, kpt_shape = (d.get(x, 1.0) for x in (\"depth_multiple\", \"width_multiple\", \"kpt_shape\"))\n    if scales:\n        scale = d.get(\"scale\")\n        if not scale:",
        "detail": "ultralytics.nn.tasks",
        "documentation": {}
    },
    {
        "label": "yaml_model_load",
        "kind": 2,
        "importPath": "ultralytics.nn.tasks",
        "description": "ultralytics.nn.tasks",
        "peekOfCode": "def yaml_model_load(path):\n    \"\"\"Load a YOLOv8 model from a YAML file.\"\"\"\n    import re\n    path = Path(path)\n    if path.stem in (f\"yolov{d}{x}6\" for x in \"nsmlx\" for d in (5, 8)):\n        new_stem = re.sub(r\"(\\d+)([nslmx])6(.+)?$\", r\"\\1\\2-p6\\3\", path.stem)\n        LOGGER.warning(f\"WARNING ⚠️ Ultralytics YOLO P6 models now use -p6 suffix. Renaming {path.stem} to {new_stem}.\")\n        path = path.with_name(new_stem + path.suffix)\n    unified_path = re.sub(r\"(\\d+)([nslmx])(.+)?$\", r\"\\1\\3\", str(path))  # i.e. yolov8x.yaml -> yolov8.yaml\n    yaml_file = check_yaml(unified_path, hard=False) or check_yaml(path)",
        "detail": "ultralytics.nn.tasks",
        "documentation": {}
    },
    {
        "label": "guess_model_scale",
        "kind": 2,
        "importPath": "ultralytics.nn.tasks",
        "description": "ultralytics.nn.tasks",
        "peekOfCode": "def guess_model_scale(model_path):\n    \"\"\"\n    Takes a path to a YOLO model's YAML file as input and extracts the size character of the model's scale. The function\n    uses regular expression matching to find the pattern of the model scale in the YAML file name, which is denoted by\n    n, s, m, l, or x. The function returns the size character of the model scale as a string.\n    Args:\n        model_path (str | Path): The path to the YOLO model's YAML file.\n    Returns:\n        (str): The size character of the model's scale, which can be n, s, m, l, or x.\n    \"\"\"",
        "detail": "ultralytics.nn.tasks",
        "documentation": {}
    },
    {
        "label": "guess_model_task",
        "kind": 2,
        "importPath": "ultralytics.nn.tasks",
        "description": "ultralytics.nn.tasks",
        "peekOfCode": "def guess_model_task(model):\n    \"\"\"\n    Guess the task of a PyTorch model from its architecture or configuration.\n    Args:\n        model (nn.Module | dict): PyTorch model or model configuration in YAML format.\n    Returns:\n        (str): Task of the model ('detect', 'segment', 'classify', 'pose').\n    Raises:\n        SyntaxError: If the task of the model could not be determined.\n    \"\"\"",
        "detail": "ultralytics.nn.tasks",
        "documentation": {}
    },
    {
        "label": "AIGym",
        "kind": 6,
        "importPath": "ultralytics.solutions.ai_gym",
        "description": "ultralytics.solutions.ai_gym",
        "peekOfCode": "class AIGym:\n    \"\"\"A class to manage the gym steps of people in a real-time video stream based on their poses.\"\"\"\n    def __init__(\n        self,\n        kpts_to_check,\n        line_thickness=2,\n        view_img=False,\n        pose_up_angle=145.0,\n        pose_down_angle=90.0,\n        pose_type=\"pullup\",",
        "detail": "ultralytics.solutions.ai_gym",
        "documentation": {}
    },
    {
        "label": "Analytics",
        "kind": 6,
        "importPath": "ultralytics.solutions.analytics",
        "description": "ultralytics.solutions.analytics",
        "peekOfCode": "class Analytics:\n    \"\"\"A class to create and update various types of charts (line, bar, pie, area) for visual analytics.\"\"\"\n    def __init__(\n        self,\n        type,\n        writer,\n        im0_shape,\n        title=\"ultralytics\",\n        x_label=\"x\",\n        y_label=\"y\",",
        "detail": "ultralytics.solutions.analytics",
        "documentation": {}
    },
    {
        "label": "DistanceCalculation",
        "kind": 6,
        "importPath": "ultralytics.solutions.distance_calculation",
        "description": "ultralytics.solutions.distance_calculation",
        "peekOfCode": "class DistanceCalculation:\n    \"\"\"A class to calculate distance between two objects in a real-time video stream based on their tracks.\"\"\"\n    def __init__(\n        self,\n        names,\n        pixels_per_meter=10,\n        view_img=False,\n        line_thickness=2,\n        line_color=(255, 255, 0),\n        centroid_color=(255, 0, 255),",
        "detail": "ultralytics.solutions.distance_calculation",
        "documentation": {}
    },
    {
        "label": "Heatmap",
        "kind": 6,
        "importPath": "ultralytics.solutions.heatmap",
        "description": "ultralytics.solutions.heatmap",
        "peekOfCode": "class Heatmap:\n    \"\"\"A class to draw heatmaps in real-time video stream based on their tracks.\"\"\"\n    def __init__(\n        self,\n        names,\n        imw=0,\n        imh=0,\n        colormap=cv2.COLORMAP_JET,\n        heatmap_alpha=0.5,\n        view_img=False,",
        "detail": "ultralytics.solutions.heatmap",
        "documentation": {}
    },
    {
        "label": "ObjectCounter",
        "kind": 6,
        "importPath": "ultralytics.solutions.object_counter",
        "description": "ultralytics.solutions.object_counter",
        "peekOfCode": "class ObjectCounter:\n    \"\"\"A class to manage the counting of objects in a real-time video stream based on their tracks.\"\"\"\n    def __init__(\n        self,\n        names,\n        reg_pts=None,\n        count_reg_color=(255, 0, 255),\n        count_txt_color=(0, 0, 0),\n        count_bg_color=(255, 255, 255),\n        line_thickness=2,",
        "detail": "ultralytics.solutions.object_counter",
        "documentation": {}
    },
    {
        "label": "ParkingPtsSelection",
        "kind": 6,
        "importPath": "ultralytics.solutions.parking_management",
        "description": "ultralytics.solutions.parking_management",
        "peekOfCode": "class ParkingPtsSelection:\n    \"\"\"Class for selecting and managing parking zone points on images using a Tkinter-based UI.\"\"\"\n    def __init__(self):\n        \"\"\"Initializes the UI for selecting parking zone points in a tkinter window.\"\"\"\n        check_requirements(\"tkinter\")\n        import tkinter as tk  # scope for multi-environment compatibility\n        self.tk = tk\n        self.master = tk.Tk()\n        self.master.title(\"Ultralytics Parking Zones Points Selector\")\n        # Disable window resizing",
        "detail": "ultralytics.solutions.parking_management",
        "documentation": {}
    },
    {
        "label": "ParkingManagement",
        "kind": 6,
        "importPath": "ultralytics.solutions.parking_management",
        "description": "ultralytics.solutions.parking_management",
        "peekOfCode": "class ParkingManagement:\n    \"\"\"Manages parking occupancy and availability using YOLOv8 for real-time monitoring and visualization.\"\"\"\n    def __init__(\n        self,\n        model_path,\n        txt_color=(0, 0, 0),\n        bg_color=(255, 255, 255),\n        occupied_region_color=(0, 255, 0),\n        available_region_color=(0, 0, 255),\n        margin=10,",
        "detail": "ultralytics.solutions.parking_management",
        "documentation": {}
    },
    {
        "label": "QueueManager",
        "kind": 6,
        "importPath": "ultralytics.solutions.queue_management",
        "description": "ultralytics.solutions.queue_management",
        "peekOfCode": "class QueueManager:\n    \"\"\"A class to manage the queue in a real-time video stream based on object tracks.\"\"\"\n    def __init__(\n        self,\n        names,\n        reg_pts=None,\n        line_thickness=2,\n        track_thickness=2,\n        view_img=False,\n        region_color=(255, 0, 255),",
        "detail": "ultralytics.solutions.queue_management",
        "documentation": {}
    },
    {
        "label": "SpeedEstimator",
        "kind": 6,
        "importPath": "ultralytics.solutions.speed_estimation",
        "description": "ultralytics.solutions.speed_estimation",
        "peekOfCode": "class SpeedEstimator:\n    \"\"\"A class to estimate the speed of objects in a real-time video stream based on their tracks.\"\"\"\n    def __init__(self, names, reg_pts=None, view_img=False, line_thickness=2, region_thickness=5, spdl_dist_thresh=10):\n        \"\"\"\n        Initializes the SpeedEstimator with the given parameters.\n        Args:\n            names (dict): Dictionary of class names.\n            reg_pts (list, optional): List of region points for speed estimation. Defaults to [(20, 400), (1260, 400)].\n            view_img (bool, optional): Whether to display the image with annotations. Defaults to False.\n            line_thickness (int, optional): Thickness of the lines for drawing boxes and tracks. Defaults to 2.",
        "detail": "ultralytics.solutions.speed_estimation",
        "documentation": {}
    },
    {
        "label": "inference",
        "kind": 2,
        "importPath": "ultralytics.solutions.streamlit_inference",
        "description": "ultralytics.solutions.streamlit_inference",
        "peekOfCode": "def inference(model=None):\n    \"\"\"Runs real-time object detection on video input using Ultralytics YOLOv8 in a Streamlit application.\"\"\"\n    check_requirements(\"streamlit>=1.29.0\")  # scope imports for faster ultralytics package load speeds\n    import streamlit as st\n    from ultralytics import YOLO\n    # Hide main menu style\n    menu_style_cfg = \"\"\"<style>MainMenu {visibility: hidden;}</style>\"\"\"\n    # Main title of streamlit application\n    main_title_cfg = \"\"\"<div><h1 style=\"color:#FF64DA; text-align:center; font-size:40px; \n                             font-family: 'Archivo', sans-serif; margin-top:-50px;margin-bottom:20px;\">",
        "detail": "ultralytics.solutions.streamlit_inference",
        "documentation": {}
    },
    {
        "label": "GMC",
        "kind": 6,
        "importPath": "ultralytics.trackers.utils.gmc",
        "description": "ultralytics.trackers.utils.gmc",
        "peekOfCode": "class GMC:\n    \"\"\"\n    Generalized Motion Compensation (GMC) class for tracking and object detection in video frames.\n    This class provides methods for tracking and detecting objects based on several tracking algorithms including ORB,\n    SIFT, ECC, and Sparse Optical Flow. It also supports downscaling of frames for computational efficiency.\n    Attributes:\n        method (str): The method used for tracking. Options include 'orb', 'sift', 'ecc', 'sparseOptFlow', 'none'.\n        downscale (int): Factor by which to downscale the frames for processing.\n        prevFrame (np.ndarray): Stores the previous frame for tracking.\n        prevKeyPoints (list): Stores the keypoints from the previous frame.",
        "detail": "ultralytics.trackers.utils.gmc",
        "documentation": {}
    },
    {
        "label": "KalmanFilterXYAH",
        "kind": 6,
        "importPath": "ultralytics.trackers.utils.kalman_filter",
        "description": "ultralytics.trackers.utils.kalman_filter",
        "peekOfCode": "class KalmanFilterXYAH:\n    \"\"\"\n    For bytetrack. A simple Kalman filter for tracking bounding boxes in image space.\n    The 8-dimensional state space (x, y, a, h, vx, vy, va, vh) contains the bounding box center position (x, y), aspect\n    ratio a, height h, and their respective velocities.\n    Object motion follows a constant velocity model. The bounding box location (x, y, a, h) is taken as direct\n    observation of the state space (linear observation model).\n    \"\"\"\n    def __init__(self):\n        \"\"\"Initialize Kalman filter model matrices with motion and observation uncertainty weights.\"\"\"",
        "detail": "ultralytics.trackers.utils.kalman_filter",
        "documentation": {}
    },
    {
        "label": "KalmanFilterXYWH",
        "kind": 6,
        "importPath": "ultralytics.trackers.utils.kalman_filter",
        "description": "ultralytics.trackers.utils.kalman_filter",
        "peekOfCode": "class KalmanFilterXYWH(KalmanFilterXYAH):\n    \"\"\"\n    For BoT-SORT. A simple Kalman filter for tracking bounding boxes in image space.\n    The 8-dimensional state space (x, y, w, h, vx, vy, vw, vh) contains the bounding box center position (x, y), width\n    w, height h, and their respective velocities.\n    Object motion follows a constant velocity model. The bounding box location (x, y, w, h) is taken as direct\n    observation of the state space (linear observation model).\n    \"\"\"\n    def initiate(self, measurement: np.ndarray) -> tuple:\n        \"\"\"",
        "detail": "ultralytics.trackers.utils.kalman_filter",
        "documentation": {}
    },
    {
        "label": "linear_assignment",
        "kind": 2,
        "importPath": "ultralytics.trackers.utils.matching",
        "description": "ultralytics.trackers.utils.matching",
        "peekOfCode": "def linear_assignment(cost_matrix: np.ndarray, thresh: float, use_lap: bool = True) -> tuple:\n    \"\"\"\n    Perform linear assignment using scipy or lap.lapjv.\n    Args:\n        cost_matrix (np.ndarray): The matrix containing cost values for assignments.\n        thresh (float): Threshold for considering an assignment valid.\n        use_lap (bool, optional): Whether to use lap.lapjv. Defaults to True.\n    Returns:\n        Tuple with:\n            - matched indices",
        "detail": "ultralytics.trackers.utils.matching",
        "documentation": {}
    },
    {
        "label": "iou_distance",
        "kind": 2,
        "importPath": "ultralytics.trackers.utils.matching",
        "description": "ultralytics.trackers.utils.matching",
        "peekOfCode": "def iou_distance(atracks: list, btracks: list) -> np.ndarray:\n    \"\"\"\n    Compute cost based on Intersection over Union (IoU) between tracks.\n    Args:\n        atracks (list[STrack] | list[np.ndarray]): List of tracks 'a' or bounding boxes.\n        btracks (list[STrack] | list[np.ndarray]): List of tracks 'b' or bounding boxes.\n    Returns:\n        (np.ndarray): Cost matrix computed based on IoU.\n    \"\"\"\n    if atracks and isinstance(atracks[0], np.ndarray) or btracks and isinstance(btracks[0], np.ndarray):",
        "detail": "ultralytics.trackers.utils.matching",
        "documentation": {}
    },
    {
        "label": "embedding_distance",
        "kind": 2,
        "importPath": "ultralytics.trackers.utils.matching",
        "description": "ultralytics.trackers.utils.matching",
        "peekOfCode": "def embedding_distance(tracks: list, detections: list, metric: str = \"cosine\") -> np.ndarray:\n    \"\"\"\n    Compute distance between tracks and detections based on embeddings.\n    Args:\n        tracks (list[STrack]): List of tracks.\n        detections (list[BaseTrack]): List of detections.\n        metric (str, optional): Metric for distance computation. Defaults to 'cosine'.\n    Returns:\n        (np.ndarray): Cost matrix computed based on embeddings.\n    \"\"\"",
        "detail": "ultralytics.trackers.utils.matching",
        "documentation": {}
    },
    {
        "label": "fuse_score",
        "kind": 2,
        "importPath": "ultralytics.trackers.utils.matching",
        "description": "ultralytics.trackers.utils.matching",
        "peekOfCode": "def fuse_score(cost_matrix: np.ndarray, detections: list) -> np.ndarray:\n    \"\"\"\n    Fuses cost matrix with detection scores to produce a single similarity matrix.\n    Args:\n        cost_matrix (np.ndarray): The matrix containing cost values for assignments.\n        detections (list[BaseTrack]): List of detections with scores.\n    Returns:\n        (np.ndarray): Fused similarity matrix.\n    \"\"\"\n    if cost_matrix.size == 0:",
        "detail": "ultralytics.trackers.utils.matching",
        "documentation": {}
    },
    {
        "label": "TrackState",
        "kind": 6,
        "importPath": "ultralytics.trackers.basetrack",
        "description": "ultralytics.trackers.basetrack",
        "peekOfCode": "class TrackState:\n    \"\"\"\n    Enumeration class representing the possible states of an object being tracked.\n    Attributes:\n        New (int): State when the object is newly detected.\n        Tracked (int): State when the object is successfully tracked in subsequent frames.\n        Lost (int): State when the object is no longer tracked.\n        Removed (int): State when the object is removed from tracking.\n    \"\"\"\n    New = 0",
        "detail": "ultralytics.trackers.basetrack",
        "documentation": {}
    },
    {
        "label": "BaseTrack",
        "kind": 6,
        "importPath": "ultralytics.trackers.basetrack",
        "description": "ultralytics.trackers.basetrack",
        "peekOfCode": "class BaseTrack:\n    \"\"\"\n    Base class for object tracking, providing foundational attributes and methods.\n    Attributes:\n        _count (int): Class-level counter for unique track IDs.\n        track_id (int): Unique identifier for the track.\n        is_activated (bool): Flag indicating whether the track is currently active.\n        state (TrackState): Current state of the track.\n        history (OrderedDict): Ordered history of the track's states.\n        features (list): List of features extracted from the object for tracking.",
        "detail": "ultralytics.trackers.basetrack",
        "documentation": {}
    },
    {
        "label": "BOTrack",
        "kind": 6,
        "importPath": "ultralytics.trackers.bot_sort",
        "description": "ultralytics.trackers.bot_sort",
        "peekOfCode": "class BOTrack(STrack):\n    \"\"\"\n    An extended version of the STrack class for YOLOv8, adding object tracking features.\n    Attributes:\n        shared_kalman (KalmanFilterXYWH): A shared Kalman filter for all instances of BOTrack.\n        smooth_feat (np.ndarray): Smoothed feature vector.\n        curr_feat (np.ndarray): Current feature vector.\n        features (deque): A deque to store feature vectors with a maximum length defined by `feat_history`.\n        alpha (float): Smoothing factor for the exponential moving average of features.\n        mean (np.ndarray): The mean state of the Kalman filter.",
        "detail": "ultralytics.trackers.bot_sort",
        "documentation": {}
    },
    {
        "label": "BOTSORT",
        "kind": 6,
        "importPath": "ultralytics.trackers.bot_sort",
        "description": "ultralytics.trackers.bot_sort",
        "peekOfCode": "class BOTSORT(BYTETracker):\n    \"\"\"\n    An extended version of the BYTETracker class for YOLOv8, designed for object tracking with ReID and GMC algorithm.\n    Attributes:\n        proximity_thresh (float): Threshold for spatial proximity (IoU) between tracks and detections.\n        appearance_thresh (float): Threshold for appearance similarity (ReID embeddings) between tracks and detections.\n        encoder (object): Object to handle ReID embeddings, set to None if ReID is not enabled.\n        gmc (GMC): An instance of the GMC algorithm for data association.\n        args (object): Parsed command-line arguments containing tracking parameters.\n    Methods:",
        "detail": "ultralytics.trackers.bot_sort",
        "documentation": {}
    },
    {
        "label": "STrack",
        "kind": 6,
        "importPath": "ultralytics.trackers.byte_tracker",
        "description": "ultralytics.trackers.byte_tracker",
        "peekOfCode": "class STrack(BaseTrack):\n    \"\"\"\n    Single object tracking representation that uses Kalman filtering for state estimation.\n    This class is responsible for storing all the information regarding individual tracklets and performs state updates\n    and predictions based on Kalman filter.\n    Attributes:\n        shared_kalman (KalmanFilterXYAH): Shared Kalman filter that is used across all STrack instances for prediction.\n        _tlwh (np.ndarray): Private attribute to store top-left corner coordinates and width and height of bounding box.\n        kalman_filter (KalmanFilterXYAH): Instance of Kalman filter used for this particular object track.\n        mean (np.ndarray): Mean state estimate vector.",
        "detail": "ultralytics.trackers.byte_tracker",
        "documentation": {}
    },
    {
        "label": "BYTETracker",
        "kind": 6,
        "importPath": "ultralytics.trackers.byte_tracker",
        "description": "ultralytics.trackers.byte_tracker",
        "peekOfCode": "class BYTETracker:\n    \"\"\"\n    BYTETracker: A tracking algorithm built on top of YOLOv8 for object detection and tracking.\n    The class is responsible for initializing, updating, and managing the tracks for detected objects in a video\n    sequence. It maintains the state of tracked, lost, and removed tracks over frames, utilizes Kalman filtering for\n    predicting the new object locations, and performs data association.\n    Attributes:\n        tracked_stracks (list[STrack]): List of successfully activated tracks.\n        lost_stracks (list[STrack]): List of lost tracks.\n        removed_stracks (list[STrack]): List of removed tracks.",
        "detail": "ultralytics.trackers.byte_tracker",
        "documentation": {}
    },
    {
        "label": "on_predict_start",
        "kind": 2,
        "importPath": "ultralytics.trackers.track",
        "description": "ultralytics.trackers.track",
        "peekOfCode": "def on_predict_start(predictor: object, persist: bool = False) -> None:\n    \"\"\"\n    Initialize trackers for object tracking during prediction.\n    Args:\n        predictor (object): The predictor object to initialize trackers for.\n        persist (bool, optional): Whether to persist the trackers if they already exist. Defaults to False.\n    Raises:\n        AssertionError: If the tracker_type is not 'bytetrack' or 'botsort'.\n    \"\"\"\n    if hasattr(predictor, \"trackers\") and persist:",
        "detail": "ultralytics.trackers.track",
        "documentation": {}
    },
    {
        "label": "on_predict_postprocess_end",
        "kind": 2,
        "importPath": "ultralytics.trackers.track",
        "description": "ultralytics.trackers.track",
        "peekOfCode": "def on_predict_postprocess_end(predictor: object, persist: bool = False) -> None:\n    \"\"\"\n    Postprocess detected boxes and update with object tracking.\n    Args:\n        predictor (object): The predictor object containing the predictions.\n        persist (bool, optional): Whether to persist the trackers if they already exist. Defaults to False.\n    \"\"\"\n    path, im0s = predictor.batch[:2]\n    is_obb = predictor.args.task == \"obb\"\n    is_stream = predictor.dataset.mode == \"stream\"",
        "detail": "ultralytics.trackers.track",
        "documentation": {}
    },
    {
        "label": "register_tracker",
        "kind": 2,
        "importPath": "ultralytics.trackers.track",
        "description": "ultralytics.trackers.track",
        "peekOfCode": "def register_tracker(model: object, persist: bool) -> None:\n    \"\"\"\n    Register tracking callbacks to the model for object tracking during prediction.\n    Args:\n        model (object): The model object to register tracking callbacks for.\n        persist (bool): Whether to persist the trackers if they already exist.\n    \"\"\"\n    model.add_callback(\"on_predict_start\", partial(on_predict_start, persist=persist))\n    model.add_callback(\"on_predict_postprocess_end\", partial(on_predict_postprocess_end, persist=persist))",
        "detail": "ultralytics.trackers.track",
        "documentation": {}
    },
    {
        "label": "TRACKER_MAP",
        "kind": 5,
        "importPath": "ultralytics.trackers.track",
        "description": "ultralytics.trackers.track",
        "peekOfCode": "TRACKER_MAP = {\"bytetrack\": BYTETracker, \"botsort\": BOTSORT}\ndef on_predict_start(predictor: object, persist: bool = False) -> None:\n    \"\"\"\n    Initialize trackers for object tracking during prediction.\n    Args:\n        predictor (object): The predictor object to initialize trackers for.\n        persist (bool, optional): Whether to persist the trackers if they already exist. Defaults to False.\n    Raises:\n        AssertionError: If the tracker_type is not 'bytetrack' or 'botsort'.\n    \"\"\"",
        "detail": "ultralytics.trackers.track",
        "documentation": {}
    },
    {
        "label": "on_pretrain_routine_start",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.base",
        "description": "ultralytics.utils.callbacks.base",
        "peekOfCode": "def on_pretrain_routine_start(trainer):\n    \"\"\"Called before the pretraining routine starts.\"\"\"\n    pass\ndef on_pretrain_routine_end(trainer):\n    \"\"\"Called after the pretraining routine ends.\"\"\"\n    pass\ndef on_train_start(trainer):\n    \"\"\"Called when the training starts.\"\"\"\n    pass\ndef on_train_epoch_start(trainer):",
        "detail": "ultralytics.utils.callbacks.base",
        "documentation": {}
    },
    {
        "label": "on_pretrain_routine_end",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.base",
        "description": "ultralytics.utils.callbacks.base",
        "peekOfCode": "def on_pretrain_routine_end(trainer):\n    \"\"\"Called after the pretraining routine ends.\"\"\"\n    pass\ndef on_train_start(trainer):\n    \"\"\"Called when the training starts.\"\"\"\n    pass\ndef on_train_epoch_start(trainer):\n    \"\"\"Called at the start of each training epoch.\"\"\"\n    pass\ndef on_train_batch_start(trainer):",
        "detail": "ultralytics.utils.callbacks.base",
        "documentation": {}
    },
    {
        "label": "on_train_start",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.base",
        "description": "ultralytics.utils.callbacks.base",
        "peekOfCode": "def on_train_start(trainer):\n    \"\"\"Called when the training starts.\"\"\"\n    pass\ndef on_train_epoch_start(trainer):\n    \"\"\"Called at the start of each training epoch.\"\"\"\n    pass\ndef on_train_batch_start(trainer):\n    \"\"\"Called at the start of each training batch.\"\"\"\n    pass\ndef optimizer_step(trainer):",
        "detail": "ultralytics.utils.callbacks.base",
        "documentation": {}
    },
    {
        "label": "on_train_epoch_start",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.base",
        "description": "ultralytics.utils.callbacks.base",
        "peekOfCode": "def on_train_epoch_start(trainer):\n    \"\"\"Called at the start of each training epoch.\"\"\"\n    pass\ndef on_train_batch_start(trainer):\n    \"\"\"Called at the start of each training batch.\"\"\"\n    pass\ndef optimizer_step(trainer):\n    \"\"\"Called when the optimizer takes a step.\"\"\"\n    pass\ndef on_before_zero_grad(trainer):",
        "detail": "ultralytics.utils.callbacks.base",
        "documentation": {}
    },
    {
        "label": "on_train_batch_start",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.base",
        "description": "ultralytics.utils.callbacks.base",
        "peekOfCode": "def on_train_batch_start(trainer):\n    \"\"\"Called at the start of each training batch.\"\"\"\n    pass\ndef optimizer_step(trainer):\n    \"\"\"Called when the optimizer takes a step.\"\"\"\n    pass\ndef on_before_zero_grad(trainer):\n    \"\"\"Called before the gradients are set to zero.\"\"\"\n    pass\ndef on_train_batch_end(trainer):",
        "detail": "ultralytics.utils.callbacks.base",
        "documentation": {}
    },
    {
        "label": "optimizer_step",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.base",
        "description": "ultralytics.utils.callbacks.base",
        "peekOfCode": "def optimizer_step(trainer):\n    \"\"\"Called when the optimizer takes a step.\"\"\"\n    pass\ndef on_before_zero_grad(trainer):\n    \"\"\"Called before the gradients are set to zero.\"\"\"\n    pass\ndef on_train_batch_end(trainer):\n    \"\"\"Called at the end of each training batch.\"\"\"\n    pass\ndef on_train_epoch_end(trainer):",
        "detail": "ultralytics.utils.callbacks.base",
        "documentation": {}
    },
    {
        "label": "on_before_zero_grad",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.base",
        "description": "ultralytics.utils.callbacks.base",
        "peekOfCode": "def on_before_zero_grad(trainer):\n    \"\"\"Called before the gradients are set to zero.\"\"\"\n    pass\ndef on_train_batch_end(trainer):\n    \"\"\"Called at the end of each training batch.\"\"\"\n    pass\ndef on_train_epoch_end(trainer):\n    \"\"\"Called at the end of each training epoch.\"\"\"\n    pass\ndef on_fit_epoch_end(trainer):",
        "detail": "ultralytics.utils.callbacks.base",
        "documentation": {}
    },
    {
        "label": "on_train_batch_end",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.base",
        "description": "ultralytics.utils.callbacks.base",
        "peekOfCode": "def on_train_batch_end(trainer):\n    \"\"\"Called at the end of each training batch.\"\"\"\n    pass\ndef on_train_epoch_end(trainer):\n    \"\"\"Called at the end of each training epoch.\"\"\"\n    pass\ndef on_fit_epoch_end(trainer):\n    \"\"\"Called at the end of each fit epoch (train + val).\"\"\"\n    pass\ndef on_model_save(trainer):",
        "detail": "ultralytics.utils.callbacks.base",
        "documentation": {}
    },
    {
        "label": "on_train_epoch_end",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.base",
        "description": "ultralytics.utils.callbacks.base",
        "peekOfCode": "def on_train_epoch_end(trainer):\n    \"\"\"Called at the end of each training epoch.\"\"\"\n    pass\ndef on_fit_epoch_end(trainer):\n    \"\"\"Called at the end of each fit epoch (train + val).\"\"\"\n    pass\ndef on_model_save(trainer):\n    \"\"\"Called when the model is saved.\"\"\"\n    pass\ndef on_train_end(trainer):",
        "detail": "ultralytics.utils.callbacks.base",
        "documentation": {}
    },
    {
        "label": "on_fit_epoch_end",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.base",
        "description": "ultralytics.utils.callbacks.base",
        "peekOfCode": "def on_fit_epoch_end(trainer):\n    \"\"\"Called at the end of each fit epoch (train + val).\"\"\"\n    pass\ndef on_model_save(trainer):\n    \"\"\"Called when the model is saved.\"\"\"\n    pass\ndef on_train_end(trainer):\n    \"\"\"Called when the training ends.\"\"\"\n    pass\ndef on_params_update(trainer):",
        "detail": "ultralytics.utils.callbacks.base",
        "documentation": {}
    },
    {
        "label": "on_model_save",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.base",
        "description": "ultralytics.utils.callbacks.base",
        "peekOfCode": "def on_model_save(trainer):\n    \"\"\"Called when the model is saved.\"\"\"\n    pass\ndef on_train_end(trainer):\n    \"\"\"Called when the training ends.\"\"\"\n    pass\ndef on_params_update(trainer):\n    \"\"\"Called when the model parameters are updated.\"\"\"\n    pass\ndef teardown(trainer):",
        "detail": "ultralytics.utils.callbacks.base",
        "documentation": {}
    },
    {
        "label": "on_train_end",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.base",
        "description": "ultralytics.utils.callbacks.base",
        "peekOfCode": "def on_train_end(trainer):\n    \"\"\"Called when the training ends.\"\"\"\n    pass\ndef on_params_update(trainer):\n    \"\"\"Called when the model parameters are updated.\"\"\"\n    pass\ndef teardown(trainer):\n    \"\"\"Called during the teardown of the training process.\"\"\"\n    pass\n# Validator callbacks --------------------------------------------------------------------------------------------------",
        "detail": "ultralytics.utils.callbacks.base",
        "documentation": {}
    },
    {
        "label": "on_params_update",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.base",
        "description": "ultralytics.utils.callbacks.base",
        "peekOfCode": "def on_params_update(trainer):\n    \"\"\"Called when the model parameters are updated.\"\"\"\n    pass\ndef teardown(trainer):\n    \"\"\"Called during the teardown of the training process.\"\"\"\n    pass\n# Validator callbacks --------------------------------------------------------------------------------------------------\ndef on_val_start(validator):\n    \"\"\"Called when the validation starts.\"\"\"\n    pass",
        "detail": "ultralytics.utils.callbacks.base",
        "documentation": {}
    },
    {
        "label": "teardown",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.base",
        "description": "ultralytics.utils.callbacks.base",
        "peekOfCode": "def teardown(trainer):\n    \"\"\"Called during the teardown of the training process.\"\"\"\n    pass\n# Validator callbacks --------------------------------------------------------------------------------------------------\ndef on_val_start(validator):\n    \"\"\"Called when the validation starts.\"\"\"\n    pass\ndef on_val_batch_start(validator):\n    \"\"\"Called at the start of each validation batch.\"\"\"\n    pass",
        "detail": "ultralytics.utils.callbacks.base",
        "documentation": {}
    },
    {
        "label": "on_val_start",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.base",
        "description": "ultralytics.utils.callbacks.base",
        "peekOfCode": "def on_val_start(validator):\n    \"\"\"Called when the validation starts.\"\"\"\n    pass\ndef on_val_batch_start(validator):\n    \"\"\"Called at the start of each validation batch.\"\"\"\n    pass\ndef on_val_batch_end(validator):\n    \"\"\"Called at the end of each validation batch.\"\"\"\n    pass\ndef on_val_end(validator):",
        "detail": "ultralytics.utils.callbacks.base",
        "documentation": {}
    },
    {
        "label": "on_val_batch_start",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.base",
        "description": "ultralytics.utils.callbacks.base",
        "peekOfCode": "def on_val_batch_start(validator):\n    \"\"\"Called at the start of each validation batch.\"\"\"\n    pass\ndef on_val_batch_end(validator):\n    \"\"\"Called at the end of each validation batch.\"\"\"\n    pass\ndef on_val_end(validator):\n    \"\"\"Called when the validation ends.\"\"\"\n    pass\n# Predictor callbacks --------------------------------------------------------------------------------------------------",
        "detail": "ultralytics.utils.callbacks.base",
        "documentation": {}
    },
    {
        "label": "on_val_batch_end",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.base",
        "description": "ultralytics.utils.callbacks.base",
        "peekOfCode": "def on_val_batch_end(validator):\n    \"\"\"Called at the end of each validation batch.\"\"\"\n    pass\ndef on_val_end(validator):\n    \"\"\"Called when the validation ends.\"\"\"\n    pass\n# Predictor callbacks --------------------------------------------------------------------------------------------------\ndef on_predict_start(predictor):\n    \"\"\"Called when the prediction starts.\"\"\"\n    pass",
        "detail": "ultralytics.utils.callbacks.base",
        "documentation": {}
    },
    {
        "label": "on_val_end",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.base",
        "description": "ultralytics.utils.callbacks.base",
        "peekOfCode": "def on_val_end(validator):\n    \"\"\"Called when the validation ends.\"\"\"\n    pass\n# Predictor callbacks --------------------------------------------------------------------------------------------------\ndef on_predict_start(predictor):\n    \"\"\"Called when the prediction starts.\"\"\"\n    pass\ndef on_predict_batch_start(predictor):\n    \"\"\"Called at the start of each prediction batch.\"\"\"\n    pass",
        "detail": "ultralytics.utils.callbacks.base",
        "documentation": {}
    },
    {
        "label": "on_predict_start",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.base",
        "description": "ultralytics.utils.callbacks.base",
        "peekOfCode": "def on_predict_start(predictor):\n    \"\"\"Called when the prediction starts.\"\"\"\n    pass\ndef on_predict_batch_start(predictor):\n    \"\"\"Called at the start of each prediction batch.\"\"\"\n    pass\ndef on_predict_batch_end(predictor):\n    \"\"\"Called at the end of each prediction batch.\"\"\"\n    pass\ndef on_predict_postprocess_end(predictor):",
        "detail": "ultralytics.utils.callbacks.base",
        "documentation": {}
    },
    {
        "label": "on_predict_batch_start",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.base",
        "description": "ultralytics.utils.callbacks.base",
        "peekOfCode": "def on_predict_batch_start(predictor):\n    \"\"\"Called at the start of each prediction batch.\"\"\"\n    pass\ndef on_predict_batch_end(predictor):\n    \"\"\"Called at the end of each prediction batch.\"\"\"\n    pass\ndef on_predict_postprocess_end(predictor):\n    \"\"\"Called after the post-processing of the prediction ends.\"\"\"\n    pass\ndef on_predict_end(predictor):",
        "detail": "ultralytics.utils.callbacks.base",
        "documentation": {}
    },
    {
        "label": "on_predict_batch_end",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.base",
        "description": "ultralytics.utils.callbacks.base",
        "peekOfCode": "def on_predict_batch_end(predictor):\n    \"\"\"Called at the end of each prediction batch.\"\"\"\n    pass\ndef on_predict_postprocess_end(predictor):\n    \"\"\"Called after the post-processing of the prediction ends.\"\"\"\n    pass\ndef on_predict_end(predictor):\n    \"\"\"Called when the prediction ends.\"\"\"\n    pass\n# Exporter callbacks ---------------------------------------------------------------------------------------------------",
        "detail": "ultralytics.utils.callbacks.base",
        "documentation": {}
    },
    {
        "label": "on_predict_postprocess_end",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.base",
        "description": "ultralytics.utils.callbacks.base",
        "peekOfCode": "def on_predict_postprocess_end(predictor):\n    \"\"\"Called after the post-processing of the prediction ends.\"\"\"\n    pass\ndef on_predict_end(predictor):\n    \"\"\"Called when the prediction ends.\"\"\"\n    pass\n# Exporter callbacks ---------------------------------------------------------------------------------------------------\ndef on_export_start(exporter):\n    \"\"\"Called when the model export starts.\"\"\"\n    pass",
        "detail": "ultralytics.utils.callbacks.base",
        "documentation": {}
    },
    {
        "label": "on_predict_end",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.base",
        "description": "ultralytics.utils.callbacks.base",
        "peekOfCode": "def on_predict_end(predictor):\n    \"\"\"Called when the prediction ends.\"\"\"\n    pass\n# Exporter callbacks ---------------------------------------------------------------------------------------------------\ndef on_export_start(exporter):\n    \"\"\"Called when the model export starts.\"\"\"\n    pass\ndef on_export_end(exporter):\n    \"\"\"Called when the model export ends.\"\"\"\n    pass",
        "detail": "ultralytics.utils.callbacks.base",
        "documentation": {}
    },
    {
        "label": "on_export_start",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.base",
        "description": "ultralytics.utils.callbacks.base",
        "peekOfCode": "def on_export_start(exporter):\n    \"\"\"Called when the model export starts.\"\"\"\n    pass\ndef on_export_end(exporter):\n    \"\"\"Called when the model export ends.\"\"\"\n    pass\ndefault_callbacks = {\n    # Run in trainer\n    \"on_pretrain_routine_start\": [on_pretrain_routine_start],\n    \"on_pretrain_routine_end\": [on_pretrain_routine_end],",
        "detail": "ultralytics.utils.callbacks.base",
        "documentation": {}
    },
    {
        "label": "on_export_end",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.base",
        "description": "ultralytics.utils.callbacks.base",
        "peekOfCode": "def on_export_end(exporter):\n    \"\"\"Called when the model export ends.\"\"\"\n    pass\ndefault_callbacks = {\n    # Run in trainer\n    \"on_pretrain_routine_start\": [on_pretrain_routine_start],\n    \"on_pretrain_routine_end\": [on_pretrain_routine_end],\n    \"on_train_start\": [on_train_start],\n    \"on_train_epoch_start\": [on_train_epoch_start],\n    \"on_train_batch_start\": [on_train_batch_start],",
        "detail": "ultralytics.utils.callbacks.base",
        "documentation": {}
    },
    {
        "label": "get_default_callbacks",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.base",
        "description": "ultralytics.utils.callbacks.base",
        "peekOfCode": "def get_default_callbacks():\n    \"\"\"\n    Return a copy of the default_callbacks dictionary with lists as default values.\n    Returns:\n        (defaultdict): A defaultdict with keys from default_callbacks and empty lists as default values.\n    \"\"\"\n    return defaultdict(list, deepcopy(default_callbacks))\ndef add_integration_callbacks(instance):\n    \"\"\"\n    Add integration callbacks from various sources to the instance's callbacks.",
        "detail": "ultralytics.utils.callbacks.base",
        "documentation": {}
    },
    {
        "label": "add_integration_callbacks",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.base",
        "description": "ultralytics.utils.callbacks.base",
        "peekOfCode": "def add_integration_callbacks(instance):\n    \"\"\"\n    Add integration callbacks from various sources to the instance's callbacks.\n    Args:\n        instance (Trainer, Predictor, Validator, Exporter): An object with a 'callbacks' attribute that is a dictionary\n            of callback lists.\n    \"\"\"\n    # Load HUB callbacks\n    from .hub import callbacks as hub_cb\n    callbacks_list = [hub_cb]",
        "detail": "ultralytics.utils.callbacks.base",
        "documentation": {}
    },
    {
        "label": "default_callbacks",
        "kind": 5,
        "importPath": "ultralytics.utils.callbacks.base",
        "description": "ultralytics.utils.callbacks.base",
        "peekOfCode": "default_callbacks = {\n    # Run in trainer\n    \"on_pretrain_routine_start\": [on_pretrain_routine_start],\n    \"on_pretrain_routine_end\": [on_pretrain_routine_end],\n    \"on_train_start\": [on_train_start],\n    \"on_train_epoch_start\": [on_train_epoch_start],\n    \"on_train_batch_start\": [on_train_batch_start],\n    \"optimizer_step\": [optimizer_step],\n    \"on_before_zero_grad\": [on_before_zero_grad],\n    \"on_train_batch_end\": [on_train_batch_end],",
        "detail": "ultralytics.utils.callbacks.base",
        "documentation": {}
    },
    {
        "label": "on_pretrain_routine_start",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.clearml",
        "description": "ultralytics.utils.callbacks.clearml",
        "peekOfCode": "def on_pretrain_routine_start(trainer):\n    \"\"\"Runs at start of pretraining routine; initializes and connects/ logs task to ClearML.\"\"\"\n    try:\n        if task := Task.current_task():\n            # WARNING: make sure the automatic pytorch and matplotlib bindings are disabled!\n            # We are logging these plots and model files manually in the integration\n            from clearml.binding.frameworks.pytorch_bind import PatchPyTorchModelIO\n            from clearml.binding.matplotlib_bind import PatchedMatplotlib\n            PatchPyTorchModelIO.update_current_task(None)\n            PatchedMatplotlib.update_current_task(None)",
        "detail": "ultralytics.utils.callbacks.clearml",
        "documentation": {}
    },
    {
        "label": "on_train_epoch_end",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.clearml",
        "description": "ultralytics.utils.callbacks.clearml",
        "peekOfCode": "def on_train_epoch_end(trainer):\n    \"\"\"Logs debug samples for the first epoch of YOLO training and report current training progress.\"\"\"\n    if task := Task.current_task():\n        # Log debug samples\n        if trainer.epoch == 1:\n            _log_debug_samples(sorted(trainer.save_dir.glob(\"train_batch*.jpg\")), \"Mosaic\")\n        # Report the current training progress\n        for k, v in trainer.label_loss_items(trainer.tloss, prefix=\"train\").items():\n            task.get_logger().report_scalar(\"train\", k, v, iteration=trainer.epoch)\n        for k, v in trainer.lr.items():",
        "detail": "ultralytics.utils.callbacks.clearml",
        "documentation": {}
    },
    {
        "label": "on_fit_epoch_end",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.clearml",
        "description": "ultralytics.utils.callbacks.clearml",
        "peekOfCode": "def on_fit_epoch_end(trainer):\n    \"\"\"Reports model information to logger at the end of an epoch.\"\"\"\n    if task := Task.current_task():\n        # You should have access to the validation bboxes under jdict\n        task.get_logger().report_scalar(\n            title=\"Epoch Time\", series=\"Epoch Time\", value=trainer.epoch_time, iteration=trainer.epoch\n        )\n        for k, v in trainer.metrics.items():\n            task.get_logger().report_scalar(\"val\", k, v, iteration=trainer.epoch)\n        if trainer.epoch == 0:",
        "detail": "ultralytics.utils.callbacks.clearml",
        "documentation": {}
    },
    {
        "label": "on_val_end",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.clearml",
        "description": "ultralytics.utils.callbacks.clearml",
        "peekOfCode": "def on_val_end(validator):\n    \"\"\"Logs validation results including labels and predictions.\"\"\"\n    if Task.current_task():\n        # Log val_labels and val_pred\n        _log_debug_samples(sorted(validator.save_dir.glob(\"val*.jpg\")), \"Validation\")\ndef on_train_end(trainer):\n    \"\"\"Logs final model and its name on training completion.\"\"\"\n    if task := Task.current_task():\n        # Log final results, CM matrix + PR plots\n        files = [",
        "detail": "ultralytics.utils.callbacks.clearml",
        "documentation": {}
    },
    {
        "label": "on_train_end",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.clearml",
        "description": "ultralytics.utils.callbacks.clearml",
        "peekOfCode": "def on_train_end(trainer):\n    \"\"\"Logs final model and its name on training completion.\"\"\"\n    if task := Task.current_task():\n        # Log final results, CM matrix + PR plots\n        files = [\n            \"results.png\",\n            \"confusion_matrix.png\",\n            \"confusion_matrix_normalized.png\",\n            *(f\"{x}_curve.png\" for x in (\"F1\", \"PR\", \"P\", \"R\")),\n        ]",
        "detail": "ultralytics.utils.callbacks.clearml",
        "documentation": {}
    },
    {
        "label": "callbacks",
        "kind": 5,
        "importPath": "ultralytics.utils.callbacks.clearml",
        "description": "ultralytics.utils.callbacks.clearml",
        "peekOfCode": "callbacks = (\n    {\n        \"on_pretrain_routine_start\": on_pretrain_routine_start,\n        \"on_train_epoch_end\": on_train_epoch_end,\n        \"on_fit_epoch_end\": on_fit_epoch_end,\n        \"on_val_end\": on_val_end,\n        \"on_train_end\": on_train_end,\n    }\n    if clearml\n    else {}",
        "detail": "ultralytics.utils.callbacks.clearml",
        "documentation": {}
    },
    {
        "label": "on_pretrain_routine_start",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.comet",
        "description": "ultralytics.utils.callbacks.comet",
        "peekOfCode": "def on_pretrain_routine_start(trainer):\n    \"\"\"Creates or resumes a CometML experiment at the start of a YOLO pre-training routine.\"\"\"\n    experiment = comet_ml.get_global_experiment()\n    is_alive = getattr(experiment, \"alive\", False)\n    if not experiment or not is_alive:\n        _create_experiment(trainer.args)\ndef on_train_epoch_end(trainer):\n    \"\"\"Log metrics and save batch images at the end of training epochs.\"\"\"\n    experiment = comet_ml.get_global_experiment()\n    if not experiment:",
        "detail": "ultralytics.utils.callbacks.comet",
        "documentation": {}
    },
    {
        "label": "on_train_epoch_end",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.comet",
        "description": "ultralytics.utils.callbacks.comet",
        "peekOfCode": "def on_train_epoch_end(trainer):\n    \"\"\"Log metrics and save batch images at the end of training epochs.\"\"\"\n    experiment = comet_ml.get_global_experiment()\n    if not experiment:\n        return\n    metadata = _fetch_trainer_metadata(trainer)\n    curr_epoch = metadata[\"curr_epoch\"]\n    curr_step = metadata[\"curr_step\"]\n    experiment.log_metrics(trainer.label_loss_items(trainer.tloss, prefix=\"train\"), step=curr_step, epoch=curr_epoch)\n    if curr_epoch == 1:",
        "detail": "ultralytics.utils.callbacks.comet",
        "documentation": {}
    },
    {
        "label": "on_fit_epoch_end",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.comet",
        "description": "ultralytics.utils.callbacks.comet",
        "peekOfCode": "def on_fit_epoch_end(trainer):\n    \"\"\"Logs model assets at the end of each epoch.\"\"\"\n    experiment = comet_ml.get_global_experiment()\n    if not experiment:\n        return\n    metadata = _fetch_trainer_metadata(trainer)\n    curr_epoch = metadata[\"curr_epoch\"]\n    curr_step = metadata[\"curr_step\"]\n    save_assets = metadata[\"save_assets\"]\n    experiment.log_metrics(trainer.metrics, step=curr_step, epoch=curr_epoch)",
        "detail": "ultralytics.utils.callbacks.comet",
        "documentation": {}
    },
    {
        "label": "on_train_end",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.comet",
        "description": "ultralytics.utils.callbacks.comet",
        "peekOfCode": "def on_train_end(trainer):\n    \"\"\"Perform operations at the end of training.\"\"\"\n    experiment = comet_ml.get_global_experiment()\n    if not experiment:\n        return\n    metadata = _fetch_trainer_metadata(trainer)\n    curr_epoch = metadata[\"curr_epoch\"]\n    curr_step = metadata[\"curr_step\"]\n    plots = trainer.args.plots\n    _log_model(experiment, trainer)",
        "detail": "ultralytics.utils.callbacks.comet",
        "documentation": {}
    },
    {
        "label": "callbacks",
        "kind": 5,
        "importPath": "ultralytics.utils.callbacks.comet",
        "description": "ultralytics.utils.callbacks.comet",
        "peekOfCode": "callbacks = (\n    {\n        \"on_pretrain_routine_start\": on_pretrain_routine_start,\n        \"on_train_epoch_end\": on_train_epoch_end,\n        \"on_fit_epoch_end\": on_fit_epoch_end,\n        \"on_train_end\": on_train_end,\n    }\n    if comet_ml\n    else {}\n)",
        "detail": "ultralytics.utils.callbacks.comet",
        "documentation": {}
    },
    {
        "label": "on_pretrain_routine_start",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.dvc",
        "description": "ultralytics.utils.callbacks.dvc",
        "peekOfCode": "def on_pretrain_routine_start(trainer):\n    \"\"\"Initializes DVCLive logger for training metadata during pre-training routine.\"\"\"\n    try:\n        global live\n        live = dvclive.Live(save_dvc_exp=True, cache_images=True)\n        LOGGER.info(\"DVCLive is detected and auto logging is enabled (run 'yolo settings dvc=False' to disable).\")\n    except Exception as e:\n        LOGGER.warning(f\"WARNING ⚠️ DVCLive installed but not initialized correctly, not logging this run. {e}\")\ndef on_pretrain_routine_end(trainer):\n    \"\"\"Logs plots related to the training process at the end of the pretraining routine.\"\"\"",
        "detail": "ultralytics.utils.callbacks.dvc",
        "documentation": {}
    },
    {
        "label": "on_pretrain_routine_end",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.dvc",
        "description": "ultralytics.utils.callbacks.dvc",
        "peekOfCode": "def on_pretrain_routine_end(trainer):\n    \"\"\"Logs plots related to the training process at the end of the pretraining routine.\"\"\"\n    _log_plots(trainer.plots, \"train\")\ndef on_train_start(trainer):\n    \"\"\"Logs the training parameters if DVCLive logging is active.\"\"\"\n    if live:\n        live.log_params(trainer.args)\ndef on_train_epoch_start(trainer):\n    \"\"\"Sets the global variable _training_epoch value to True at the start of training each epoch.\"\"\"\n    global _training_epoch",
        "detail": "ultralytics.utils.callbacks.dvc",
        "documentation": {}
    },
    {
        "label": "on_train_start",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.dvc",
        "description": "ultralytics.utils.callbacks.dvc",
        "peekOfCode": "def on_train_start(trainer):\n    \"\"\"Logs the training parameters if DVCLive logging is active.\"\"\"\n    if live:\n        live.log_params(trainer.args)\ndef on_train_epoch_start(trainer):\n    \"\"\"Sets the global variable _training_epoch value to True at the start of training each epoch.\"\"\"\n    global _training_epoch\n    _training_epoch = True\ndef on_fit_epoch_end(trainer):\n    \"\"\"Logs training metrics and model info, and advances to next step on the end of each fit epoch.\"\"\"",
        "detail": "ultralytics.utils.callbacks.dvc",
        "documentation": {}
    },
    {
        "label": "on_train_epoch_start",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.dvc",
        "description": "ultralytics.utils.callbacks.dvc",
        "peekOfCode": "def on_train_epoch_start(trainer):\n    \"\"\"Sets the global variable _training_epoch value to True at the start of training each epoch.\"\"\"\n    global _training_epoch\n    _training_epoch = True\ndef on_fit_epoch_end(trainer):\n    \"\"\"Logs training metrics and model info, and advances to next step on the end of each fit epoch.\"\"\"\n    global _training_epoch\n    if live and _training_epoch:\n        all_metrics = {**trainer.label_loss_items(trainer.tloss, prefix=\"train\"), **trainer.metrics, **trainer.lr}\n        for metric, value in all_metrics.items():",
        "detail": "ultralytics.utils.callbacks.dvc",
        "documentation": {}
    },
    {
        "label": "on_fit_epoch_end",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.dvc",
        "description": "ultralytics.utils.callbacks.dvc",
        "peekOfCode": "def on_fit_epoch_end(trainer):\n    \"\"\"Logs training metrics and model info, and advances to next step on the end of each fit epoch.\"\"\"\n    global _training_epoch\n    if live and _training_epoch:\n        all_metrics = {**trainer.label_loss_items(trainer.tloss, prefix=\"train\"), **trainer.metrics, **trainer.lr}\n        for metric, value in all_metrics.items():\n            live.log_metric(metric, value)\n        if trainer.epoch == 0:\n            from ultralytics.utils.torch_utils import model_info_for_loggers\n            for metric, value in model_info_for_loggers(trainer).items():",
        "detail": "ultralytics.utils.callbacks.dvc",
        "documentation": {}
    },
    {
        "label": "on_train_end",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.dvc",
        "description": "ultralytics.utils.callbacks.dvc",
        "peekOfCode": "def on_train_end(trainer):\n    \"\"\"Logs the best metrics, plots, and confusion matrix at the end of training if DVCLive is active.\"\"\"\n    if live:\n        # At the end log the best metrics. It runs validator on the best model internally.\n        all_metrics = {**trainer.label_loss_items(trainer.tloss, prefix=\"train\"), **trainer.metrics, **trainer.lr}\n        for metric, value in all_metrics.items():\n            live.log_metric(metric, value, plot=False)\n        _log_plots(trainer.plots, \"val\")\n        _log_plots(trainer.validator.plots, \"val\")\n        _log_confusion_matrix(trainer.validator)",
        "detail": "ultralytics.utils.callbacks.dvc",
        "documentation": {}
    },
    {
        "label": "callbacks",
        "kind": 5,
        "importPath": "ultralytics.utils.callbacks.dvc",
        "description": "ultralytics.utils.callbacks.dvc",
        "peekOfCode": "callbacks = (\n    {\n        \"on_pretrain_routine_start\": on_pretrain_routine_start,\n        \"on_pretrain_routine_end\": on_pretrain_routine_end,\n        \"on_train_start\": on_train_start,\n        \"on_train_epoch_start\": on_train_epoch_start,\n        \"on_fit_epoch_end\": on_fit_epoch_end,\n        \"on_train_end\": on_train_end,\n    }\n    if dvclive",
        "detail": "ultralytics.utils.callbacks.dvc",
        "documentation": {}
    },
    {
        "label": "on_pretrain_routine_start",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.hub",
        "description": "ultralytics.utils.callbacks.hub",
        "peekOfCode": "def on_pretrain_routine_start(trainer):\n    \"\"\"Create a remote Ultralytics HUB session to log local model training.\"\"\"\n    if RANK in {-1, 0} and SETTINGS[\"hub\"] is True and SETTINGS[\"api_key\"] and trainer.hub_session is None:\n        trainer.hub_session = HUBTrainingSession.create_session(trainer.args.model, trainer.args)\ndef on_pretrain_routine_end(trainer):\n    \"\"\"Logs info before starting timer for upload rate limit.\"\"\"\n    session = getattr(trainer, \"hub_session\", None)\n    if session:\n        # Start timer for upload rate limit\n        session.timers = {\"metrics\": time(), \"ckpt\": time()}  # start timer on session.rate_limit",
        "detail": "ultralytics.utils.callbacks.hub",
        "documentation": {}
    },
    {
        "label": "on_pretrain_routine_end",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.hub",
        "description": "ultralytics.utils.callbacks.hub",
        "peekOfCode": "def on_pretrain_routine_end(trainer):\n    \"\"\"Logs info before starting timer for upload rate limit.\"\"\"\n    session = getattr(trainer, \"hub_session\", None)\n    if session:\n        # Start timer for upload rate limit\n        session.timers = {\"metrics\": time(), \"ckpt\": time()}  # start timer on session.rate_limit\ndef on_fit_epoch_end(trainer):\n    \"\"\"Uploads training progress metrics at the end of each epoch.\"\"\"\n    session = getattr(trainer, \"hub_session\", None)\n    if session:",
        "detail": "ultralytics.utils.callbacks.hub",
        "documentation": {}
    },
    {
        "label": "on_fit_epoch_end",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.hub",
        "description": "ultralytics.utils.callbacks.hub",
        "peekOfCode": "def on_fit_epoch_end(trainer):\n    \"\"\"Uploads training progress metrics at the end of each epoch.\"\"\"\n    session = getattr(trainer, \"hub_session\", None)\n    if session:\n        # Upload metrics after val end\n        all_plots = {\n            **trainer.label_loss_items(trainer.tloss, prefix=\"train\"),\n            **trainer.metrics,\n        }\n        if trainer.epoch == 0:",
        "detail": "ultralytics.utils.callbacks.hub",
        "documentation": {}
    },
    {
        "label": "on_model_save",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.hub",
        "description": "ultralytics.utils.callbacks.hub",
        "peekOfCode": "def on_model_save(trainer):\n    \"\"\"Saves checkpoints to Ultralytics HUB with rate limiting.\"\"\"\n    session = getattr(trainer, \"hub_session\", None)\n    if session:\n        # Upload checkpoints with rate limiting\n        is_best = trainer.best_fitness == trainer.fitness\n        if time() - session.timers[\"ckpt\"] > session.rate_limits[\"ckpt\"]:\n            LOGGER.info(f\"{PREFIX}Uploading checkpoint {HUB_WEB_ROOT}/models/{session.model.id}\")\n            session.upload_model(trainer.epoch, trainer.last, is_best)\n            session.timers[\"ckpt\"] = time()  # reset timer",
        "detail": "ultralytics.utils.callbacks.hub",
        "documentation": {}
    },
    {
        "label": "on_train_end",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.hub",
        "description": "ultralytics.utils.callbacks.hub",
        "peekOfCode": "def on_train_end(trainer):\n    \"\"\"Upload final model and metrics to Ultralytics HUB at the end of training.\"\"\"\n    session = getattr(trainer, \"hub_session\", None)\n    if session:\n        # Upload final model and metrics with exponential standoff\n        LOGGER.info(f\"{PREFIX}Syncing final model...\")\n        session.upload_model(\n            trainer.epoch,\n            trainer.best,\n            map=trainer.metrics.get(\"metrics/mAP50-95(B)\", 0),",
        "detail": "ultralytics.utils.callbacks.hub",
        "documentation": {}
    },
    {
        "label": "on_train_start",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.hub",
        "description": "ultralytics.utils.callbacks.hub",
        "peekOfCode": "def on_train_start(trainer):\n    \"\"\"Run events on train start.\"\"\"\n    events(trainer.args)\ndef on_val_start(validator):\n    \"\"\"Runs events on validation start.\"\"\"\n    events(validator.args)\ndef on_predict_start(predictor):\n    \"\"\"Run events on predict start.\"\"\"\n    events(predictor.args)\ndef on_export_start(exporter):",
        "detail": "ultralytics.utils.callbacks.hub",
        "documentation": {}
    },
    {
        "label": "on_val_start",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.hub",
        "description": "ultralytics.utils.callbacks.hub",
        "peekOfCode": "def on_val_start(validator):\n    \"\"\"Runs events on validation start.\"\"\"\n    events(validator.args)\ndef on_predict_start(predictor):\n    \"\"\"Run events on predict start.\"\"\"\n    events(predictor.args)\ndef on_export_start(exporter):\n    \"\"\"Run events on export start.\"\"\"\n    events(exporter.args)\ncallbacks = (",
        "detail": "ultralytics.utils.callbacks.hub",
        "documentation": {}
    },
    {
        "label": "on_predict_start",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.hub",
        "description": "ultralytics.utils.callbacks.hub",
        "peekOfCode": "def on_predict_start(predictor):\n    \"\"\"Run events on predict start.\"\"\"\n    events(predictor.args)\ndef on_export_start(exporter):\n    \"\"\"Run events on export start.\"\"\"\n    events(exporter.args)\ncallbacks = (\n    {\n        \"on_pretrain_routine_start\": on_pretrain_routine_start,\n        \"on_pretrain_routine_end\": on_pretrain_routine_end,",
        "detail": "ultralytics.utils.callbacks.hub",
        "documentation": {}
    },
    {
        "label": "on_export_start",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.hub",
        "description": "ultralytics.utils.callbacks.hub",
        "peekOfCode": "def on_export_start(exporter):\n    \"\"\"Run events on export start.\"\"\"\n    events(exporter.args)\ncallbacks = (\n    {\n        \"on_pretrain_routine_start\": on_pretrain_routine_start,\n        \"on_pretrain_routine_end\": on_pretrain_routine_end,\n        \"on_fit_epoch_end\": on_fit_epoch_end,\n        \"on_model_save\": on_model_save,\n        \"on_train_end\": on_train_end,",
        "detail": "ultralytics.utils.callbacks.hub",
        "documentation": {}
    },
    {
        "label": "callbacks",
        "kind": 5,
        "importPath": "ultralytics.utils.callbacks.hub",
        "description": "ultralytics.utils.callbacks.hub",
        "peekOfCode": "callbacks = (\n    {\n        \"on_pretrain_routine_start\": on_pretrain_routine_start,\n        \"on_pretrain_routine_end\": on_pretrain_routine_end,\n        \"on_fit_epoch_end\": on_fit_epoch_end,\n        \"on_model_save\": on_model_save,\n        \"on_train_end\": on_train_end,\n        \"on_train_start\": on_train_start,\n        \"on_val_start\": on_val_start,\n        \"on_predict_start\": on_predict_start,",
        "detail": "ultralytics.utils.callbacks.hub",
        "documentation": {}
    },
    {
        "label": "sanitize_dict",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.mlflow",
        "description": "ultralytics.utils.callbacks.mlflow",
        "peekOfCode": "def sanitize_dict(x):\n    \"\"\"Sanitize dictionary keys by removing parentheses and converting values to floats.\"\"\"\n    return {k.replace(\"(\", \"\").replace(\")\", \"\"): float(v) for k, v in x.items()}\ndef on_pretrain_routine_end(trainer):\n    \"\"\"\n    Log training parameters to MLflow at the end of the pretraining routine.\n    This function sets up MLflow logging based on environment variables and trainer arguments. It sets the tracking URI,\n    experiment name, and run name, then starts the MLflow run if not already active. It finally logs the parameters\n    from the trainer.\n    Args:",
        "detail": "ultralytics.utils.callbacks.mlflow",
        "documentation": {}
    },
    {
        "label": "on_pretrain_routine_end",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.mlflow",
        "description": "ultralytics.utils.callbacks.mlflow",
        "peekOfCode": "def on_pretrain_routine_end(trainer):\n    \"\"\"\n    Log training parameters to MLflow at the end of the pretraining routine.\n    This function sets up MLflow logging based on environment variables and trainer arguments. It sets the tracking URI,\n    experiment name, and run name, then starts the MLflow run if not already active. It finally logs the parameters\n    from the trainer.\n    Args:\n        trainer (ultralytics.engine.trainer.BaseTrainer): The training object with arguments and parameters to log.\n    Global:\n        mlflow: The imported mlflow module to use for logging.",
        "detail": "ultralytics.utils.callbacks.mlflow",
        "documentation": {}
    },
    {
        "label": "on_train_epoch_end",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.mlflow",
        "description": "ultralytics.utils.callbacks.mlflow",
        "peekOfCode": "def on_train_epoch_end(trainer):\n    \"\"\"Log training metrics at the end of each train epoch to MLflow.\"\"\"\n    if mlflow:\n        mlflow.log_metrics(\n            metrics={\n                **sanitize_dict(trainer.lr),\n                **sanitize_dict(trainer.label_loss_items(trainer.tloss, prefix=\"train\")),\n            },\n            step=trainer.epoch,\n        )",
        "detail": "ultralytics.utils.callbacks.mlflow",
        "documentation": {}
    },
    {
        "label": "on_fit_epoch_end",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.mlflow",
        "description": "ultralytics.utils.callbacks.mlflow",
        "peekOfCode": "def on_fit_epoch_end(trainer):\n    \"\"\"Log training metrics at the end of each fit epoch to MLflow.\"\"\"\n    if mlflow:\n        mlflow.log_metrics(metrics=sanitize_dict(trainer.metrics), step=trainer.epoch)\ndef on_train_end(trainer):\n    \"\"\"Log model artifacts at the end of the training.\"\"\"\n    if not mlflow:\n        return\n    mlflow.log_artifact(str(trainer.best.parent))  # log save_dir/weights directory with best.pt and last.pt\n    for f in trainer.save_dir.glob(\"*\"):  # log all other files in save_dir",
        "detail": "ultralytics.utils.callbacks.mlflow",
        "documentation": {}
    },
    {
        "label": "on_train_end",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.mlflow",
        "description": "ultralytics.utils.callbacks.mlflow",
        "peekOfCode": "def on_train_end(trainer):\n    \"\"\"Log model artifacts at the end of the training.\"\"\"\n    if not mlflow:\n        return\n    mlflow.log_artifact(str(trainer.best.parent))  # log save_dir/weights directory with best.pt and last.pt\n    for f in trainer.save_dir.glob(\"*\"):  # log all other files in save_dir\n        if f.suffix in {\".png\", \".jpg\", \".csv\", \".pt\", \".yaml\"}:\n            mlflow.log_artifact(str(f))\n    keep_run_active = os.environ.get(\"MLFLOW_KEEP_RUN_ACTIVE\", \"False\").lower() == \"true\"\n    if keep_run_active:",
        "detail": "ultralytics.utils.callbacks.mlflow",
        "documentation": {}
    },
    {
        "label": "callbacks",
        "kind": 5,
        "importPath": "ultralytics.utils.callbacks.mlflow",
        "description": "ultralytics.utils.callbacks.mlflow",
        "peekOfCode": "callbacks = (\n    {\n        \"on_pretrain_routine_end\": on_pretrain_routine_end,\n        \"on_train_epoch_end\": on_train_epoch_end,\n        \"on_fit_epoch_end\": on_fit_epoch_end,\n        \"on_train_end\": on_train_end,\n    }\n    if mlflow\n    else {}\n)",
        "detail": "ultralytics.utils.callbacks.mlflow",
        "documentation": {}
    },
    {
        "label": "on_pretrain_routine_start",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.neptune",
        "description": "ultralytics.utils.callbacks.neptune",
        "peekOfCode": "def on_pretrain_routine_start(trainer):\n    \"\"\"Callback function called before the training routine starts.\"\"\"\n    try:\n        global run\n        run = neptune.init_run(project=trainer.args.project or \"YOLOv8\", name=trainer.args.name, tags=[\"YOLOv8\"])\n        run[\"Configuration/Hyperparameters\"] = {k: \"\" if v is None else v for k, v in vars(trainer.args).items()}\n    except Exception as e:\n        LOGGER.warning(f\"WARNING ⚠️ NeptuneAI installed but not initialized correctly, not logging this run. {e}\")\ndef on_train_epoch_end(trainer):\n    \"\"\"Callback function called at end of each training epoch.\"\"\"",
        "detail": "ultralytics.utils.callbacks.neptune",
        "documentation": {}
    },
    {
        "label": "on_train_epoch_end",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.neptune",
        "description": "ultralytics.utils.callbacks.neptune",
        "peekOfCode": "def on_train_epoch_end(trainer):\n    \"\"\"Callback function called at end of each training epoch.\"\"\"\n    _log_scalars(trainer.label_loss_items(trainer.tloss, prefix=\"train\"), trainer.epoch + 1)\n    _log_scalars(trainer.lr, trainer.epoch + 1)\n    if trainer.epoch == 1:\n        _log_images({f.stem: str(f) for f in trainer.save_dir.glob(\"train_batch*.jpg\")}, \"Mosaic\")\ndef on_fit_epoch_end(trainer):\n    \"\"\"Callback function called at end of each fit (train+val) epoch.\"\"\"\n    if run and trainer.epoch == 0:\n        from ultralytics.utils.torch_utils import model_info_for_loggers",
        "detail": "ultralytics.utils.callbacks.neptune",
        "documentation": {}
    },
    {
        "label": "on_fit_epoch_end",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.neptune",
        "description": "ultralytics.utils.callbacks.neptune",
        "peekOfCode": "def on_fit_epoch_end(trainer):\n    \"\"\"Callback function called at end of each fit (train+val) epoch.\"\"\"\n    if run and trainer.epoch == 0:\n        from ultralytics.utils.torch_utils import model_info_for_loggers\n        run[\"Configuration/Model\"] = model_info_for_loggers(trainer)\n    _log_scalars(trainer.metrics, trainer.epoch + 1)\ndef on_val_end(validator):\n    \"\"\"Callback function called at end of each validation.\"\"\"\n    if run:\n        # Log val_labels and val_pred",
        "detail": "ultralytics.utils.callbacks.neptune",
        "documentation": {}
    },
    {
        "label": "on_val_end",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.neptune",
        "description": "ultralytics.utils.callbacks.neptune",
        "peekOfCode": "def on_val_end(validator):\n    \"\"\"Callback function called at end of each validation.\"\"\"\n    if run:\n        # Log val_labels and val_pred\n        _log_images({f.stem: str(f) for f in validator.save_dir.glob(\"val*.jpg\")}, \"Validation\")\ndef on_train_end(trainer):\n    \"\"\"Callback function called at end of training.\"\"\"\n    if run:\n        # Log final results, CM matrix + PR plots\n        files = [",
        "detail": "ultralytics.utils.callbacks.neptune",
        "documentation": {}
    },
    {
        "label": "on_train_end",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.neptune",
        "description": "ultralytics.utils.callbacks.neptune",
        "peekOfCode": "def on_train_end(trainer):\n    \"\"\"Callback function called at end of training.\"\"\"\n    if run:\n        # Log final results, CM matrix + PR plots\n        files = [\n            \"results.png\",\n            \"confusion_matrix.png\",\n            \"confusion_matrix_normalized.png\",\n            *(f\"{x}_curve.png\" for x in (\"F1\", \"PR\", \"P\", \"R\")),\n        ]",
        "detail": "ultralytics.utils.callbacks.neptune",
        "documentation": {}
    },
    {
        "label": "callbacks",
        "kind": 5,
        "importPath": "ultralytics.utils.callbacks.neptune",
        "description": "ultralytics.utils.callbacks.neptune",
        "peekOfCode": "callbacks = (\n    {\n        \"on_pretrain_routine_start\": on_pretrain_routine_start,\n        \"on_train_epoch_end\": on_train_epoch_end,\n        \"on_fit_epoch_end\": on_fit_epoch_end,\n        \"on_val_end\": on_val_end,\n        \"on_train_end\": on_train_end,\n    }\n    if neptune\n    else {}",
        "detail": "ultralytics.utils.callbacks.neptune",
        "documentation": {}
    },
    {
        "label": "on_fit_epoch_end",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.raytune",
        "description": "ultralytics.utils.callbacks.raytune",
        "peekOfCode": "def on_fit_epoch_end(trainer):\n    \"\"\"Sends training metrics to Ray Tune at end of each epoch.\"\"\"\n    if ray.train._internal.session._get_session():  # replacement for deprecated ray.tune.is_session_enabled()\n        metrics = trainer.metrics\n        metrics[\"epoch\"] = trainer.epoch\n        session.report(metrics)\ncallbacks = (\n    {\n        \"on_fit_epoch_end\": on_fit_epoch_end,\n    }",
        "detail": "ultralytics.utils.callbacks.raytune",
        "documentation": {}
    },
    {
        "label": "callbacks",
        "kind": 5,
        "importPath": "ultralytics.utils.callbacks.raytune",
        "description": "ultralytics.utils.callbacks.raytune",
        "peekOfCode": "callbacks = (\n    {\n        \"on_fit_epoch_end\": on_fit_epoch_end,\n    }\n    if tune\n    else {}\n)",
        "detail": "ultralytics.utils.callbacks.raytune",
        "documentation": {}
    },
    {
        "label": "on_pretrain_routine_start",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.tensorboard",
        "description": "ultralytics.utils.callbacks.tensorboard",
        "peekOfCode": "def on_pretrain_routine_start(trainer):\n    \"\"\"Initialize TensorBoard logging with SummaryWriter.\"\"\"\n    if SummaryWriter:\n        try:\n            global WRITER\n            WRITER = SummaryWriter(str(trainer.save_dir))\n            LOGGER.info(f\"{PREFIX}Start with 'tensorboard --logdir {trainer.save_dir}', view at http://localhost:6006/\")\n        except Exception as e:\n            LOGGER.warning(f\"{PREFIX}WARNING ⚠️ TensorBoard not initialized correctly, not logging this run. {e}\")\ndef on_train_start(trainer):",
        "detail": "ultralytics.utils.callbacks.tensorboard",
        "documentation": {}
    },
    {
        "label": "on_train_start",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.tensorboard",
        "description": "ultralytics.utils.callbacks.tensorboard",
        "peekOfCode": "def on_train_start(trainer):\n    \"\"\"Log TensorBoard graph.\"\"\"\n    if WRITER:\n        _log_tensorboard_graph(trainer)\ndef on_train_epoch_end(trainer):\n    \"\"\"Logs scalar statistics at the end of a training epoch.\"\"\"\n    _log_scalars(trainer.label_loss_items(trainer.tloss, prefix=\"train\"), trainer.epoch + 1)\n    _log_scalars(trainer.lr, trainer.epoch + 1)\ndef on_fit_epoch_end(trainer):\n    \"\"\"Logs epoch metrics at end of training epoch.\"\"\"",
        "detail": "ultralytics.utils.callbacks.tensorboard",
        "documentation": {}
    },
    {
        "label": "on_train_epoch_end",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.tensorboard",
        "description": "ultralytics.utils.callbacks.tensorboard",
        "peekOfCode": "def on_train_epoch_end(trainer):\n    \"\"\"Logs scalar statistics at the end of a training epoch.\"\"\"\n    _log_scalars(trainer.label_loss_items(trainer.tloss, prefix=\"train\"), trainer.epoch + 1)\n    _log_scalars(trainer.lr, trainer.epoch + 1)\ndef on_fit_epoch_end(trainer):\n    \"\"\"Logs epoch metrics at end of training epoch.\"\"\"\n    _log_scalars(trainer.metrics, trainer.epoch + 1)\ncallbacks = (\n    {\n        \"on_pretrain_routine_start\": on_pretrain_routine_start,",
        "detail": "ultralytics.utils.callbacks.tensorboard",
        "documentation": {}
    },
    {
        "label": "on_fit_epoch_end",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.tensorboard",
        "description": "ultralytics.utils.callbacks.tensorboard",
        "peekOfCode": "def on_fit_epoch_end(trainer):\n    \"\"\"Logs epoch metrics at end of training epoch.\"\"\"\n    _log_scalars(trainer.metrics, trainer.epoch + 1)\ncallbacks = (\n    {\n        \"on_pretrain_routine_start\": on_pretrain_routine_start,\n        \"on_train_start\": on_train_start,\n        \"on_fit_epoch_end\": on_fit_epoch_end,\n        \"on_train_epoch_end\": on_train_epoch_end,\n    }",
        "detail": "ultralytics.utils.callbacks.tensorboard",
        "documentation": {}
    },
    {
        "label": "callbacks",
        "kind": 5,
        "importPath": "ultralytics.utils.callbacks.tensorboard",
        "description": "ultralytics.utils.callbacks.tensorboard",
        "peekOfCode": "callbacks = (\n    {\n        \"on_pretrain_routine_start\": on_pretrain_routine_start,\n        \"on_train_start\": on_train_start,\n        \"on_fit_epoch_end\": on_fit_epoch_end,\n        \"on_train_epoch_end\": on_train_epoch_end,\n    }\n    if SummaryWriter\n    else {}\n)",
        "detail": "ultralytics.utils.callbacks.tensorboard",
        "documentation": {}
    },
    {
        "label": "on_pretrain_routine_start",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.wb",
        "description": "ultralytics.utils.callbacks.wb",
        "peekOfCode": "def on_pretrain_routine_start(trainer):\n    \"\"\"Initiate and start project if module is present.\"\"\"\n    wb.run or wb.init(project=trainer.args.project or \"YOLOv8\", name=trainer.args.name, config=vars(trainer.args))\ndef on_fit_epoch_end(trainer):\n    \"\"\"Logs training metrics and model information at the end of an epoch.\"\"\"\n    wb.run.log(trainer.metrics, step=trainer.epoch + 1)\n    _log_plots(trainer.plots, step=trainer.epoch + 1)\n    _log_plots(trainer.validator.plots, step=trainer.epoch + 1)\n    if trainer.epoch == 0:\n        wb.run.log(model_info_for_loggers(trainer), step=trainer.epoch + 1)",
        "detail": "ultralytics.utils.callbacks.wb",
        "documentation": {}
    },
    {
        "label": "on_fit_epoch_end",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.wb",
        "description": "ultralytics.utils.callbacks.wb",
        "peekOfCode": "def on_fit_epoch_end(trainer):\n    \"\"\"Logs training metrics and model information at the end of an epoch.\"\"\"\n    wb.run.log(trainer.metrics, step=trainer.epoch + 1)\n    _log_plots(trainer.plots, step=trainer.epoch + 1)\n    _log_plots(trainer.validator.plots, step=trainer.epoch + 1)\n    if trainer.epoch == 0:\n        wb.run.log(model_info_for_loggers(trainer), step=trainer.epoch + 1)\ndef on_train_epoch_end(trainer):\n    \"\"\"Log metrics and save images at the end of each training epoch.\"\"\"\n    wb.run.log(trainer.label_loss_items(trainer.tloss, prefix=\"train\"), step=trainer.epoch + 1)",
        "detail": "ultralytics.utils.callbacks.wb",
        "documentation": {}
    },
    {
        "label": "on_train_epoch_end",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.wb",
        "description": "ultralytics.utils.callbacks.wb",
        "peekOfCode": "def on_train_epoch_end(trainer):\n    \"\"\"Log metrics and save images at the end of each training epoch.\"\"\"\n    wb.run.log(trainer.label_loss_items(trainer.tloss, prefix=\"train\"), step=trainer.epoch + 1)\n    wb.run.log(trainer.lr, step=trainer.epoch + 1)\n    if trainer.epoch == 1:\n        _log_plots(trainer.plots, step=trainer.epoch + 1)\ndef on_train_end(trainer):\n    \"\"\"Save the best model as an artifact at end of training.\"\"\"\n    _log_plots(trainer.validator.plots, step=trainer.epoch + 1)\n    _log_plots(trainer.plots, step=trainer.epoch + 1)",
        "detail": "ultralytics.utils.callbacks.wb",
        "documentation": {}
    },
    {
        "label": "on_train_end",
        "kind": 2,
        "importPath": "ultralytics.utils.callbacks.wb",
        "description": "ultralytics.utils.callbacks.wb",
        "peekOfCode": "def on_train_end(trainer):\n    \"\"\"Save the best model as an artifact at end of training.\"\"\"\n    _log_plots(trainer.validator.plots, step=trainer.epoch + 1)\n    _log_plots(trainer.plots, step=trainer.epoch + 1)\n    art = wb.Artifact(type=\"model\", name=f\"run_{wb.run.id}_model\")\n    if trainer.best.exists():\n        art.add_file(trainer.best)\n        wb.run.log_artifact(art, aliases=[\"best\"])\n    for curve_name, curve_values in zip(trainer.validator.metrics.curves, trainer.validator.metrics.curves_results):\n        x, y, x_title, y_title = curve_values",
        "detail": "ultralytics.utils.callbacks.wb",
        "documentation": {}
    },
    {
        "label": "callbacks",
        "kind": 5,
        "importPath": "ultralytics.utils.callbacks.wb",
        "description": "ultralytics.utils.callbacks.wb",
        "peekOfCode": "callbacks = (\n    {\n        \"on_pretrain_routine_start\": on_pretrain_routine_start,\n        \"on_train_epoch_end\": on_train_epoch_end,\n        \"on_fit_epoch_end\": on_fit_epoch_end,\n        \"on_train_end\": on_train_end,\n    }\n    if wb\n    else {}\n)",
        "detail": "ultralytics.utils.callbacks.wb",
        "documentation": {}
    },
    {
        "label": "check_train_batch_size",
        "kind": 2,
        "importPath": "ultralytics.utils.autobatch",
        "description": "ultralytics.utils.autobatch",
        "peekOfCode": "def check_train_batch_size(model, imgsz=640, amp=True, batch=-1):\n    \"\"\"\n    Compute optimal YOLO training batch size using the autobatch() function.\n    Args:\n        model (torch.nn.Module): YOLO model to check batch size for.\n        imgsz (int): Image size used for training.\n        amp (bool): If True, use automatic mixed precision (AMP) for training.\n    Returns:\n        (int): Optimal batch size computed using the autobatch() function.\n    \"\"\"",
        "detail": "ultralytics.utils.autobatch",
        "documentation": {}
    },
    {
        "label": "autobatch",
        "kind": 2,
        "importPath": "ultralytics.utils.autobatch",
        "description": "ultralytics.utils.autobatch",
        "peekOfCode": "def autobatch(model, imgsz=640, fraction=0.60, batch_size=DEFAULT_CFG.batch):\n    \"\"\"\n    Automatically estimate the best YOLO batch size to use a fraction of the available CUDA memory.\n    Args:\n        model (torch.nn.module): YOLO model to compute batch size for.\n        imgsz (int, optional): The image size used as input for the YOLO model. Defaults to 640.\n        fraction (float, optional): The fraction of available CUDA memory to use. Defaults to 0.60.\n        batch_size (int, optional): The default batch size to use if an error is detected. Defaults to 16.\n    Returns:\n        (int): The optimal batch size.",
        "detail": "ultralytics.utils.autobatch",
        "documentation": {}
    },
    {
        "label": "RF100Benchmark",
        "kind": 6,
        "importPath": "ultralytics.utils.benchmarks",
        "description": "ultralytics.utils.benchmarks",
        "peekOfCode": "class RF100Benchmark:\n    \"\"\"Benchmark YOLO model performance across formats for speed and accuracy.\"\"\"\n    def __init__(self):\n        \"\"\"Function for initialization of RF100Benchmark.\"\"\"\n        self.ds_names = []\n        self.ds_cfg_list = []\n        self.rf = None\n        self.val_metrics = [\"class\", \"images\", \"targets\", \"precision\", \"recall\", \"map50\", \"map95\"]\n    def set_key(self, api_key):\n        \"\"\"",
        "detail": "ultralytics.utils.benchmarks",
        "documentation": {}
    },
    {
        "label": "ProfileModels",
        "kind": 6,
        "importPath": "ultralytics.utils.benchmarks",
        "description": "ultralytics.utils.benchmarks",
        "peekOfCode": "class ProfileModels:\n    \"\"\"\n    ProfileModels class for profiling different models on ONNX and TensorRT.\n    This class profiles the performance of different models, returning results such as model speed and FLOPs.\n    Attributes:\n        paths (list): Paths of the models to profile.\n        num_timed_runs (int): Number of timed runs for the profiling. Default is 100.\n        num_warmup_runs (int): Number of warmup runs before profiling. Default is 10.\n        min_time (float): Minimum number of seconds to profile for. Default is 60.\n        imgsz (int): Image size used in the models. Default is 640.",
        "detail": "ultralytics.utils.benchmarks",
        "documentation": {}
    },
    {
        "label": "benchmark",
        "kind": 2,
        "importPath": "ultralytics.utils.benchmarks",
        "description": "ultralytics.utils.benchmarks",
        "peekOfCode": "def benchmark(\n    model=WEIGHTS_DIR / \"yolov8n.pt\", data=None, imgsz=160, half=False, int8=False, device=\"cpu\", verbose=False\n):\n    \"\"\"\n    Benchmark a YOLO model across different formats for speed and accuracy.\n    Args:\n        model (str | Path | optional): Path to the model file or directory. Default is\n            Path(SETTINGS['weights_dir']) / 'yolov8n.pt'.\n        data (str, optional): Dataset to evaluate on, inherited from TASK2DATA if not passed. Default is None.\n        imgsz (int, optional): Image size for the benchmark. Default is 160.",
        "detail": "ultralytics.utils.benchmarks",
        "documentation": {}
    },
    {
        "label": "parse_requirements",
        "kind": 2,
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "peekOfCode": "def parse_requirements(file_path=ROOT.parent / \"requirements.txt\", package=\"\"):\n    \"\"\"\n    Parse a requirements.txt file, ignoring lines that start with '#' and any text after '#'.\n    Args:\n        file_path (Path): Path to the requirements.txt file.\n        package (str, optional): Python package to use instead of requirements.txt file, i.e. package='ultralytics'.\n    Returns:\n        (List[Dict[str, str]]): List of parsed requirements as dictionaries with `name` and `specifier` keys.\n    Example:\n        ```python",
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "parse_version",
        "kind": 2,
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "peekOfCode": "def parse_version(version=\"0.0.0\") -> tuple:\n    \"\"\"\n    Convert a version string to a tuple of integers, ignoring any extra non-numeric string attached to the version. This\n    function replaces deprecated 'pkg_resources.parse_version(v)'.\n    Args:\n        version (str): Version string, i.e. '2.0.1+cpu'\n    Returns:\n        (tuple): Tuple of integers representing the numeric part of the version and the extra string, i.e. (2, 0, 1)\n    \"\"\"\n    try:",
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "is_ascii",
        "kind": 2,
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "peekOfCode": "def is_ascii(s) -> bool:\n    \"\"\"\n    Check if a string is composed of only ASCII characters.\n    Args:\n        s (str): String to be checked.\n    Returns:\n        (bool): True if the string is composed only of ASCII characters, False otherwise.\n    \"\"\"\n    # Convert list, tuple, None, etc. to string\n    s = str(s)",
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_imgsz",
        "kind": 2,
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "peekOfCode": "def check_imgsz(imgsz, stride=32, min_dim=1, max_dim=2, floor=0):\n    \"\"\"\n    Verify image size is a multiple of the given stride in each dimension. If the image size is not a multiple of the\n    stride, update it to the nearest multiple of the stride that is greater than or equal to the given floor value.\n    Args:\n        imgsz (int | cList[int]): Image size.\n        stride (int): Stride value.\n        min_dim (int): Minimum number of dimensions.\n        max_dim (int): Maximum number of dimensions.\n        floor (int): Minimum allowed value for image size.",
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_version",
        "kind": 2,
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "peekOfCode": "def check_version(\n    current: str = \"0.0.0\",\n    required: str = \"0.0.0\",\n    name: str = \"version\",\n    hard: bool = False,\n    verbose: bool = False,\n    msg: str = \"\",\n) -> bool:\n    \"\"\"\n    Check current version against the required version or range.",
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_latest_pypi_version",
        "kind": 2,
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "peekOfCode": "def check_latest_pypi_version(package_name=\"ultralytics\"):\n    \"\"\"\n    Returns the latest version of a PyPI package without downloading or installing it.\n    Parameters:\n        package_name (str): The name of the package to find the latest version for.\n    Returns:\n        (str): The latest version of the package.\n    \"\"\"\n    with contextlib.suppress(Exception):\n        requests.packages.urllib3.disable_warnings()  # Disable the InsecureRequestWarning",
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_pip_update_available",
        "kind": 2,
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "peekOfCode": "def check_pip_update_available():\n    \"\"\"\n    Checks if a new version of the ultralytics package is available on PyPI.\n    Returns:\n        (bool): True if an update is available, False otherwise.\n    \"\"\"\n    if ONLINE and IS_PIP_PACKAGE:\n        with contextlib.suppress(Exception):\n            from ultralytics import __version__\n            latest = check_latest_pypi_version()",
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_font",
        "kind": 2,
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "peekOfCode": "def check_font(font=\"Arial.ttf\"):\n    \"\"\"\n    Find font locally or download to user's configuration directory if it does not already exist.\n    Args:\n        font (str): Path or name of font.\n    Returns:\n        file (Path): Resolved font file path.\n    \"\"\"\n    from matplotlib import font_manager\n    # Check USER_CONFIG_DIR",
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_python",
        "kind": 2,
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "peekOfCode": "def check_python(minimum: str = \"3.8.0\", hard: bool = True) -> bool:\n    \"\"\"\n    Check current python version against the required minimum version.\n    Args:\n        minimum (str): Required minimum version of python.\n        hard (bool, optional): If True, raise an AssertionError if the requirement is not met.\n    Returns:\n        (bool): Whether the installed Python version meets the minimum constraints.\n    \"\"\"\n    return check_version(PYTHON_VERSION, minimum, name=\"Python\", hard=hard)",
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_requirements",
        "kind": 2,
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "peekOfCode": "def check_requirements(requirements=ROOT.parent / \"requirements.txt\", exclude=(), install=True, cmds=\"\"):\n    \"\"\"\n    Check if installed dependencies meet YOLOv8 requirements and attempt to auto-update if needed.\n    Args:\n        requirements (Union[Path, str, List[str]]): Path to a requirements.txt file, a single package requirement as a\n            string, or a list of package requirements as strings.\n        exclude (Tuple[str]): Tuple of package names to exclude from checking.\n        install (bool): If True, attempt to auto-update packages that don't meet requirements.\n        cmds (str): Additional commands to pass to the pip install command when auto-updating.\n    Example:",
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_torchvision",
        "kind": 2,
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "peekOfCode": "def check_torchvision():\n    \"\"\"\n    Checks the installed versions of PyTorch and Torchvision to ensure they're compatible.\n    This function checks the installed versions of PyTorch and Torchvision, and warns if they're incompatible according\n    to the provided compatibility table based on:\n    https://github.com/pytorch/vision#installation.\n    The compatibility table is a dictionary where the keys are PyTorch versions and the values are lists of compatible\n    Torchvision versions.\n    \"\"\"\n    # Compatibility table",
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_suffix",
        "kind": 2,
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "peekOfCode": "def check_suffix(file=\"yolov8n.pt\", suffix=\".pt\", msg=\"\"):\n    \"\"\"Check file(s) for acceptable suffix.\"\"\"\n    if file and suffix:\n        if isinstance(suffix, str):\n            suffix = (suffix,)\n        for f in file if isinstance(file, (list, tuple)) else [file]:\n            s = Path(f).suffix.lower().strip()  # file suffix\n            if len(s):\n                assert s in suffix, f\"{msg}{f} acceptable suffix is {suffix}, not {s}\"\ndef check_yolov5u_filename(file: str, verbose: bool = True):",
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_yolov5u_filename",
        "kind": 2,
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "peekOfCode": "def check_yolov5u_filename(file: str, verbose: bool = True):\n    \"\"\"Replace legacy YOLOv5 filenames with updated YOLOv5u filenames.\"\"\"\n    if \"yolov3\" in file or \"yolov5\" in file:\n        if \"u.yaml\" in file:\n            file = file.replace(\"u.yaml\", \".yaml\")  # i.e. yolov5nu.yaml -> yolov5n.yaml\n        elif \".pt\" in file and \"u\" not in file:\n            original_file = file\n            file = re.sub(r\"(.*yolov5([nsmlx]))\\.pt\", \"\\\\1u.pt\", file)  # i.e. yolov5n.pt -> yolov5nu.pt\n            file = re.sub(r\"(.*yolov5([nsmlx])6)\\.pt\", \"\\\\1u.pt\", file)  # i.e. yolov5n6.pt -> yolov5n6u.pt\n            file = re.sub(r\"(.*yolov3(|-tiny|-spp))\\.pt\", \"\\\\1u.pt\", file)  # i.e. yolov3-spp.pt -> yolov3-sppu.pt",
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_model_file_from_stem",
        "kind": 2,
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "peekOfCode": "def check_model_file_from_stem(model=\"yolov8n\"):\n    \"\"\"Return a model filename from a valid model stem.\"\"\"\n    if model and not Path(model).suffix and Path(model).stem in downloads.GITHUB_ASSETS_STEMS:\n        return Path(model).with_suffix(\".pt\")  # add suffix, i.e. yolov8n -> yolov8n.pt\n    else:\n        return model\ndef check_file(file, suffix=\"\", download=True, hard=True):\n    \"\"\"Search/download file (if necessary) and return path.\"\"\"\n    check_suffix(file, suffix)  # optional\n    file = str(file).strip()  # convert to string and strip spaces",
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_file",
        "kind": 2,
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "peekOfCode": "def check_file(file, suffix=\"\", download=True, hard=True):\n    \"\"\"Search/download file (if necessary) and return path.\"\"\"\n    check_suffix(file, suffix)  # optional\n    file = str(file).strip()  # convert to string and strip spaces\n    file = check_yolov5u_filename(file)  # yolov5n -> yolov5nu\n    if (\n        not file\n        or (\"://\" not in file and Path(file).exists())  # '://' check required in Windows Python<3.10\n        or file.lower().startswith(\"grpc://\")\n    ):  # file exists or gRPC Triton images",
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_yaml",
        "kind": 2,
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "peekOfCode": "def check_yaml(file, suffix=(\".yaml\", \".yml\"), hard=True):\n    \"\"\"Search/download YAML file (if necessary) and return path, checking suffix.\"\"\"\n    return check_file(file, suffix, hard=hard)\ndef check_is_path_safe(basedir, path):\n    \"\"\"\n    Check if the resolved path is under the intended directory to prevent path traversal.\n    Args:\n        basedir (Path | str): The intended directory.\n        path (Path | str): The path to check.\n    Returns:",
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_is_path_safe",
        "kind": 2,
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "peekOfCode": "def check_is_path_safe(basedir, path):\n    \"\"\"\n    Check if the resolved path is under the intended directory to prevent path traversal.\n    Args:\n        basedir (Path | str): The intended directory.\n        path (Path | str): The path to check.\n    Returns:\n        (bool): True if the path is safe, False otherwise.\n    \"\"\"\n    base_dir_resolved = Path(basedir).resolve()",
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_imshow",
        "kind": 2,
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "peekOfCode": "def check_imshow(warn=False):\n    \"\"\"Check if environment supports image displays.\"\"\"\n    try:\n        if LINUX:\n            assert not IS_COLAB and not IS_KAGGLE\n            assert \"DISPLAY\" in os.environ, \"The DISPLAY environment variable isn't set.\"\n        cv2.imshow(\"test\", np.zeros((8, 8, 3), dtype=np.uint8))  # show a small 8-pixel image\n        cv2.waitKey(1)\n        cv2.destroyAllWindows()\n        cv2.waitKey(1)",
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_yolo",
        "kind": 2,
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "peekOfCode": "def check_yolo(verbose=True, device=\"\"):\n    \"\"\"Return a human-readable YOLO software and hardware summary.\"\"\"\n    import psutil\n    from ultralytics.utils.torch_utils import select_device\n    if IS_JUPYTER:\n        if check_requirements(\"wandb\", install=False):\n            os.system(\"pip uninstall -y wandb\")  # uninstall wandb: unwanted account creation prompt with infinite hang\n        if IS_COLAB:\n            shutil.rmtree(\"sample_data\", ignore_errors=True)  # remove colab /sample_data directory\n    if verbose:",
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "collect_system_info",
        "kind": 2,
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "peekOfCode": "def collect_system_info():\n    \"\"\"Collect and print relevant system information including OS, Python, RAM, CPU, and CUDA.\"\"\"\n    import psutil\n    from ultralytics.utils import ENVIRONMENT, IS_GIT_DIR\n    from ultralytics.utils.torch_utils import get_cpu_info\n    ram_info = psutil.virtual_memory().total / (1024**3)  # Convert bytes to GB\n    check_yolo()\n    LOGGER.info(\n        f\"\\n{'OS':<20}{platform.platform()}\\n\"\n        f\"{'Environment':<20}{ENVIRONMENT}\\n\"",
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_amp",
        "kind": 2,
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "peekOfCode": "def check_amp(model):\n    \"\"\"\n    This function checks the PyTorch Automatic Mixed Precision (AMP) functionality of a YOLOv8 model. If the checks\n    fail, it means there are anomalies with AMP on the system that may cause NaN losses or zero-mAP results, so AMP will\n    be disabled during training.\n    Args:\n        model (nn.Module): A YOLOv8 model instance.\n    Example:\n        ```python\n        from ultralytics import YOLO",
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "git_describe",
        "kind": 2,
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "peekOfCode": "def git_describe(path=ROOT):  # path must be a directory\n    \"\"\"Return human-readable git description, i.e. v5.0-5-g3e25f1e https://git-scm.com/docs/git-describe.\"\"\"\n    with contextlib.suppress(Exception):\n        return subprocess.check_output(f\"git -C {path} describe --tags --long --always\", shell=True).decode()[:-1]\n    return \"\"\ndef print_args(args: Optional[dict] = None, show_file=True, show_func=False):\n    \"\"\"Print function arguments (optional args dict).\"\"\"\n    def strip_auth(v):\n        \"\"\"Clean longer Ultralytics HUB URLs by stripping potential authentication information.\"\"\"\n        return clean_url(v) if (isinstance(v, str) and v.startswith(\"http\") and len(v) > 100) else v",
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "print_args",
        "kind": 2,
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "peekOfCode": "def print_args(args: Optional[dict] = None, show_file=True, show_func=False):\n    \"\"\"Print function arguments (optional args dict).\"\"\"\n    def strip_auth(v):\n        \"\"\"Clean longer Ultralytics HUB URLs by stripping potential authentication information.\"\"\"\n        return clean_url(v) if (isinstance(v, str) and v.startswith(\"http\") and len(v) > 100) else v\n    x = inspect.currentframe().f_back  # previous frame\n    file, _, func, _, _ = inspect.getframeinfo(x)\n    if args is None:  # get args automatically\n        args, _, _, frm = inspect.getargvalues(x)\n        args = {k: v for k, v in frm.items() if k in args}",
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "cuda_device_count",
        "kind": 2,
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "peekOfCode": "def cuda_device_count() -> int:\n    \"\"\"\n    Get the number of NVIDIA GPUs available in the environment.\n    Returns:\n        (int): The number of NVIDIA GPUs available.\n    \"\"\"\n    try:\n        # Run the nvidia-smi command and capture its output\n        output = subprocess.check_output(\n            [\"nvidia-smi\", \"--query-gpu=count\", \"--format=csv,noheader,nounits\"], encoding=\"utf-8\"",
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "cuda_is_available",
        "kind": 2,
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "peekOfCode": "def cuda_is_available() -> bool:\n    \"\"\"\n    Check if CUDA is available in the environment.\n    Returns:\n        (bool): True if one or more NVIDIA GPUs are available, False otherwise.\n    \"\"\"\n    return cuda_device_count() > 0\n# Define constants\nIS_PYTHON_MINIMUM_3_10 = check_python(\"3.10\", hard=False)\nIS_PYTHON_3_12 = PYTHON_VERSION.startswith(\"3.12\")",
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "IS_PYTHON_MINIMUM_3_10",
        "kind": 5,
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "peekOfCode": "IS_PYTHON_MINIMUM_3_10 = check_python(\"3.10\", hard=False)\nIS_PYTHON_3_12 = PYTHON_VERSION.startswith(\"3.12\")",
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "IS_PYTHON_3_12",
        "kind": 5,
        "importPath": "ultralytics.utils.checks",
        "description": "ultralytics.utils.checks",
        "peekOfCode": "IS_PYTHON_3_12 = PYTHON_VERSION.startswith(\"3.12\")",
        "detail": "ultralytics.utils.checks",
        "documentation": {}
    },
    {
        "label": "find_free_network_port",
        "kind": 2,
        "importPath": "ultralytics.utils.dist",
        "description": "ultralytics.utils.dist",
        "peekOfCode": "def find_free_network_port() -> int:\n    \"\"\"\n    Finds a free port on localhost.\n    It is useful in single-node training when we don't want to connect to a real main node but have to set the\n    `MASTER_PORT` environment variable.\n    \"\"\"\n    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n        s.bind((\"127.0.0.1\", 0))\n        return s.getsockname()[1]  # port\ndef generate_ddp_file(trainer):",
        "detail": "ultralytics.utils.dist",
        "documentation": {}
    },
    {
        "label": "generate_ddp_file",
        "kind": 2,
        "importPath": "ultralytics.utils.dist",
        "description": "ultralytics.utils.dist",
        "peekOfCode": "def generate_ddp_file(trainer):\n    \"\"\"Generates a DDP file and returns its file name.\"\"\"\n    module, name = f\"{trainer.__class__.__module__}.{trainer.__class__.__name__}\".rsplit(\".\", 1)\n    content = f\"\"\"\n# Ultralytics Multi-GPU training temp file (should be automatically deleted after use)\noverrides = {vars(trainer.args)}\nif __name__ == \"__main__\":\n    from {module} import {name}\n    from ultralytics.utils import DEFAULT_CFG_DICT\n    cfg = DEFAULT_CFG_DICT.copy()",
        "detail": "ultralytics.utils.dist",
        "documentation": {}
    },
    {
        "label": "generate_ddp_command",
        "kind": 2,
        "importPath": "ultralytics.utils.dist",
        "description": "ultralytics.utils.dist",
        "peekOfCode": "def generate_ddp_command(world_size, trainer):\n    \"\"\"Generates and returns command for distributed training.\"\"\"\n    import __main__  # noqa local import to avoid https://github.com/Lightning-AI/lightning/issues/15218\n    if not trainer.resume:\n        shutil.rmtree(trainer.save_dir)  # remove the save_dir\n    file = generate_ddp_file(trainer)\n    dist_cmd = \"torch.distributed.run\" if TORCH_1_9 else \"torch.distributed.launch\"\n    port = find_free_network_port()\n    cmd = [sys.executable, \"-m\", dist_cmd, \"--nproc_per_node\", f\"{world_size}\", \"--master_port\", f\"{port}\", file]\n    return cmd, file",
        "detail": "ultralytics.utils.dist",
        "documentation": {}
    },
    {
        "label": "ddp_cleanup",
        "kind": 2,
        "importPath": "ultralytics.utils.dist",
        "description": "ultralytics.utils.dist",
        "peekOfCode": "def ddp_cleanup(trainer, file):\n    \"\"\"Delete temp file if created.\"\"\"\n    if f\"{id(trainer)}.py\" in file:  # if temp_file suffix in file\n        os.remove(file)",
        "detail": "ultralytics.utils.dist",
        "documentation": {}
    },
    {
        "label": "overrides",
        "kind": 5,
        "importPath": "ultralytics.utils.dist",
        "description": "ultralytics.utils.dist",
        "peekOfCode": "overrides = {vars(trainer.args)}\nif __name__ == \"__main__\":\n    from {module} import {name}\n    from ultralytics.utils import DEFAULT_CFG_DICT\n    cfg = DEFAULT_CFG_DICT.copy()\n    cfg.update(save_dir='')   # handle the extra key 'save_dir'\n    trainer = {name}(cfg=cfg, overrides=overrides)\n    trainer.args.model = \"{getattr(trainer.hub_session, 'model_url', trainer.args.model)}\"\n    results = trainer.train()\n\"\"\"",
        "detail": "ultralytics.utils.dist",
        "documentation": {}
    },
    {
        "label": "is_url",
        "kind": 2,
        "importPath": "ultralytics.utils.downloads",
        "description": "ultralytics.utils.downloads",
        "peekOfCode": "def is_url(url, check=False):\n    \"\"\"\n    Validates if the given string is a URL and optionally checks if the URL exists online.\n    Args:\n        url (str): The string to be validated as a URL.\n        check (bool, optional): If True, performs an additional check to see if the URL exists online.\n            Defaults to True.\n    Returns:\n        (bool): Returns True for a valid URL. If 'check' is True, also returns True if the URL exists online.\n            Returns False otherwise.",
        "detail": "ultralytics.utils.downloads",
        "documentation": {}
    },
    {
        "label": "delete_dsstore",
        "kind": 2,
        "importPath": "ultralytics.utils.downloads",
        "description": "ultralytics.utils.downloads",
        "peekOfCode": "def delete_dsstore(path, files_to_delete=(\".DS_Store\", \"__MACOSX\")):\n    \"\"\"\n    Deletes all \".DS_store\" files under a specified directory.\n    Args:\n        path (str, optional): The directory path where the \".DS_store\" files should be deleted.\n        files_to_delete (tuple): The files to be deleted.\n    Example:\n        ```python\n        from ultralytics.utils.downloads import delete_dsstore\n        delete_dsstore('path/to/dir')",
        "detail": "ultralytics.utils.downloads",
        "documentation": {}
    },
    {
        "label": "zip_directory",
        "kind": 2,
        "importPath": "ultralytics.utils.downloads",
        "description": "ultralytics.utils.downloads",
        "peekOfCode": "def zip_directory(directory, compress=True, exclude=(\".DS_Store\", \"__MACOSX\"), progress=True):\n    \"\"\"\n    Zips the contents of a directory, excluding files containing strings in the exclude list. The resulting zip file is\n    named after the directory and placed alongside it.\n    Args:\n        directory (str | Path): The path to the directory to be zipped.\n        compress (bool): Whether to compress the files while zipping. Default is True.\n        exclude (tuple, optional): A tuple of filename strings to be excluded. Defaults to ('.DS_Store', '__MACOSX').\n        progress (bool, optional): Whether to display a progress bar. Defaults to True.\n    Returns:",
        "detail": "ultralytics.utils.downloads",
        "documentation": {}
    },
    {
        "label": "unzip_file",
        "kind": 2,
        "importPath": "ultralytics.utils.downloads",
        "description": "ultralytics.utils.downloads",
        "peekOfCode": "def unzip_file(file, path=None, exclude=(\".DS_Store\", \"__MACOSX\"), exist_ok=False, progress=True):\n    \"\"\"\n    Unzips a *.zip file to the specified path, excluding files containing strings in the exclude list.\n    If the zipfile does not contain a single top-level directory, the function will create a new\n    directory with the same name as the zipfile (without the extension) to extract its contents.\n    If a path is not provided, the function will use the parent directory of the zipfile as the default path.\n    Args:\n        file (str): The path to the zipfile to be extracted.\n        path (str, optional): The path to extract the zipfile to. Defaults to None.\n        exclude (tuple, optional): A tuple of filename strings to be excluded. Defaults to ('.DS_Store', '__MACOSX').",
        "detail": "ultralytics.utils.downloads",
        "documentation": {}
    },
    {
        "label": "check_disk_space",
        "kind": 2,
        "importPath": "ultralytics.utils.downloads",
        "description": "ultralytics.utils.downloads",
        "peekOfCode": "def check_disk_space(url=\"https://ultralytics.com/assets/coco8.zip\", path=Path.cwd(), sf=1.5, hard=True):\n    \"\"\"\n    Check if there is sufficient disk space to download and store a file.\n    Args:\n        url (str, optional): The URL to the file. Defaults to 'https://ultralytics.com/assets/coco8.zip'.\n        path (str | Path, optional): The path or drive to check the available free space on.\n        sf (float, optional): Safety factor, the multiplier for the required free space. Defaults to 2.0.\n        hard (bool, optional): Whether to throw an error or not on insufficient disk space. Defaults to True.\n    Returns:\n        (bool): True if there is sufficient disk space, False otherwise.",
        "detail": "ultralytics.utils.downloads",
        "documentation": {}
    },
    {
        "label": "get_google_drive_file_info",
        "kind": 2,
        "importPath": "ultralytics.utils.downloads",
        "description": "ultralytics.utils.downloads",
        "peekOfCode": "def get_google_drive_file_info(link):\n    \"\"\"\n    Retrieves the direct download link and filename for a shareable Google Drive file link.\n    Args:\n        link (str): The shareable link of the Google Drive file.\n    Returns:\n        (str): Direct download URL for the Google Drive file.\n        (str): Original filename of the Google Drive file. If filename extraction fails, returns None.\n    Example:\n        ```python",
        "detail": "ultralytics.utils.downloads",
        "documentation": {}
    },
    {
        "label": "safe_download",
        "kind": 2,
        "importPath": "ultralytics.utils.downloads",
        "description": "ultralytics.utils.downloads",
        "peekOfCode": "def safe_download(\n    url,\n    file=None,\n    dir=None,\n    unzip=True,\n    delete=False,\n    curl=False,\n    retry=3,\n    min_bytes=1e0,\n    exist_ok=False,",
        "detail": "ultralytics.utils.downloads",
        "documentation": {}
    },
    {
        "label": "get_github_assets",
        "kind": 2,
        "importPath": "ultralytics.utils.downloads",
        "description": "ultralytics.utils.downloads",
        "peekOfCode": "def get_github_assets(repo=\"ultralytics/assets\", version=\"latest\", retry=False):\n    \"\"\"\n    Retrieve the specified version's tag and assets from a GitHub repository. If the version is not specified, the\n    function fetches the latest release assets.\n    Args:\n        repo (str, optional): The GitHub repository in the format 'owner/repo'. Defaults to 'ultralytics/assets'.\n        version (str, optional): The release version to fetch assets from. Defaults to 'latest'.\n        retry (bool, optional): Flag to retry the request in case of a failure. Defaults to False.\n    Returns:\n        (tuple): A tuple containing the release tag and a list of asset names.",
        "detail": "ultralytics.utils.downloads",
        "documentation": {}
    },
    {
        "label": "attempt_download_asset",
        "kind": 2,
        "importPath": "ultralytics.utils.downloads",
        "description": "ultralytics.utils.downloads",
        "peekOfCode": "def attempt_download_asset(file, repo=\"ultralytics/assets\", release=\"v8.2.0\", **kwargs):\n    \"\"\"\n    Attempt to download a file from GitHub release assets if it is not found locally. The function checks for the file\n    locally first, then tries to download it from the specified GitHub repository release.\n    Args:\n        file (str | Path): The filename or file path to be downloaded.\n        repo (str, optional): The GitHub repository in the format 'owner/repo'. Defaults to 'ultralytics/assets'.\n        release (str, optional): The specific release version to be downloaded. Defaults to 'v8.2.0'.\n        **kwargs (any): Additional keyword arguments for the download process.\n    Returns:",
        "detail": "ultralytics.utils.downloads",
        "documentation": {}
    },
    {
        "label": "download",
        "kind": 2,
        "importPath": "ultralytics.utils.downloads",
        "description": "ultralytics.utils.downloads",
        "peekOfCode": "def download(url, dir=Path.cwd(), unzip=True, delete=False, curl=False, threads=1, retry=3, exist_ok=False):\n    \"\"\"\n    Downloads files from specified URLs to a given directory. Supports concurrent downloads if multiple threads are\n    specified.\n    Args:\n        url (str | list): The URL or list of URLs of the files to be downloaded.\n        dir (Path, optional): The directory where the files will be saved. Defaults to the current working directory.\n        unzip (bool, optional): Flag to unzip the files after downloading. Defaults to True.\n        delete (bool, optional): Flag to delete the zip files after extraction. Defaults to False.\n        curl (bool, optional): Flag to use curl for downloading. Defaults to False.",
        "detail": "ultralytics.utils.downloads",
        "documentation": {}
    },
    {
        "label": "GITHUB_ASSETS_REPO",
        "kind": 5,
        "importPath": "ultralytics.utils.downloads",
        "description": "ultralytics.utils.downloads",
        "peekOfCode": "GITHUB_ASSETS_REPO = \"ultralytics/assets\"\nGITHUB_ASSETS_NAMES = (\n    [f\"yolov8{k}{suffix}.pt\" for k in \"nsmlx\" for suffix in (\"\", \"-cls\", \"-seg\", \"-pose\", \"-obb\", \"-oiv7\")]\n    + [f\"yolov5{k}{resolution}u.pt\" for k in \"nsmlx\" for resolution in (\"\", \"6\")]\n    + [f\"yolov3{k}u.pt\" for k in (\"\", \"-spp\", \"-tiny\")]\n    + [f\"yolov8{k}-world.pt\" for k in \"smlx\"]\n    + [f\"yolov8{k}-worldv2.pt\" for k in \"smlx\"]\n    + [f\"yolov9{k}.pt\" for k in \"tsmce\"]\n    + [f\"yolov10{k}.pt\" for k in \"nsmblx\"]\n    + [f\"yolo_nas_{k}.pt\" for k in \"sml\"]",
        "detail": "ultralytics.utils.downloads",
        "documentation": {}
    },
    {
        "label": "GITHUB_ASSETS_NAMES",
        "kind": 5,
        "importPath": "ultralytics.utils.downloads",
        "description": "ultralytics.utils.downloads",
        "peekOfCode": "GITHUB_ASSETS_NAMES = (\n    [f\"yolov8{k}{suffix}.pt\" for k in \"nsmlx\" for suffix in (\"\", \"-cls\", \"-seg\", \"-pose\", \"-obb\", \"-oiv7\")]\n    + [f\"yolov5{k}{resolution}u.pt\" for k in \"nsmlx\" for resolution in (\"\", \"6\")]\n    + [f\"yolov3{k}u.pt\" for k in (\"\", \"-spp\", \"-tiny\")]\n    + [f\"yolov8{k}-world.pt\" for k in \"smlx\"]\n    + [f\"yolov8{k}-worldv2.pt\" for k in \"smlx\"]\n    + [f\"yolov9{k}.pt\" for k in \"tsmce\"]\n    + [f\"yolov10{k}.pt\" for k in \"nsmblx\"]\n    + [f\"yolo_nas_{k}.pt\" for k in \"sml\"]\n    + [f\"sam_{k}.pt\" for k in \"bl\"]",
        "detail": "ultralytics.utils.downloads",
        "documentation": {}
    },
    {
        "label": "GITHUB_ASSETS_STEMS",
        "kind": 5,
        "importPath": "ultralytics.utils.downloads",
        "description": "ultralytics.utils.downloads",
        "peekOfCode": "GITHUB_ASSETS_STEMS = [Path(k).stem for k in GITHUB_ASSETS_NAMES]\ndef is_url(url, check=False):\n    \"\"\"\n    Validates if the given string is a URL and optionally checks if the URL exists online.\n    Args:\n        url (str): The string to be validated as a URL.\n        check (bool, optional): If True, performs an additional check to see if the URL exists online.\n            Defaults to True.\n    Returns:\n        (bool): Returns True for a valid URL. If 'check' is True, also returns True if the URL exists online.",
        "detail": "ultralytics.utils.downloads",
        "documentation": {}
    },
    {
        "label": "HUBModelError",
        "kind": 6,
        "importPath": "ultralytics.utils.errors",
        "description": "ultralytics.utils.errors",
        "peekOfCode": "class HUBModelError(Exception):\n    \"\"\"\n    Custom exception class for handling errors related to model fetching in Ultralytics YOLO.\n    This exception is raised when a requested model is not found or cannot be retrieved.\n    The message is also processed to include emojis for better user experience.\n    Attributes:\n        message (str): The error message displayed when the exception is raised.\n    Note:\n        The message is automatically processed through the 'emojis' function from the 'ultralytics.utils' package.\n    \"\"\"",
        "detail": "ultralytics.utils.errors",
        "documentation": {}
    },
    {
        "label": "WorkingDirectory",
        "kind": 6,
        "importPath": "ultralytics.utils.files",
        "description": "ultralytics.utils.files",
        "peekOfCode": "class WorkingDirectory(contextlib.ContextDecorator):\n    \"\"\"Usage: @WorkingDirectory(dir) decorator or 'with WorkingDirectory(dir):' context manager.\"\"\"\n    def __init__(self, new_dir):\n        \"\"\"Sets the working directory to 'new_dir' upon instantiation.\"\"\"\n        self.dir = new_dir  # new dir\n        self.cwd = Path.cwd().resolve()  # current dir\n    def __enter__(self):\n        \"\"\"Changes the current directory to the specified directory.\"\"\"\n        os.chdir(self.dir)\n    def __exit__(self, exc_type, exc_val, exc_tb):  # noqa",
        "detail": "ultralytics.utils.files",
        "documentation": {}
    },
    {
        "label": "spaces_in_path",
        "kind": 2,
        "importPath": "ultralytics.utils.files",
        "description": "ultralytics.utils.files",
        "peekOfCode": "def spaces_in_path(path):\n    \"\"\"\n    Context manager to handle paths with spaces in their names. If a path contains spaces, it replaces them with\n    underscores, copies the file/directory to the new path, executes the context code block, then copies the\n    file/directory back to its original location.\n    Args:\n        path (str | Path): The original path.\n    Yields:\n        (Path): Temporary path with spaces replaced by underscores if spaces were present, otherwise the original path.\n    Example:",
        "detail": "ultralytics.utils.files",
        "documentation": {}
    },
    {
        "label": "increment_path",
        "kind": 2,
        "importPath": "ultralytics.utils.files",
        "description": "ultralytics.utils.files",
        "peekOfCode": "def increment_path(path, exist_ok=False, sep=\"\", mkdir=False):\n    \"\"\"\n    Increments a file or directory path, i.e. runs/exp --> runs/exp{sep}2, runs/exp{sep}3, ... etc.\n    If the path exists and exist_ok is not set to True, the path will be incremented by appending a number and sep to\n    the end of the path. If the path is a file, the file extension will be preserved. If the path is a directory, the\n    number will be appended directly to the end of the path. If mkdir is set to True, the path will be created as a\n    directory if it does not already exist.\n    Args:\n        path (str, pathlib.Path): Path to increment.\n        exist_ok (bool, optional): If True, the path will not be incremented and returned as-is. Defaults to False.",
        "detail": "ultralytics.utils.files",
        "documentation": {}
    },
    {
        "label": "file_age",
        "kind": 2,
        "importPath": "ultralytics.utils.files",
        "description": "ultralytics.utils.files",
        "peekOfCode": "def file_age(path=__file__):\n    \"\"\"Return days since last file update.\"\"\"\n    dt = datetime.now() - datetime.fromtimestamp(Path(path).stat().st_mtime)  # delta\n    return dt.days  # + dt.seconds / 86400  # fractional days\ndef file_date(path=__file__):\n    \"\"\"Return human-readable file modification date, i.e. '2021-3-26'.\"\"\"\n    t = datetime.fromtimestamp(Path(path).stat().st_mtime)\n    return f\"{t.year}-{t.month}-{t.day}\"\ndef file_size(path):\n    \"\"\"Return file/dir size (MB).\"\"\"",
        "detail": "ultralytics.utils.files",
        "documentation": {}
    },
    {
        "label": "file_date",
        "kind": 2,
        "importPath": "ultralytics.utils.files",
        "description": "ultralytics.utils.files",
        "peekOfCode": "def file_date(path=__file__):\n    \"\"\"Return human-readable file modification date, i.e. '2021-3-26'.\"\"\"\n    t = datetime.fromtimestamp(Path(path).stat().st_mtime)\n    return f\"{t.year}-{t.month}-{t.day}\"\ndef file_size(path):\n    \"\"\"Return file/dir size (MB).\"\"\"\n    if isinstance(path, (str, Path)):\n        mb = 1 << 20  # bytes to MiB (1024 ** 2)\n        path = Path(path)\n        if path.is_file():",
        "detail": "ultralytics.utils.files",
        "documentation": {}
    },
    {
        "label": "file_size",
        "kind": 2,
        "importPath": "ultralytics.utils.files",
        "description": "ultralytics.utils.files",
        "peekOfCode": "def file_size(path):\n    \"\"\"Return file/dir size (MB).\"\"\"\n    if isinstance(path, (str, Path)):\n        mb = 1 << 20  # bytes to MiB (1024 ** 2)\n        path = Path(path)\n        if path.is_file():\n            return path.stat().st_size / mb\n        elif path.is_dir():\n            return sum(f.stat().st_size for f in path.glob(\"**/*\") if f.is_file()) / mb\n    return 0.0",
        "detail": "ultralytics.utils.files",
        "documentation": {}
    },
    {
        "label": "get_latest_run",
        "kind": 2,
        "importPath": "ultralytics.utils.files",
        "description": "ultralytics.utils.files",
        "peekOfCode": "def get_latest_run(search_dir=\".\"):\n    \"\"\"Return path to most recent 'last.pt' in /runs (i.e. to --resume from).\"\"\"\n    last_list = glob.glob(f\"{search_dir}/**/last*.pt\", recursive=True)\n    return max(last_list, key=os.path.getctime) if last_list else \"\"\ndef update_models(model_names=(\"yolov8n.pt\",), source_dir=Path(\".\"), update_names=False):\n    \"\"\"\n    Updates and re-saves specified YOLO models in an 'updated_models' subdirectory.\n    Args:\n        model_names (tuple, optional): Model filenames to update, defaults to (\"yolov8n.pt\").\n        source_dir (Path, optional): Directory containing models and target subdirectory, defaults to current directory.",
        "detail": "ultralytics.utils.files",
        "documentation": {}
    },
    {
        "label": "update_models",
        "kind": 2,
        "importPath": "ultralytics.utils.files",
        "description": "ultralytics.utils.files",
        "peekOfCode": "def update_models(model_names=(\"yolov8n.pt\",), source_dir=Path(\".\"), update_names=False):\n    \"\"\"\n    Updates and re-saves specified YOLO models in an 'updated_models' subdirectory.\n    Args:\n        model_names (tuple, optional): Model filenames to update, defaults to (\"yolov8n.pt\").\n        source_dir (Path, optional): Directory containing models and target subdirectory, defaults to current directory.\n        update_names (bool, optional): Update model names from a data YAML.\n    Example:\n        ```python\n        from ultralytics.utils.files import update_models",
        "detail": "ultralytics.utils.files",
        "documentation": {}
    },
    {
        "label": "Bboxes",
        "kind": 6,
        "importPath": "ultralytics.utils.instance",
        "description": "ultralytics.utils.instance",
        "peekOfCode": "class Bboxes:\n    \"\"\"\n    A class for handling bounding boxes.\n    The class supports various bounding box formats like 'xyxy', 'xywh', and 'ltwh'.\n    Bounding box data should be provided in numpy arrays.\n    Attributes:\n        bboxes (numpy.ndarray): The bounding boxes stored in a 2D numpy array.\n        format (str): The format of the bounding boxes ('xyxy', 'xywh', or 'ltwh').\n    Note:\n        This class does not handle normalization or denormalization of bounding boxes.",
        "detail": "ultralytics.utils.instance",
        "documentation": {}
    },
    {
        "label": "Instances",
        "kind": 6,
        "importPath": "ultralytics.utils.instance",
        "description": "ultralytics.utils.instance",
        "peekOfCode": "class Instances:\n    \"\"\"\n    Container for bounding boxes, segments, and keypoints of detected objects in an image.\n    Attributes:\n        _bboxes (Bboxes): Internal object for handling bounding box operations.\n        keypoints (ndarray): keypoints(x, y, visible) with shape [N, 17, 3]. Default is None.\n        normalized (bool): Flag indicating whether the bounding box coordinates are normalized.\n        segments (ndarray): Segments array with shape [N, 1000, 2] after resampling.\n    Args:\n        bboxes (ndarray): An array of bounding boxes with shape [N, 4].",
        "detail": "ultralytics.utils.instance",
        "documentation": {}
    },
    {
        "label": "to_2tuple",
        "kind": 5,
        "importPath": "ultralytics.utils.instance",
        "description": "ultralytics.utils.instance",
        "peekOfCode": "to_2tuple = _ntuple(2)\nto_4tuple = _ntuple(4)\n# `xyxy` means left top and right bottom\n# `xywh` means center x, center y and width, height(YOLO format)\n# `ltwh` means left top and width, height(COCO format)\n_formats = [\"xyxy\", \"xywh\", \"ltwh\"]\n__all__ = (\"Bboxes\",)  # tuple or list\nclass Bboxes:\n    \"\"\"\n    A class for handling bounding boxes.",
        "detail": "ultralytics.utils.instance",
        "documentation": {}
    },
    {
        "label": "to_4tuple",
        "kind": 5,
        "importPath": "ultralytics.utils.instance",
        "description": "ultralytics.utils.instance",
        "peekOfCode": "to_4tuple = _ntuple(4)\n# `xyxy` means left top and right bottom\n# `xywh` means center x, center y and width, height(YOLO format)\n# `ltwh` means left top and width, height(COCO format)\n_formats = [\"xyxy\", \"xywh\", \"ltwh\"]\n__all__ = (\"Bboxes\",)  # tuple or list\nclass Bboxes:\n    \"\"\"\n    A class for handling bounding boxes.\n    The class supports various bounding box formats like 'xyxy', 'xywh', and 'ltwh'.",
        "detail": "ultralytics.utils.instance",
        "documentation": {}
    },
    {
        "label": "_formats",
        "kind": 5,
        "importPath": "ultralytics.utils.instance",
        "description": "ultralytics.utils.instance",
        "peekOfCode": "_formats = [\"xyxy\", \"xywh\", \"ltwh\"]\n__all__ = (\"Bboxes\",)  # tuple or list\nclass Bboxes:\n    \"\"\"\n    A class for handling bounding boxes.\n    The class supports various bounding box formats like 'xyxy', 'xywh', and 'ltwh'.\n    Bounding box data should be provided in numpy arrays.\n    Attributes:\n        bboxes (numpy.ndarray): The bounding boxes stored in a 2D numpy array.\n        format (str): The format of the bounding boxes ('xyxy', 'xywh', or 'ltwh').",
        "detail": "ultralytics.utils.instance",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "ultralytics.utils.instance",
        "description": "ultralytics.utils.instance",
        "peekOfCode": "__all__ = (\"Bboxes\",)  # tuple or list\nclass Bboxes:\n    \"\"\"\n    A class for handling bounding boxes.\n    The class supports various bounding box formats like 'xyxy', 'xywh', and 'ltwh'.\n    Bounding box data should be provided in numpy arrays.\n    Attributes:\n        bboxes (numpy.ndarray): The bounding boxes stored in a 2D numpy array.\n        format (str): The format of the bounding boxes ('xyxy', 'xywh', or 'ltwh').\n    Note:",
        "detail": "ultralytics.utils.instance",
        "documentation": {}
    },
    {
        "label": "VarifocalLoss",
        "kind": 6,
        "importPath": "ultralytics.utils.loss",
        "description": "ultralytics.utils.loss",
        "peekOfCode": "class VarifocalLoss(nn.Module):\n    \"\"\"\n    Varifocal loss by Zhang et al.\n    https://arxiv.org/abs/2008.13367.\n    \"\"\"\n    def __init__(self):\n        \"\"\"Initialize the VarifocalLoss class.\"\"\"\n        super().__init__()\n    @staticmethod\n    def forward(pred_score, gt_score, label, alpha=0.75, gamma=2.0):",
        "detail": "ultralytics.utils.loss",
        "documentation": {}
    },
    {
        "label": "FocalLoss",
        "kind": 6,
        "importPath": "ultralytics.utils.loss",
        "description": "ultralytics.utils.loss",
        "peekOfCode": "class FocalLoss(nn.Module):\n    \"\"\"Wraps focal loss around existing loss_fcn(), i.e. criteria = FocalLoss(nn.BCEWithLogitsLoss(), gamma=1.5).\"\"\"\n    def __init__(self):\n        \"\"\"Initializer for FocalLoss class with no parameters.\"\"\"\n        super().__init__()\n    @staticmethod\n    def forward(pred, label, gamma=1.5, alpha=0.25):\n        \"\"\"Calculates and updates confusion matrix for object detection/classification tasks.\"\"\"\n        loss = F.binary_cross_entropy_with_logits(pred, label, reduction=\"none\")\n        # p_t = torch.exp(-loss)",
        "detail": "ultralytics.utils.loss",
        "documentation": {}
    },
    {
        "label": "DFLoss",
        "kind": 6,
        "importPath": "ultralytics.utils.loss",
        "description": "ultralytics.utils.loss",
        "peekOfCode": "class DFLoss(nn.Module):\n    \"\"\"Criterion class for computing DFL losses during training.\"\"\"\n    def __init__(self, reg_max=16) -> None:\n        \"\"\"Initialize the DFL module.\"\"\"\n        super().__init__()\n        self.reg_max = reg_max\n    def __call__(self, pred_dist, target):\n        \"\"\"\n        Return sum of left and right DFL losses.\n        Distribution Focal Loss (DFL) proposed in Generalized Focal Loss",
        "detail": "ultralytics.utils.loss",
        "documentation": {}
    },
    {
        "label": "BboxLoss",
        "kind": 6,
        "importPath": "ultralytics.utils.loss",
        "description": "ultralytics.utils.loss",
        "peekOfCode": "class BboxLoss(nn.Module):\n    \"\"\"Criterion class for computing training losses during training.\"\"\"\n    def __init__(self, reg_max=16):\n        \"\"\"Initialize the BboxLoss module with regularization maximum and DFL settings.\"\"\"\n        super().__init__()\n        self.dfl_loss = DFLoss(reg_max) if reg_max > 1 else None\n    def forward(self, pred_dist, pred_bboxes, anchor_points, target_bboxes, target_scores, target_scores_sum, fg_mask):\n        \"\"\"IoU loss.\"\"\"\n        weight = target_scores.sum(-1)[fg_mask].unsqueeze(-1)\n        iou = bbox_iou(pred_bboxes[fg_mask], target_bboxes[fg_mask], xywh=False, CIoU=True)",
        "detail": "ultralytics.utils.loss",
        "documentation": {}
    },
    {
        "label": "RotatedBboxLoss",
        "kind": 6,
        "importPath": "ultralytics.utils.loss",
        "description": "ultralytics.utils.loss",
        "peekOfCode": "class RotatedBboxLoss(BboxLoss):\n    \"\"\"Criterion class for computing training losses during training.\"\"\"\n    def __init__(self, reg_max):\n        \"\"\"Initialize the BboxLoss module with regularization maximum and DFL settings.\"\"\"\n        super().__init__(reg_max)\n    def forward(self, pred_dist, pred_bboxes, anchor_points, target_bboxes, target_scores, target_scores_sum, fg_mask):\n        \"\"\"IoU loss.\"\"\"\n        weight = target_scores.sum(-1)[fg_mask].unsqueeze(-1)\n        iou = probiou(pred_bboxes[fg_mask], target_bboxes[fg_mask])\n        loss_iou = ((1.0 - iou) * weight).sum() / target_scores_sum",
        "detail": "ultralytics.utils.loss",
        "documentation": {}
    },
    {
        "label": "KeypointLoss",
        "kind": 6,
        "importPath": "ultralytics.utils.loss",
        "description": "ultralytics.utils.loss",
        "peekOfCode": "class KeypointLoss(nn.Module):\n    \"\"\"Criterion class for computing training losses.\"\"\"\n    def __init__(self, sigmas) -> None:\n        \"\"\"Initialize the KeypointLoss class.\"\"\"\n        super().__init__()\n        self.sigmas = sigmas\n    def forward(self, pred_kpts, gt_kpts, kpt_mask, area):\n        \"\"\"Calculates keypoint loss factor and Euclidean distance loss for predicted and actual keypoints.\"\"\"\n        d = (pred_kpts[..., 0] - gt_kpts[..., 0]).pow(2) + (pred_kpts[..., 1] - gt_kpts[..., 1]).pow(2)\n        kpt_loss_factor = kpt_mask.shape[1] / (torch.sum(kpt_mask != 0, dim=1) + 1e-9)",
        "detail": "ultralytics.utils.loss",
        "documentation": {}
    },
    {
        "label": "v8DetectionLoss",
        "kind": 6,
        "importPath": "ultralytics.utils.loss",
        "description": "ultralytics.utils.loss",
        "peekOfCode": "class v8DetectionLoss:\n    \"\"\"Criterion class for computing training losses.\"\"\"\n    def __init__(self, model, tal_topk=10):  # model must be de-paralleled\n        \"\"\"Initializes v8DetectionLoss with the model, defining model-related properties and BCE loss function.\"\"\"\n        device = next(model.parameters()).device  # get model device\n        h = model.args  # hyperparameters\n        m = model.model[-1]  # Detect() module\n        self.bce = nn.BCEWithLogitsLoss(reduction=\"none\")\n        self.hyp = h\n        self.stride = m.stride  # model strides",
        "detail": "ultralytics.utils.loss",
        "documentation": {}
    },
    {
        "label": "v8SegmentationLoss",
        "kind": 6,
        "importPath": "ultralytics.utils.loss",
        "description": "ultralytics.utils.loss",
        "peekOfCode": "class v8SegmentationLoss(v8DetectionLoss):\n    \"\"\"Criterion class for computing training losses.\"\"\"\n    def __init__(self, model):  # model must be de-paralleled\n        \"\"\"Initializes the v8SegmentationLoss class, taking a de-paralleled model as argument.\"\"\"\n        super().__init__(model)\n        self.overlap = model.args.overlap_mask\n    def __call__(self, preds, batch):\n        \"\"\"Calculate and return the loss for the YOLO model.\"\"\"\n        loss = torch.zeros(4, device=self.device)  # box, cls, dfl\n        feats, pred_masks, proto = preds if len(preds) == 3 else preds[1]",
        "detail": "ultralytics.utils.loss",
        "documentation": {}
    },
    {
        "label": "v8PoseLoss",
        "kind": 6,
        "importPath": "ultralytics.utils.loss",
        "description": "ultralytics.utils.loss",
        "peekOfCode": "class v8PoseLoss(v8DetectionLoss):\n    \"\"\"Criterion class for computing training losses.\"\"\"\n    def __init__(self, model):  # model must be de-paralleled\n        \"\"\"Initializes v8PoseLoss with model, sets keypoint variables and declares a keypoint loss instance.\"\"\"\n        super().__init__(model)\n        self.kpt_shape = model.model[-1].kpt_shape\n        self.bce_pose = nn.BCEWithLogitsLoss()\n        is_pose = self.kpt_shape == [17, 3]\n        nkpt = self.kpt_shape[0]  # number of keypoints\n        sigmas = torch.from_numpy(OKS_SIGMA).to(self.device) if is_pose else torch.ones(nkpt, device=self.device) / nkpt",
        "detail": "ultralytics.utils.loss",
        "documentation": {}
    },
    {
        "label": "v8ClassificationLoss",
        "kind": 6,
        "importPath": "ultralytics.utils.loss",
        "description": "ultralytics.utils.loss",
        "peekOfCode": "class v8ClassificationLoss:\n    \"\"\"Criterion class for computing training losses.\"\"\"\n    def __call__(self, preds, batch):\n        \"\"\"Compute the classification loss between predictions and true labels.\"\"\"\n        loss = F.cross_entropy(preds, batch[\"cls\"], reduction=\"mean\")\n        loss_items = loss.detach()\n        return loss, loss_items\nclass v8OBBLoss(v8DetectionLoss):\n    \"\"\"Calculates losses for object detection, classification, and box distribution in rotated YOLO models.\"\"\"\n    def __init__(self, model):",
        "detail": "ultralytics.utils.loss",
        "documentation": {}
    },
    {
        "label": "v8OBBLoss",
        "kind": 6,
        "importPath": "ultralytics.utils.loss",
        "description": "ultralytics.utils.loss",
        "peekOfCode": "class v8OBBLoss(v8DetectionLoss):\n    \"\"\"Calculates losses for object detection, classification, and box distribution in rotated YOLO models.\"\"\"\n    def __init__(self, model):\n        \"\"\"Initializes v8OBBLoss with model, assigner, and rotated bbox loss; note model must be de-paralleled.\"\"\"\n        super().__init__(model)\n        self.assigner = RotatedTaskAlignedAssigner(topk=10, num_classes=self.nc, alpha=0.5, beta=6.0)\n        self.bbox_loss = RotatedBboxLoss(self.reg_max).to(self.device)\n    def preprocess(self, targets, batch_size, scale_tensor):\n        \"\"\"Preprocesses the target counts and matches with the input batch size to output a tensor.\"\"\"\n        if targets.shape[0] == 0:",
        "detail": "ultralytics.utils.loss",
        "documentation": {}
    },
    {
        "label": "E2EDetectLoss",
        "kind": 6,
        "importPath": "ultralytics.utils.loss",
        "description": "ultralytics.utils.loss",
        "peekOfCode": "class E2EDetectLoss:\n    \"\"\"Criterion class for computing training losses.\"\"\"\n    def __init__(self, model):\n        \"\"\"Initialize E2EDetectLoss with one-to-many and one-to-one detection losses using the provided model.\"\"\"\n        self.one2many = v8DetectionLoss(model, tal_topk=10)\n        self.one2one = v8DetectionLoss(model, tal_topk=1)\n    def __call__(self, preds, batch):\n        \"\"\"Calculate the sum of the loss for box, cls and dfl multiplied by batch size.\"\"\"\n        preds = preds[1] if isinstance(preds, tuple) else preds\n        one2many = preds[\"one2many\"]",
        "detail": "ultralytics.utils.loss",
        "documentation": {}
    },
    {
        "label": "ConfusionMatrix",
        "kind": 6,
        "importPath": "ultralytics.utils.metrics",
        "description": "ultralytics.utils.metrics",
        "peekOfCode": "class ConfusionMatrix:\n    \"\"\"\n    A class for calculating and updating a confusion matrix for object detection and classification tasks.\n    Attributes:\n        task (str): The type of task, either 'detect' or 'classify'.\n        matrix (np.ndarray): The confusion matrix, with dimensions depending on the task.\n        nc (int): The number of classes.\n        conf (float): The confidence threshold for detections.\n        iou_thres (float): The Intersection over Union threshold.\n    \"\"\"",
        "detail": "ultralytics.utils.metrics",
        "documentation": {}
    },
    {
        "label": "Metric",
        "kind": 6,
        "importPath": "ultralytics.utils.metrics",
        "description": "ultralytics.utils.metrics",
        "peekOfCode": "class Metric(SimpleClass):\n    \"\"\"\n    Class for computing evaluation metrics for YOLOv8 model.\n    Attributes:\n        p (list): Precision for each class. Shape: (nc,).\n        r (list): Recall for each class. Shape: (nc,).\n        f1 (list): F1 score for each class. Shape: (nc,).\n        all_ap (list): AP scores for all classes and all IoU thresholds. Shape: (nc, 10).\n        ap_class_index (list): Index of class for each AP score. Shape: (nc,).\n        nc (int): Number of classes.",
        "detail": "ultralytics.utils.metrics",
        "documentation": {}
    },
    {
        "label": "DetMetrics",
        "kind": 6,
        "importPath": "ultralytics.utils.metrics",
        "description": "ultralytics.utils.metrics",
        "peekOfCode": "class DetMetrics(SimpleClass):\n    \"\"\"\n    This class is a utility class for computing detection metrics such as precision, recall, and mean average precision\n    (mAP) of an object detection model.\n    Args:\n        save_dir (Path): A path to the directory where the output plots will be saved. Defaults to current directory.\n        plot (bool): A flag that indicates whether to plot precision-recall curves for each class. Defaults to False.\n        on_plot (func): An optional callback to pass plots path and data when they are rendered. Defaults to None.\n        names (tuple of str): A tuple of strings that represents the names of the classes. Defaults to an empty tuple.\n    Attributes:",
        "detail": "ultralytics.utils.metrics",
        "documentation": {}
    },
    {
        "label": "SegmentMetrics",
        "kind": 6,
        "importPath": "ultralytics.utils.metrics",
        "description": "ultralytics.utils.metrics",
        "peekOfCode": "class SegmentMetrics(SimpleClass):\n    \"\"\"\n    Calculates and aggregates detection and segmentation metrics over a given set of classes.\n    Args:\n        save_dir (Path): Path to the directory where the output plots should be saved. Default is the current directory.\n        plot (bool): Whether to save the detection and segmentation plots. Default is False.\n        on_plot (func): An optional callback to pass plots path and data when they are rendered. Defaults to None.\n        names (list): List of class names. Default is an empty list.\n    Attributes:\n        save_dir (Path): Path to the directory where the output plots should be saved.",
        "detail": "ultralytics.utils.metrics",
        "documentation": {}
    },
    {
        "label": "PoseMetrics",
        "kind": 6,
        "importPath": "ultralytics.utils.metrics",
        "description": "ultralytics.utils.metrics",
        "peekOfCode": "class PoseMetrics(SegmentMetrics):\n    \"\"\"\n    Calculates and aggregates detection and pose metrics over a given set of classes.\n    Args:\n        save_dir (Path): Path to the directory where the output plots should be saved. Default is the current directory.\n        plot (bool): Whether to save the detection and segmentation plots. Default is False.\n        on_plot (func): An optional callback to pass plots path and data when they are rendered. Defaults to None.\n        names (list): List of class names. Default is an empty list.\n    Attributes:\n        save_dir (Path): Path to the directory where the output plots should be saved.",
        "detail": "ultralytics.utils.metrics",
        "documentation": {}
    },
    {
        "label": "ClassifyMetrics",
        "kind": 6,
        "importPath": "ultralytics.utils.metrics",
        "description": "ultralytics.utils.metrics",
        "peekOfCode": "class ClassifyMetrics(SimpleClass):\n    \"\"\"\n    Class for computing classification metrics including top-1 and top-5 accuracy.\n    Attributes:\n        top1 (float): The top-1 accuracy.\n        top5 (float): The top-5 accuracy.\n        speed (Dict[str, float]): A dictionary containing the time taken for each step in the pipeline.\n        fitness (float): The fitness of the model, which is equal to top-5 accuracy.\n        results_dict (Dict[str, Union[float, str]]): A dictionary containing the classification metrics and fitness.\n        keys (List[str]): A list of keys for the results_dict.",
        "detail": "ultralytics.utils.metrics",
        "documentation": {}
    },
    {
        "label": "OBBMetrics",
        "kind": 6,
        "importPath": "ultralytics.utils.metrics",
        "description": "ultralytics.utils.metrics",
        "peekOfCode": "class OBBMetrics(SimpleClass):\n    \"\"\"Metrics for evaluating oriented bounding box (OBB) detection, see https://arxiv.org/pdf/2106.06072.pdf.\"\"\"\n    def __init__(self, save_dir=Path(\".\"), plot=False, on_plot=None, names=()) -> None:\n        \"\"\"Initialize an OBBMetrics instance with directory, plotting, callback, and class names.\"\"\"\n        self.save_dir = save_dir\n        self.plot = plot\n        self.on_plot = on_plot\n        self.names = names\n        self.box = Metric()\n        self.speed = {\"preprocess\": 0.0, \"inference\": 0.0, \"loss\": 0.0, \"postprocess\": 0.0}",
        "detail": "ultralytics.utils.metrics",
        "documentation": {}
    },
    {
        "label": "bbox_ioa",
        "kind": 2,
        "importPath": "ultralytics.utils.metrics",
        "description": "ultralytics.utils.metrics",
        "peekOfCode": "def bbox_ioa(box1, box2, iou=False, eps=1e-7):\n    \"\"\"\n    Calculate the intersection over box2 area given box1 and box2. Boxes are in x1y1x2y2 format.\n    Args:\n        box1 (np.ndarray): A numpy array of shape (n, 4) representing n bounding boxes.\n        box2 (np.ndarray): A numpy array of shape (m, 4) representing m bounding boxes.\n        iou (bool): Calculate the standard IoU if True else return inter_area/box2_area.\n        eps (float, optional): A small value to avoid division by zero. Defaults to 1e-7.\n    Returns:\n        (np.ndarray): A numpy array of shape (n, m) representing the intersection over box2 area.",
        "detail": "ultralytics.utils.metrics",
        "documentation": {}
    },
    {
        "label": "box_iou",
        "kind": 2,
        "importPath": "ultralytics.utils.metrics",
        "description": "ultralytics.utils.metrics",
        "peekOfCode": "def box_iou(box1, box2, eps=1e-7):\n    \"\"\"\n    Calculate intersection-over-union (IoU) of boxes. Both sets of boxes are expected to be in (x1, y1, x2, y2) format.\n    Based on https://github.com/pytorch/vision/blob/master/torchvision/ops/boxes.py\n    Args:\n        box1 (torch.Tensor): A tensor of shape (N, 4) representing N bounding boxes.\n        box2 (torch.Tensor): A tensor of shape (M, 4) representing M bounding boxes.\n        eps (float, optional): A small value to avoid division by zero. Defaults to 1e-7.\n    Returns:\n        (torch.Tensor): An NxM tensor containing the pairwise IoU values for every element in box1 and box2.",
        "detail": "ultralytics.utils.metrics",
        "documentation": {}
    },
    {
        "label": "bbox_iou",
        "kind": 2,
        "importPath": "ultralytics.utils.metrics",
        "description": "ultralytics.utils.metrics",
        "peekOfCode": "def bbox_iou(box1, box2, xywh=True, GIoU=False, DIoU=False, CIoU=False, eps=1e-7):\n    \"\"\"\n    Calculate Intersection over Union (IoU) of box1(1, 4) to box2(n, 4).\n    Args:\n        box1 (torch.Tensor): A tensor representing a single bounding box with shape (1, 4).\n        box2 (torch.Tensor): A tensor representing n bounding boxes with shape (n, 4).\n        xywh (bool, optional): If True, input boxes are in (x, y, w, h) format. If False, input boxes are in\n                               (x1, y1, x2, y2) format. Defaults to True.\n        GIoU (bool, optional): If True, calculate Generalized IoU. Defaults to False.\n        DIoU (bool, optional): If True, calculate Distance IoU. Defaults to False.",
        "detail": "ultralytics.utils.metrics",
        "documentation": {}
    },
    {
        "label": "mask_iou",
        "kind": 2,
        "importPath": "ultralytics.utils.metrics",
        "description": "ultralytics.utils.metrics",
        "peekOfCode": "def mask_iou(mask1, mask2, eps=1e-7):\n    \"\"\"\n    Calculate masks IoU.\n    Args:\n        mask1 (torch.Tensor): A tensor of shape (N, n) where N is the number of ground truth objects and n is the\n                        product of image width and height.\n        mask2 (torch.Tensor): A tensor of shape (M, n) where M is the number of predicted objects and n is the\n                        product of image width and height.\n        eps (float, optional): A small value to avoid division by zero. Defaults to 1e-7.\n    Returns:",
        "detail": "ultralytics.utils.metrics",
        "documentation": {}
    },
    {
        "label": "kpt_iou",
        "kind": 2,
        "importPath": "ultralytics.utils.metrics",
        "description": "ultralytics.utils.metrics",
        "peekOfCode": "def kpt_iou(kpt1, kpt2, area, sigma, eps=1e-7):\n    \"\"\"\n    Calculate Object Keypoint Similarity (OKS).\n    Args:\n        kpt1 (torch.Tensor): A tensor of shape (N, 17, 3) representing ground truth keypoints.\n        kpt2 (torch.Tensor): A tensor of shape (M, 17, 3) representing predicted keypoints.\n        area (torch.Tensor): A tensor of shape (N,) representing areas from ground truth.\n        sigma (list): A list containing 17 values representing keypoint scales.\n        eps (float, optional): A small value to avoid division by zero. Defaults to 1e-7.\n    Returns:",
        "detail": "ultralytics.utils.metrics",
        "documentation": {}
    },
    {
        "label": "probiou",
        "kind": 2,
        "importPath": "ultralytics.utils.metrics",
        "description": "ultralytics.utils.metrics",
        "peekOfCode": "def probiou(obb1, obb2, CIoU=False, eps=1e-7):\n    \"\"\"\n    Calculate the prob IoU between oriented bounding boxes, https://arxiv.org/pdf/2106.06072v1.pdf.\n    Args:\n        obb1 (torch.Tensor): A tensor of shape (N, 5) representing ground truth obbs, with xywhr format.\n        obb2 (torch.Tensor): A tensor of shape (N, 5) representing predicted obbs, with xywhr format.\n        eps (float, optional): A small value to avoid division by zero. Defaults to 1e-7.\n    Returns:\n        (torch.Tensor): A tensor of shape (N, ) representing obb similarities.\n    \"\"\"",
        "detail": "ultralytics.utils.metrics",
        "documentation": {}
    },
    {
        "label": "batch_probiou",
        "kind": 2,
        "importPath": "ultralytics.utils.metrics",
        "description": "ultralytics.utils.metrics",
        "peekOfCode": "def batch_probiou(obb1, obb2, eps=1e-7):\n    \"\"\"\n    Calculate the prob IoU between oriented bounding boxes, https://arxiv.org/pdf/2106.06072v1.pdf.\n    Args:\n        obb1 (torch.Tensor | np.ndarray): A tensor of shape (N, 5) representing ground truth obbs, with xywhr format.\n        obb2 (torch.Tensor | np.ndarray): A tensor of shape (M, 5) representing predicted obbs, with xywhr format.\n        eps (float, optional): A small value to avoid division by zero. Defaults to 1e-7.\n    Returns:\n        (torch.Tensor): A tensor of shape (N, M) representing obb similarities.\n    \"\"\"",
        "detail": "ultralytics.utils.metrics",
        "documentation": {}
    },
    {
        "label": "smooth_BCE",
        "kind": 2,
        "importPath": "ultralytics.utils.metrics",
        "description": "ultralytics.utils.metrics",
        "peekOfCode": "def smooth_BCE(eps=0.1):\n    \"\"\"\n    Computes smoothed positive and negative Binary Cross-Entropy targets.\n    This function calculates positive and negative label smoothing BCE targets based on a given epsilon value.\n    For implementation details, refer to https://github.com/ultralytics/yolov3/issues/238#issuecomment-598028441.\n    Args:\n        eps (float, optional): The epsilon value for label smoothing. Defaults to 0.1.\n    Returns:\n        (tuple): A tuple containing the positive and negative label smoothing BCE targets.\n    \"\"\"",
        "detail": "ultralytics.utils.metrics",
        "documentation": {}
    },
    {
        "label": "smooth",
        "kind": 2,
        "importPath": "ultralytics.utils.metrics",
        "description": "ultralytics.utils.metrics",
        "peekOfCode": "def smooth(y, f=0.05):\n    \"\"\"Box filter of fraction f.\"\"\"\n    nf = round(len(y) * f * 2) // 2 + 1  # number of filter elements (must be odd)\n    p = np.ones(nf // 2)  # ones padding\n    yp = np.concatenate((p * y[0], y, p * y[-1]), 0)  # y padded\n    return np.convolve(yp, np.ones(nf) / nf, mode=\"valid\")  # y-smoothed\n@plt_settings()\ndef plot_pr_curve(px, py, ap, save_dir=Path(\"pr_curve.png\"), names=(), on_plot=None):\n    \"\"\"Plots a precision-recall curve.\"\"\"\n    fig, ax = plt.subplots(1, 1, figsize=(9, 6), tight_layout=True)",
        "detail": "ultralytics.utils.metrics",
        "documentation": {}
    },
    {
        "label": "plot_pr_curve",
        "kind": 2,
        "importPath": "ultralytics.utils.metrics",
        "description": "ultralytics.utils.metrics",
        "peekOfCode": "def plot_pr_curve(px, py, ap, save_dir=Path(\"pr_curve.png\"), names=(), on_plot=None):\n    \"\"\"Plots a precision-recall curve.\"\"\"\n    fig, ax = plt.subplots(1, 1, figsize=(9, 6), tight_layout=True)\n    py = np.stack(py, axis=1)\n    if 0 < len(names) < 21:  # display per-class legend if < 21 classes\n        for i, y in enumerate(py.T):\n            ax.plot(px, y, linewidth=1, label=f\"{names[i]} {ap[i, 0]:.3f}\")  # plot(recall, precision)\n    else:\n        ax.plot(px, py, linewidth=1, color=\"grey\")  # plot(recall, precision)\n    ax.plot(px, py.mean(1), linewidth=3, color=\"blue\", label=\"all classes %.3f mAP@0.5\" % ap[:, 0].mean())",
        "detail": "ultralytics.utils.metrics",
        "documentation": {}
    },
    {
        "label": "plot_mc_curve",
        "kind": 2,
        "importPath": "ultralytics.utils.metrics",
        "description": "ultralytics.utils.metrics",
        "peekOfCode": "def plot_mc_curve(px, py, save_dir=Path(\"mc_curve.png\"), names=(), xlabel=\"Confidence\", ylabel=\"Metric\", on_plot=None):\n    \"\"\"Plots a metric-confidence curve.\"\"\"\n    fig, ax = plt.subplots(1, 1, figsize=(9, 6), tight_layout=True)\n    if 0 < len(names) < 21:  # display per-class legend if < 21 classes\n        for i, y in enumerate(py):\n            ax.plot(px, y, linewidth=1, label=f\"{names[i]}\")  # plot(confidence, metric)\n    else:\n        ax.plot(px, py.T, linewidth=1, color=\"grey\")  # plot(confidence, metric)\n    y = smooth(py.mean(0), 0.05)\n    ax.plot(px, y, linewidth=3, color=\"blue\", label=f\"all classes {y.max():.2f} at {px[y.argmax()]:.3f}\")",
        "detail": "ultralytics.utils.metrics",
        "documentation": {}
    },
    {
        "label": "compute_ap",
        "kind": 2,
        "importPath": "ultralytics.utils.metrics",
        "description": "ultralytics.utils.metrics",
        "peekOfCode": "def compute_ap(recall, precision):\n    \"\"\"\n    Compute the average precision (AP) given the recall and precision curves.\n    Args:\n        recall (list): The recall curve.\n        precision (list): The precision curve.\n    Returns:\n        (float): Average precision.\n        (np.ndarray): Precision envelope curve.\n        (np.ndarray): Modified recall curve with sentinel values added at the beginning and end.",
        "detail": "ultralytics.utils.metrics",
        "documentation": {}
    },
    {
        "label": "ap_per_class",
        "kind": 2,
        "importPath": "ultralytics.utils.metrics",
        "description": "ultralytics.utils.metrics",
        "peekOfCode": "def ap_per_class(\n    tp, conf, pred_cls, target_cls, plot=False, on_plot=None, save_dir=Path(), names=(), eps=1e-16, prefix=\"\"\n):\n    \"\"\"\n    Computes the average precision per class for object detection evaluation.\n    Args:\n        tp (np.ndarray): Binary array indicating whether the detection is correct (True) or not (False).\n        conf (np.ndarray): Array of confidence scores of the detections.\n        pred_cls (np.ndarray): Array of predicted classes of the detections.\n        target_cls (np.ndarray): Array of true classes of the detections.",
        "detail": "ultralytics.utils.metrics",
        "documentation": {}
    },
    {
        "label": "OKS_SIGMA",
        "kind": 5,
        "importPath": "ultralytics.utils.metrics",
        "description": "ultralytics.utils.metrics",
        "peekOfCode": "OKS_SIGMA = (\n    np.array([0.26, 0.25, 0.25, 0.35, 0.35, 0.79, 0.79, 0.72, 0.72, 0.62, 0.62, 1.07, 1.07, 0.87, 0.87, 0.89, 0.89])\n    / 10.0\n)\ndef bbox_ioa(box1, box2, iou=False, eps=1e-7):\n    \"\"\"\n    Calculate the intersection over box2 area given box1 and box2. Boxes are in x1y1x2y2 format.\n    Args:\n        box1 (np.ndarray): A numpy array of shape (n, 4) representing n bounding boxes.\n        box2 (np.ndarray): A numpy array of shape (m, 4) representing m bounding boxes.",
        "detail": "ultralytics.utils.metrics",
        "documentation": {}
    },
    {
        "label": "Profile",
        "kind": 6,
        "importPath": "ultralytics.utils.ops",
        "description": "ultralytics.utils.ops",
        "peekOfCode": "class Profile(contextlib.ContextDecorator):\n    \"\"\"\n    YOLOv8 Profile class. Use as a decorator with @Profile() or as a context manager with 'with Profile():'.\n    Example:\n        ```python\n        from ultralytics.utils.ops import Profile\n        with Profile(device=device) as dt:\n            pass  # slow operation here\n        print(dt)  # prints \"Elapsed time is 9.5367431640625e-07 s\"\n        ```",
        "detail": "ultralytics.utils.ops",
        "documentation": {}
    },
    {
        "label": "segment2box",
        "kind": 2,
        "importPath": "ultralytics.utils.ops",
        "description": "ultralytics.utils.ops",
        "peekOfCode": "def segment2box(segment, width=640, height=640):\n    \"\"\"\n    Convert 1 segment label to 1 box label, applying inside-image constraint, i.e. (xy1, xy2, ...) to (xyxy).\n    Args:\n        segment (torch.Tensor): the segment label\n        width (int): the width of the image. Defaults to 640\n        height (int): The height of the image. Defaults to 640\n    Returns:\n        (np.ndarray): the minimum and maximum x and y values of the segment.\n    \"\"\"",
        "detail": "ultralytics.utils.ops",
        "documentation": {}
    },
    {
        "label": "scale_boxes",
        "kind": 2,
        "importPath": "ultralytics.utils.ops",
        "description": "ultralytics.utils.ops",
        "peekOfCode": "def scale_boxes(img1_shape, boxes, img0_shape, ratio_pad=None, padding=True, xywh=False):\n    \"\"\"\n    Rescales bounding boxes (in the format of xyxy by default) from the shape of the image they were originally\n    specified in (img1_shape) to the shape of a different image (img0_shape).\n    Args:\n        img1_shape (tuple): The shape of the image that the bounding boxes are for, in the format of (height, width).\n        boxes (torch.Tensor): the bounding boxes of the objects in the image, in the format of (x1, y1, x2, y2)\n        img0_shape (tuple): the shape of the target image, in the format of (height, width).\n        ratio_pad (tuple): a tuple of (ratio, pad) for scaling the boxes. If not provided, the ratio and pad will be\n            calculated based on the size difference between the two images.",
        "detail": "ultralytics.utils.ops",
        "documentation": {}
    },
    {
        "label": "make_divisible",
        "kind": 2,
        "importPath": "ultralytics.utils.ops",
        "description": "ultralytics.utils.ops",
        "peekOfCode": "def make_divisible(x, divisor):\n    \"\"\"\n    Returns the nearest number that is divisible by the given divisor.\n    Args:\n        x (int): The number to make divisible.\n        divisor (int | torch.Tensor): The divisor.\n    Returns:\n        (int): The nearest number divisible by the divisor.\n    \"\"\"\n    if isinstance(divisor, torch.Tensor):",
        "detail": "ultralytics.utils.ops",
        "documentation": {}
    },
    {
        "label": "nms_rotated",
        "kind": 2,
        "importPath": "ultralytics.utils.ops",
        "description": "ultralytics.utils.ops",
        "peekOfCode": "def nms_rotated(boxes, scores, threshold=0.45):\n    \"\"\"\n    NMS for obbs, powered by probiou and fast-nms.\n    Args:\n        boxes (torch.Tensor): (N, 5), xywhr.\n        scores (torch.Tensor): (N, ).\n        threshold (float): IoU threshold.\n    Returns:\n    \"\"\"\n    if len(boxes) == 0:",
        "detail": "ultralytics.utils.ops",
        "documentation": {}
    },
    {
        "label": "non_max_suppression",
        "kind": 2,
        "importPath": "ultralytics.utils.ops",
        "description": "ultralytics.utils.ops",
        "peekOfCode": "def non_max_suppression(\n    prediction,\n    conf_thres=0.25,\n    iou_thres=0.45,\n    classes=None,\n    agnostic=False,\n    multi_label=False,\n    labels=(),\n    max_det=300,\n    nc=0,  # number of classes (optional)",
        "detail": "ultralytics.utils.ops",
        "documentation": {}
    },
    {
        "label": "clip_boxes",
        "kind": 2,
        "importPath": "ultralytics.utils.ops",
        "description": "ultralytics.utils.ops",
        "peekOfCode": "def clip_boxes(boxes, shape):\n    \"\"\"\n    Takes a list of bounding boxes and a shape (height, width) and clips the bounding boxes to the shape.\n    Args:\n        boxes (torch.Tensor): the bounding boxes to clip\n        shape (tuple): the shape of the image\n    Returns:\n        (torch.Tensor | numpy.ndarray): Clipped boxes\n    \"\"\"\n    if isinstance(boxes, torch.Tensor):  # faster individually (WARNING: inplace .clamp_() Apple MPS bug)",
        "detail": "ultralytics.utils.ops",
        "documentation": {}
    },
    {
        "label": "clip_coords",
        "kind": 2,
        "importPath": "ultralytics.utils.ops",
        "description": "ultralytics.utils.ops",
        "peekOfCode": "def clip_coords(coords, shape):\n    \"\"\"\n    Clip line coordinates to the image boundaries.\n    Args:\n        coords (torch.Tensor | numpy.ndarray): A list of line coordinates.\n        shape (tuple): A tuple of integers representing the size of the image in the format (height, width).\n    Returns:\n        (torch.Tensor | numpy.ndarray): Clipped coordinates\n    \"\"\"\n    if isinstance(coords, torch.Tensor):  # faster individually (WARNING: inplace .clamp_() Apple MPS bug)",
        "detail": "ultralytics.utils.ops",
        "documentation": {}
    },
    {
        "label": "scale_image",
        "kind": 2,
        "importPath": "ultralytics.utils.ops",
        "description": "ultralytics.utils.ops",
        "peekOfCode": "def scale_image(masks, im0_shape, ratio_pad=None):\n    \"\"\"\n    Takes a mask, and resizes it to the original image size.\n    Args:\n        masks (np.ndarray): resized and padded masks/images, [h, w, num]/[h, w, 3].\n        im0_shape (tuple): the original image shape\n        ratio_pad (tuple): the ratio of the padding to the original image.\n    Returns:\n        masks (torch.Tensor): The masks that are being returned.\n    \"\"\"",
        "detail": "ultralytics.utils.ops",
        "documentation": {}
    },
    {
        "label": "xyxy2xywh",
        "kind": 2,
        "importPath": "ultralytics.utils.ops",
        "description": "ultralytics.utils.ops",
        "peekOfCode": "def xyxy2xywh(x):\n    \"\"\"\n    Convert bounding box coordinates from (x1, y1, x2, y2) format to (x, y, width, height) format where (x1, y1) is the\n    top-left corner and (x2, y2) is the bottom-right corner.\n    Args:\n        x (np.ndarray | torch.Tensor): The input bounding box coordinates in (x1, y1, x2, y2) format.\n    Returns:\n        y (np.ndarray | torch.Tensor): The bounding box coordinates in (x, y, width, height) format.\n    \"\"\"\n    assert x.shape[-1] == 4, f\"input shape last dimension expected 4 but input shape is {x.shape}\"",
        "detail": "ultralytics.utils.ops",
        "documentation": {}
    },
    {
        "label": "xywh2xyxy",
        "kind": 2,
        "importPath": "ultralytics.utils.ops",
        "description": "ultralytics.utils.ops",
        "peekOfCode": "def xywh2xyxy(x):\n    \"\"\"\n    Convert bounding box coordinates from (x, y, width, height) format to (x1, y1, x2, y2) format where (x1, y1) is the\n    top-left corner and (x2, y2) is the bottom-right corner. Note: ops per 2 channels faster than per channel.\n    Args:\n        x (np.ndarray | torch.Tensor): The input bounding box coordinates in (x, y, width, height) format.\n    Returns:\n        y (np.ndarray | torch.Tensor): The bounding box coordinates in (x1, y1, x2, y2) format.\n    \"\"\"\n    assert x.shape[-1] == 4, f\"input shape last dimension expected 4 but input shape is {x.shape}\"",
        "detail": "ultralytics.utils.ops",
        "documentation": {}
    },
    {
        "label": "xywhn2xyxy",
        "kind": 2,
        "importPath": "ultralytics.utils.ops",
        "description": "ultralytics.utils.ops",
        "peekOfCode": "def xywhn2xyxy(x, w=640, h=640, padw=0, padh=0):\n    \"\"\"\n    Convert normalized bounding box coordinates to pixel coordinates.\n    Args:\n        x (np.ndarray | torch.Tensor): The bounding box coordinates.\n        w (int): Width of the image. Defaults to 640\n        h (int): Height of the image. Defaults to 640\n        padw (int): Padding width. Defaults to 0\n        padh (int): Padding height. Defaults to 0\n    Returns:",
        "detail": "ultralytics.utils.ops",
        "documentation": {}
    },
    {
        "label": "xyxy2xywhn",
        "kind": 2,
        "importPath": "ultralytics.utils.ops",
        "description": "ultralytics.utils.ops",
        "peekOfCode": "def xyxy2xywhn(x, w=640, h=640, clip=False, eps=0.0):\n    \"\"\"\n    Convert bounding box coordinates from (x1, y1, x2, y2) format to (x, y, width, height, normalized) format. x, y,\n    width and height are normalized to image dimensions.\n    Args:\n        x (np.ndarray | torch.Tensor): The input bounding box coordinates in (x1, y1, x2, y2) format.\n        w (int): The width of the image. Defaults to 640\n        h (int): The height of the image. Defaults to 640\n        clip (bool): If True, the boxes will be clipped to the image boundaries. Defaults to False\n        eps (float): The minimum value of the box's width and height. Defaults to 0.0",
        "detail": "ultralytics.utils.ops",
        "documentation": {}
    },
    {
        "label": "xywh2ltwh",
        "kind": 2,
        "importPath": "ultralytics.utils.ops",
        "description": "ultralytics.utils.ops",
        "peekOfCode": "def xywh2ltwh(x):\n    \"\"\"\n    Convert the bounding box format from [x, y, w, h] to [x1, y1, w, h], where x1, y1 are the top-left coordinates.\n    Args:\n        x (np.ndarray | torch.Tensor): The input tensor with the bounding box coordinates in the xywh format\n    Returns:\n        y (np.ndarray | torch.Tensor): The bounding box coordinates in the xyltwh format\n    \"\"\"\n    y = x.clone() if isinstance(x, torch.Tensor) else np.copy(x)\n    y[..., 0] = x[..., 0] - x[..., 2] / 2  # top left x",
        "detail": "ultralytics.utils.ops",
        "documentation": {}
    },
    {
        "label": "xyxy2ltwh",
        "kind": 2,
        "importPath": "ultralytics.utils.ops",
        "description": "ultralytics.utils.ops",
        "peekOfCode": "def xyxy2ltwh(x):\n    \"\"\"\n    Convert nx4 bounding boxes from [x1, y1, x2, y2] to [x1, y1, w, h], where xy1=top-left, xy2=bottom-right.\n    Args:\n        x (np.ndarray | torch.Tensor): The input tensor with the bounding boxes coordinates in the xyxy format\n    Returns:\n        y (np.ndarray | torch.Tensor): The bounding box coordinates in the xyltwh format.\n    \"\"\"\n    y = x.clone() if isinstance(x, torch.Tensor) else np.copy(x)\n    y[..., 2] = x[..., 2] - x[..., 0]  # width",
        "detail": "ultralytics.utils.ops",
        "documentation": {}
    },
    {
        "label": "ltwh2xywh",
        "kind": 2,
        "importPath": "ultralytics.utils.ops",
        "description": "ultralytics.utils.ops",
        "peekOfCode": "def ltwh2xywh(x):\n    \"\"\"\n    Convert nx4 boxes from [x1, y1, w, h] to [x, y, w, h] where xy1=top-left, xy=center.\n    Args:\n        x (torch.Tensor): the input tensor\n    Returns:\n        y (np.ndarray | torch.Tensor): The bounding box coordinates in the xywh format.\n    \"\"\"\n    y = x.clone() if isinstance(x, torch.Tensor) else np.copy(x)\n    y[..., 0] = x[..., 0] + x[..., 2] / 2  # center x",
        "detail": "ultralytics.utils.ops",
        "documentation": {}
    },
    {
        "label": "xyxyxyxy2xywhr",
        "kind": 2,
        "importPath": "ultralytics.utils.ops",
        "description": "ultralytics.utils.ops",
        "peekOfCode": "def xyxyxyxy2xywhr(x):\n    \"\"\"\n    Convert batched Oriented Bounding Boxes (OBB) from [xy1, xy2, xy3, xy4] to [xywh, rotation]. Rotation values are\n    expected in degrees from 0 to 90.\n    Args:\n        x (numpy.ndarray | torch.Tensor): Input box corners [xy1, xy2, xy3, xy4] of shape (n, 8).\n    Returns:\n        (numpy.ndarray | torch.Tensor): Converted data in [cx, cy, w, h, rotation] format of shape (n, 5).\n    \"\"\"\n    is_torch = isinstance(x, torch.Tensor)",
        "detail": "ultralytics.utils.ops",
        "documentation": {}
    },
    {
        "label": "xywhr2xyxyxyxy",
        "kind": 2,
        "importPath": "ultralytics.utils.ops",
        "description": "ultralytics.utils.ops",
        "peekOfCode": "def xywhr2xyxyxyxy(x):\n    \"\"\"\n    Convert batched Oriented Bounding Boxes (OBB) from [xywh, rotation] to [xy1, xy2, xy3, xy4]. Rotation values should\n    be in degrees from 0 to 90.\n    Args:\n        x (numpy.ndarray | torch.Tensor): Boxes in [cx, cy, w, h, rotation] format of shape (n, 5) or (b, n, 5).\n    Returns:\n        (numpy.ndarray | torch.Tensor): Converted corner points of shape (n, 4, 2) or (b, n, 4, 2).\n    \"\"\"\n    cos, sin, cat, stack = (",
        "detail": "ultralytics.utils.ops",
        "documentation": {}
    },
    {
        "label": "ltwh2xyxy",
        "kind": 2,
        "importPath": "ultralytics.utils.ops",
        "description": "ultralytics.utils.ops",
        "peekOfCode": "def ltwh2xyxy(x):\n    \"\"\"\n    It converts the bounding box from [x1, y1, w, h] to [x1, y1, x2, y2] where xy1=top-left, xy2=bottom-right.\n    Args:\n        x (np.ndarray | torch.Tensor): the input image\n    Returns:\n        y (np.ndarray | torch.Tensor): the xyxy coordinates of the bounding boxes.\n    \"\"\"\n    y = x.clone() if isinstance(x, torch.Tensor) else np.copy(x)\n    y[..., 2] = x[..., 2] + x[..., 0]  # width",
        "detail": "ultralytics.utils.ops",
        "documentation": {}
    },
    {
        "label": "segments2boxes",
        "kind": 2,
        "importPath": "ultralytics.utils.ops",
        "description": "ultralytics.utils.ops",
        "peekOfCode": "def segments2boxes(segments):\n    \"\"\"\n    It converts segment labels to box labels, i.e. (cls, xy1, xy2, ...) to (cls, xywh)\n    Args:\n        segments (list): list of segments, each segment is a list of points, each point is a list of x, y coordinates\n    Returns:\n        (np.ndarray): the xywh coordinates of the bounding boxes.\n    \"\"\"\n    boxes = []\n    for s in segments:",
        "detail": "ultralytics.utils.ops",
        "documentation": {}
    },
    {
        "label": "resample_segments",
        "kind": 2,
        "importPath": "ultralytics.utils.ops",
        "description": "ultralytics.utils.ops",
        "peekOfCode": "def resample_segments(segments, n=1000):\n    \"\"\"\n    Inputs a list of segments (n,2) and returns a list of segments (n,2) up-sampled to n points each.\n    Args:\n        segments (list): a list of (n,2) arrays, where n is the number of points in the segment.\n        n (int): number of points to resample the segment to. Defaults to 1000\n    Returns:\n        segments (list): the resampled segments.\n    \"\"\"\n    for i, s in enumerate(segments):",
        "detail": "ultralytics.utils.ops",
        "documentation": {}
    },
    {
        "label": "crop_mask",
        "kind": 2,
        "importPath": "ultralytics.utils.ops",
        "description": "ultralytics.utils.ops",
        "peekOfCode": "def crop_mask(masks, boxes):\n    \"\"\"\n    It takes a mask and a bounding box, and returns a mask that is cropped to the bounding box.\n    Args:\n        masks (torch.Tensor): [n, h, w] tensor of masks\n        boxes (torch.Tensor): [n, 4] tensor of bbox coordinates in relative point form\n    Returns:\n        (torch.Tensor): The masks are being cropped to the bounding box.\n    \"\"\"\n    _, h, w = masks.shape",
        "detail": "ultralytics.utils.ops",
        "documentation": {}
    },
    {
        "label": "process_mask",
        "kind": 2,
        "importPath": "ultralytics.utils.ops",
        "description": "ultralytics.utils.ops",
        "peekOfCode": "def process_mask(protos, masks_in, bboxes, shape, upsample=False):\n    \"\"\"\n    Apply masks to bounding boxes using the output of the mask head.\n    Args:\n        protos (torch.Tensor): A tensor of shape [mask_dim, mask_h, mask_w].\n        masks_in (torch.Tensor): A tensor of shape [n, mask_dim], where n is the number of masks after NMS.\n        bboxes (torch.Tensor): A tensor of shape [n, 4], where n is the number of masks after NMS.\n        shape (tuple): A tuple of integers representing the size of the input image in the format (h, w).\n        upsample (bool): A flag to indicate whether to upsample the mask to the original image size. Default is False.\n    Returns:",
        "detail": "ultralytics.utils.ops",
        "documentation": {}
    },
    {
        "label": "process_mask_native",
        "kind": 2,
        "importPath": "ultralytics.utils.ops",
        "description": "ultralytics.utils.ops",
        "peekOfCode": "def process_mask_native(protos, masks_in, bboxes, shape):\n    \"\"\"\n    It takes the output of the mask head, and crops it after upsampling to the bounding boxes.\n    Args:\n        protos (torch.Tensor): [mask_dim, mask_h, mask_w]\n        masks_in (torch.Tensor): [n, mask_dim], n is number of masks after nms\n        bboxes (torch.Tensor): [n, 4], n is number of masks after nms\n        shape (tuple): the size of the input image (h,w)\n    Returns:\n        masks (torch.Tensor): The returned masks with dimensions [h, w, n]",
        "detail": "ultralytics.utils.ops",
        "documentation": {}
    },
    {
        "label": "scale_masks",
        "kind": 2,
        "importPath": "ultralytics.utils.ops",
        "description": "ultralytics.utils.ops",
        "peekOfCode": "def scale_masks(masks, shape, padding=True):\n    \"\"\"\n    Rescale segment masks to shape.\n    Args:\n        masks (torch.Tensor): (N, C, H, W).\n        shape (tuple): Height and width.\n        padding (bool): If True, assuming the boxes is based on image augmented by yolo style. If False then do regular\n            rescaling.\n    \"\"\"\n    mh, mw = masks.shape[2:]",
        "detail": "ultralytics.utils.ops",
        "documentation": {}
    },
    {
        "label": "scale_coords",
        "kind": 2,
        "importPath": "ultralytics.utils.ops",
        "description": "ultralytics.utils.ops",
        "peekOfCode": "def scale_coords(img1_shape, coords, img0_shape, ratio_pad=None, normalize=False, padding=True):\n    \"\"\"\n    Rescale segment coordinates (xy) from img1_shape to img0_shape.\n    Args:\n        img1_shape (tuple): The shape of the image that the coords are from.\n        coords (torch.Tensor): the coords to be scaled of shape n,2.\n        img0_shape (tuple): the shape of the image that the segmentation is being applied to.\n        ratio_pad (tuple): the ratio of the image size to the padded image size.\n        normalize (bool): If True, the coordinates will be normalized to the range [0, 1]. Defaults to False.\n        padding (bool): If True, assuming the boxes is based on image augmented by yolo style. If False then do regular",
        "detail": "ultralytics.utils.ops",
        "documentation": {}
    },
    {
        "label": "regularize_rboxes",
        "kind": 2,
        "importPath": "ultralytics.utils.ops",
        "description": "ultralytics.utils.ops",
        "peekOfCode": "def regularize_rboxes(rboxes):\n    \"\"\"\n    Regularize rotated boxes in range [0, pi/2].\n    Args:\n        rboxes (torch.Tensor): Input boxes of shape(N, 5) in xywhr format.\n    Returns:\n        (torch.Tensor): The regularized boxes.\n    \"\"\"\n    x, y, w, h, t = rboxes.unbind(dim=-1)\n    # Swap edge and angle if h >= w",
        "detail": "ultralytics.utils.ops",
        "documentation": {}
    },
    {
        "label": "masks2segments",
        "kind": 2,
        "importPath": "ultralytics.utils.ops",
        "description": "ultralytics.utils.ops",
        "peekOfCode": "def masks2segments(masks, strategy=\"largest\"):\n    \"\"\"\n    It takes a list of masks(n,h,w) and returns a list of segments(n,xy)\n    Args:\n        masks (torch.Tensor): the output of the model, which is a tensor of shape (batch_size, 160, 160)\n        strategy (str): 'concat' or 'largest'. Defaults to largest\n    Returns:\n        segments (List): list of segment masks\n    \"\"\"\n    segments = []",
        "detail": "ultralytics.utils.ops",
        "documentation": {}
    },
    {
        "label": "convert_torch2numpy_batch",
        "kind": 2,
        "importPath": "ultralytics.utils.ops",
        "description": "ultralytics.utils.ops",
        "peekOfCode": "def convert_torch2numpy_batch(batch: torch.Tensor) -> np.ndarray:\n    \"\"\"\n    Convert a batch of FP32 torch tensors (0.0-1.0) to a NumPy uint8 array (0-255), changing from BCHW to BHWC layout.\n    Args:\n        batch (torch.Tensor): Input tensor batch of shape (Batch, Channels, Height, Width) and dtype torch.float32.\n    Returns:\n        (np.ndarray): Output NumPy array batch of shape (Batch, Height, Width, Channels) and dtype uint8.\n    \"\"\"\n    return (batch.permute(0, 2, 3, 1).contiguous() * 255).clamp(0, 255).to(torch.uint8).cpu().numpy()\ndef clean_str(s):",
        "detail": "ultralytics.utils.ops",
        "documentation": {}
    },
    {
        "label": "clean_str",
        "kind": 2,
        "importPath": "ultralytics.utils.ops",
        "description": "ultralytics.utils.ops",
        "peekOfCode": "def clean_str(s):\n    \"\"\"\n    Cleans a string by replacing special characters with underscore _\n    Args:\n        s (str): a string needing special characters replaced\n    Returns:\n        (str): a string with special characters replaced by an underscore _\n    \"\"\"\n    return re.sub(pattern=\"[|@#!¡·$€%&()=?¿^*;:,¨´><+]\", repl=\"_\", string=s)",
        "detail": "ultralytics.utils.ops",
        "documentation": {}
    },
    {
        "label": "imread",
        "kind": 2,
        "importPath": "ultralytics.utils.patches",
        "description": "ultralytics.utils.patches",
        "peekOfCode": "def imread(filename: str, flags: int = cv2.IMREAD_COLOR):\n    \"\"\"\n    Read an image from a file.\n    Args:\n        filename (str): Path to the file to read.\n        flags (int, optional): Flag that can take values of cv2.IMREAD_*. Defaults to cv2.IMREAD_COLOR.\n    Returns:\n        (np.ndarray): The read image.\n    \"\"\"\n    return cv2.imdecode(np.fromfile(filename, np.uint8), flags)",
        "detail": "ultralytics.utils.patches",
        "documentation": {}
    },
    {
        "label": "imwrite",
        "kind": 2,
        "importPath": "ultralytics.utils.patches",
        "description": "ultralytics.utils.patches",
        "peekOfCode": "def imwrite(filename: str, img: np.ndarray, params=None):\n    \"\"\"\n    Write an image to a file.\n    Args:\n        filename (str): Path to the file to write.\n        img (np.ndarray): Image to write.\n        params (list of ints, optional): Additional parameters. See OpenCV documentation.\n    Returns:\n        (bool): True if the file was written, False otherwise.\n    \"\"\"",
        "detail": "ultralytics.utils.patches",
        "documentation": {}
    },
    {
        "label": "imshow",
        "kind": 2,
        "importPath": "ultralytics.utils.patches",
        "description": "ultralytics.utils.patches",
        "peekOfCode": "def imshow(winname: str, mat: np.ndarray):\n    \"\"\"\n    Displays an image in the specified window.\n    Args:\n        winname (str): Name of the window.\n        mat (np.ndarray): Image to be shown.\n    \"\"\"\n    _imshow(winname.encode(\"unicode_escape\").decode(), mat)\n# PyTorch functions ----------------------------------------------------------------------------------------------------\n_torch_save = torch.save  # copy to avoid recursion errors",
        "detail": "ultralytics.utils.patches",
        "documentation": {}
    },
    {
        "label": "torch_save",
        "kind": 2,
        "importPath": "ultralytics.utils.patches",
        "description": "ultralytics.utils.patches",
        "peekOfCode": "def torch_save(*args, use_dill=True, **kwargs):\n    \"\"\"\n    Optionally use dill to serialize lambda functions where pickle does not, adding robustness with 3 retries and\n    exponential standoff in case of save failure.\n    Args:\n        *args (tuple): Positional arguments to pass to torch.save.\n        use_dill (bool): Whether to try using dill for serialization if available. Defaults to True.\n        **kwargs (any): Keyword arguments to pass to torch.save.\n    \"\"\"\n    try:",
        "detail": "ultralytics.utils.patches",
        "documentation": {}
    },
    {
        "label": "_imshow",
        "kind": 5,
        "importPath": "ultralytics.utils.patches",
        "description": "ultralytics.utils.patches",
        "peekOfCode": "_imshow = cv2.imshow  # copy to avoid recursion errors\ndef imread(filename: str, flags: int = cv2.IMREAD_COLOR):\n    \"\"\"\n    Read an image from a file.\n    Args:\n        filename (str): Path to the file to read.\n        flags (int, optional): Flag that can take values of cv2.IMREAD_*. Defaults to cv2.IMREAD_COLOR.\n    Returns:\n        (np.ndarray): The read image.\n    \"\"\"",
        "detail": "ultralytics.utils.patches",
        "documentation": {}
    },
    {
        "label": "_torch_save",
        "kind": 5,
        "importPath": "ultralytics.utils.patches",
        "description": "ultralytics.utils.patches",
        "peekOfCode": "_torch_save = torch.save  # copy to avoid recursion errors\ndef torch_save(*args, use_dill=True, **kwargs):\n    \"\"\"\n    Optionally use dill to serialize lambda functions where pickle does not, adding robustness with 3 retries and\n    exponential standoff in case of save failure.\n    Args:\n        *args (tuple): Positional arguments to pass to torch.save.\n        use_dill (bool): Whether to try using dill for serialization if available. Defaults to True.\n        **kwargs (any): Keyword arguments to pass to torch.save.\n    \"\"\"",
        "detail": "ultralytics.utils.patches",
        "documentation": {}
    },
    {
        "label": "Colors",
        "kind": 6,
        "importPath": "ultralytics.utils.plotting",
        "description": "ultralytics.utils.plotting",
        "peekOfCode": "class Colors:\n    \"\"\"\n    Ultralytics default color palette https://ultralytics.com/.\n    This class provides methods to work with the Ultralytics color palette, including converting hex color codes to\n    RGB values.\n    Attributes:\n        palette (list of tuple): List of RGB color values.\n        n (int): The number of colors in the palette.\n        pose_palette (np.ndarray): A specific color palette array with dtype np.uint8.\n    \"\"\"",
        "detail": "ultralytics.utils.plotting",
        "documentation": {}
    },
    {
        "label": "Annotator",
        "kind": 6,
        "importPath": "ultralytics.utils.plotting",
        "description": "ultralytics.utils.plotting",
        "peekOfCode": "class Annotator:\n    \"\"\"\n    Ultralytics Annotator for train/val mosaics and JPGs and predictions annotations.\n    Attributes:\n        im (Image.Image or numpy array): The image to annotate.\n        pil (bool): Whether to use PIL or cv2 for drawing annotations.\n        font (ImageFont.truetype or ImageFont.load_default): Font used for text annotations.\n        lw (float): Line width for drawing.\n        skeleton (List[List[int]]): Skeleton structure for keypoints.\n        limb_color (List[int]): Color palette for limbs.",
        "detail": "ultralytics.utils.plotting",
        "documentation": {}
    },
    {
        "label": "plot_labels",
        "kind": 2,
        "importPath": "ultralytics.utils.plotting",
        "description": "ultralytics.utils.plotting",
        "peekOfCode": "def plot_labels(boxes, cls, names=(), save_dir=Path(\"\"), on_plot=None):\n    \"\"\"Plot training labels including class histograms and box statistics.\"\"\"\n    import pandas  # scope for faster 'import ultralytics'\n    import seaborn  # scope for faster 'import ultralytics'\n    # Filter matplotlib>=3.7.2 warning and Seaborn use_inf and is_categorical FutureWarnings\n    warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"The figure layout has changed to tight\")\n    warnings.filterwarnings(\"ignore\", category=FutureWarning)\n    # Plot dataset labels\n    LOGGER.info(f\"Plotting labels to {save_dir / 'labels.jpg'}... \")\n    nc = int(cls.max() + 1)  # number of classes",
        "detail": "ultralytics.utils.plotting",
        "documentation": {}
    },
    {
        "label": "save_one_box",
        "kind": 2,
        "importPath": "ultralytics.utils.plotting",
        "description": "ultralytics.utils.plotting",
        "peekOfCode": "def save_one_box(xyxy, im, file=Path(\"im.jpg\"), gain=1.02, pad=10, square=False, BGR=False, save=True):\n    \"\"\"\n    Save image crop as {file} with crop size multiple {gain} and {pad} pixels. Save and/or return crop.\n    This function takes a bounding box and an image, and then saves a cropped portion of the image according\n    to the bounding box. Optionally, the crop can be squared, and the function allows for gain and padding\n    adjustments to the bounding box.\n    Args:\n        xyxy (torch.Tensor or list): A tensor or list representing the bounding box in xyxy format.\n        im (numpy.ndarray): The input image.\n        file (Path, optional): The path where the cropped image will be saved. Defaults to 'im.jpg'.",
        "detail": "ultralytics.utils.plotting",
        "documentation": {}
    },
    {
        "label": "plot_images",
        "kind": 2,
        "importPath": "ultralytics.utils.plotting",
        "description": "ultralytics.utils.plotting",
        "peekOfCode": "def plot_images(\n    images: Union[torch.Tensor, np.ndarray],\n    batch_idx: Union[torch.Tensor, np.ndarray],\n    cls: Union[torch.Tensor, np.ndarray],\n    bboxes: Union[torch.Tensor, np.ndarray] = np.zeros(0, dtype=np.float32),\n    confs: Optional[Union[torch.Tensor, np.ndarray]] = None,\n    masks: Union[torch.Tensor, np.ndarray] = np.zeros(0, dtype=np.uint8),\n    kpts: Union[torch.Tensor, np.ndarray] = np.zeros((0, 51), dtype=np.float32),\n    paths: Optional[List[str]] = None,\n    fname: str = \"images.jpg\",",
        "detail": "ultralytics.utils.plotting",
        "documentation": {}
    },
    {
        "label": "plot_results",
        "kind": 2,
        "importPath": "ultralytics.utils.plotting",
        "description": "ultralytics.utils.plotting",
        "peekOfCode": "def plot_results(file=\"path/to/results.csv\", dir=\"\", segment=False, pose=False, classify=False, on_plot=None):\n    \"\"\"\n    Plot training results from a results CSV file. The function supports various types of data including segmentation,\n    pose estimation, and classification. Plots are saved as 'results.png' in the directory where the CSV is located.\n    Args:\n        file (str, optional): Path to the CSV file containing the training results. Defaults to 'path/to/results.csv'.\n        dir (str, optional): Directory where the CSV file is located if 'file' is not provided. Defaults to ''.\n        segment (bool, optional): Flag to indicate if the data is for segmentation. Defaults to False.\n        pose (bool, optional): Flag to indicate if the data is for pose estimation. Defaults to False.\n        classify (bool, optional): Flag to indicate if the data is for classification. Defaults to False.",
        "detail": "ultralytics.utils.plotting",
        "documentation": {}
    },
    {
        "label": "plt_color_scatter",
        "kind": 2,
        "importPath": "ultralytics.utils.plotting",
        "description": "ultralytics.utils.plotting",
        "peekOfCode": "def plt_color_scatter(v, f, bins=20, cmap=\"viridis\", alpha=0.8, edgecolors=\"none\"):\n    \"\"\"\n    Plots a scatter plot with points colored based on a 2D histogram.\n    Args:\n        v (array-like): Values for the x-axis.\n        f (array-like): Values for the y-axis.\n        bins (int, optional): Number of bins for the histogram. Defaults to 20.\n        cmap (str, optional): Colormap for the scatter plot. Defaults to 'viridis'.\n        alpha (float, optional): Alpha for the scatter plot. Defaults to 0.8.\n        edgecolors (str, optional): Edge colors for the scatter plot. Defaults to 'none'.",
        "detail": "ultralytics.utils.plotting",
        "documentation": {}
    },
    {
        "label": "plot_tune_results",
        "kind": 2,
        "importPath": "ultralytics.utils.plotting",
        "description": "ultralytics.utils.plotting",
        "peekOfCode": "def plot_tune_results(csv_file=\"tune_results.csv\"):\n    \"\"\"\n    Plot the evolution results stored in an 'tune_results.csv' file. The function generates a scatter plot for each key\n    in the CSV, color-coded based on fitness scores. The best-performing configurations are highlighted on the plots.\n    Args:\n        csv_file (str, optional): Path to the CSV file containing the tuning results. Defaults to 'tune_results.csv'.\n    Examples:\n        >>> plot_tune_results('path/to/tune_results.csv')\n    \"\"\"\n    import pandas as pd  # scope for faster 'import ultralytics'",
        "detail": "ultralytics.utils.plotting",
        "documentation": {}
    },
    {
        "label": "output_to_target",
        "kind": 2,
        "importPath": "ultralytics.utils.plotting",
        "description": "ultralytics.utils.plotting",
        "peekOfCode": "def output_to_target(output, max_det=300):\n    \"\"\"Convert model output to target format [batch_id, class_id, x, y, w, h, conf] for plotting.\"\"\"\n    targets = []\n    for i, o in enumerate(output):\n        box, conf, cls = o[:max_det, :6].cpu().split((4, 1, 1), 1)\n        j = torch.full((conf.shape[0], 1), i)\n        targets.append(torch.cat((j, cls, ops.xyxy2xywh(box), conf), 1))\n    targets = torch.cat(targets, 0).numpy()\n    return targets[:, 0], targets[:, 1], targets[:, 2:-1], targets[:, -1]\ndef output_to_rotated_target(output, max_det=300):",
        "detail": "ultralytics.utils.plotting",
        "documentation": {}
    },
    {
        "label": "output_to_rotated_target",
        "kind": 2,
        "importPath": "ultralytics.utils.plotting",
        "description": "ultralytics.utils.plotting",
        "peekOfCode": "def output_to_rotated_target(output, max_det=300):\n    \"\"\"Convert model output to target format [batch_id, class_id, x, y, w, h, conf] for plotting.\"\"\"\n    targets = []\n    for i, o in enumerate(output):\n        box, conf, cls, angle = o[:max_det].cpu().split((4, 1, 1, 1), 1)\n        j = torch.full((conf.shape[0], 1), i)\n        targets.append(torch.cat((j, cls, box, angle, conf), 1))\n    targets = torch.cat(targets, 0).numpy()\n    return targets[:, 0], targets[:, 1], targets[:, 2:-1], targets[:, -1]\ndef feature_visualization(x, module_type, stage, n=32, save_dir=Path(\"runs/detect/exp\")):",
        "detail": "ultralytics.utils.plotting",
        "documentation": {}
    },
    {
        "label": "feature_visualization",
        "kind": 2,
        "importPath": "ultralytics.utils.plotting",
        "description": "ultralytics.utils.plotting",
        "peekOfCode": "def feature_visualization(x, module_type, stage, n=32, save_dir=Path(\"runs/detect/exp\")):\n    \"\"\"\n    Visualize feature maps of a given model module during inference.\n    Args:\n        x (torch.Tensor): Features to be visualized.\n        module_type (str): Module type.\n        stage (int): Module stage within the model.\n        n (int, optional): Maximum number of feature maps to plot. Defaults to 32.\n        save_dir (Path, optional): Directory to save results. Defaults to Path('runs/detect/exp').\n    \"\"\"",
        "detail": "ultralytics.utils.plotting",
        "documentation": {}
    },
    {
        "label": "colors",
        "kind": 5,
        "importPath": "ultralytics.utils.plotting",
        "description": "ultralytics.utils.plotting",
        "peekOfCode": "colors = Colors()  # create instance for 'from utils.plots import colors'\nclass Annotator:\n    \"\"\"\n    Ultralytics Annotator for train/val mosaics and JPGs and predictions annotations.\n    Attributes:\n        im (Image.Image or numpy array): The image to annotate.\n        pil (bool): Whether to use PIL or cv2 for drawing annotations.\n        font (ImageFont.truetype or ImageFont.load_default): Font used for text annotations.\n        lw (float): Line width for drawing.\n        skeleton (List[List[int]]): Skeleton structure for keypoints.",
        "detail": "ultralytics.utils.plotting",
        "documentation": {}
    },
    {
        "label": "TaskAlignedAssigner",
        "kind": 6,
        "importPath": "ultralytics.utils.tal",
        "description": "ultralytics.utils.tal",
        "peekOfCode": "class TaskAlignedAssigner(nn.Module):\n    \"\"\"\n    A task-aligned assigner for object detection.\n    This class assigns ground-truth (gt) objects to anchors based on the task-aligned metric, which combines both\n    classification and localization information.\n    Attributes:\n        topk (int): The number of top candidates to consider.\n        num_classes (int): The number of object classes.\n        alpha (float): The alpha parameter for the classification component of the task-aligned metric.\n        beta (float): The beta parameter for the localization component of the task-aligned metric.",
        "detail": "ultralytics.utils.tal",
        "documentation": {}
    },
    {
        "label": "RotatedTaskAlignedAssigner",
        "kind": 6,
        "importPath": "ultralytics.utils.tal",
        "description": "ultralytics.utils.tal",
        "peekOfCode": "class RotatedTaskAlignedAssigner(TaskAlignedAssigner):\n    \"\"\"Assigns ground-truth objects to rotated bounding boxes using a task-aligned metric.\"\"\"\n    def iou_calculation(self, gt_bboxes, pd_bboxes):\n        \"\"\"IoU calculation for rotated bounding boxes.\"\"\"\n        return probiou(gt_bboxes, pd_bboxes).squeeze(-1).clamp_(0)\n    @staticmethod\n    def select_candidates_in_gts(xy_centers, gt_bboxes):\n        \"\"\"\n        Select the positive anchor center in gt for rotated bounding boxes.\n        Args:",
        "detail": "ultralytics.utils.tal",
        "documentation": {}
    },
    {
        "label": "make_anchors",
        "kind": 2,
        "importPath": "ultralytics.utils.tal",
        "description": "ultralytics.utils.tal",
        "peekOfCode": "def make_anchors(feats, strides, grid_cell_offset=0.5):\n    \"\"\"Generate anchors from features.\"\"\"\n    anchor_points, stride_tensor = [], []\n    assert feats is not None\n    dtype, device = feats[0].dtype, feats[0].device\n    for i, stride in enumerate(strides):\n        _, _, h, w = feats[i].shape\n        sx = torch.arange(end=w, device=device, dtype=dtype) + grid_cell_offset  # shift x\n        sy = torch.arange(end=h, device=device, dtype=dtype) + grid_cell_offset  # shift y\n        sy, sx = torch.meshgrid(sy, sx, indexing=\"ij\") if TORCH_1_10 else torch.meshgrid(sy, sx)",
        "detail": "ultralytics.utils.tal",
        "documentation": {}
    },
    {
        "label": "dist2bbox",
        "kind": 2,
        "importPath": "ultralytics.utils.tal",
        "description": "ultralytics.utils.tal",
        "peekOfCode": "def dist2bbox(distance, anchor_points, xywh=True, dim=-1):\n    \"\"\"Transform distance(ltrb) to box(xywh or xyxy).\"\"\"\n    lt, rb = distance.chunk(2, dim)\n    x1y1 = anchor_points - lt\n    x2y2 = anchor_points + rb\n    if xywh:\n        c_xy = (x1y1 + x2y2) / 2\n        wh = x2y2 - x1y1\n        return torch.cat((c_xy, wh), dim)  # xywh bbox\n    return torch.cat((x1y1, x2y2), dim)  # xyxy bbox",
        "detail": "ultralytics.utils.tal",
        "documentation": {}
    },
    {
        "label": "bbox2dist",
        "kind": 2,
        "importPath": "ultralytics.utils.tal",
        "description": "ultralytics.utils.tal",
        "peekOfCode": "def bbox2dist(anchor_points, bbox, reg_max):\n    \"\"\"Transform bbox(xyxy) to dist(ltrb).\"\"\"\n    x1y1, x2y2 = bbox.chunk(2, -1)\n    return torch.cat((anchor_points - x1y1, x2y2 - anchor_points), -1).clamp_(0, reg_max - 0.01)  # dist (lt, rb)\ndef dist2rbox(pred_dist, pred_angle, anchor_points, dim=-1):\n    \"\"\"\n    Decode predicted object bounding box coordinates from anchor points and distribution.\n    Args:\n        pred_dist (torch.Tensor): Predicted rotated distance, (bs, h*w, 4).\n        pred_angle (torch.Tensor): Predicted angle, (bs, h*w, 1).",
        "detail": "ultralytics.utils.tal",
        "documentation": {}
    },
    {
        "label": "dist2rbox",
        "kind": 2,
        "importPath": "ultralytics.utils.tal",
        "description": "ultralytics.utils.tal",
        "peekOfCode": "def dist2rbox(pred_dist, pred_angle, anchor_points, dim=-1):\n    \"\"\"\n    Decode predicted object bounding box coordinates from anchor points and distribution.\n    Args:\n        pred_dist (torch.Tensor): Predicted rotated distance, (bs, h*w, 4).\n        pred_angle (torch.Tensor): Predicted angle, (bs, h*w, 1).\n        anchor_points (torch.Tensor): Anchor points, (h*w, 2).\n    Returns:\n        (torch.Tensor): Predicted rotated bounding boxes, (bs, h*w, 4).\n    \"\"\"",
        "detail": "ultralytics.utils.tal",
        "documentation": {}
    },
    {
        "label": "TORCH_1_10",
        "kind": 5,
        "importPath": "ultralytics.utils.tal",
        "description": "ultralytics.utils.tal",
        "peekOfCode": "TORCH_1_10 = check_version(torch.__version__, \"1.10.0\")\nclass TaskAlignedAssigner(nn.Module):\n    \"\"\"\n    A task-aligned assigner for object detection.\n    This class assigns ground-truth (gt) objects to anchors based on the task-aligned metric, which combines both\n    classification and localization information.\n    Attributes:\n        topk (int): The number of top candidates to consider.\n        num_classes (int): The number of object classes.\n        alpha (float): The alpha parameter for the classification component of the task-aligned metric.",
        "detail": "ultralytics.utils.tal",
        "documentation": {}
    },
    {
        "label": "ModelEMA",
        "kind": 6,
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "peekOfCode": "class ModelEMA:\n    \"\"\"\n    Updated Exponential Moving Average (EMA) from https://github.com/rwightman/pytorch-image-models. Keeps a moving\n    average of everything in the model state_dict (parameters and buffers)\n    For EMA details see https://www.tensorflow.org/api_docs/python/tf/train/ExponentialMovingAverage\n    To disable EMA set the `enabled` attribute to `False`.\n    \"\"\"\n    def __init__(self, model, decay=0.9999, tau=2000, updates=0):\n        \"\"\"Initialize EMA for 'model' with given arguments.\"\"\"\n        self.ema = deepcopy(de_parallel(model)).eval()  # FP32 EMA",
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "EarlyStopping",
        "kind": 6,
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "peekOfCode": "class EarlyStopping:\n    \"\"\"Early stopping class that stops training when a specified number of epochs have passed without improvement.\"\"\"\n    def __init__(self, patience=50):\n        \"\"\"\n        Initialize early stopping object.\n        Args:\n            patience (int, optional): Number of epochs to wait after fitness stops improving before stopping.\n        \"\"\"\n        self.best_fitness = 0.0  # i.e. mAP\n        self.best_epoch = 0",
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "torch_distributed_zero_first",
        "kind": 2,
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "peekOfCode": "def torch_distributed_zero_first(local_rank: int):\n    \"\"\"Ensures all processes in distributed training wait for the local master (rank 0) to complete a task first.\"\"\"\n    initialized = dist.is_available() and dist.is_initialized()\n    if initialized and local_rank not in {-1, 0}:\n        dist.barrier(device_ids=[local_rank])\n    yield\n    if initialized and local_rank == 0:\n        dist.barrier(device_ids=[0])\ndef smart_inference_mode():\n    \"\"\"Applies torch.inference_mode() decorator if torch>=1.9.0 else torch.no_grad() decorator.\"\"\"",
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "smart_inference_mode",
        "kind": 2,
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "peekOfCode": "def smart_inference_mode():\n    \"\"\"Applies torch.inference_mode() decorator if torch>=1.9.0 else torch.no_grad() decorator.\"\"\"\n    def decorate(fn):\n        \"\"\"Applies appropriate torch decorator for inference mode based on torch version.\"\"\"\n        if TORCH_1_9 and torch.is_inference_mode_enabled():\n            return fn  # already in inference_mode, act as a pass-through\n        else:\n            return (torch.inference_mode if TORCH_1_9 else torch.no_grad)()(fn)\n    return decorate\ndef get_cpu_info():",
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "get_cpu_info",
        "kind": 2,
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "peekOfCode": "def get_cpu_info():\n    \"\"\"Return a string with system CPU information, i.e. 'Apple M2'.\"\"\"\n    import cpuinfo  # pip install py-cpuinfo\n    k = \"brand_raw\", \"hardware_raw\", \"arch_string_raw\"  # info keys sorted by preference (not all keys always available)\n    info = cpuinfo.get_cpu_info()  # info dict\n    string = info.get(k[0] if k[0] in info else k[1] if k[1] in info else k[2], \"unknown\")\n    return string.replace(\"(R)\", \"\").replace(\"CPU \", \"\").replace(\"@ \", \"\")\ndef select_device(device=\"\", batch=0, newline=False, verbose=True):\n    \"\"\"\n    Selects the appropriate PyTorch device based on the provided arguments.",
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "select_device",
        "kind": 2,
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "peekOfCode": "def select_device(device=\"\", batch=0, newline=False, verbose=True):\n    \"\"\"\n    Selects the appropriate PyTorch device based on the provided arguments.\n    The function takes a string specifying the device or a torch.device object and returns a torch.device object\n    representing the selected device. The function also validates the number of available devices and raises an\n    exception if the requested device(s) are not available.\n    Args:\n        device (str | torch.device, optional): Device string or torch.device object.\n            Options are 'None', 'cpu', or 'cuda', or '0' or '0,1,2,3'. Defaults to an empty string, which auto-selects\n            the first available GPU, or CPU if no GPU is available.",
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "time_sync",
        "kind": 2,
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "peekOfCode": "def time_sync():\n    \"\"\"PyTorch-accurate time.\"\"\"\n    if torch.cuda.is_available():\n        torch.cuda.synchronize()\n    return time.time()\ndef fuse_conv_and_bn(conv, bn):\n    \"\"\"Fuse Conv2d() and BatchNorm2d() layers https://tehnokv.com/posts/fusing-batchnorm-and-conv/.\"\"\"\n    fusedconv = (\n        nn.Conv2d(\n            conv.in_channels,",
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "fuse_conv_and_bn",
        "kind": 2,
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "peekOfCode": "def fuse_conv_and_bn(conv, bn):\n    \"\"\"Fuse Conv2d() and BatchNorm2d() layers https://tehnokv.com/posts/fusing-batchnorm-and-conv/.\"\"\"\n    fusedconv = (\n        nn.Conv2d(\n            conv.in_channels,\n            conv.out_channels,\n            kernel_size=conv.kernel_size,\n            stride=conv.stride,\n            padding=conv.padding,\n            dilation=conv.dilation,",
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "fuse_deconv_and_bn",
        "kind": 2,
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "peekOfCode": "def fuse_deconv_and_bn(deconv, bn):\n    \"\"\"Fuse ConvTranspose2d() and BatchNorm2d() layers.\"\"\"\n    fuseddconv = (\n        nn.ConvTranspose2d(\n            deconv.in_channels,\n            deconv.out_channels,\n            kernel_size=deconv.kernel_size,\n            stride=deconv.stride,\n            padding=deconv.padding,\n            output_padding=deconv.output_padding,",
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "model_info",
        "kind": 2,
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "peekOfCode": "def model_info(model, detailed=False, verbose=True, imgsz=640):\n    \"\"\"\n    Model information.\n    imgsz may be int or list, i.e. imgsz=640 or imgsz=[640, 320].\n    \"\"\"\n    if not verbose:\n        return\n    n_p = get_num_params(model)  # number of parameters\n    n_g = get_num_gradients(model)  # number of gradients\n    n_l = len(list(model.modules()))  # number of layers",
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "get_num_params",
        "kind": 2,
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "peekOfCode": "def get_num_params(model):\n    \"\"\"Return the total number of parameters in a YOLO model.\"\"\"\n    return sum(x.numel() for x in model.parameters())\ndef get_num_gradients(model):\n    \"\"\"Return the total number of parameters with gradients in a YOLO model.\"\"\"\n    return sum(x.numel() for x in model.parameters() if x.requires_grad)\ndef model_info_for_loggers(trainer):\n    \"\"\"\n    Return model info dict with useful model information.\n    Example:",
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "get_num_gradients",
        "kind": 2,
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "peekOfCode": "def get_num_gradients(model):\n    \"\"\"Return the total number of parameters with gradients in a YOLO model.\"\"\"\n    return sum(x.numel() for x in model.parameters() if x.requires_grad)\ndef model_info_for_loggers(trainer):\n    \"\"\"\n    Return model info dict with useful model information.\n    Example:\n        YOLOv8n info for loggers\n        ```python\n        results = {'model/parameters': 3151904,",
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "model_info_for_loggers",
        "kind": 2,
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "peekOfCode": "def model_info_for_loggers(trainer):\n    \"\"\"\n    Return model info dict with useful model information.\n    Example:\n        YOLOv8n info for loggers\n        ```python\n        results = {'model/parameters': 3151904,\n                   'model/GFLOPs': 8.746,\n                   'model/speed_ONNX(ms)': 41.244,\n                   'model/speed_TensorRT(ms)': 3.211,",
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "get_flops",
        "kind": 2,
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "peekOfCode": "def get_flops(model, imgsz=640):\n    \"\"\"Return a YOLO model's FLOPs.\"\"\"\n    if not thop:\n        return 0.0  # if not installed return 0.0 GFLOPs\n    try:\n        model = de_parallel(model)\n        p = next(model.parameters())\n        if not isinstance(imgsz, list):\n            imgsz = [imgsz, imgsz]  # expand if int/float\n        try:",
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "get_flops_with_torch_profiler",
        "kind": 2,
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "peekOfCode": "def get_flops_with_torch_profiler(model, imgsz=640):\n    \"\"\"Compute model FLOPs (thop package alternative, but 2-10x slower unfortunately).\"\"\"\n    if not TORCH_2_0:  # torch profiler implemented in torch>=2.0\n        return 0.0\n    model = de_parallel(model)\n    p = next(model.parameters())\n    if not isinstance(imgsz, list):\n        imgsz = [imgsz, imgsz]  # expand if int/float\n    try:\n        # Use stride size for input tensor",
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "initialize_weights",
        "kind": 2,
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "peekOfCode": "def initialize_weights(model):\n    \"\"\"Initialize model weights to random values.\"\"\"\n    for m in model.modules():\n        t = type(m)\n        if t is nn.Conv2d:\n            pass  # nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n        elif t is nn.BatchNorm2d:\n            m.eps = 1e-3\n            m.momentum = 0.03\n        elif t in {nn.Hardswish, nn.LeakyReLU, nn.ReLU, nn.ReLU6, nn.SiLU}:",
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "scale_img",
        "kind": 2,
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "peekOfCode": "def scale_img(img, ratio=1.0, same_shape=False, gs=32):\n    \"\"\"Scales and pads an image tensor of shape img(bs,3,y,x) based on given ratio and grid size gs, optionally\n    retaining the original shape.\n    \"\"\"\n    if ratio == 1.0:\n        return img\n    h, w = img.shape[2:]\n    s = (int(h * ratio), int(w * ratio))  # new size\n    img = F.interpolate(img, size=s, mode=\"bilinear\", align_corners=False)  # resize\n    if not same_shape:  # pad/crop img",
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "make_divisible",
        "kind": 2,
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "peekOfCode": "def make_divisible(x, divisor):\n    \"\"\"Returns nearest x divisible by divisor.\"\"\"\n    if isinstance(divisor, torch.Tensor):\n        divisor = int(divisor.max())  # to int\n    return math.ceil(x / divisor) * divisor\ndef copy_attr(a, b, include=(), exclude=()):\n    \"\"\"Copies attributes from object 'b' to object 'a', with options to include/exclude certain attributes.\"\"\"\n    for k, v in b.__dict__.items():\n        if (len(include) and k not in include) or k.startswith(\"_\") or k in exclude:\n            continue",
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "copy_attr",
        "kind": 2,
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "peekOfCode": "def copy_attr(a, b, include=(), exclude=()):\n    \"\"\"Copies attributes from object 'b' to object 'a', with options to include/exclude certain attributes.\"\"\"\n    for k, v in b.__dict__.items():\n        if (len(include) and k not in include) or k.startswith(\"_\") or k in exclude:\n            continue\n        else:\n            setattr(a, k, v)\ndef get_latest_opset():\n    \"\"\"Return the second-most recent ONNX opset version supported by this version of PyTorch, adjusted for maturity.\"\"\"\n    if TORCH_1_13:",
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "get_latest_opset",
        "kind": 2,
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "peekOfCode": "def get_latest_opset():\n    \"\"\"Return the second-most recent ONNX opset version supported by this version of PyTorch, adjusted for maturity.\"\"\"\n    if TORCH_1_13:\n        # If the PyTorch>=1.13, dynamically compute the latest opset minus one using 'symbolic_opset'\n        return max(int(k[14:]) for k in vars(torch.onnx) if \"symbolic_opset\" in k) - 1\n    # Otherwise for PyTorch<=1.12 return the corresponding predefined opset\n    version = torch.onnx.producer_version.rsplit(\".\", 1)[0]  # i.e. '2.3'\n    return {\"1.12\": 15, \"1.11\": 14, \"1.10\": 13, \"1.9\": 12, \"1.8\": 12}.get(version, 12)\ndef intersect_dicts(da, db, exclude=()):\n    \"\"\"Returns a dictionary of intersecting keys with matching shapes, excluding 'exclude' keys, using da values.\"\"\"",
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "intersect_dicts",
        "kind": 2,
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "peekOfCode": "def intersect_dicts(da, db, exclude=()):\n    \"\"\"Returns a dictionary of intersecting keys with matching shapes, excluding 'exclude' keys, using da values.\"\"\"\n    return {k: v for k, v in da.items() if k in db and all(x not in k for x in exclude) and v.shape == db[k].shape}\ndef is_parallel(model):\n    \"\"\"Returns True if model is of type DP or DDP.\"\"\"\n    return isinstance(model, (nn.parallel.DataParallel, nn.parallel.DistributedDataParallel))\ndef de_parallel(model):\n    \"\"\"De-parallelize a model: returns single-GPU model if model is of type DP or DDP.\"\"\"\n    return model.module if is_parallel(model) else model\ndef one_cycle(y1=0.0, y2=1.0, steps=100):",
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "is_parallel",
        "kind": 2,
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "peekOfCode": "def is_parallel(model):\n    \"\"\"Returns True if model is of type DP or DDP.\"\"\"\n    return isinstance(model, (nn.parallel.DataParallel, nn.parallel.DistributedDataParallel))\ndef de_parallel(model):\n    \"\"\"De-parallelize a model: returns single-GPU model if model is of type DP or DDP.\"\"\"\n    return model.module if is_parallel(model) else model\ndef one_cycle(y1=0.0, y2=1.0, steps=100):\n    \"\"\"Returns a lambda function for sinusoidal ramp from y1 to y2 https://arxiv.org/pdf/1812.01187.pdf.\"\"\"\n    return lambda x: max((1 - math.cos(x * math.pi / steps)) / 2, 0) * (y2 - y1) + y1\ndef init_seeds(seed=0, deterministic=False):",
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "de_parallel",
        "kind": 2,
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "peekOfCode": "def de_parallel(model):\n    \"\"\"De-parallelize a model: returns single-GPU model if model is of type DP or DDP.\"\"\"\n    return model.module if is_parallel(model) else model\ndef one_cycle(y1=0.0, y2=1.0, steps=100):\n    \"\"\"Returns a lambda function for sinusoidal ramp from y1 to y2 https://arxiv.org/pdf/1812.01187.pdf.\"\"\"\n    return lambda x: max((1 - math.cos(x * math.pi / steps)) / 2, 0) * (y2 - y1) + y1\ndef init_seeds(seed=0, deterministic=False):\n    \"\"\"Initialize random number generator (RNG) seeds https://pytorch.org/docs/stable/notes/randomness.html.\"\"\"\n    random.seed(seed)\n    np.random.seed(seed)",
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "one_cycle",
        "kind": 2,
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "peekOfCode": "def one_cycle(y1=0.0, y2=1.0, steps=100):\n    \"\"\"Returns a lambda function for sinusoidal ramp from y1 to y2 https://arxiv.org/pdf/1812.01187.pdf.\"\"\"\n    return lambda x: max((1 - math.cos(x * math.pi / steps)) / 2, 0) * (y2 - y1) + y1\ndef init_seeds(seed=0, deterministic=False):\n    \"\"\"Initialize random number generator (RNG) seeds https://pytorch.org/docs/stable/notes/randomness.html.\"\"\"\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)  # for Multi-GPU, exception safe",
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "init_seeds",
        "kind": 2,
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "peekOfCode": "def init_seeds(seed=0, deterministic=False):\n    \"\"\"Initialize random number generator (RNG) seeds https://pytorch.org/docs/stable/notes/randomness.html.\"\"\"\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)  # for Multi-GPU, exception safe\n    # torch.backends.cudnn.benchmark = True  # AutoBatch problem https://github.com/ultralytics/yolov5/issues/9287\n    if deterministic:\n        if TORCH_2_0:",
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "strip_optimizer",
        "kind": 2,
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "peekOfCode": "def strip_optimizer(f: Union[str, Path] = \"best.pt\", s: str = \"\") -> None:\n    \"\"\"\n    Strip optimizer from 'f' to finalize training, optionally save as 's'.\n    Args:\n        f (str): file path to model to strip the optimizer from. Default is 'best.pt'.\n        s (str): file path to save the model with stripped optimizer to. If not provided, 'f' will be overwritten.\n    Returns:\n        None\n    Example:\n        ```python",
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "convert_optimizer_state_dict_to_fp16",
        "kind": 2,
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "peekOfCode": "def convert_optimizer_state_dict_to_fp16(state_dict):\n    \"\"\"\n    Converts the state_dict of a given optimizer to FP16, focusing on the 'state' key for tensor conversions.\n    This method aims to reduce storage size without altering 'param_groups' as they contain non-tensor data.\n    \"\"\"\n    for state in state_dict[\"state\"].values():\n        for k, v in state.items():\n            if k != \"step\" and isinstance(v, torch.Tensor) and v.dtype is torch.float32:\n                state[k] = v.half()\n    return state_dict",
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "profile",
        "kind": 2,
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "peekOfCode": "def profile(input, ops, n=10, device=None):\n    \"\"\"\n    Ultralytics speed, memory and FLOPs profiler.\n    Example:\n        ```python\n        from ultralytics.utils.torch_utils import profile\n        input = torch.randn(16, 3, 640, 640)\n        m1 = lambda x: x * torch.sigmoid(x)\n        m2 = nn.SiLU()\n        profile(input, [m1, m2], n=100)  # profile over 100 iterations",
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "TORCH_1_9",
        "kind": 5,
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "peekOfCode": "TORCH_1_9 = check_version(torch.__version__, \"1.9.0\")\nTORCH_1_13 = check_version(torch.__version__, \"1.13.0\")\nTORCH_2_0 = check_version(torch.__version__, \"2.0.0\")\nTORCHVISION_0_10 = check_version(TORCHVISION_VERSION, \"0.10.0\")\nTORCHVISION_0_11 = check_version(TORCHVISION_VERSION, \"0.11.0\")\nTORCHVISION_0_13 = check_version(TORCHVISION_VERSION, \"0.13.0\")\nTORCHVISION_0_18 = check_version(TORCHVISION_VERSION, \"0.18.0\")\n@contextmanager\ndef torch_distributed_zero_first(local_rank: int):\n    \"\"\"Ensures all processes in distributed training wait for the local master (rank 0) to complete a task first.\"\"\"",
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "TORCH_1_13",
        "kind": 5,
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "peekOfCode": "TORCH_1_13 = check_version(torch.__version__, \"1.13.0\")\nTORCH_2_0 = check_version(torch.__version__, \"2.0.0\")\nTORCHVISION_0_10 = check_version(TORCHVISION_VERSION, \"0.10.0\")\nTORCHVISION_0_11 = check_version(TORCHVISION_VERSION, \"0.11.0\")\nTORCHVISION_0_13 = check_version(TORCHVISION_VERSION, \"0.13.0\")\nTORCHVISION_0_18 = check_version(TORCHVISION_VERSION, \"0.18.0\")\n@contextmanager\ndef torch_distributed_zero_first(local_rank: int):\n    \"\"\"Ensures all processes in distributed training wait for the local master (rank 0) to complete a task first.\"\"\"\n    initialized = dist.is_available() and dist.is_initialized()",
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "TORCH_2_0",
        "kind": 5,
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "peekOfCode": "TORCH_2_0 = check_version(torch.__version__, \"2.0.0\")\nTORCHVISION_0_10 = check_version(TORCHVISION_VERSION, \"0.10.0\")\nTORCHVISION_0_11 = check_version(TORCHVISION_VERSION, \"0.11.0\")\nTORCHVISION_0_13 = check_version(TORCHVISION_VERSION, \"0.13.0\")\nTORCHVISION_0_18 = check_version(TORCHVISION_VERSION, \"0.18.0\")\n@contextmanager\ndef torch_distributed_zero_first(local_rank: int):\n    \"\"\"Ensures all processes in distributed training wait for the local master (rank 0) to complete a task first.\"\"\"\n    initialized = dist.is_available() and dist.is_initialized()\n    if initialized and local_rank not in {-1, 0}:",
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "TORCHVISION_0_10",
        "kind": 5,
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "peekOfCode": "TORCHVISION_0_10 = check_version(TORCHVISION_VERSION, \"0.10.0\")\nTORCHVISION_0_11 = check_version(TORCHVISION_VERSION, \"0.11.0\")\nTORCHVISION_0_13 = check_version(TORCHVISION_VERSION, \"0.13.0\")\nTORCHVISION_0_18 = check_version(TORCHVISION_VERSION, \"0.18.0\")\n@contextmanager\ndef torch_distributed_zero_first(local_rank: int):\n    \"\"\"Ensures all processes in distributed training wait for the local master (rank 0) to complete a task first.\"\"\"\n    initialized = dist.is_available() and dist.is_initialized()\n    if initialized and local_rank not in {-1, 0}:\n        dist.barrier(device_ids=[local_rank])",
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "TORCHVISION_0_11",
        "kind": 5,
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "peekOfCode": "TORCHVISION_0_11 = check_version(TORCHVISION_VERSION, \"0.11.0\")\nTORCHVISION_0_13 = check_version(TORCHVISION_VERSION, \"0.13.0\")\nTORCHVISION_0_18 = check_version(TORCHVISION_VERSION, \"0.18.0\")\n@contextmanager\ndef torch_distributed_zero_first(local_rank: int):\n    \"\"\"Ensures all processes in distributed training wait for the local master (rank 0) to complete a task first.\"\"\"\n    initialized = dist.is_available() and dist.is_initialized()\n    if initialized and local_rank not in {-1, 0}:\n        dist.barrier(device_ids=[local_rank])\n    yield",
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "TORCHVISION_0_13",
        "kind": 5,
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "peekOfCode": "TORCHVISION_0_13 = check_version(TORCHVISION_VERSION, \"0.13.0\")\nTORCHVISION_0_18 = check_version(TORCHVISION_VERSION, \"0.18.0\")\n@contextmanager\ndef torch_distributed_zero_first(local_rank: int):\n    \"\"\"Ensures all processes in distributed training wait for the local master (rank 0) to complete a task first.\"\"\"\n    initialized = dist.is_available() and dist.is_initialized()\n    if initialized and local_rank not in {-1, 0}:\n        dist.barrier(device_ids=[local_rank])\n    yield\n    if initialized and local_rank == 0:",
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "TORCHVISION_0_18",
        "kind": 5,
        "importPath": "ultralytics.utils.torch_utils",
        "description": "ultralytics.utils.torch_utils",
        "peekOfCode": "TORCHVISION_0_18 = check_version(TORCHVISION_VERSION, \"0.18.0\")\n@contextmanager\ndef torch_distributed_zero_first(local_rank: int):\n    \"\"\"Ensures all processes in distributed training wait for the local master (rank 0) to complete a task first.\"\"\"\n    initialized = dist.is_available() and dist.is_initialized()\n    if initialized and local_rank not in {-1, 0}:\n        dist.barrier(device_ids=[local_rank])\n    yield\n    if initialized and local_rank == 0:\n        dist.barrier(device_ids=[0])",
        "detail": "ultralytics.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "TritonRemoteModel",
        "kind": 6,
        "importPath": "ultralytics.utils.triton",
        "description": "ultralytics.utils.triton",
        "peekOfCode": "class TritonRemoteModel:\n    \"\"\"\n    Client for interacting with a remote Triton Inference Server model.\n    Attributes:\n        endpoint (str): The name of the model on the Triton server.\n        url (str): The URL of the Triton server.\n        triton_client: The Triton client (either HTTP or gRPC).\n        InferInput: The input class for the Triton client.\n        InferRequestedOutput: The output request class for the Triton client.\n        input_formats (List[str]): The data types of the model inputs.",
        "detail": "ultralytics.utils.triton",
        "documentation": {}
    },
    {
        "label": "run_ray_tune",
        "kind": 2,
        "importPath": "ultralytics.utils.tuner",
        "description": "ultralytics.utils.tuner",
        "peekOfCode": "def run_ray_tune(\n    model, space: dict = None, grace_period: int = 10, gpu_per_trial: int = None, max_samples: int = 10, **train_args\n):\n    \"\"\"\n    Runs hyperparameter tuning using Ray Tune.\n    Args:\n        model (YOLO): Model to run the tuner on.\n        space (dict, optional): The hyperparameter search space. Defaults to None.\n        grace_period (int, optional): The grace period in epochs of the ASHA scheduler. Defaults to 10.\n        gpu_per_trial (int, optional): The number of GPUs to allocate per trial. Defaults to None.",
        "detail": "ultralytics.utils.tuner",
        "documentation": {}
    }
]